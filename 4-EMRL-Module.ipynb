{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dcdda58-1ee5-4203-8bd8-0a98875d5915",
   "metadata": {},
   "source": [
    "# Simulate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "747e8363-fee4-4d5f-9fe5-e546881c17f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 3)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 5)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 5)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from fieldnn.utils.layerfn import traverse\n",
    "from fieldnn.utils.simulate import get_next_info, get_simulated_tensor_from_fldname\n",
    "\n",
    "B_lenP = 3\n",
    "B2P_lnEC = [6, 5, 2] # \n",
    "prefix_layers_num = 2\n",
    "vocab_size = 100 \n",
    "Ignore_PSN_Layers = ['B', 'St']\n",
    "\n",
    "###############\n",
    "FLD_LIST = [\n",
    "'B-St-Tk:SlfGrn',\n",
    "'B-St-Tk:POSGrn',\n",
    "'B-St-Tk:AnnoGrn',\n",
    "'B-St-Tk:SubWord-CharGrn',\n",
    "'B-St-Tk:SubWord-SyllableGrn',\n",
    "'B-St-Tk:SubWord-PhonemeGrn',\n",
    "]\n",
    "\n",
    "\n",
    "### TODO:\n",
    "FLD_END = 'B-St'\n",
    "FLD_END = 'B-St-Tk'\n",
    "\n",
    "# FLD_LIST = [\n",
    "# 'B-P-EC:Diag-DiagRec:DiagV-DiagVdftGrn',\n",
    "# 'B-P-EC:Diag-DiagRec:DiagDT-DiagDTdftGrn',\n",
    "# 'B-P-EC:Med-MedRec:MedV-MedVdftGrn',\n",
    "# 'B-P-EC:Med-MedRec:MedDT-MedDTdftGrn',\n",
    "# 'B-P-EC:A1C-A1CRec:A1CV-A1CVdftGrn',\n",
    "# 'B-P-EC:A1C-A1CRec:A1CDT-A1CDTdftGrn',\n",
    "# 'B-P-EC:PN-PNRec:SctName-SNdftGrn',\n",
    "# 'B-P-EC:PN-PNRec:SctText-SctSent-Tk:SelfGrn',\n",
    "# 'B-P-EC:PN-PNRec:SctText-SctSent-Tk:POSGrn',\n",
    "# 'B-P-EC:PN-PNRec:SctText-SctSent-Tk:SubWord-CharGrn',\n",
    "# ]\n",
    "\n",
    "# FLD_END = 'B-P'\n",
    "# FLD_END = 'B-P-EC'\n",
    "\n",
    "\n",
    "###############\n",
    "NAME_2_FULLNAME = {i.split('-')[-1]:i for i in FLD_LIST}\n",
    "\n",
    "###############\n",
    "FLD_2_VOCABSIZE = {k: np.random.randint(5000) for k in FLD_LIST}\n",
    "\n",
    "#####################\n",
    "FLD_2_DATA = {}\n",
    "\n",
    "for fullname in FLD_LIST:\n",
    "    vocab_size = FLD_2_VOCABSIZE[fullname]\n",
    "    info_idx = get_simulated_tensor_from_fldname(fullname, B_lenP, B2P_lnEC, prefix_layers_num, vocab_size)\n",
    "    # print(info_idx.shape)\n",
    "    holder = torch.LongTensor(info_idx)\n",
    "    # info_idx = torch.LongTensor(info_idx)\n",
    "    FLD_2_DATA[fullname] = {'holder': holder, 'info': 'Empty'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb405fff-ce4a-4810-8c4c-8c6f9fe27fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "B-St-Tk:SlfGrn\n",
      "torch.Size([3, 6])\n",
      "\n",
      "B-St-Tk:POSGrn\n",
      "torch.Size([3, 6])\n",
      "\n",
      "B-St-Tk:AnnoGrn\n",
      "torch.Size([3, 6])\n",
      "\n",
      "B-St-Tk:SubWord-CharGrn\n",
      "torch.Size([3, 6, 3])\n",
      "\n",
      "B-St-Tk:SubWord-SyllableGrn\n",
      "torch.Size([3, 6, 5])\n",
      "\n",
      "B-St-Tk:SubWord-PhonemeGrn\n",
      "torch.Size([3, 6, 5])\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "for fullname, data in FLD_2_DATA.items():\n",
    "    print(f'\\n{fullname}')\n",
    "    holder = data['holder']\n",
    "    print(holder.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b83ef92e-e0f8-4188-9e8b-a56037105ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2186, 2999, 1115, 3456,  739,  323],\n",
       "        [1796, 2415, 2022, 1411, 2961,    0],\n",
       "        [1649,  597,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# st: sentence\n",
    "# Tk:SlfGrn: Token's as itself. Token. \n",
    "data = FLD_2_DATA['B-St-Tk:SlfGrn']\n",
    "data['holder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "596dfc7c-e9b8-434c-9646-7a7453941451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['holder'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33ff330-5c56-4872-96b9-8103c9e5066d",
   "metadata": {},
   "source": [
    "# Data Flow Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbd2ee14-3ca0-4345-99bb-be6c28a6165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_dataflow_info(fld_list):\n",
    "    df = pd.DataFrame([i.split('-') for i in fld_list])\n",
    "    L = []\n",
    "    for idx, row in df.iterrows():\n",
    "        for layer_idx in range(1, len(row) - 1):\n",
    "\n",
    "            # f'{layer_idx}-{(layer_idx + 1)}' + ':' +\n",
    "            a, b = layer_idx, layer_idx + 1\n",
    "            if row[b] == None: continue\n",
    "            if row[a] == None: continue\n",
    "            layer_nn_name =  f'{a}-{b}@{row[a]}-{row[b]}'\n",
    "            if layer_nn_name not in L:\n",
    "                L.append(layer_nn_name)\n",
    "    # print(L)\n",
    "    layers = [i.split('@')[0] for i in L]\n",
    "    L = [i.split('@')[-1] for i in L]\n",
    "    # print(layers)\n",
    "    info = pd.DataFrame({'layers': layers, 'nn': L}).sort_values('nn').reset_index(drop = True)\n",
    "    return info\n",
    "\n",
    "\n",
    "def get_merge_layernn(x):\n",
    "    D = {}\n",
    "    layer_name = x[0].split(':')[0]\n",
    "    for i in x:\n",
    "        i = i.split(':')[-1]\n",
    "        a, b = i.split('-')\n",
    "        if a not in D:\n",
    "            D[a] = [b]\n",
    "        else:\n",
    "            D[a].append(b)\n",
    "    \n",
    "    L = []\n",
    "    for parent, childrens in D.items():\n",
    "        if len(childrens) >= 2:\n",
    "            L.append(layer_name + ':' + parent + '-' + '&'.join(childrens))\n",
    "    return L\n",
    "\n",
    "\n",
    "def get_single_layernn(x):\n",
    "    D = {}\n",
    "    layer_name = x[0].split(':')[0]\n",
    "    for i in x:\n",
    "        i = i.split(':')[-1]\n",
    "        a, b = i.split('-')\n",
    "        if a not in D:\n",
    "            D[a] = [b]\n",
    "        else:\n",
    "            D[a].append(b)\n",
    "    \n",
    "    L = []\n",
    "    for parent, childrens in D.items():\n",
    "        if len(childrens) == 1:\n",
    "            L.append(layer_name + ':' + parent + '-' + '&'.join(childrens))\n",
    "    return L\n",
    "    \n",
    "    \n",
    "def generate_df_struct(fld_list, mergefirst_fld_list):\n",
    "    info = get_dataflow_info(fld_list)\n",
    "    df_struct = info.groupby('layers').apply(lambda x: x['nn'].to_list()).reset_index()\n",
    "    df_struct.columns = ['layers', 'nn']\n",
    "    # df_struct['grn'] = df_struct['nn'].apply(lambda x: [i for i in x if 'Grn' in i])\n",
    "    # df_struct['fld'] = df_struct['nn'].apply(lambda x: [i for i in x if 'Grn' not in i])\n",
    "    # df_struct\n",
    "\n",
    "    df_struct['single'] = df_struct['nn'].apply(lambda x: get_single_layernn(x))\n",
    "    df_struct['merge'] = df_struct['nn'].apply(lambda x: get_merge_layernn(x))\n",
    "\n",
    "    df_struct['mergefirst'] = df_struct['merge'].apply(lambda x: [i for i in x if i.split('-')[-1] in mergefirst_fld_list])\n",
    "    df_struct['mergelast'] = df_struct['merge'].apply(lambda x: [i for i in x if i.split('-')[-1] not in mergefirst_fld_list])\n",
    "    # df_struct = df_struct.drop(columns = ['merge'])\n",
    "    return df_struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26ced28f-dba9-46a6-a65f-8adb70daf8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merge_layernn(x):\n",
    "    D = {}\n",
    "    for i in x:\n",
    "        # i = i.split(':')[-1]\n",
    "        a, b = i.split('-')\n",
    "        if a not in D:\n",
    "            D[a] = [b]\n",
    "        else:\n",
    "            D[a].append(b)\n",
    "    \n",
    "    L = []\n",
    "    for parent, childrens in D.items():\n",
    "        L.append(f'{\"^\".join(childrens)}==>{parent}')\n",
    "\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66ed71b9-54ed-4c64-a2da-7fdaff8c4612",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_structures_from_fldlist(fld_list):\n",
    "    info = get_dataflow_info(fld_list)# .groupby('layers')\n",
    "    df_struct = info.groupby('layers').apply(lambda x: x['nn'].to_list()).reset_index()\n",
    "    df_struct.columns = ['layers', 'nn']\n",
    "    # # df_struct\n",
    "    # info\n",
    "    df_struct['struct_name'] = df_struct['nn'].apply(lambda x: get_merge_layernn(x))\n",
    "    # for nn_list in df_struct['nn'].values:\n",
    "    #     # print(nn_list)\n",
    "    #     for nn_name in nn_list:\n",
    "    #         print(nn_name)\n",
    "    #         # print(nn_name.split('-'))\n",
    "    #     # print()\n",
    "    #     x = nn_list\n",
    "    #     L = get_merge_layernn(x)\n",
    "    #     print(L)\n",
    "    return df_struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb4cfd50-13f8-4a4f-8af3-c1eb6b959e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layers</th>\n",
       "      <th>nn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-2</td>\n",
       "      <td>St-Tk:AnnoGrn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-2</td>\n",
       "      <td>St-Tk:POSGrn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-2</td>\n",
       "      <td>St-Tk:SlfGrn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-2</td>\n",
       "      <td>St-Tk:SubWord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2-3</td>\n",
       "      <td>Tk:SubWord-CharGrn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2-3</td>\n",
       "      <td>Tk:SubWord-PhonemeGrn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2-3</td>\n",
       "      <td>Tk:SubWord-SyllableGrn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  layers                      nn\n",
       "0    1-2           St-Tk:AnnoGrn\n",
       "1    1-2            St-Tk:POSGrn\n",
       "2    1-2            St-Tk:SlfGrn\n",
       "3    1-2           St-Tk:SubWord\n",
       "4    2-3      Tk:SubWord-CharGrn\n",
       "5    2-3   Tk:SubWord-PhonemeGrn\n",
       "6    2-3  Tk:SubWord-SyllableGrn"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = get_dataflow_info(FLD_LIST)\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89aca461-109c-44d0-98e5-c9d673c703b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layers</th>\n",
       "      <th>nn</th>\n",
       "      <th>struct_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-2</td>\n",
       "      <td>[St-Tk:AnnoGrn, St-Tk:POSGrn, St-Tk:SlfGrn, St...</td>\n",
       "      <td>[Tk:AnnoGrn^Tk:POSGrn^Tk:SlfGrn^Tk:SubWord==&gt;St]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-3</td>\n",
       "      <td>[Tk:SubWord-CharGrn, Tk:SubWord-PhonemeGrn, Tk...</td>\n",
       "      <td>[CharGrn^PhonemeGrn^SyllableGrn==&gt;Tk:SubWord]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  layers                                                 nn  \\\n",
       "0    1-2  [St-Tk:AnnoGrn, St-Tk:POSGrn, St-Tk:SlfGrn, St...   \n",
       "1    2-3  [Tk:SubWord-CharGrn, Tk:SubWord-PhonemeGrn, Tk...   \n",
       "\n",
       "                                        struct_name  \n",
       "0  [Tk:AnnoGrn^Tk:POSGrn^Tk:SlfGrn^Tk:SubWord==>St]  \n",
       "1     [CharGrn^PhonemeGrn^SyllableGrn==>Tk:SubWord]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_struct = get_structures_from_fldlist(FLD_LIST)\n",
    "df_struct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d6bfba-6c89-4a8c-9a1c-00d8fdeeeedf",
   "metadata": {},
   "source": [
    "# Struct Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7e9efc5-1aa8-4c6c-a5d4-c7b6e261ca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_struct_info(struct_name, NAME_2_FULLNAME):\n",
    "    inputs = struct_name.split('==>')[0].split('^')\n",
    "    output = struct_name.split('==>')[1]\n",
    "    fullname_inputs = [NAME_2_FULLNAME[i] for i in inputs]\n",
    "    fullname_output = '-'.join(fullname_inputs[0].split('-')[:-2]) + '-' + output\n",
    "    \n",
    "    NAME_2_FULLNAME[output] = fullname_output\n",
    "\n",
    "    if len(inputs) == 1:\n",
    "        struct_model = 'RL'\n",
    "    elif len(inputs) > 1:\n",
    "        tmp = list(set([len(i.split(':')) for i in inputs]))\n",
    "        assert len(tmp) == 1\n",
    "        struct_model = 'MLRLRL' if tmp[0] == 2 else 'RLMLRL'\n",
    "        \n",
    "        \n",
    "        # TODO HERE\n",
    "        # 'MLRL'\n",
    "    return fullname_inputs, fullname_output, struct_model, NAME_2_FULLNAME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef802fab-8db9-44b0-9361-5ed74f0a60a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_structure(fullname_inputs, struct_model):\n",
    "    # each input\n",
    "    D_model = {}\n",
    "    D_data = {}\n",
    "    \n",
    "    # things before M\n",
    "    stages = struct_model.split('M')\n",
    "    preM = stages[0]\n",
    "    for fullname in fullname_inputs:\n",
    "        input_field = fullname\n",
    "        L = []\n",
    "        # print('\\n=== EL ===')\n",
    "        if 'Grn' in fullname:\n",
    "            inp = fullname\n",
    "            out = fullname.replace('Grn', '')\n",
    "            name = f'EL**{inp}=>{out}'\n",
    "            L.append(name)\n",
    "            fullname = out\n",
    "        \n",
    "        if 'R' in preM:\n",
    "            # print('\\n=== RL ===')\n",
    "            inp = fullname\n",
    "            out = '-'.join(fullname.split('-')[:-1]) + ':' + fullname.split('-')[-1]\n",
    "            fullname = out\n",
    "            name = f'RL**{inp}=>{out}'\n",
    "            L.append(name)\n",
    "        \n",
    "        D_model[input_field] = L\n",
    "        D_data[input_field] = fullname\n",
    "\n",
    "    if 'M' not in struct_model:\n",
    "        return D_model, D_data\n",
    "    \n",
    "    else:\n",
    "        # print('\\n=== ML ===')\n",
    "        L = [v for k, v in D_data.items()]\n",
    "        parents = ['-'.join(i.split('-')[:-1]) for i in L]\n",
    "        # print(parents)\n",
    "        assert len(set(parents)) == 1\n",
    "        parent = parents[0]\n",
    "\n",
    "        name_new_list = [i.split('-')[-1] for i in L]\n",
    "        prefixes = [':'.join(i.split(':')[:-1]) for i in name_new_list]\n",
    "        assert len(set(prefixes)) == 1\n",
    "        prefix = prefixes[0]\n",
    "\n",
    "        fields = [i.split(':')[-1] for i in name_new_list]\n",
    "        new_layer = '&'.join(fields)\n",
    "        new_name = '-'.join([prefix, new_layer])\n",
    "        fullname = parent + '-' + new_name\n",
    "\n",
    "        Model_list = []\n",
    "        inp = '^'.join(L)\n",
    "        out = fullname\n",
    "        name = f'ML**{inp}=>{out}'\n",
    "        Model_list.append(name)\n",
    "    \n",
    "    # post M\n",
    "    if len(stages) == 1:\n",
    "        # no post M\n",
    "        D_model['^'.join(L)] = Model_list\n",
    "        D_data['^'.join(L)] = fullname\n",
    "        return D_model, D_data\n",
    "    else:\n",
    "        postM = stages[-1]\n",
    "        for i in range(postM.count('R')):\n",
    "            # print('\\n=== RL ===')\n",
    "            inp = fullname\n",
    "            out = '-'.join(inp.split('-')[:-1]) + ':' + inp.split('-')[-1]\n",
    "            # print(out)\n",
    "            name = f'RL**{inp}=>{out}'\n",
    "            Model_list.append(name)\n",
    "            fullname = out\n",
    "\n",
    "        D_model['^'.join(L)] = Model_list\n",
    "        D_data['^'.join(L)] = fullname\n",
    "        # final_fullname = ':'.join(fullname.split(':')[:-1])\n",
    "        return D_model, D_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba860aeb-c837-4268-83e0-0d08c555b0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2-3': ['CharGrn^PhonemeGrn^SyllableGrn==>Tk:SubWord'],\n",
       " '1-2': ['Tk:AnnoGrn^Tk:POSGrn^Tk:SlfGrn^Tk:SubWord==>St']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_struct = get_structures_from_fldlist(FLD_LIST)\n",
    "\n",
    "tmp = df_struct.sort_values('layers', ascending = False)\n",
    "layer2modulelist = dict(zip(tmp['layers'].to_list(), tmp['struct_name'].to_list()))\n",
    "layer2modulelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4e36fda-26e4-4146-94e4-dffa7dbffaac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2-3': ['CharGrn^PhonemeGrn^SyllableGrn==>Tk:SubWord'],\n",
       " '1-2': ['Tk:AnnoGrn^Tk:POSGrn^Tk:SlfGrn^Tk:SubWord==>St']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# name2fullname = {i.split('-')[-1]:i for i in fld_list}\n",
    "df_struct = get_structures_from_fldlist(FLD_LIST)\n",
    "# df_struct# .sort_values('layers', ascending = False)['struct_name'].to_list()\n",
    "\n",
    "tmp = df_struct.sort_values('layers', ascending = False)\n",
    "layer2modulelist = dict(zip(tmp['layers'].to_list(), tmp['struct_name'].to_list()))\n",
    "layer2modulelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d2bc1d3-5a4f-4a61-a6fa-91c52ebea778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-St-Tk:SlfGrn\n",
      "{'B-St-Tk:SlfGrn': ('Embedding',\n",
      "                    {'embedding_size': 512,\n",
      "                     'init': 'random',\n",
      "                     'input_size': 3478}),\n",
      " 'Ignore_PSN_Layers': ['B', 'St'],\n",
      " 'input_size': None,\n",
      " 'output_size': 512,\n",
      " 'postprocess': {'activator': 'gelu',\n",
      "                 'dropout': {'inplace': False, 'p': 0.5},\n",
      "                 'layernorm': {'elementwise_affine': True, 'eps': 1e-05}}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from fieldnn.utils.parafn import get_expander_para\n",
    "\n",
    "fullname = FLD_LIST[0]\n",
    "print(fullname)\n",
    "\n",
    "embed_size = 512\n",
    "\n",
    "expander_process = {# 'activator': 'gelu',\n",
    "           'dropout': {'p': 0.5, 'inplace': False},\n",
    "           'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "\n",
    "\n",
    "process = {'activator': 'gelu',\n",
    "           'dropout': {'p': 0.5, 'inplace': False},\n",
    "           'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "\n",
    "nn_name = 'Embedding'\n",
    "vocab_size = FLD_2_VOCABSIZE[fullname]\n",
    "nn_para = {'input_size': vocab_size}\n",
    "postprocess = process\n",
    "Ignore_PSN_Layers = fullname.split('-')[:2]\n",
    "expander_layer_para = get_expander_para(fullname, nn_name, nn_para, embed_size, \n",
    "                                        Ignore_PSN_Layers, \n",
    "                                        postprocess\n",
    "                                       )\n",
    "pprint(expander_layer_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e67e5777-7ac1-4d74-b3cc-11e545bbe521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-3 CharGrn^PhonemeGrn^SyllableGrn==>Tk:SubWord\n",
      "----> (input) B-St-Tk:SubWord-CharGrn\n",
      "   ----> (pipeline name) EL**B-St-Tk:SubWord-CharGrn=>B-St-Tk:SubWord-Char\n",
      "   ----> (pipeline name) RL**B-St-Tk:SubWord-Char=>B-St-Tk:SubWord:Char\n",
      "----> (input) B-St-Tk:SubWord-PhonemeGrn\n",
      "   ----> (pipeline name) EL**B-St-Tk:SubWord-PhonemeGrn=>B-St-Tk:SubWord-Phoneme\n",
      "   ----> (pipeline name) RL**B-St-Tk:SubWord-Phoneme=>B-St-Tk:SubWord:Phoneme\n",
      "----> (input) B-St-Tk:SubWord-SyllableGrn\n",
      "   ----> (pipeline name) EL**B-St-Tk:SubWord-SyllableGrn=>B-St-Tk:SubWord-Syllable\n",
      "   ----> (pipeline name) RL**B-St-Tk:SubWord-Syllable=>B-St-Tk:SubWord:Syllable\n",
      "----> (input) B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable\n",
      "   ----> (pipeline name) ML**B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable=>B-St-Tk:SubWord-Char&Phoneme&Syllable\n",
      "   ----> (pipeline name) RL**B-St-Tk:SubWord-Char&Phoneme&Syllable=>B-St-Tk:SubWord:Char&Phoneme&Syllable\n",
      "1-2 Tk:AnnoGrn^Tk:POSGrn^Tk:SlfGrn^Tk:SubWord==>St\n",
      "----> (input) B-St-Tk:AnnoGrn\n",
      "   ----> (pipeline name) EL**B-St-Tk:AnnoGrn=>B-St-Tk:Anno\n",
      "----> (input) B-St-Tk:POSGrn\n",
      "   ----> (pipeline name) EL**B-St-Tk:POSGrn=>B-St-Tk:POS\n",
      "----> (input) B-St-Tk:SlfGrn\n",
      "   ----> (pipeline name) EL**B-St-Tk:SlfGrn=>B-St-Tk:Slf\n",
      "----> (input) B-St-Tk:SubWord\n",
      "----> (input) B-St-Tk:Anno^B-St-Tk:POS^B-St-Tk:Slf^B-St-Tk:SubWord\n",
      "   ----> (pipeline name) ML**B-St-Tk:Anno^B-St-Tk:POS^B-St-Tk:Slf^B-St-Tk:SubWord=>B-St-Tk-Anno&POS&Slf&SubWord\n",
      "   ----> (pipeline name) RL**B-St-Tk-Anno&POS&Slf&SubWord=>B-St-Tk:Anno&POS&Slf&SubWord\n",
      "   ----> (pipeline name) RL**B-St-Tk:Anno&POS&Slf&SubWord=>B-St:Tk:Anno&POS&Slf&SubWord\n"
     ]
    }
   ],
   "source": [
    "StructName2Settings = {}\n",
    "for layername, struct_list in layer2modulelist.items():\n",
    "    # print(layername, struct_list)\n",
    "    for struct_name in struct_list:\n",
    "        print(layername, struct_name)\n",
    "        fullname_inputs, fullname_output, struct_model, NAME_2_FULLNAME = get_struct_info(struct_name, NAME_2_FULLNAME)\n",
    "        D_model, D_data = generate_structure(fullname_inputs, struct_model)\n",
    "        \n",
    "        d = {}\n",
    "        d['fullname_inputs'] = fullname_inputs\n",
    "        d['fullname_output'] = fullname_output\n",
    "        d['struct_model'] = struct_model\n",
    "        d['D_model'] = D_model\n",
    "        d['D_data'] = D_data\n",
    "        StructName2Settings[struct_name] = d\n",
    "        \n",
    "        for input_data, pipeline_list in StructName2Settings[struct_name]['D_model'].items():\n",
    "            print('----> (input)', input_data)\n",
    "            for pipeline_name in pipeline_list:\n",
    "                print('   ----> (pipeline name)', pipeline_name)\n",
    "                \n",
    "                sublayer_type, input_output = pipeline_name.split('**')\n",
    "                input_fullnames, output_fullname = input_output.split('=>')\n",
    "                input_fullname_list = input_fullnames.split('^')\n",
    "                \n",
    "                # print('       ----> (+)', sublayer_type)\n",
    "                # print('       ----> (+)', input_fullname_list)\n",
    "                # print('       ----> (+)', output_fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e4dc22b-016a-440c-9ea5-d321a607e497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(StructName2Settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eb52fd-c7ef-4da2-95b1-892bbefed583",
   "metadata": {},
   "source": [
    "# Pipeline Para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb725415-5d0a-4fba-8481-2bbfb03e38b8",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2faa90c3-6786-4cc8-8e8f-3b707ebbbc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fullname_from_inputs(fullname_list):\n",
    "    names = [i.split('-')[-1] for i in fullname_list]\n",
    "    \n",
    "    prefix = ['-'.join(i.split('-')[:-1]) for i in fullname_list][0]\n",
    "    \n",
    "    table_row_indicator = list(set([i.count(':') for i in names]))[0]\n",
    "    \n",
    "    if table_row_indicator == 0:\n",
    "        fullname = f'{prefix}-{\"&\".join(names)}'\n",
    "    elif table_row_indicator >= 1:\n",
    "        table_name = [':'.join(i.split(':')[:-1]) for i in names][0]\n",
    "        columns =  [i.split(':')[-1] for i in names]\n",
    "        fullname = f'{prefix}-{table_name}-{\"&\".join(columns)}'\n",
    "    else:\n",
    "        raise ValueError(f'\"table_row_indicator\" {table_row_indicator} if not correct')\n",
    "    return fullname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9adccec-d479-49e2-8184-3f87859135c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fieldnn.utils.parafn import get_expander_para, get_learner_para, get_reducer_para, get_merger_para\n",
    "# from fieldnn.utils.parafn import get_fullname_from_inputs\n",
    "# from .parafn import get_expander_para, get_learner_para, get_reducer_para, get_merger_para\n",
    "# from .parafn import get_fullname_from_inputs\n",
    "\n",
    "default_learner_para  = {\n",
    "    'nn_name': 'TFM',\n",
    "    'nn_para': {'num_encoder_layers': 6}\n",
    "}\n",
    "\n",
    "default_reducer_para  = {\n",
    "    'nn_name': 'Max',\n",
    "}\n",
    "\n",
    "\n",
    "def get_EL_sublayer_para_list(input_fullname_list, \n",
    "                              FLD_2_VOCABSIZE, \n",
    "                              embed_size,\n",
    "                              default_learner_para, \n",
    "                              expander_process, \n",
    "                              default_process, \n",
    "                              Ignore_PSN_Layers):\n",
    "    # print(input_fullname_list)\n",
    "    assert len(input_fullname_list) == 1\n",
    "    fullname = input_fullname_list[0]\n",
    "    output_fullname = fullname.replace('Grn', '')\n",
    "    ###########\n",
    "    nn_name = 'Embedding'\n",
    "    vocab_size = FLD_2_VOCABSIZE[fullname]\n",
    "    nn_para = {'input_size': vocab_size}\n",
    "    postprocess = expander_process\n",
    "    ###########\n",
    "    expander_layer_para = get_expander_para(fullname, nn_name, nn_para, embed_size, \n",
    "                                            Ignore_PSN_Layers, \n",
    "                                            postprocess\n",
    "                                           )\n",
    "    # print(expander_layer_para)\n",
    "    ###########\n",
    "    \n",
    "    nn_name = default_learner_para['nn_name']\n",
    "    nn_para = default_learner_para['nn_para']\n",
    "    input_size = embed_size\n",
    "    output_size = embed_size\n",
    "    embedprocess = default_process\n",
    "    postprocess = default_process\n",
    "    ###########\n",
    "    learner_layer_para  = get_learner_para(output_fullname, \n",
    "                                           nn_name, nn_para, \n",
    "                                           input_size, output_size, \n",
    "                                           Ignore_PSN_Layers, \n",
    "                                           embedprocess, postprocess\n",
    "                                          )\n",
    "    # print(learner_layer_para)\n",
    "    para_dict = {'Expander': expander_layer_para, 'Learner': learner_layer_para}\n",
    "    return para_dict\n",
    "\n",
    "\n",
    "\n",
    "def get_RL_sublayer_para_list(input_fullname_list, \n",
    "                              embed_size, \n",
    "                              default_learner_para,\n",
    "                              default_reducer_para,\n",
    "                              default_process,\n",
    "                              Ignore_PSN_Layers):\n",
    "    assert len(input_fullname_list) == 1\n",
    "    fullname = input_fullname_list[0]\n",
    "\n",
    "    #########\n",
    "    nn_name = default_reducer_para['nn_name'] # 'Max'\n",
    "    nn_para = {}\n",
    "    input_size = embed_size\n",
    "    output_size = embed_size if nn_name != 'concat' else embed_size * 3\n",
    "    postprocess = default_process\n",
    "    #########\n",
    "\n",
    "    reducer_layer_para = get_reducer_para(fullname, nn_name, nn_para, input_size, output_size, postprocess)\n",
    "    # print(reducer_layer_para)\n",
    "\n",
    "    ###########\n",
    "    output_fullname = '-'.join(fullname.split('-')[:-1]) + ':' + fullname.split('-')[-1]\n",
    "    \n",
    "    if len(output_fullname.split('-')) == 2:\n",
    "        # B and Obs: from tfm to linear\n",
    "        nn_name = 'linear'\n",
    "        nn_para = {}\n",
    "        embedprocess = {}\n",
    "        postprocess = default_process\n",
    "    \n",
    "    else:\n",
    "        nn_name = default_learner_para['nn_name']\n",
    "        nn_para = default_learner_para['nn_para']\n",
    "        embedprocess = default_process\n",
    "        postprocess = default_process\n",
    "    input_size = embed_size\n",
    "    output_size = embed_size\n",
    "    \n",
    "    ###########\n",
    "    learner_layer_para  = get_learner_para(output_fullname, \n",
    "                                           nn_name, nn_para, \n",
    "                                           input_size, output_size, \n",
    "                                           Ignore_PSN_Layers, \n",
    "                                           embedprocess, postprocess\n",
    "                                          )\n",
    "    # print(learner_layer_para)\n",
    "    para_dict = {'Reducer': reducer_layer_para, 'Learner': learner_layer_para}\n",
    "    return para_dict\n",
    "    \n",
    "\n",
    "def get_ML_sublayer_para_list(input_fullname_list,\n",
    "                              embed_size, \n",
    "                              default_learner_para,\n",
    "                              default_process, \n",
    "                              Ignore_PSN_Layers):\n",
    "    assert len(input_fullname_list) > 1\n",
    "    fullname = '^'.join(input_fullname_list) # input of M\n",
    "    # fullname = get_fullname_from_inputs(input_fullname_list)\n",
    "\n",
    "    #########\n",
    "    nn_name = 'Merger'\n",
    "    nn_para = {}\n",
    "    input_size = embed_size\n",
    "    output_size = embed_size\n",
    "    postprocess = default_process\n",
    "    #########\n",
    "\n",
    "    merger_layer_para = get_merger_para(fullname, nn_name, nn_para, input_size, output_size, postprocess)\n",
    "    # print(merger_layer_para)\n",
    "\n",
    "    ###########\n",
    "    # print(input_fullname_list, '<----get_ML_sublayer_para_list') \n",
    "    fullname = get_fullname_from_inputs(input_fullname_list) # input of L\n",
    "    # print(fullname, '<----get_ML_sublayer_para_list') \n",
    "    nn_name = default_learner_para['nn_name']\n",
    "    nn_para = default_learner_para['nn_para']\n",
    "    input_size = embed_size\n",
    "    output_size = embed_size\n",
    "    embedprocess = default_process\n",
    "    postprocess = default_process\n",
    "    ###########\n",
    "    learner_layer_para  = get_learner_para(fullname, \n",
    "                                           nn_name, nn_para, \n",
    "                                           input_size, output_size, \n",
    "                                           Ignore_PSN_Layers, \n",
    "                                           embedprocess, postprocess\n",
    "                                          )\n",
    "    # print(merger_layer_para)\n",
    "    para_dict = {'Merger': merger_layer_para, 'Learner': learner_layer_para}\n",
    "    return para_dict\n",
    "\n",
    "    \n",
    "\n",
    "def process_pipeline_name(sublayer_name, FLD_2_VOCABSIZE, embed_size, \n",
    "                          default_learner_para,  default_reducer_para,\n",
    "                          expander_process, default_process, Ignore_PSN_Layers):\n",
    "    # print('   ----> (sublayer name)', sublayer_name)   \n",
    "    sublayer_type, input_output = sublayer_name.split('**')\n",
    "    input_fullnames, output_fullname = input_output.split('=>')\n",
    "    input_fullname_list = input_fullnames.split('^')\n",
    "    # print('       ----> (+)', sublayer_type)\n",
    "    # print('       ----> (+)', input_fullname_list)\n",
    "    # print('       ----> (+)', output_fullname)\n",
    "\n",
    "    if 'EL' == sublayer_type:\n",
    "        para_dict = get_EL_sublayer_para_list(input_fullname_list, \n",
    "                                              FLD_2_VOCABSIZE, \n",
    "                                              embed_size,\n",
    "                                              default_learner_para, \n",
    "                                              expander_process, \n",
    "                                              default_process, \n",
    "                                              Ignore_PSN_Layers)\n",
    "    elif 'RL' == sublayer_type:\n",
    "        para_dict = get_RL_sublayer_para_list(input_fullname_list, \n",
    "                                              embed_size, \n",
    "                                              default_learner_para,\n",
    "                                              default_reducer_para,\n",
    "                                              default_process,\n",
    "                                              Ignore_PSN_Layers)\n",
    "    elif 'ML' == sublayer_type:\n",
    "        para_dict = get_ML_sublayer_para_list(input_fullname_list,\n",
    "                                              embed_size, \n",
    "                                              default_learner_para,\n",
    "                                              default_process, \n",
    "                                              Ignore_PSN_Layers)\n",
    "    else:\n",
    "        raise ValueError(f'The sublayer type {sublayer_type} is not available')\n",
    "        \n",
    "        \n",
    "    return input_fullname_list, output_fullname, para_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfd82b3-76c5-4d2d-b4fa-3b2f26e348fd",
   "metadata": {},
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7af5bff4-4422-4e3e-be7a-1a7ccce03338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# from .expander import Expander_Layer\n",
    "# from .learner import Learner_Layer\n",
    "# from .merger import Merger_Layer\n",
    "\n",
    "from fieldnn.sublayer.expander import Expander_Layer\n",
    "from fieldnn.sublayer.learner import Learner_Layer\n",
    "from fieldnn.sublayer.merger import Merger_Layer\n",
    "from fieldnn.sublayer.reducer import Reducer_Layer\n",
    "\n",
    "\n",
    "class Pipeline_Layer(torch.nn.Module):\n",
    "    def __init__(self, pipeline_name, input_fullname, output_fullname, para_dict):\n",
    "        super(Pipeline_Layer, self).__init__()\n",
    "        \n",
    "        self.pipeline_name = pipeline_name\n",
    "        self.input_fullname = input_fullname\n",
    "        # self.input_fullname_list = input_fullname.split('^')\n",
    "        self.output_fullname = output_fullname\n",
    "        self.para_dict = para_dict\n",
    "        \n",
    "        self.Layers = torch.nn.ModuleDict()\n",
    "        for name, para in para_dict.items():\n",
    "            if name == 'Expander':\n",
    "                assert 'Grn' == input_fullname[-3:]\n",
    "                assert input_fullname.replace('Grn', '') == output_fullname\n",
    "                self.Layers[input_fullname] = Expander_Layer(input_fullname, output_fullname, para)\n",
    "        \n",
    "            elif name == 'Merger':\n",
    "                assert len(input_fullname.split('^')) > 1\n",
    "                self.Layers[input_fullname] = Merger_Layer(input_fullname, output_fullname, para)\n",
    "        \n",
    "            elif name == 'Reducer':\n",
    "                self.Layers[input_fullname] = Reducer_Layer(input_fullname, output_fullname, para)\n",
    "                \n",
    "            elif name == 'Learner':\n",
    "                assert output_fullname in para\n",
    "                self.Layers[output_fullname] = Learner_Layer(output_fullname, output_fullname, para)\n",
    "            else:\n",
    "                raise ValueError(f'The sublayer name \"{name}\" is not available')\n",
    "                \n",
    "    def forward(self, fullname2data):\n",
    "        for input_fullname, Layer in self.Layers.items():\n",
    "            \n",
    "            if '^' not in input_fullname:\n",
    "                # holder, info = fullname2data.pop(input_fullname)\n",
    "                # print(input_fullname, '<---input_fullname')\n",
    "                # print(type(Layer), '<---Layer type')\n",
    "                # print(Layer.input_fullname, '<---Layer type')\n",
    "                # print(Layer.output_fullname, '<---Layer type')\n",
    "                data = fullname2data.get(input_fullname)\n",
    "                holder, info = data['holder'], data['info']\n",
    "                # print(f'input_fullname: {input_fullname}, Layer Type {type(Layer)}')\n",
    "                # print(holder.max())\n",
    "                fullname, holder, info = Layer(input_fullname, holder, info)\n",
    "                # print(fullname, '<--- output fullname')\n",
    "                fullname2data[fullname] = {'holder': holder, 'info': info}\n",
    "            else:\n",
    "                input_fullname_list = input_fullname.split('^')\n",
    "                # print(input_fullname)\n",
    "                # fullname2data_copy = {k: fullname2data.pop(k) for k in input_fullname_list}\n",
    "                fullname2data_copy = {k: fullname2data.get(k) for k in input_fullname_list}\n",
    "                fullname, holder, info = Layer(input_fullname, fullname2data_copy)\n",
    "                fullname2data[fullname] = {'holder': holder, 'info': info}\n",
    "                \n",
    "        return fullname2data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a5556b-0162-4810-aad9-ec2a849752c8",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599af5a9-96bf-457b-91d6-1adb47828a06",
   "metadata": {},
   "source": [
    "### Simulate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "279e7fa3-1a3e-4ffa-aeeb-a643e38a692d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 9)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 4)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 7)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from fieldnn.utils.layerfn import traverse\n",
    "from fieldnn.utils.simulate import get_next_info, get_simulated_tensor_from_fldname\n",
    "\n",
    "B_lenP = 3\n",
    "B2P_lnEC = [6, 5, 2] # \n",
    "prefix_layers_num = 2\n",
    "vocab_size = 100\n",
    "Ignore_PSN_Layers = ['B', 'St']\n",
    "\n",
    "###############\n",
    "FLD_LIST = [\n",
    "'B-St-Tk:SlfGrn',\n",
    "'B-St-Tk:POSGrn',\n",
    "'B-St-Tk:AnnoGrn',\n",
    "'B-St-Tk:SubWord-CharGrn',\n",
    "'B-St-Tk:SubWord-SyllableGrn',\n",
    "'B-St-Tk:SubWord-PhonemeGrn',\n",
    "]\n",
    "\n",
    "# FLD_LIST = [\n",
    "# 'B-P-EC:Diag-DiagRec:DiagV-DiagVdftGrn',\n",
    "# 'B-P-EC:Diag-DiagRec:DiagDT-DiagDTdftGrn',\n",
    "# 'B-P-EC:Med-MedRec:MedV-MedVdftGrn',\n",
    "# 'B-P-EC:Med-MedRec:MedDT-MedDTdftGrn',\n",
    "# 'B-P-EC:A1C-A1CRec:A1CV-A1CVdftGrn',\n",
    "# 'B-P-EC:A1C-A1CRec:A1CDT-A1CDTdftGrn',\n",
    "# 'B-P-EC:PN-PNRec:SctName-SNdftGrn',\n",
    "# 'B-P-EC:PN-PNRec:SctText-SctSent-Tk:SelfGrn',\n",
    "# 'B-P-EC:PN-PNRec:SctText-SctSent-Tk:POSGrn',\n",
    "# 'B-P-EC:PN-PNRec:SctText-SctSent-Tk:SubWord-CharGrn',\n",
    "# ]\n",
    "\n",
    "###############\n",
    "NAME_2_FULLNAME = {i.split('-')[-1]:i for i in FLD_LIST}\n",
    "\n",
    "###############\n",
    "FLD_2_VOCABSIZE = {k: np.random.randint(5000) for k in FLD_LIST}\n",
    "\n",
    "#####################\n",
    "FLD_2_DATA = {}\n",
    "\n",
    "for fullname in FLD_LIST:\n",
    "    vocab_size = FLD_2_VOCABSIZE[fullname]\n",
    "    info_idx = get_simulated_tensor_from_fldname(fullname, B_lenP, B2P_lnEC, prefix_layers_num, vocab_size)\n",
    "    # print(info_idx.shape)\n",
    "    holder = torch.LongTensor(info_idx)\n",
    "    # info_idx = torch.LongTensor(info_idx)\n",
    "    FLD_2_DATA[fullname] = {'holder': holder, 'info': 'Empty'}\n",
    "    \n",
    "######################\n",
    "embed_size = 512\n",
    "expander_process = {# 'activator': 'gelu',\n",
    "           'dropout': {'p': 0.5, 'inplace': False},\n",
    "           'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "\n",
    "default_process = {'activator': 'gelu',\n",
    "           'dropout': {'p': 0.5, 'inplace': False},\n",
    "           'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "\n",
    "default_learner_para  = {\n",
    "    'nn_name': 'TFM',\n",
    "    'nn_para': {'num_encoder_layers': 6}\n",
    "}\n",
    "default_reducer_para  = {\n",
    "    'nn_name': 'Max',\n",
    "}\n",
    "##################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4676d24-b394-4900-886c-55b64a4fb7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-St-Tk:SlfGrn',\n",
       " 'B-St-Tk:POSGrn',\n",
       " 'B-St-Tk:AnnoGrn',\n",
       " 'B-St-Tk:SubWord-CharGrn',\n",
       " 'B-St-Tk:SubWord-SyllableGrn',\n",
       " 'B-St-Tk:SubWord-PhonemeGrn']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in FLD_2_DATA]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e20ea6-2dac-4415-8c24-a7395ca63770",
   "metadata": {},
   "source": [
    "### Pipeline 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f83ca8d7-eb59-4654-b646-db80954cf22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-St-Tk:SubWord-CharGrn\n",
      "B-St-Tk:SubWord-Char\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "pipeline_name = 'EL**B-St-Tk:SubWord-CharGrn=>B-St-Tk:SubWord-Char'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Char=>B-St-Tk:SubWord:Char'\n",
    "\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-PhonemeGrn=>B-St-Tk:SubWord-Phoneme'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Phoneme=>B-St-Tk:SubWord:Phoneme'\n",
    "\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-SyllableGrn=>B-St-Tk:SubWord-Syllable'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Syllable=>B-St-Tk:SubWord:Syllable'\n",
    "\n",
    "# pipeline_name = 'ML**B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable=>B-St-Tk:SubWord-Char&Phoneme&Syllable'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Char&Phoneme&Syllable=>B-St-Tk:SubWord:Char&Phoneme&Syllable'\n",
    "######################################################\n",
    "\n",
    "input_fullname_list, output_fullname, para_dict = process_pipeline_name(pipeline_name, FLD_2_VOCABSIZE, embed_size, \n",
    "                                                                        default_learner_para,  default_reducer_para,\n",
    "                                                                        expander_process, default_process, Ignore_PSN_Layers)\n",
    "\n",
    "input_fullname = '^'.join(input_fullname_list)\n",
    "\n",
    "print(input_fullname)\n",
    "print(output_fullname)\n",
    "# pprint(para_dict)\n",
    "PipeLine = Pipeline_Layer(pipeline_name, input_fullname, output_fullname, para_dict)\n",
    "\n",
    "# print(PipeLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d71a5691-967d-4aa9-a7a8-04ee0c001671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PipeLine.Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03b82c93-e5d3-422a-9729-8070a64d3607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char']\n"
     ]
    }
   ],
   "source": [
    "print([i for i in FLD_2_DATA])\n",
    "FLD_2_DATA = PipeLine(FLD_2_DATA)\n",
    "print([i for i in FLD_2_DATA]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4fa6d4e-40f3-4498-b5e5-5b512e20a9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-St-Tk:SubWord-CharGrn\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 45, 104,  85,   0,   0,   0,   0,   0,   0],\n",
       "         [307, 431, 214,   0,   0,   0,   0,   0,   0],\n",
       "         [134, 337, 363, 391, 344,  94, 484,   0,   0],\n",
       "         [429,  54, 272, 416,   0,   0,   0,   0,   0],\n",
       "         [ 52, 339, 190, 181,   0,   0,   0,   0,   0],\n",
       "         [311, 403,   0,   0,   0,   0,   0,   0,   0]],\n",
       "\n",
       "        [[ 81, 369, 430,   0,   0,   0,   0,   0,   0],\n",
       "         [ 49, 346, 269,  54,   0,   0,   0,   0,   0],\n",
       "         [  4,  40, 405, 248,  82, 310, 243, 397,   0],\n",
       "         [400,   2, 326, 428,   0,   0,   0,   0,   0],\n",
       "         [315, 168, 132, 141,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "\n",
       "        [[481, 213, 227, 356,   0,   0,   0,   0,   0],\n",
       "         [475, 308, 411, 252,   9, 159,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(input_fullname)\n",
    "data = FLD_2_DATA[input_fullname]\n",
    "holder = data['holder']\n",
    "holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7231193b-9e9e-4fc8-b6a0-b846a56d0a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-St-Tk:SubWord-Char\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 45, 104,  85,   0,   0,   0,   0,   0,   0],\n",
       "         [307, 431, 214,   0,   0,   0,   0,   0,   0],\n",
       "         [134, 337, 363, 391, 344,  94, 484,   0,   0],\n",
       "         [429,  54, 272, 416,   0,   0,   0,   0,   0],\n",
       "         [ 52, 339, 190, 181,   0,   0,   0,   0,   0],\n",
       "         [311, 403,   0,   0,   0,   0,   0,   0,   0]],\n",
       "\n",
       "        [[ 81, 369, 430,   0,   0,   0,   0,   0,   0],\n",
       "         [ 49, 346, 269,  54,   0,   0,   0,   0,   0],\n",
       "         [  4,  40, 405, 248,  82, 310, 243, 397,   0],\n",
       "         [400,   2, 326, 428,   0,   0,   0,   0,   0],\n",
       "         [315, 168, 132, 141,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "\n",
       "        [[481, 213, 227, 356,   0,   0,   0,   0,   0],\n",
       "         [475, 308, 411, 252,   9, 159,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(output_fullname)\n",
    "data = FLD_2_DATA[output_fullname]\n",
    "holder = data['holder']\n",
    "holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6ad5dbc-d2d0-4e72-9231-9b0266b5e6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.2399e+00, -2.4432e-01, -1.9674e-02,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [-1.2034e-03, -1.1415e-02,  3.3665e-02,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [-1.5489e+00,  2.1165e-02,  9.7997e-01,  8.9551e-01,  5.5132e-03,\n",
       "          -9.9906e-01, -6.4794e-03,  0.0000e+00,  0.0000e+00],\n",
       "         [-7.7219e-01, -5.6175e-02, -5.1582e-01,  2.5596e-02,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 3.2194e-02, -7.8172e-02,  2.6554e+00, -5.1002e-01,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 2.8408e-02, -8.8949e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-1.5224e-02,  1.5349e-02, -4.9126e-02,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [-2.3654e+00, -1.6772e+00, -4.9726e-01, -4.8565e-01,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [-1.0587e+00, -4.9278e-01, -1.6987e-02, -4.8846e-03,  1.7341e+00,\n",
       "           1.3118e-02, -3.4642e+00, -7.0318e-02,  0.0000e+00],\n",
       "         [ 8.2996e-02, -2.1550e-02,  4.3080e-02, -2.0529e-02,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [-2.5039e+00,  6.8523e-01,  2.4974e-01,  1.7199e-02,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-1.2441e-03, -1.4921e+00, -9.4966e-02, -1.1396e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [-2.5682e+00,  2.7964e-04, -7.0828e-01, -5.9598e-01, -2.6921e-02,\n",
       "          -2.6943e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = data['info']\n",
    "info[:,:,:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f574b8b-1501-4e87-b4b2-cf07a3d8322b",
   "metadata": {},
   "source": [
    "### Pipeline 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0599370-a860-4fc2-99d1-3e88ce6986cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-St-Tk:SubWord-Char\n",
      "B-St-Tk:SubWord:Char\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-CharGrn=>B-St-Tk:SubWord-Char'\n",
    "pipeline_name = 'RL**B-St-Tk:SubWord-Char=>B-St-Tk:SubWord:Char'\n",
    "\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-PhonemeGrn=>B-St-Tk:SubWord-Phoneme'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Phoneme=>B-St-Tk:SubWord:Phoneme'\n",
    "\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-SyllableGrn=>B-St-Tk:SubWord-Syllable'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Syllable=>B-St-Tk:SubWord:Syllable'\n",
    "\n",
    "# pipeline_name = 'ML**B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable=>B-St-Tk:SubWord-Char&Phoneme&Syllable'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Char&Phoneme&Syllable=>B-St-Tk:SubWord:Char&Phoneme&Syllable'\n",
    "######################################################\n",
    "\n",
    "input_fullname_list, output_fullname, para_dict = process_pipeline_name(pipeline_name, FLD_2_VOCABSIZE, embed_size, \n",
    "                                                                        default_learner_para,  default_reducer_para,\n",
    "                                                                        expander_process, default_process, Ignore_PSN_Layers)\n",
    "\n",
    "input_fullname = '^'.join(input_fullname_list)\n",
    "\n",
    "print(input_fullname)\n",
    "print(output_fullname)\n",
    "# pprint(para_dict)\n",
    "PipeLine = Pipeline_Layer(pipeline_name, input_fullname, output_fullname, para_dict)\n",
    "\n",
    "# print(PipeLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3ba2947-63f4-4a3a-9b43-f32ed226e91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char']\n"
     ]
    }
   ],
   "source": [
    "print([i for i in FLD_2_DATA])\n",
    "FLD_2_DATA = PipeLine(FLD_2_DATA)\n",
    "print([i for i in FLD_2_DATA]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32c99533-d59e-422e-8883-b30b4f749370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-St-Tk:SubWord-Char\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 45, 104,  85,   0,   0,   0,   0,   0,   0],\n",
       "         [307, 431, 214,   0,   0,   0,   0,   0,   0],\n",
       "         [134, 337, 363, 391, 344,  94, 484,   0,   0],\n",
       "         [429,  54, 272, 416,   0,   0,   0,   0,   0],\n",
       "         [ 52, 339, 190, 181,   0,   0,   0,   0,   0],\n",
       "         [311, 403,   0,   0,   0,   0,   0,   0,   0]],\n",
       "\n",
       "        [[ 81, 369, 430,   0,   0,   0,   0,   0,   0],\n",
       "         [ 49, 346, 269,  54,   0,   0,   0,   0,   0],\n",
       "         [  4,  40, 405, 248,  82, 310, 243, 397,   0],\n",
       "         [400,   2, 326, 428,   0,   0,   0,   0,   0],\n",
       "         [315, 168, 132, 141,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "\n",
       "        [[481, 213, 227, 356,   0,   0,   0,   0,   0],\n",
       "         [475, 308, 411, 252,   9, 159,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(input_fullname)\n",
    "data = FLD_2_DATA[input_fullname]\n",
    "holder = data['holder']\n",
    "holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db8bdda2-855c-42d5-b1f0-1f0377911715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-St-Tk:SubWord:Char\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[3, 3, 7, 4, 4, 2],\n",
       "        [3, 4, 8, 4, 4, 0],\n",
       "        [4, 6, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(output_fullname)\n",
    "data = FLD_2_DATA[output_fullname]\n",
    "holder = data['holder']\n",
    "holder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93d5ed7-e921-46b8-b003-294703db85e7",
   "metadata": {},
   "source": [
    "### Pipeline 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8fc2929c-2524-48fb-927f-5a8daebe42c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-St-Tk:SubWord-PhonemeGrn\n",
      "B-St-Tk:SubWord-Phoneme\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme']\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-CharGrn=>B-St-Tk:SubWord-Char'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Char=>B-St-Tk:SubWord:Char'\n",
    "\n",
    "pipeline_name = 'EL**B-St-Tk:SubWord-PhonemeGrn=>B-St-Tk:SubWord-Phoneme'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Phoneme=>B-St-Tk:SubWord:Phoneme'\n",
    "\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-SyllableGrn=>B-St-Tk:SubWord-Syllable'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Syllable=>B-St-Tk:SubWord:Syllable'\n",
    "\n",
    "# pipeline_name = 'ML**B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable=>B-St-Tk:SubWord-Char&Phoneme&Syllable'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Char&Phoneme&Syllable=>B-St-Tk:SubWord:Char&Phoneme&Syllable'\n",
    "######################################################\n",
    "\n",
    "input_fullname_list, output_fullname, para_dict = process_pipeline_name(pipeline_name, FLD_2_VOCABSIZE, embed_size, \n",
    "                                                                        default_learner_para,  default_reducer_para,\n",
    "                                                                        expander_process, default_process, Ignore_PSN_Layers)\n",
    "\n",
    "input_fullname = '^'.join(input_fullname_list)\n",
    "\n",
    "print(input_fullname)\n",
    "print(output_fullname)\n",
    "# pprint(para_dict)\n",
    "PipeLine = Pipeline_Layer(pipeline_name, input_fullname, output_fullname, para_dict)\n",
    "# print(PipeLine)\n",
    "\n",
    "print([i for i in FLD_2_DATA])\n",
    "FLD_2_DATA = PipeLine(FLD_2_DATA)\n",
    "print([i for i in FLD_2_DATA]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ec75b2-b7b7-47d9-af58-67c0917fa8bb",
   "metadata": {},
   "source": [
    "### Pipeline 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec98f743-7010-4e75-9115-628ccd148f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-St-Tk:SubWord-Phoneme\n",
      "B-St-Tk:SubWord:Phoneme\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme']\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-CharGrn=>B-St-Tk:SubWord-Char'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Char=>B-St-Tk:SubWord:Char'\n",
    "\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-PhonemeGrn=>B-St-Tk:SubWord-Phoneme'\n",
    "pipeline_name = 'RL**B-St-Tk:SubWord-Phoneme=>B-St-Tk:SubWord:Phoneme'\n",
    "\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-SyllableGrn=>B-St-Tk:SubWord-Syllable'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Syllable=>B-St-Tk:SubWord:Syllable'\n",
    "\n",
    "# pipeline_name = 'ML**B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable=>B-St-Tk:SubWord-Char&Phoneme&Syllable'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Char&Phoneme&Syllable=>B-St-Tk:SubWord:Char&Phoneme&Syllable'\n",
    "######################################################\n",
    "\n",
    "input_fullname_list, output_fullname, para_dict = process_pipeline_name(pipeline_name, FLD_2_VOCABSIZE, embed_size, \n",
    "                                                                        default_learner_para,  default_reducer_para,\n",
    "                                                                        expander_process, default_process, Ignore_PSN_Layers)\n",
    "\n",
    "input_fullname = '^'.join(input_fullname_list)\n",
    "\n",
    "print(input_fullname)\n",
    "print(output_fullname)\n",
    "# pprint(para_dict)\n",
    "PipeLine = Pipeline_Layer(pipeline_name, input_fullname, output_fullname, para_dict)\n",
    "# print(PipeLine)\n",
    "\n",
    "print([i for i in FLD_2_DATA])\n",
    "FLD_2_DATA = PipeLine(FLD_2_DATA)\n",
    "print([i for i in FLD_2_DATA]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15f0942-963f-473a-9b32-880b44260755",
   "metadata": {},
   "source": [
    "### Pipeline 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5639b6f9-46fd-4f1f-831e-ebc0018321b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-St-Tk:SubWord-SyllableGrn\n",
      "B-St-Tk:SubWord-Syllable\n",
      "{'Expander': {'B-St-Tk:SubWord-SyllableGrn': ('Embedding',\n",
      "                                              {'embedding_size': 512,\n",
      "                                               'init': 'random',\n",
      "                                               'input_size': 445}),\n",
      "              'Ignore_PSN_Layers': ['B', 'St'],\n",
      "              'input_size': None,\n",
      "              'output_size': 512,\n",
      "              'postprocess': {'dropout': {'inplace': False, 'p': 0.5},\n",
      "                              'layernorm': {'elementwise_affine': True,\n",
      "                                            'eps': 1e-05}}},\n",
      " 'Learner': {'B-St-Tk:SubWord-Syllable': ('TFM',\n",
      "                                          {'dim_feedforward': 2048,\n",
      "                                           'input_size': 512,\n",
      "                                           'nhead': 8,\n",
      "                                           'num_decoder_layers': 0,\n",
      "                                           'num_encoder_layers': 6,\n",
      "                                           'output_size': 512,\n",
      "                                           'tfm_activation': 'relu',\n",
      "                                           'tfm_dropout': 0.1}),\n",
      "             'Ignore_PSN_Layers': ['B', 'St'],\n",
      "             'embedprocess': {'activator': 'gelu',\n",
      "                              'dropout': {'inplace': False, 'p': 0.5},\n",
      "                              'layernorm': {'elementwise_affine': True,\n",
      "                                            'eps': 1e-05}},\n",
      "             'input_size': 512,\n",
      "             'output_size': 512,\n",
      "             'postprocess': {'activator': 'gelu',\n",
      "                             'dropout': {'inplace': False, 'p': 0.5},\n",
      "                             'layernorm': {'elementwise_affine': True,\n",
      "                                           'eps': 1e-05}},\n",
      "             'psn_layers': ['Syllable', 'Tk:SubWord']}}\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-CharGrn=>B-St-Tk:SubWord-Char'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Char=>B-St-Tk:SubWord:Char'\n",
    "\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-PhonemeGrn=>B-St-Tk:SubWord-Phoneme'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Phoneme=>B-St-Tk:SubWord:Phoneme'\n",
    "\n",
    "pipeline_name = 'EL**B-St-Tk:SubWord-SyllableGrn=>B-St-Tk:SubWord-Syllable'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Syllable=>B-St-Tk:SubWord:Syllable'\n",
    "\n",
    "# pipeline_name = 'ML**B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable=>B-St-Tk:SubWord-Char&Phoneme&Syllable'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Char&Phoneme&Syllable=>B-St-Tk:SubWord:Char&Phoneme&Syllable'\n",
    "######################################################\n",
    "\n",
    "input_fullname_list, output_fullname, para_dict = process_pipeline_name(pipeline_name, FLD_2_VOCABSIZE, embed_size, \n",
    "                                                                        default_learner_para,  default_reducer_para,\n",
    "                                                                        expander_process, default_process, Ignore_PSN_Layers)\n",
    "\n",
    "input_fullname = '^'.join(input_fullname_list)\n",
    "\n",
    "print(input_fullname)\n",
    "print(output_fullname)\n",
    "pprint(para_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7bbadc5c-2062-4de3-afdf-5b320c5d3ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PipeLine = Pipeline_Layer(pipeline_name, input_fullname, output_fullname, para_dict)\n",
    "# print(PipeLine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea35d954-ffa4-4858-8745-ebb5e032c516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(434)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = FLD_2_DATA[input_fullname]\n",
    "data['holder'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e9a2745-e74d-4756-838e-1e46438c5be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print([i for i in FLD_2_DATA])\n",
    "FLD_2_DATA = PipeLine(FLD_2_DATA)\n",
    "print([i for i in FLD_2_DATA]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1afd80-a356-4bb7-af3f-ef7f1c44b875",
   "metadata": {},
   "source": [
    "### Pipeline 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb246545-cc5f-4681-b7a0-161ecbf47223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-St-Tk:SubWord-Syllable\n",
      "B-St-Tk:SubWord:Syllable\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable']\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-CharGrn=>B-St-Tk:SubWord-Char'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Char=>B-St-Tk:SubWord:Char'\n",
    "\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-PhonemeGrn=>B-St-Tk:SubWord-Phoneme'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Phoneme=>B-St-Tk:SubWord:Phoneme'\n",
    "\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-SyllableGrn=>B-St-Tk:SubWord-Syllable'\n",
    "pipeline_name = 'RL**B-St-Tk:SubWord-Syllable=>B-St-Tk:SubWord:Syllable'\n",
    "\n",
    "# pipeline_name = 'ML**B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable=>B-St-Tk:SubWord-Char&Phoneme&Syllable'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Char&Phoneme&Syllable=>B-St-Tk:SubWord:Char&Phoneme&Syllable'\n",
    "######################################################\n",
    "\n",
    "input_fullname_list, output_fullname, para_dict = process_pipeline_name(pipeline_name, FLD_2_VOCABSIZE, embed_size, \n",
    "                                                                        default_learner_para,  default_reducer_para,\n",
    "                                                                        expander_process, default_process, Ignore_PSN_Layers)\n",
    "\n",
    "input_fullname = '^'.join(input_fullname_list)\n",
    "\n",
    "print(input_fullname)\n",
    "print(output_fullname)\n",
    "# pprint(para_dict)\n",
    "PipeLine = Pipeline_Layer(pipeline_name, input_fullname, output_fullname, para_dict)\n",
    "# print(PipeLine)\n",
    "\n",
    "print([i for i in FLD_2_DATA])\n",
    "FLD_2_DATA = PipeLine(FLD_2_DATA)\n",
    "print([i for i in FLD_2_DATA]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd469f2-137b-4cb7-b627-2b45f75255e5",
   "metadata": {},
   "source": [
    "### Pipeline 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f1127fc-0662-41df-8377-1abd64d9ef1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable\n",
      "B-St-Tk:SubWord-Char&Phoneme&Syllable\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-CharGrn=>B-St-Tk:SubWord-Char'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Char=>B-St-Tk:SubWord:Char'\n",
    "\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-PhonemeGrn=>B-St-Tk:SubWord-Phoneme'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Phoneme=>B-St-Tk:SubWord:Phoneme'\n",
    "\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-SyllableGrn=>B-St-Tk:SubWord-Syllable'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Syllable=>B-St-Tk:SubWord:Syllable'\n",
    "\n",
    "pipeline_name = 'ML**B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable=>B-St-Tk:SubWord-Char&Phoneme&Syllable'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Char&Phoneme&Syllable=>B-St-Tk:SubWord:Char&Phoneme&Syllable'\n",
    "######################################################\n",
    "\n",
    "input_fullname_list, output_fullname, para_dict = process_pipeline_name(pipeline_name, FLD_2_VOCABSIZE, embed_size, \n",
    "                                                                        default_learner_para,  default_reducer_para,\n",
    "                                                                        expander_process, default_process, Ignore_PSN_Layers)\n",
    "\n",
    "input_fullname = '^'.join(input_fullname_list)\n",
    "\n",
    "print(input_fullname)\n",
    "print(output_fullname)\n",
    "# pprint(para_dict)\n",
    "PipeLine = Pipeline_Layer(pipeline_name, input_fullname, output_fullname, para_dict)\n",
    "# print(PipeLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9158732-dd36-4724-840e-118c97a022a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PipeLine.Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e6bb23fe-0ffc-4159-8440-29d7cc708ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable']\n"
     ]
    }
   ],
   "source": [
    "print([i for i in FLD_2_DATA])\n",
    "FLD_2_DATA = PipeLine(FLD_2_DATA)\n",
    "print([i for i in FLD_2_DATA]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4c4b3a-2e86-49f3-a8a7-1c56ebb450e7",
   "metadata": {},
   "source": [
    "### Pipeline 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "77ab3910-5e2b-43f9-a550-cd3b84847811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-St-Tk:SubWord-Char&Phoneme&Syllable\n",
      "B-St-Tk:SubWord:Char&Phoneme&Syllable\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable']\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-CharGrn=>B-St-Tk:SubWord-Char'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Char=>B-St-Tk:SubWord:Char'\n",
    "\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-PhonemeGrn=>B-St-Tk:SubWord-Phoneme'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Phoneme=>B-St-Tk:SubWord:Phoneme'\n",
    "\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-SyllableGrn=>B-St-Tk:SubWord-Syllable'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Syllable=>B-St-Tk:SubWord:Syllable'\n",
    "\n",
    "# pipeline_name = 'ML**B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable=>B-St-Tk:SubWord-Char&Phoneme&Syllable'\n",
    "pipeline_name = 'RL**B-St-Tk:SubWord-Char&Phoneme&Syllable=>B-St-Tk:SubWord:Char&Phoneme&Syllable'\n",
    "######################################################\n",
    "\n",
    "input_fullname_list, output_fullname, para_dict = process_pipeline_name(pipeline_name, FLD_2_VOCABSIZE, embed_size, \n",
    "                                                                        default_learner_para,  default_reducer_para,\n",
    "                                                                        expander_process, default_process, Ignore_PSN_Layers)\n",
    "\n",
    "input_fullname = '^'.join(input_fullname_list)\n",
    "\n",
    "print(input_fullname)\n",
    "print(output_fullname)\n",
    "# pprint(para_dict)\n",
    "PipeLine = Pipeline_Layer(pipeline_name, input_fullname, output_fullname, para_dict)\n",
    "# print(PipeLine)\n",
    "\n",
    "print([i for i in FLD_2_DATA])\n",
    "FLD_2_DATA = PipeLine(FLD_2_DATA)\n",
    "print([i for i in FLD_2_DATA]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "525173e2-8d78-4ccf-8634-632b2e5f6f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-St-Tk:SubWord:Char&Phoneme&Syllable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[3, 3, 3, 3, 3, 3],\n",
       "        [3, 3, 3, 3, 3, 0],\n",
       "        [3, 3, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(output_fullname)\n",
    "data = FLD_2_DATA[output_fullname]\n",
    "holder = data['holder']\n",
    "holder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0f027c-d674-461f-935f-dabf9006d7d2",
   "metadata": {},
   "source": [
    "# Struct Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c0bce1-de1a-4586-a1bd-e35d401d1281",
   "metadata": {},
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9aa5b817-0b6b-47e8-8b0c-b88f040728db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# from .pipeline import Pipeline_Layer\n",
    "# from ..utils.parafn import process_sublayer_name\n",
    "\n",
    "class Struct_Layer(torch.nn.Module):\n",
    "    def __init__(self, struct_name, struct_para, meta_para):\n",
    "        super(Struct_Layer, self).__init__()\n",
    "        self.struct_name = struct_name\n",
    "        \n",
    "        self.final_fullname_output = struct_para['final_fullname_output']\n",
    "        self.D_model = struct_para['D_model'] \n",
    "        self.D_data = struct_para['D_data'] \n",
    "        \n",
    "        \n",
    "        self.FLD_2_VOCABSIZE = meta_para['FLD_2_VOCABSIZE']\n",
    "        self.embed_size = meta_para['embed_size']\n",
    "        self.default_learner_para = meta_para['default_learner_para']\n",
    "        self.default_reducer_para = meta_para['default_reducer_para']\n",
    "        self.expander_process = meta_para['expander_process']\n",
    "        self.default_process = meta_para['default_process']\n",
    "        self.Ignore_PSN_Layers = meta_para['Ignore_PSN_Layers']\n",
    "        \n",
    "        self.Layers = torch.nn.ModuleDict()\n",
    "        \n",
    "        for input_fullname, pipeline_list in self.D_model.items():\n",
    "            self.Layers[input_fullname] = torch.nn.ModuleDict() \n",
    "            # print(input_fullname)\n",
    "            for pipeline_name in pipeline_list:\n",
    "                # print(pipeline_name, '<---- pipeline_name')\n",
    "                input_fullname_list, output_fullname, para_dict = process_pipeline_name(pipeline_name, self.FLD_2_VOCABSIZE, self.embed_size, \n",
    "                                                                                        self.default_learner_para,  self.default_reducer_para,\n",
    "                                                                                        self.expander_process, self.default_process, self.Ignore_PSN_Layers)\n",
    "                pipe_input_fullname = '^'.join(input_fullname_list)\n",
    "                PipeLine = Pipeline_Layer(pipeline_name, pipe_input_fullname, output_fullname, para_dict)\n",
    "                self.Layers[input_fullname][pipeline_name] = PipeLine\n",
    "\n",
    "    def forward(self, FLD_2_DATA):\n",
    "        for input_fullname, output_full_name in self.D_data.items():\n",
    "            for pipeline_name, Pipeline in self.Layers[input_fullname].items():\n",
    "                print(f'\\npipeline_name <---------- {pipeline_name} ')\n",
    "                print([i for i in FLD_2_DATA])\n",
    "                FLD_2_DATA = Pipeline(FLD_2_DATA)\n",
    "                print([i for i in FLD_2_DATA])\n",
    "            assert output_full_name in FLD_2_DATA\n",
    "            \n",
    "        # update the new output name to final_fullname_output\n",
    "        assert self.final_fullname_output in output_full_name\n",
    "        # fullname2data[self.final_fullname_output] = fullname2data.pop(output_full_name)\n",
    "        FLD_2_DATA[self.final_fullname_output] = FLD_2_DATA.get(output_full_name)\n",
    "        print(f'\\n Final <---------- ')\n",
    "        print([i for i in FLD_2_DATA])\n",
    "        return FLD_2_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf23afff-6ca5-45d6-ac3d-3e2cdb6fa3ba",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "210e4467-600c-4602-aa91-3e4051cdaa71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 8)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 9)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 9)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from fieldnn.utils.layerfn import traverse\n",
    "from fieldnn.utils.simulate import get_next_info, get_simulated_tensor_from_fldname\n",
    "\n",
    "B_lenP = 3\n",
    "B2P_lnEC = [6, 5, 2] # \n",
    "prefix_layers_num = 2\n",
    "vocab_size = 100\n",
    "\n",
    "###############\n",
    "FLD_LIST = [\n",
    "'B-St-Tk:SlfGrn',\n",
    "'B-St-Tk:POSGrn',\n",
    "'B-St-Tk:AnnoGrn',\n",
    "'B-St-Tk:SubWord-CharGrn',\n",
    "'B-St-Tk:SubWord-SyllableGrn',\n",
    "'B-St-Tk:SubWord-PhonemeGrn',\n",
    "]\n",
    "\n",
    "# FLD_LIST = [\n",
    "# 'B-P-EC:Diag-DiagRec:DiagV-DiagVdftGrn',\n",
    "# 'B-P-EC:Diag-DiagRec:DiagDT-DiagDTdftGrn',\n",
    "# 'B-P-EC:Med-MedRec:MedV-MedVdftGrn',\n",
    "# 'B-P-EC:Med-MedRec:MedDT-MedDTdftGrn',\n",
    "# 'B-P-EC:A1C-A1CRec:A1CV-A1CVdftGrn',\n",
    "# 'B-P-EC:A1C-A1CRec:A1CDT-A1CDTdftGrn',\n",
    "# 'B-P-EC:PN-PNRec:SctName-SNdftGrn',\n",
    "# 'B-P-EC:PN-PNRec:SctText-SctSent-Tk:SelfGrn',\n",
    "# 'B-P-EC:PN-PNRec:SctText-SctSent-Tk:POSGrn',\n",
    "# 'B-P-EC:PN-PNRec:SctText-SctSent-Tk:SubWord-CharGrn',\n",
    "# ]\n",
    "\n",
    "###############\n",
    "\n",
    "Ignore_PSN_Layers = FLD_LIST[0].split('-')[:2]\n",
    "\n",
    "\n",
    "\n",
    "NAME_2_FULLNAME = {i.split('-')[-1]:i for i in FLD_LIST}\n",
    "\n",
    "###############\n",
    "FLD_2_VOCABSIZE = {k: np.random.randint(5000) for k in FLD_LIST}\n",
    "\n",
    "#####################\n",
    "FLD_2_DATA = {}\n",
    "\n",
    "for fullname in FLD_LIST:\n",
    "    vocab_size = FLD_2_VOCABSIZE[fullname]\n",
    "    info_idx = get_simulated_tensor_from_fldname(fullname, B_lenP, B2P_lnEC, prefix_layers_num, vocab_size)\n",
    "    # print(info_idx.shape)\n",
    "    holder = torch.LongTensor(info_idx)\n",
    "    # info_idx = torch.LongTensor(info_idx)\n",
    "    FLD_2_DATA[fullname] = {'holder': holder, 'info': 'Empty'}\n",
    "    \n",
    "######################\n",
    "embed_size = 512\n",
    "expander_process = {# 'activator': 'gelu',\n",
    "           'dropout': {'p': 0.5, 'inplace': False},\n",
    "           'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "\n",
    "default_process = {'activator': 'gelu',\n",
    "           'dropout': {'p': 0.5, 'inplace': False},\n",
    "           'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "\n",
    "default_learner_para  = {\n",
    "    'nn_name': 'TFM',\n",
    "    'nn_para': {'num_encoder_layers': 6}\n",
    "}\n",
    "default_reducer_para  = {\n",
    "    'nn_name': 'Max',\n",
    "}\n",
    "##################################\n",
    "\n",
    "\n",
    "meta_para = {}\n",
    "meta_para['FLD_2_VOCABSIZE'] = FLD_2_VOCABSIZE\n",
    "meta_para['embed_size'] = embed_size\n",
    "meta_para['expander_process'] = expander_process\n",
    "meta_para['default_process'] = default_process\n",
    "meta_para['default_learner_para'] = default_learner_para\n",
    "meta_para['default_reducer_para'] = default_reducer_para\n",
    "meta_para['Ignore_PSN_Layers'] = Ignore_PSN_Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "19e8445e-72a5-4595-bc43-01c54b7abaad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2-3': ['CharGrn^PhonemeGrn^SyllableGrn==>Tk:SubWord'],\n",
       " '1-2': ['Tk:AnnoGrn^Tk:POSGrn^Tk:SlfGrn^Tk:SubWord==>St']}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# name2fullname = {i.split('-')[-1]:i for i in fld_list}\n",
    "df_struct = get_structures_from_fldlist(FLD_LIST)\n",
    "# df_struct# .sort_values('layers', ascending = False)['struct_name'].to_list()\n",
    "\n",
    "tmp = df_struct.sort_values('layers', ascending = False)\n",
    "layer2modulelist = dict(zip(tmp['layers'].to_list(), tmp['struct_name'].to_list()))\n",
    "layer2modulelist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a0a64b-255e-4c1a-871e-052e51de7409",
   "metadata": {},
   "source": [
    "### Struct 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b586f11f-5087-4473-bf2e-16a8689de5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-SyllableGrn']\n",
      "B-St-Tk:SubWord-CharGrn^B-St-Tk:SubWord-PhonemeGrn^B-St-Tk:SubWord-SyllableGrn\n",
      "B-St-Tk:SubWord\n",
      "RLMLRL\n",
      "{'B-St-Tk:SubWord-CharGrn': ['EL**B-St-Tk:SubWord-CharGrn=>B-St-Tk:SubWord-Char',\n",
      "                             'RL**B-St-Tk:SubWord-Char=>B-St-Tk:SubWord:Char'],\n",
      " 'B-St-Tk:SubWord-PhonemeGrn': ['EL**B-St-Tk:SubWord-PhonemeGrn=>B-St-Tk:SubWord-Phoneme',\n",
      "                                'RL**B-St-Tk:SubWord-Phoneme=>B-St-Tk:SubWord:Phoneme'],\n",
      " 'B-St-Tk:SubWord-SyllableGrn': ['EL**B-St-Tk:SubWord-SyllableGrn=>B-St-Tk:SubWord-Syllable',\n",
      "                                 'RL**B-St-Tk:SubWord-Syllable=>B-St-Tk:SubWord:Syllable'],\n",
      " 'B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable': ['ML**B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable=>B-St-Tk:SubWord-Char&Phoneme&Syllable',\n",
      "                                                                           'RL**B-St-Tk:SubWord-Char&Phoneme&Syllable=>B-St-Tk:SubWord:Char&Phoneme&Syllable']}\n",
      "{'B-St-Tk:SubWord-CharGrn': 'B-St-Tk:SubWord:Char',\n",
      " 'B-St-Tk:SubWord-PhonemeGrn': 'B-St-Tk:SubWord:Phoneme',\n",
      " 'B-St-Tk:SubWord-SyllableGrn': 'B-St-Tk:SubWord:Syllable',\n",
      " 'B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable': 'B-St-Tk:SubWord:Char&Phoneme&Syllable'}\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "struct_name = 'CharGrn^PhonemeGrn^SyllableGrn==>Tk:SubWord'\n",
    "# struct_name = 'Tk:AnnoGrn^Tk:POSGrn^Tk:SlfGrn^Tk:SubWord==>St'\n",
    "####################################\n",
    "\n",
    "fullname_input_list, final_fullname_output, struct_model, NAME_2_FULLNAME = get_struct_info(struct_name, NAME_2_FULLNAME)\n",
    "fullname_input = '^'.join(fullname_input_list)\n",
    "D_model, D_data = generate_structure(fullname_input_list, struct_model)\n",
    "\n",
    "struct_para = {}\n",
    "struct_para['fullname_input_list'] = fullname_input_list\n",
    "struct_para['fullname_input'] = fullname_input\n",
    "struct_para['final_fullname_output'] = final_fullname_output\n",
    "struct_para['struct_model'] = struct_model\n",
    "struct_para['D_model'] = D_model\n",
    "struct_para['D_data'] = D_data\n",
    "\n",
    "\n",
    "print(fullname_input_list)\n",
    "print(fullname_input)\n",
    "print(final_fullname_output)\n",
    "print(struct_model)\n",
    "# print(name2fullname)\n",
    "pprint(D_model)\n",
    "pprint(D_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e10edec-04d9-4b07-9ea4-1105b64bef59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pipeline_name <---------- EL**B-St-Tk:SubWord-CharGrn=>B-St-Tk:SubWord-Char \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char']\n",
      "\n",
      "pipeline_name <---------- RL**B-St-Tk:SubWord-Char=>B-St-Tk:SubWord:Char \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char']\n",
      "\n",
      "pipeline_name <---------- EL**B-St-Tk:SubWord-PhonemeGrn=>B-St-Tk:SubWord-Phoneme \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme']\n",
      "\n",
      "pipeline_name <---------- RL**B-St-Tk:SubWord-Phoneme=>B-St-Tk:SubWord:Phoneme \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme']\n",
      "\n",
      "pipeline_name <---------- EL**B-St-Tk:SubWord-SyllableGrn=>B-St-Tk:SubWord-Syllable \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable']\n",
      "\n",
      "pipeline_name <---------- RL**B-St-Tk:SubWord-Syllable=>B-St-Tk:SubWord:Syllable \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable']\n",
      "\n",
      "pipeline_name <---------- ML**B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable=>B-St-Tk:SubWord-Char&Phoneme&Syllable \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable']\n",
      "\n",
      "pipeline_name <---------- RL**B-St-Tk:SubWord-Char&Phoneme&Syllable=>B-St-Tk:SubWord:Char&Phoneme&Syllable \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable']\n",
      "\n",
      " Final <---------- \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord']\n"
     ]
    }
   ],
   "source": [
    "Struct = Struct_Layer(struct_name, struct_para, meta_para)\n",
    "# print(Struct)\n",
    "FLD_2_DATA = Struct(FLD_2_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "08fdcb1b-da69-415a-a96d-5ccddbabd3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 3, 3, 3, 3, 3],\n",
       "        [3, 3, 3, 3, 3, 0],\n",
       "        [3, 3, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = FLD_2_DATA[Struct.final_fullname_output]\n",
    "data['holder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "16d1303b-1ba9-401c-8415-feacfd3224ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2597, -0.2254,  1.9363,  0.8205, -0.0266, -0.0107],\n",
       "        [-0.0383,  0.0350, -0.0070,  6.2519, -0.0233,  0.0000],\n",
       "        [-0.8864,  0.5318,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['info'][:,:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4574391f-b91c-46fb-9d55-a3dbf1bd1528",
   "metadata": {},
   "source": [
    "### Struct 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f70c150-4cf4-40b0-98d2-1dc19b117c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-St-Tk:AnnoGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:SlfGrn', 'B-St-Tk:SubWord']\n",
      "B-St-Tk:AnnoGrn^B-St-Tk:POSGrn^B-St-Tk:SlfGrn^B-St-Tk:SubWord\n",
      "B-St\n",
      "MLRLRL\n",
      "{'B-St-Tk:AnnoGrn': ['EL**B-St-Tk:AnnoGrn=>B-St-Tk:Anno'],\n",
      " 'B-St-Tk:Anno^B-St-Tk:POS^B-St-Tk:Slf^B-St-Tk:SubWord': ['ML**B-St-Tk:Anno^B-St-Tk:POS^B-St-Tk:Slf^B-St-Tk:SubWord=>B-St-Tk-Anno&POS&Slf&SubWord',\n",
      "                                                          'RL**B-St-Tk-Anno&POS&Slf&SubWord=>B-St-Tk:Anno&POS&Slf&SubWord',\n",
      "                                                          'RL**B-St-Tk:Anno&POS&Slf&SubWord=>B-St:Tk:Anno&POS&Slf&SubWord'],\n",
      " 'B-St-Tk:POSGrn': ['EL**B-St-Tk:POSGrn=>B-St-Tk:POS'],\n",
      " 'B-St-Tk:SlfGrn': ['EL**B-St-Tk:SlfGrn=>B-St-Tk:Slf'],\n",
      " 'B-St-Tk:SubWord': []}\n",
      "{'B-St-Tk:AnnoGrn': 'B-St-Tk:Anno',\n",
      " 'B-St-Tk:Anno^B-St-Tk:POS^B-St-Tk:Slf^B-St-Tk:SubWord': 'B-St:Tk:Anno&POS&Slf&SubWord',\n",
      " 'B-St-Tk:POSGrn': 'B-St-Tk:POS',\n",
      " 'B-St-Tk:SlfGrn': 'B-St-Tk:Slf',\n",
      " 'B-St-Tk:SubWord': 'B-St-Tk:SubWord'}\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "# struct_name = 'CharGrn^PhonemeGrn^SyllableGrn==>Tk:SubWord'\n",
    "struct_name = 'Tk:AnnoGrn^Tk:POSGrn^Tk:SlfGrn^Tk:SubWord==>St'\n",
    "####################################\n",
    "\n",
    "fullname_input_list, final_fullname_output, struct_model, NAME_2_FULLNAME = get_struct_info(struct_name, NAME_2_FULLNAME)\n",
    "fullname_input = '^'.join(fullname_input_list)\n",
    "D_model, D_data = generate_structure(fullname_input_list, struct_model)\n",
    "\n",
    "struct_para = {}\n",
    "struct_para['fullname_input_list'] = fullname_input_list\n",
    "struct_para['fullname_input'] = fullname_input\n",
    "struct_para['final_fullname_output'] = final_fullname_output\n",
    "struct_para['struct_model'] = struct_model\n",
    "struct_para['D_model'] = D_model\n",
    "struct_para['D_data'] = D_data\n",
    "\n",
    "\n",
    "print(fullname_input_list)\n",
    "print(fullname_input)\n",
    "print(final_fullname_output)\n",
    "print(struct_model)\n",
    "# print(name2fullname)\n",
    "pprint(D_model)\n",
    "pprint(D_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3f5d5ef3-c14d-4995-b7b3-d5c585952701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pipeline_name <---------- EL**B-St-Tk:AnnoGrn=>B-St-Tk:Anno \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno']\n",
      "\n",
      "pipeline_name <---------- EL**B-St-Tk:POSGrn=>B-St-Tk:POS \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS']\n",
      "\n",
      "pipeline_name <---------- EL**B-St-Tk:SlfGrn=>B-St-Tk:Slf \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf']\n",
      "\n",
      "pipeline_name <---------- ML**B-St-Tk:Anno^B-St-Tk:POS^B-St-Tk:Slf^B-St-Tk:SubWord=>B-St-Tk-Anno&POS&Slf&SubWord \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord']\n",
      "\n",
      "pipeline_name <---------- RL**B-St-Tk-Anno&POS&Slf&SubWord=>B-St-Tk:Anno&POS&Slf&SubWord \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord']\n",
      "\n",
      "pipeline_name <---------- RL**B-St-Tk:Anno&POS&Slf&SubWord=>B-St:Tk:Anno&POS&Slf&SubWord \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord']\n",
      "\n",
      " Final <---------- \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n"
     ]
    }
   ],
   "source": [
    "Struct = Struct_Layer(struct_name, struct_para, meta_para)\n",
    "# print(Struct)\n",
    "FLD_2_DATA = Struct(FLD_2_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "53b999cb-208c-4454-b486-ff8390344763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RL**B-St-Tk:Anno&POS&Slf&SubWord=>B-St:Tk:Anno&POS&Slf&SubWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "222574a8-67aa-4784-80d8-55322304dc86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-St-Tk:AnnoGrn',\n",
       " 'B-St-Tk:POSGrn',\n",
       " 'B-St-Tk:SlfGrn',\n",
       " 'B-St-Tk:SubWord',\n",
       " 'B-St-Tk:Anno^B-St-Tk:POS^B-St-Tk:Slf^B-St-Tk:SubWord']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in Struct.Layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "de4b137a-5b9c-4669-9d55-a9ab043fad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_fullname = 'B-St-Tk:Anno^B-St-Tk:POS^B-St-Tk:Slf^B-St-Tk:SubWord'\n",
    "# pipeline_name = 'RL**B-St-Tk:Anno&POS&Slf&SubWord=>B-St:Tk:Anno&POS&Slf&SubWord'\n",
    "\n",
    "\n",
    "# Pipeline = Struct.Layers[input_fullname][pipeline_name]\n",
    "# print(Pipeline.input_fullname)\n",
    "# print(Pipeline.output_fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "443c5719-5a98-4768-895d-76a4e3716c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = FLD_2_DATA[Pipeline.input_fullname]\n",
    "# data['holder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "59813680-4b1d-4fd2-a3bd-f58b39f68faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b80657ca-d4f5-4faf-9e2c-1d7dfc7b1cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7b7b20c6-5c61-4404-97b3-d81ea0aa59f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLD_2_DATA = Pipeline(FLD_2_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2f5d2772-9c8f-494d-9273-da7d6464e030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [i for i in FLD_2_DATA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0e7dae57-0d27-42fc-b795-7e3521d0feba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = FLD_2_DATA['B-St:Tk:Anno&POS&Slf&SubWord']\n",
    "# data['holder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b00466f1-2f04-4c93-a378-29548f8b4f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['info'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fd6a7b-5525-4a5a-b04a-79cdbbac3f9e",
   "metadata": {},
   "source": [
    "# FieldRepr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab87c124-b29d-47d0-a253-42062135ab80",
   "metadata": {},
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b1e4e150-4841-445c-953f-41ec4e66932b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# from .pipeline import Pipeline_Layer\n",
    "# from ..utils.parafn import process_sublayer_name\n",
    "\n",
    "class FieldRepr_Layer(torch.nn.Module):\n",
    "    def __init__(self, FLD_LIST, FLD_END, meta_para):\n",
    "        super(FieldRepr_Layer, self).__init__()\n",
    "        \n",
    "        df_struct = get_structures_from_fldlist(FLD_LIST)\n",
    "        tmp = df_struct.sort_values('layers', ascending = False)\n",
    "        layer2structlist = dict(zip(tmp['layers'].to_list(), tmp['struct_name'].to_list()))\n",
    "        \n",
    "        NAME_2_FULLNAME = {i.split('-')[-1]:i for i in FLD_LIST}\n",
    "\n",
    "        self.FLD_LIST = FLD_LIST\n",
    "        self.FLD_END = FLD_END\n",
    "        self.NAME_2_FULLNAME = NAME_2_FULLNAME\n",
    "\n",
    "        self.LAYERS = torch.nn.ModuleDict()\n",
    "        for layer, structlist in layer2structlist.items():\n",
    "            self.LAYERS[layer] = torch.nn.ModuleDict()\n",
    "            for struct_name in structlist:\n",
    "                \n",
    "                # construct struct_para\n",
    "                fullname_input_list, final_fullname_output, struct_model, NAME_2_FULLNAME = get_struct_info(struct_name, NAME_2_FULLNAME)\n",
    "                fullname_input = '^'.join(fullname_input_list)\n",
    "                D_model, D_data = generate_structure(fullname_input_list, struct_model)\n",
    "                struct_para = {}\n",
    "                struct_para['fullname_input_list'] = fullname_input_list\n",
    "                struct_para['fullname_input'] = fullname_input\n",
    "                struct_para['final_fullname_output'] = final_fullname_output\n",
    "                struct_para['struct_model'] = struct_model\n",
    "                struct_para['D_model'] = D_model\n",
    "                struct_para['D_data'] = D_data\n",
    "                self.LAYERS[layer][struct_name] = Struct_Layer(struct_name, struct_para, meta_para)\n",
    "\n",
    "    def forward(self, FLD_2_DATA):\n",
    "        for layer, LayerDict in self.LAYERS.items():\n",
    "            for struct_name, StructLayer in LayerDict.items():\n",
    "                print(f'\\nstruct_name <---------- {struct_name} ')\n",
    "                print([i for i in FLD_2_DATA])\n",
    "                FLD_2_DATA = StructLayer(FLD_2_DATA)\n",
    "                print([i for i in FLD_2_DATA])\n",
    "                \n",
    "        assert self.FLD_END in FLD_2_DATA\n",
    "        return FLD_2_DATA[self.FLD_END]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358a8ea9-f294-49bb-b2e7-de457e2cca55",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bf5a0ff3-b80a-4353-8090-75ccdec7d042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 5)\n",
      "3\n",
      "3 --> (3, 6, 5)\n",
      "4 --> (3, 6, 5, 5)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 9)\n",
      "3\n",
      "3 --> (3, 6, 9)\n",
      "4 --> (3, 6, 9, 5)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 6)\n",
      "3\n",
      "3 --> (3, 6, 6)\n",
      "4 --> (3, 6, 6, 2)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 3)\n",
      "3\n",
      "3 --> (3, 6, 3)\n",
      "4 --> (3, 6, 3, 4)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 1)\n",
      "3\n",
      "3 --> (3, 6, 1)\n",
      "4 --> (3, 6, 1, 9)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 5)\n",
      "3\n",
      "3 --> (3, 6, 5)\n",
      "4 --> (3, 6, 5, 1)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 1)\n",
      "3\n",
      "3 --> (3, 6, 1)\n",
      "4 --> (3, 6, 1, 4)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 5)\n",
      "3\n",
      "3 --> (3, 6, 5)\n",
      "4 --> (3, 6, 5, 9)\n",
      "4\n",
      "4 --> (3, 6, 5, 9)\n",
      "5 --> (3, 6, 5, 9, 6)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 8)\n",
      "3\n",
      "3 --> (3, 6, 8)\n",
      "4 --> (3, 6, 8, 2)\n",
      "4\n",
      "4 --> (3, 6, 8, 2)\n",
      "5 --> (3, 6, 8, 2, 3)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 3)\n",
      "3\n",
      "3 --> (3, 6, 3)\n",
      "4 --> (3, 6, 3, 8)\n",
      "4\n",
      "4 --> (3, 6, 3, 8)\n",
      "5 --> (3, 6, 3, 8, 9)\n",
      "5\n",
      "5 --> (3, 6, 3, 8, 9)\n",
      "6 --> (3, 6, 3, 8, 9, 1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from fieldnn.utils.layerfn import traverse\n",
    "from fieldnn.utils.simulate import get_next_info, get_simulated_tensor_from_fldname\n",
    "\n",
    "B_lenP = 3\n",
    "B2P_lnEC = [6, 5, 2] # \n",
    "prefix_layers_num = 2\n",
    "vocab_size = 100\n",
    "\n",
    "###############\n",
    "# FLD_LIST = [\n",
    "# 'B-St-Tk:SlfGrn',\n",
    "# 'B-St-Tk:POSGrn',\n",
    "# 'B-St-Tk:AnnoGrn',\n",
    "# 'B-St-Tk:SubWord-CharGrn',\n",
    "# 'B-St-Tk:SubWord-SyllableGrn',\n",
    "# 'B-St-Tk:SubWord-PhonemeGrn',\n",
    "# ]\n",
    "\n",
    "# FLD_END = 'B-St'\n",
    "\n",
    "FLD_LIST = [\n",
    "'B-P-EC:Diag-DiagRec:DiagV-DiagVdftGrn',\n",
    "'B-P-EC:Diag-DiagRec:DiagDT-DiagDTdftGrn',\n",
    "    \n",
    "'B-P-EC:Med-MedRec:MedV-MedVdftGrn',\n",
    "'B-P-EC:Med-MedRec:MedDT-MedDTdftGrn',\n",
    "    \n",
    "'B-P-EC:A1C-A1CRec:A1CV-A1CVdftGrn',\n",
    "'B-P-EC:A1C-A1CRec:A1CDT-A1CDTdftGrn',\n",
    "    \n",
    "'B-P-EC:PN-PNRec:SctName-SNdftGrn',\n",
    "'B-P-EC:PN-PNRec:SctText-SctSent-Tk:SelfGrn',\n",
    "'B-P-EC:PN-PNRec:SctText-SctSent-Tk:POSGrn',\n",
    "'B-P-EC:PN-PNRec:SctText-SctSent-Tk:SubWord-CharGrn',\n",
    "]\n",
    "\n",
    "FLD_END = 'B-P'\n",
    "\n",
    "###############\n",
    "Ignore_PSN_Layers = FLD_LIST[0].split('-')[:2]\n",
    "\n",
    "\n",
    "\n",
    "NAME_2_FULLNAME = {i.split('-')[-1]:i for i in FLD_LIST}\n",
    "\n",
    "###############\n",
    "FLD_2_VOCABSIZE = {k: np.random.randint(5000) for k in FLD_LIST}\n",
    "\n",
    "#####################\n",
    "FLD_2_DATA = {}\n",
    "\n",
    "for fullname in FLD_LIST:\n",
    "    vocab_size = FLD_2_VOCABSIZE[fullname]\n",
    "    info_idx = get_simulated_tensor_from_fldname(fullname, B_lenP, B2P_lnEC, prefix_layers_num, vocab_size)\n",
    "    # print(info_idx.shape)\n",
    "    holder = torch.LongTensor(info_idx)\n",
    "    # info_idx = torch.LongTensor(info_idx)\n",
    "    FLD_2_DATA[fullname] = {'holder': holder, 'info': 'Empty'}\n",
    "    \n",
    "######################\n",
    "embed_size = 512\n",
    "expander_process = {# 'activator': 'gelu',\n",
    "           'dropout': {'p': 0.5, 'inplace': False},\n",
    "           'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "\n",
    "default_process = {'activator': 'gelu',\n",
    "           'dropout': {'p': 0.5, 'inplace': False},\n",
    "           'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "\n",
    "default_learner_para  = {\n",
    "    'nn_name': 'TFM',\n",
    "    'nn_para': {'num_encoder_layers': 6}\n",
    "}\n",
    "default_reducer_para  = {\n",
    "    'nn_name': 'Max',\n",
    "}\n",
    "##################################\n",
    "\n",
    "\n",
    "meta_para = {}\n",
    "meta_para['FLD_2_VOCABSIZE'] = FLD_2_VOCABSIZE\n",
    "meta_para['embed_size'] = embed_size\n",
    "meta_para['expander_process'] = expander_process\n",
    "meta_para['default_process'] = default_process\n",
    "meta_para['default_learner_para'] = default_learner_para\n",
    "meta_para['default_reducer_para'] = default_reducer_para\n",
    "meta_para['Ignore_PSN_Layers'] = Ignore_PSN_Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "30923986-093c-4633-8bdd-444c5790167a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2-3': ['CharGrn^PhonemeGrn^SyllableGrn==>Tk:SubWord'],\n",
       " '1-2': ['Tk:AnnoGrn^Tk:POSGrn^Tk:SlfGrn^Tk:SubWord==>St']}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# name2fullname = {i.split('-')[-1]:i for i in fld_list}\n",
    "df_struct = get_structures_from_fldlist(FLD_LIST)\n",
    "# df_struct# .sort_values('layers', ascending = False)['struct_name'].to_list()\n",
    "\n",
    "tmp = df_struct.sort_values('layers', ascending = False)\n",
    "layer2structlist = dict(zip(tmp['layers'].to_list(), tmp['struct_name'].to_list()))\n",
    "layer2structlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a2e29643-e151-4159-ba79-5c304b98cfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "FieldRepr = FieldRepr_Layer(FLD_LIST, FLD_END, meta_para)\n",
    "# FieldRepr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0d410e8b-199e-4570-9fd7-b20a6fc31ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "struct_name <---------- CharGrn^PhonemeGrn^SyllableGrn==>Tk:SubWord \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "\n",
      "pipeline_name <---------- EL**B-St-Tk:SubWord-CharGrn=>B-St-Tk:SubWord-Char \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "\n",
      "pipeline_name <---------- RL**B-St-Tk:SubWord-Char=>B-St-Tk:SubWord:Char \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "\n",
      "pipeline_name <---------- EL**B-St-Tk:SubWord-PhonemeGrn=>B-St-Tk:SubWord-Phoneme \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "\n",
      "pipeline_name <---------- RL**B-St-Tk:SubWord-Phoneme=>B-St-Tk:SubWord:Phoneme \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "\n",
      "pipeline_name <---------- EL**B-St-Tk:SubWord-SyllableGrn=>B-St-Tk:SubWord-Syllable \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "\n",
      "pipeline_name <---------- RL**B-St-Tk:SubWord-Syllable=>B-St-Tk:SubWord:Syllable \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "\n",
      "pipeline_name <---------- ML**B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable=>B-St-Tk:SubWord-Char&Phoneme&Syllable \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "\n",
      "pipeline_name <---------- RL**B-St-Tk:SubWord-Char&Phoneme&Syllable=>B-St-Tk:SubWord:Char&Phoneme&Syllable \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "\n",
      " Final <---------- \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "\n",
      "struct_name <---------- Tk:AnnoGrn^Tk:POSGrn^Tk:SlfGrn^Tk:SubWord==>St \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "\n",
      "pipeline_name <---------- EL**B-St-Tk:AnnoGrn=>B-St-Tk:Anno \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "\n",
      "pipeline_name <---------- EL**B-St-Tk:POSGrn=>B-St-Tk:POS \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "\n",
      "pipeline_name <---------- EL**B-St-Tk:SlfGrn=>B-St-Tk:Slf \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "\n",
      "pipeline_name <---------- ML**B-St-Tk:Anno^B-St-Tk:POS^B-St-Tk:Slf^B-St-Tk:SubWord=>B-St-Tk-Anno&POS&Slf&SubWord \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "\n",
      "pipeline_name <---------- RL**B-St-Tk-Anno&POS&Slf&SubWord=>B-St-Tk:Anno&POS&Slf&SubWord \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "\n",
      "pipeline_name <---------- RL**B-St-Tk:Anno&POS&Slf&SubWord=>B-St:Tk:Anno&POS&Slf&SubWord \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "\n",
      " Final <---------- \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n"
     ]
    }
   ],
   "source": [
    "data = FieldRepr(FLD_2_DATA)\n",
    "# data['info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "10c5e060-59c5-434f-b3e9-06560271aa7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['info'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "72463a80-0bf7-45ec-8c16-a98ab3abe00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252563456"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in FieldRepr.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d6abfd17-ddbf-40e1-8199-ee7c396fab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for para in FieldRepr.parameters():\n",
    "#     print(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a7083cd6-c255-4d07-9ab3-a1ef9dd1a842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252563456"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in FieldRepr.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dd1b56-2824-4997-a778-c98700fe95f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
