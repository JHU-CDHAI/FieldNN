{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dcdda58-1ee5-4203-8bd8-0a98875d5915",
   "metadata": {},
   "source": [
    "# Simulate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "747e8363-fee4-4d5f-9fe5-e546881c17f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from fieldnn.utils.layerfn import traverse\n",
    "from fieldnn.utils.simulate import get_next_info, get_simulated_tensor_from_fldname\n",
    "\n",
    "B_lenP = 3\n",
    "B2P_lnEC = [6, 5, 2] # \n",
    "prefix_layers_num = 2\n",
    "vocab_size = 100 \n",
    "Ignore_PSN_Layers = ['B', 'St']\n",
    "\n",
    "###############\n",
    "# FLD_LIST = [\n",
    "# 'B-St-Tk:SlfGrn',\n",
    "# 'B-St-Tk:POSGrn',\n",
    "# 'B-St-Tk:AnnoGrn',\n",
    "# 'B-St-Tk:SubWord-CharGrn',\n",
    "# 'B-St-Tk:SubWord-SyllableGrn',\n",
    "# 'B-St-Tk:SubWord-PhonemeGrn',\n",
    "# ]\n",
    "\n",
    "\n",
    "### TODO:\n",
    "# FLD_END = 'B-St'\n",
    "# FLD_END = 'B-St-Tk'\n",
    "\n",
    "FLD_LIST = [\n",
    "'B-PatRec:EC-ECRec:Diag-DiagRec:DiagV-DiagVdftGrn',\n",
    "'B-PatRec:EC-ECRec:Diag-DiagRec:DiagDT-DiagDTdftGrn',\n",
    "\n",
    "'B-PatRec:EC-ECRec:Med-MedRec:MedV-MedVdftGrn',\n",
    "'B-PatRec:EC-ECRec:Med-MedRec:MedDT-MedDTdftGrn',\n",
    "\n",
    "'B-PatRec:EC-ECRec:A1C-A1CRec:A1CV-A1CVdftGrn',\n",
    "'B-PatRec:EC-ECRec:A1C-A1CRec:A1CDT-A1CDTdftGrn',\n",
    "    \n",
    "'B-PatRec:EC-ECRec:PN-PNRec:PNDT-DTdftGrn',\n",
    "'B-PatRec:EC-ECRec:PN-PNRec:SctName-SNdftGrn',\n",
    "'B-PatRec:EC-ECRec:PN-PNRec:SctText-SctSent-TkLLMGrn',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b70bfe15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 9)\n",
      "3\n",
      "3 --> (3, 6, 9)\n",
      "4 --> (3, 6, 9, 5)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 6)\n",
      "3\n",
      "3 --> (3, 6, 6)\n",
      "4 --> (3, 6, 6, 2)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 5)\n",
      "3\n",
      "3 --> (3, 6, 5)\n",
      "4 --> (3, 6, 5, 5)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 8)\n",
      "3\n",
      "3 --> (3, 6, 8)\n",
      "4 --> (3, 6, 8, 1)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 9)\n",
      "3\n",
      "3 --> (3, 6, 9)\n",
      "4 --> (3, 6, 9, 6)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 8)\n",
      "3\n",
      "3 --> (3, 6, 8)\n",
      "4 --> (3, 6, 8, 7)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 5)\n",
      "3\n",
      "3 --> (3, 6, 5)\n",
      "4 --> (3, 6, 5, 2)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 4)\n",
      "3\n",
      "3 --> (3, 6, 4)\n",
      "4 --> (3, 6, 4, 3)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 9)\n",
      "3\n",
      "3 --> (3, 6, 9)\n",
      "4 --> (3, 6, 9, 8)\n",
      "4\n",
      "4 --> (3, 6, 9, 8)\n",
      "5 --> (3, 6, 9, 8, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# FLD_END = 'B-P'\n",
    "# FLD_END = 'B-P-EC'\n",
    "\n",
    "\n",
    "###############\n",
    "NAME_2_FULLNAME = {i.split('-')[-1]:i for i in FLD_LIST}\n",
    "\n",
    "###############\n",
    "FLD_2_VOCABSIZE = {k: np.random.randint(5000) for k in FLD_LIST}\n",
    "\n",
    "#####################\n",
    "FLD_2_DATA = {}\n",
    "\n",
    "for fullname in FLD_LIST:\n",
    "    vocab_size = FLD_2_VOCABSIZE[fullname]\n",
    "    info_idx = get_simulated_tensor_from_fldname(fullname, B_lenP, B2P_lnEC, prefix_layers_num, vocab_size)\n",
    "    # print(info_idx.shape)\n",
    "    holder = torch.LongTensor(info_idx)\n",
    "    # info_idx = torch.LongTensor(info_idx)\n",
    "    FLD_2_DATA[fullname] = {'holder': holder, 'info': 'Empty'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb405fff-ce4a-4810-8c4c-8c6f9fe27fb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "B-PatRec:EC-ECRec:Diag-DiagRec:DiagV-DiagVdftGrn\n",
      "torch.Size([3, 6, 9, 5])\n",
      "\n",
      "B-PatRec:EC-ECRec:Diag-DiagRec:DiagDT-DiagDTdftGrn\n",
      "torch.Size([3, 6, 6, 2])\n",
      "\n",
      "B-PatRec:EC-ECRec:Med-MedRec:MedV-MedVdftGrn\n",
      "torch.Size([3, 6, 5, 5])\n",
      "\n",
      "B-PatRec:EC-ECRec:Med-MedRec:MedDT-MedDTdftGrn\n",
      "torch.Size([3, 6, 8, 1])\n",
      "\n",
      "B-PatRec:EC-ECRec:A1C-A1CRec:A1CV-A1CVdftGrn\n",
      "torch.Size([3, 6, 9, 6])\n",
      "\n",
      "B-PatRec:EC-ECRec:A1C-A1CRec:A1CDT-A1CDTdftGrn\n",
      "torch.Size([3, 6, 8, 7])\n",
      "\n",
      "B-PatRec:EC-ECRec:PN-PNRec:PNDT-DTdftGrn\n",
      "torch.Size([3, 6, 5, 2])\n",
      "\n",
      "B-PatRec:EC-ECRec:PN-PNRec:SctName-SNdftGrn\n",
      "torch.Size([3, 6, 4, 3])\n",
      "\n",
      "B-PatRec:EC-ECRec:PN-PNRec:SctText-SctSent-TkLLMGrn\n",
      "torch.Size([3, 6, 9, 8, 4])\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "for fullname, data in FLD_2_DATA.items():\n",
    "    print(f'\\n{fullname}')\n",
    "    holder = data['holder']\n",
    "    print(holder.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b83ef92e-e0f8-4188-9e8b-a56037105ed9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# st: sentence\n",
    "# Tk:SlfGrn: Token's as itself. Token. \n",
    "# data = FLD_2_DATA['B-St-Tk:SlfGrn']\n",
    "# data['holder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "596dfc7c-e9b8-434c-9646-7a7453941451",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6, 9, 8, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['holder'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33ff330-5c56-4872-96b9-8103c9e5066d",
   "metadata": {},
   "source": [
    "# Data Flow Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbd2ee14-3ca0-4345-99bb-be6c28a6165d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_dataflow_info(fld_list):\n",
    "    df = pd.DataFrame([i.split('-') for i in fld_list])\n",
    "    L = []\n",
    "    for idx, row in df.iterrows():\n",
    "        for layer_idx in range(1, len(row) - 1):\n",
    "\n",
    "            # f'{layer_idx}-{(layer_idx + 1)}' + ':' +\n",
    "            a, b = layer_idx, layer_idx + 1\n",
    "            if row[b] == None: continue\n",
    "            if row[a] == None: continue\n",
    "            layer_nn_name =  f'{a}-{b}@{row[a]}-{row[b]}'\n",
    "            if layer_nn_name not in L:\n",
    "                L.append(layer_nn_name)\n",
    "    # print(L)\n",
    "    layers = [i.split('@')[0] for i in L]\n",
    "    L = [i.split('@')[-1] for i in L]\n",
    "    # print(layers)\n",
    "    info = pd.DataFrame({'layers': layers, 'nn': L}).sort_values('nn').reset_index(drop = True)\n",
    "    return info\n",
    "\n",
    "\n",
    "def get_merge_layernn(x):\n",
    "    D = {}\n",
    "    layer_name = x[0].split(':')[0]\n",
    "    for i in x:\n",
    "        i = i.split(':')[-1]\n",
    "        a, b = i.split('-')\n",
    "        if a not in D:\n",
    "            D[a] = [b]\n",
    "        else:\n",
    "            D[a].append(b)\n",
    "    \n",
    "    L = []\n",
    "    for parent, childrens in D.items():\n",
    "        if len(childrens) >= 2:\n",
    "            L.append(layer_name + ':' + parent + '-' + '&'.join(childrens))\n",
    "    return L\n",
    "\n",
    "\n",
    "def get_single_layernn(x):\n",
    "    D = {}\n",
    "    layer_name = x[0].split(':')[0]\n",
    "    for i in x:\n",
    "        i = i.split(':')[-1]\n",
    "        a, b = i.split('-')\n",
    "        if a not in D:\n",
    "            D[a] = [b]\n",
    "        else:\n",
    "            D[a].append(b)\n",
    "    \n",
    "    L = []\n",
    "    for parent, childrens in D.items():\n",
    "        if len(childrens) == 1:\n",
    "            L.append(layer_name + ':' + parent + '-' + '&'.join(childrens))\n",
    "    return L\n",
    "    \n",
    "    \n",
    "def generate_df_struct(fld_list, mergefirst_fld_list):\n",
    "    info = get_dataflow_info(fld_list)\n",
    "    df_struct = info.groupby('layers').apply(lambda x: x['nn'].to_list()).reset_index()\n",
    "    df_struct.columns = ['layers', 'nn']\n",
    "    # df_struct['grn'] = df_struct['nn'].apply(lambda x: [i for i in x if 'Grn' in i])\n",
    "    # df_struct['fld'] = df_struct['nn'].apply(lambda x: [i for i in x if 'Grn' not in i])\n",
    "    # df_struct\n",
    "\n",
    "    df_struct['single'] = df_struct['nn'].apply(lambda x: get_single_layernn(x))\n",
    "    df_struct['merge'] = df_struct['nn'].apply(lambda x: get_merge_layernn(x))\n",
    "\n",
    "    df_struct['mergefirst'] = df_struct['merge'].apply(lambda x: [i for i in x if i.split('-')[-1] in mergefirst_fld_list])\n",
    "    df_struct['mergelast'] = df_struct['merge'].apply(lambda x: [i for i in x if i.split('-')[-1] not in mergefirst_fld_list])\n",
    "    # df_struct = df_struct.drop(columns = ['merge'])\n",
    "    return df_struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26ced28f-dba9-46a6-a65f-8adb70daf8fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_merge_layernn(x):\n",
    "    D = {}\n",
    "    for i in x:\n",
    "        # i = i.split(':')[-1]\n",
    "        a, b = i.split('-')\n",
    "        if a not in D:\n",
    "            D[a] = [b]\n",
    "        else:\n",
    "            D[a].append(b)\n",
    "    \n",
    "    L = []\n",
    "    for parent, childrens in D.items():\n",
    "        L.append(f'{\"^\".join(childrens)}==>{parent}')\n",
    "\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66ed71b9-54ed-4c64-a2da-7fdaff8c4612",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_structures_from_fldlist(fld_list):\n",
    "    info = get_dataflow_info(fld_list)# .groupby('layers')\n",
    "    df_struct = info.groupby('layers').apply(lambda x: x['nn'].to_list()).reset_index()\n",
    "    df_struct.columns = ['layers', 'nn']\n",
    "    # # df_struct\n",
    "    # info\n",
    "    df_struct['struct_name'] = df_struct['nn'].apply(lambda x: get_merge_layernn(x))\n",
    "    # for nn_list in df_struct['nn'].values:\n",
    "    #     # print(nn_list)\n",
    "    #     for nn_name in nn_list:\n",
    "    #         print(nn_name)\n",
    "    #         # print(nn_name.split('-'))\n",
    "    #     # print()\n",
    "    #     x = nn_list\n",
    "    #     L = get_merge_layernn(x)\n",
    "    #     print(L)\n",
    "    return df_struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb4cfd50-13f8-4a4f-8af3-c1eb6b959e04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layers</th>\n",
       "      <th>nn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3-4</td>\n",
       "      <td>A1CRec:A1CDT-A1CDTdftGrn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3-4</td>\n",
       "      <td>A1CRec:A1CV-A1CVdftGrn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3-4</td>\n",
       "      <td>DiagRec:DiagDT-DiagDTdftGrn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3-4</td>\n",
       "      <td>DiagRec:DiagV-DiagVdftGrn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2-3</td>\n",
       "      <td>ECRec:A1C-A1CRec:A1CDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2-3</td>\n",
       "      <td>ECRec:A1C-A1CRec:A1CV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2-3</td>\n",
       "      <td>ECRec:Diag-DiagRec:DiagDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2-3</td>\n",
       "      <td>ECRec:Diag-DiagRec:DiagV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2-3</td>\n",
       "      <td>ECRec:Med-MedRec:MedDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2-3</td>\n",
       "      <td>ECRec:Med-MedRec:MedV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2-3</td>\n",
       "      <td>ECRec:PN-PNRec:PNDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2-3</td>\n",
       "      <td>ECRec:PN-PNRec:SctName</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2-3</td>\n",
       "      <td>ECRec:PN-PNRec:SctText</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3-4</td>\n",
       "      <td>MedRec:MedDT-MedDTdftGrn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3-4</td>\n",
       "      <td>MedRec:MedV-MedVdftGrn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3-4</td>\n",
       "      <td>PNRec:PNDT-DTdftGrn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3-4</td>\n",
       "      <td>PNRec:SctName-SNdftGrn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3-4</td>\n",
       "      <td>PNRec:SctText-SctSent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1-2</td>\n",
       "      <td>PatRec:EC-ECRec:A1C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1-2</td>\n",
       "      <td>PatRec:EC-ECRec:Diag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1-2</td>\n",
       "      <td>PatRec:EC-ECRec:Med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1-2</td>\n",
       "      <td>PatRec:EC-ECRec:PN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4-5</td>\n",
       "      <td>SctSent-TkLLMGrn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   layers                           nn\n",
       "0     3-4     A1CRec:A1CDT-A1CDTdftGrn\n",
       "1     3-4       A1CRec:A1CV-A1CVdftGrn\n",
       "2     3-4  DiagRec:DiagDT-DiagDTdftGrn\n",
       "3     3-4    DiagRec:DiagV-DiagVdftGrn\n",
       "4     2-3       ECRec:A1C-A1CRec:A1CDT\n",
       "5     2-3        ECRec:A1C-A1CRec:A1CV\n",
       "6     2-3    ECRec:Diag-DiagRec:DiagDT\n",
       "7     2-3     ECRec:Diag-DiagRec:DiagV\n",
       "8     2-3       ECRec:Med-MedRec:MedDT\n",
       "9     2-3        ECRec:Med-MedRec:MedV\n",
       "10    2-3          ECRec:PN-PNRec:PNDT\n",
       "11    2-3       ECRec:PN-PNRec:SctName\n",
       "12    2-3       ECRec:PN-PNRec:SctText\n",
       "13    3-4     MedRec:MedDT-MedDTdftGrn\n",
       "14    3-4       MedRec:MedV-MedVdftGrn\n",
       "15    3-4          PNRec:PNDT-DTdftGrn\n",
       "16    3-4       PNRec:SctName-SNdftGrn\n",
       "17    3-4        PNRec:SctText-SctSent\n",
       "18    1-2          PatRec:EC-ECRec:A1C\n",
       "19    1-2         PatRec:EC-ECRec:Diag\n",
       "20    1-2          PatRec:EC-ECRec:Med\n",
       "21    1-2           PatRec:EC-ECRec:PN\n",
       "22    4-5             SctSent-TkLLMGrn"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = get_dataflow_info(FLD_LIST)\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89aca461-109c-44d0-98e5-c9d673c703b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layers</th>\n",
       "      <th>nn</th>\n",
       "      <th>struct_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-2</td>\n",
       "      <td>[PatRec:EC-ECRec:A1C, PatRec:EC-ECRec:Diag, Pa...</td>\n",
       "      <td>[ECRec:A1C^ECRec:Diag^ECRec:Med^ECRec:PN==&gt;Pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-3</td>\n",
       "      <td>[ECRec:A1C-A1CRec:A1CDT, ECRec:A1C-A1CRec:A1CV...</td>\n",
       "      <td>[A1CRec:A1CDT^A1CRec:A1CV==&gt;ECRec:A1C, DiagRec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3-4</td>\n",
       "      <td>[A1CRec:A1CDT-A1CDTdftGrn, A1CRec:A1CV-A1CVdft...</td>\n",
       "      <td>[A1CDTdftGrn==&gt;A1CRec:A1CDT, A1CVdftGrn==&gt;A1CR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4-5</td>\n",
       "      <td>[SctSent-TkLLMGrn]</td>\n",
       "      <td>[TkLLMGrn==&gt;SctSent]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  layers                                                 nn  \\\n",
       "0    1-2  [PatRec:EC-ECRec:A1C, PatRec:EC-ECRec:Diag, Pa...   \n",
       "1    2-3  [ECRec:A1C-A1CRec:A1CDT, ECRec:A1C-A1CRec:A1CV...   \n",
       "2    3-4  [A1CRec:A1CDT-A1CDTdftGrn, A1CRec:A1CV-A1CVdft...   \n",
       "3    4-5                                 [SctSent-TkLLMGrn]   \n",
       "\n",
       "                                         struct_name  \n",
       "0  [ECRec:A1C^ECRec:Diag^ECRec:Med^ECRec:PN==>Pat...  \n",
       "1  [A1CRec:A1CDT^A1CRec:A1CV==>ECRec:A1C, DiagRec...  \n",
       "2  [A1CDTdftGrn==>A1CRec:A1CDT, A1CVdftGrn==>A1CR...  \n",
       "3                               [TkLLMGrn==>SctSent]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_struct = get_structures_from_fldlist(FLD_LIST)\n",
    "df_struct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d6bfba-6c89-4a8c-9a1c-00d8fdeeeedf",
   "metadata": {},
   "source": [
    "# Struct Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7e9efc5-1aa8-4c6c-a5d4-c7b6e261ca96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_struct_info(struct_name, NAME_2_FULLNAME):\n",
    "    inputs = struct_name.split('==>')[0].split('^')\n",
    "    output = struct_name.split('==>')[1]\n",
    "    fullname_inputs = [NAME_2_FULLNAME[i] for i in inputs]\n",
    "    fullname_output = '-'.join(fullname_inputs[0].split('-')[:-2]) + '-' + output\n",
    "    \n",
    "    NAME_2_FULLNAME[output] = fullname_output\n",
    "\n",
    "    if len(inputs) == 1:\n",
    "        struct_model = 'RL'\n",
    "    elif len(inputs) > 1:\n",
    "        tmp = list(set([len(i.split(':')) for i in inputs]))\n",
    "        assert len(tmp) == 1\n",
    "        struct_model = 'MLRLRL' if tmp[0] == 2 else 'RLMLRL'\n",
    "        \n",
    "        \n",
    "        # TODO HERE\n",
    "        # 'MLRL'\n",
    "    return fullname_inputs, fullname_output, struct_model, NAME_2_FULLNAME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef802fab-8db9-44b0-9361-5ed74f0a60a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_structure(fullname_inputs, struct_model):\n",
    "    # each input\n",
    "    D_model = {}\n",
    "    D_data = {}\n",
    "    \n",
    "    # things before M\n",
    "    stages = struct_model.split('M')\n",
    "    preM = stages[0]\n",
    "    for fullname in fullname_inputs:\n",
    "        input_field = fullname\n",
    "        L = []\n",
    "        # print('\\n=== EL ===')\n",
    "        if 'Grn' in fullname:\n",
    "            inp = fullname\n",
    "            out = fullname.replace('Grn', '')\n",
    "            name = f'EL**{inp}=>{out}'\n",
    "            L.append(name)\n",
    "            fullname = out\n",
    "        \n",
    "        if 'R' in preM:\n",
    "            # print('\\n=== RL ===')\n",
    "            inp = fullname\n",
    "            out = '-'.join(fullname.split('-')[:-1]) + ':' + fullname.split('-')[-1]\n",
    "            fullname = out\n",
    "            name = f'RL**{inp}=>{out}'\n",
    "            L.append(name)\n",
    "        \n",
    "        D_model[input_field] = L\n",
    "        D_data[input_field] = fullname\n",
    "\n",
    "    if 'M' not in struct_model:\n",
    "        return D_model, D_data\n",
    "    \n",
    "    else:\n",
    "        # print('\\n=== ML ===')\n",
    "        L = [v for k, v in D_data.items()]\n",
    "        parents = ['-'.join(i.split('-')[:-1]) for i in L]\n",
    "        # print(parents)\n",
    "        assert len(set(parents)) == 1\n",
    "        parent = parents[0]\n",
    "\n",
    "        name_new_list = [i.split('-')[-1] for i in L]\n",
    "        prefixes = [':'.join(i.split(':')[:-1]) for i in name_new_list]\n",
    "        assert len(set(prefixes)) == 1\n",
    "        prefix = prefixes[0]\n",
    "\n",
    "        fields = [i.split(':')[-1] for i in name_new_list]\n",
    "        new_layer = '&'.join(fields)\n",
    "        new_name = '-'.join([prefix, new_layer])\n",
    "        fullname = parent + '-' + new_name\n",
    "\n",
    "        Model_list = []\n",
    "        inp = '^'.join(L)\n",
    "        out = fullname\n",
    "        name = f'ML**{inp}=>{out}'\n",
    "        Model_list.append(name)\n",
    "    \n",
    "    # post M\n",
    "    if len(stages) == 1:\n",
    "        # no post M\n",
    "        D_model['^'.join(L)] = Model_list\n",
    "        D_data['^'.join(L)] = fullname\n",
    "        return D_model, D_data\n",
    "    else:\n",
    "        postM = stages[-1]\n",
    "        for i in range(postM.count('R')):\n",
    "            # print('\\n=== RL ===')\n",
    "            inp = fullname\n",
    "            out = '-'.join(inp.split('-')[:-1]) + ':' + inp.split('-')[-1]\n",
    "            # print(out)\n",
    "            name = f'RL**{inp}=>{out}'\n",
    "            Model_list.append(name)\n",
    "            fullname = out\n",
    "\n",
    "        D_model['^'.join(L)] = Model_list\n",
    "        D_data['^'.join(L)] = fullname\n",
    "        # final_fullname = ':'.join(fullname.split(':')[:-1])\n",
    "        return D_model, D_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba860aeb-c837-4268-83e0-0d08c555b0ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4-5': ['TkLLMGrn==>SctSent'],\n",
       " '3-4': ['A1CDTdftGrn==>A1CRec:A1CDT',\n",
       "  'A1CVdftGrn==>A1CRec:A1CV',\n",
       "  'DiagDTdftGrn==>DiagRec:DiagDT',\n",
       "  'DiagVdftGrn==>DiagRec:DiagV',\n",
       "  'MedDTdftGrn==>MedRec:MedDT',\n",
       "  'MedVdftGrn==>MedRec:MedV',\n",
       "  'DTdftGrn==>PNRec:PNDT',\n",
       "  'SNdftGrn==>PNRec:SctName',\n",
       "  'SctSent==>PNRec:SctText'],\n",
       " '2-3': ['A1CRec:A1CDT^A1CRec:A1CV==>ECRec:A1C',\n",
       "  'DiagRec:DiagDT^DiagRec:DiagV==>ECRec:Diag',\n",
       "  'MedRec:MedDT^MedRec:MedV==>ECRec:Med',\n",
       "  'PNRec:PNDT^PNRec:SctName^PNRec:SctText==>ECRec:PN'],\n",
       " '1-2': ['ECRec:A1C^ECRec:Diag^ECRec:Med^ECRec:PN==>PatRec:EC']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_struct = get_structures_from_fldlist(FLD_LIST)\n",
    "\n",
    "tmp = df_struct.sort_values('layers', ascending = False)\n",
    "layer2modulelist = dict(zip(tmp['layers'].to_list(), tmp['struct_name'].to_list()))\n",
    "layer2modulelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4e36fda-26e4-4146-94e4-dffa7dbffaac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4-5': ['TkLLMGrn==>SctSent'],\n",
       " '3-4': ['A1CDTdftGrn==>A1CRec:A1CDT',\n",
       "  'A1CVdftGrn==>A1CRec:A1CV',\n",
       "  'DiagDTdftGrn==>DiagRec:DiagDT',\n",
       "  'DiagVdftGrn==>DiagRec:DiagV',\n",
       "  'MedDTdftGrn==>MedRec:MedDT',\n",
       "  'MedVdftGrn==>MedRec:MedV',\n",
       "  'DTdftGrn==>PNRec:PNDT',\n",
       "  'SNdftGrn==>PNRec:SctName',\n",
       "  'SctSent==>PNRec:SctText'],\n",
       " '2-3': ['A1CRec:A1CDT^A1CRec:A1CV==>ECRec:A1C',\n",
       "  'DiagRec:DiagDT^DiagRec:DiagV==>ECRec:Diag',\n",
       "  'MedRec:MedDT^MedRec:MedV==>ECRec:Med',\n",
       "  'PNRec:PNDT^PNRec:SctName^PNRec:SctText==>ECRec:PN'],\n",
       " '1-2': ['ECRec:A1C^ECRec:Diag^ECRec:Med^ECRec:PN==>PatRec:EC']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# name2fullname = {i.split('-')[-1]:i for i in fld_list}\n",
    "df_struct = get_structures_from_fldlist(FLD_LIST)\n",
    "# df_struct# .sort_values('layers', ascending = False)['struct_name'].to_list()\n",
    "\n",
    "tmp = df_struct.sort_values('layers', ascending = False)\n",
    "layer2modulelist = dict(zip(tmp['layers'].to_list(), tmp['struct_name'].to_list()))\n",
    "layer2modulelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d2bc1d3-5a4f-4a61-a6fa-91c52ebea778",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-PatRec:EC-ECRec:Diag-DiagRec:DiagV-DiagVdftGrn\n",
      "{'B-PatRec:EC-ECRec:Diag-DiagRec:DiagV-DiagVdftGrn': ('Embedding',\n",
      "                                                      {'embedding_size': 512,\n",
      "                                                       'init': 'random',\n",
      "                                                       'input_size': 1277}),\n",
      " 'Ignore_PSN_Layers': ['B', 'PatRec:EC'],\n",
      " 'input_size': None,\n",
      " 'output_size': 512,\n",
      " 'postprocess': {'activator': 'gelu',\n",
      "                 'dropout': {'inplace': False, 'p': 0.5},\n",
      "                 'layernorm': {'elementwise_affine': True, 'eps': 1e-05}}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from fieldnn.utils.parafn import get_expander_para\n",
    "\n",
    "fullname = FLD_LIST[0]\n",
    "print(fullname)\n",
    "\n",
    "embed_size = 512\n",
    "\n",
    "expander_process = {# 'activator': 'gelu',\n",
    "           'dropout': {'p': 0.5, 'inplace': False},\n",
    "           'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "\n",
    "\n",
    "process = {'activator': 'gelu',\n",
    "           'dropout': {'p': 0.5, 'inplace': False},\n",
    "           'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "\n",
    "nn_name = 'Embedding'\n",
    "vocab_size = FLD_2_VOCABSIZE[fullname]\n",
    "nn_para = {'input_size': vocab_size}\n",
    "postprocess = process\n",
    "Ignore_PSN_Layers = fullname.split('-')[:2]\n",
    "expander_layer_para = get_expander_para(fullname, nn_name, nn_para, embed_size, \n",
    "                                        Ignore_PSN_Layers, \n",
    "                                        postprocess\n",
    "                                       )\n",
    "pprint(expander_layer_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e67e5777-7ac1-4d74-b3cc-11e545bbe521",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-5 TkLLMGrn==>SctSent\n",
      "----> (input) B-PatRec:EC-ECRec:PN-PNRec:SctText-SctSent-TkLLMGrn\n",
      "   ----> (pipeline name) EL**B-PatRec:EC-ECRec:PN-PNRec:SctText-SctSent-TkLLMGrn=>B-PatRec:EC-ECRec:PN-PNRec:SctText-SctSent-TkLLM\n",
      "   ----> (pipeline name) RL**B-PatRec:EC-ECRec:PN-PNRec:SctText-SctSent-TkLLM=>B-PatRec:EC-ECRec:PN-PNRec:SctText-SctSent:TkLLM\n",
      "3-4 A1CDTdftGrn==>A1CRec:A1CDT\n",
      "----> (input) B-PatRec:EC-ECRec:A1C-A1CRec:A1CDT-A1CDTdftGrn\n",
      "   ----> (pipeline name) EL**B-PatRec:EC-ECRec:A1C-A1CRec:A1CDT-A1CDTdftGrn=>B-PatRec:EC-ECRec:A1C-A1CRec:A1CDT-A1CDTdft\n",
      "   ----> (pipeline name) RL**B-PatRec:EC-ECRec:A1C-A1CRec:A1CDT-A1CDTdft=>B-PatRec:EC-ECRec:A1C-A1CRec:A1CDT:A1CDTdft\n",
      "3-4 A1CVdftGrn==>A1CRec:A1CV\n",
      "----> (input) B-PatRec:EC-ECRec:A1C-A1CRec:A1CV-A1CVdftGrn\n",
      "   ----> (pipeline name) EL**B-PatRec:EC-ECRec:A1C-A1CRec:A1CV-A1CVdftGrn=>B-PatRec:EC-ECRec:A1C-A1CRec:A1CV-A1CVdft\n",
      "   ----> (pipeline name) RL**B-PatRec:EC-ECRec:A1C-A1CRec:A1CV-A1CVdft=>B-PatRec:EC-ECRec:A1C-A1CRec:A1CV:A1CVdft\n",
      "3-4 DiagDTdftGrn==>DiagRec:DiagDT\n",
      "----> (input) B-PatRec:EC-ECRec:Diag-DiagRec:DiagDT-DiagDTdftGrn\n",
      "   ----> (pipeline name) EL**B-PatRec:EC-ECRec:Diag-DiagRec:DiagDT-DiagDTdftGrn=>B-PatRec:EC-ECRec:Diag-DiagRec:DiagDT-DiagDTdft\n",
      "   ----> (pipeline name) RL**B-PatRec:EC-ECRec:Diag-DiagRec:DiagDT-DiagDTdft=>B-PatRec:EC-ECRec:Diag-DiagRec:DiagDT:DiagDTdft\n",
      "3-4 DiagVdftGrn==>DiagRec:DiagV\n",
      "----> (input) B-PatRec:EC-ECRec:Diag-DiagRec:DiagV-DiagVdftGrn\n",
      "   ----> (pipeline name) EL**B-PatRec:EC-ECRec:Diag-DiagRec:DiagV-DiagVdftGrn=>B-PatRec:EC-ECRec:Diag-DiagRec:DiagV-DiagVdft\n",
      "   ----> (pipeline name) RL**B-PatRec:EC-ECRec:Diag-DiagRec:DiagV-DiagVdft=>B-PatRec:EC-ECRec:Diag-DiagRec:DiagV:DiagVdft\n",
      "3-4 MedDTdftGrn==>MedRec:MedDT\n",
      "----> (input) B-PatRec:EC-ECRec:Med-MedRec:MedDT-MedDTdftGrn\n",
      "   ----> (pipeline name) EL**B-PatRec:EC-ECRec:Med-MedRec:MedDT-MedDTdftGrn=>B-PatRec:EC-ECRec:Med-MedRec:MedDT-MedDTdft\n",
      "   ----> (pipeline name) RL**B-PatRec:EC-ECRec:Med-MedRec:MedDT-MedDTdft=>B-PatRec:EC-ECRec:Med-MedRec:MedDT:MedDTdft\n",
      "3-4 MedVdftGrn==>MedRec:MedV\n",
      "----> (input) B-PatRec:EC-ECRec:Med-MedRec:MedV-MedVdftGrn\n",
      "   ----> (pipeline name) EL**B-PatRec:EC-ECRec:Med-MedRec:MedV-MedVdftGrn=>B-PatRec:EC-ECRec:Med-MedRec:MedV-MedVdft\n",
      "   ----> (pipeline name) RL**B-PatRec:EC-ECRec:Med-MedRec:MedV-MedVdft=>B-PatRec:EC-ECRec:Med-MedRec:MedV:MedVdft\n",
      "3-4 DTdftGrn==>PNRec:PNDT\n",
      "----> (input) B-PatRec:EC-ECRec:PN-PNRec:PNDT-DTdftGrn\n",
      "   ----> (pipeline name) EL**B-PatRec:EC-ECRec:PN-PNRec:PNDT-DTdftGrn=>B-PatRec:EC-ECRec:PN-PNRec:PNDT-DTdft\n",
      "   ----> (pipeline name) RL**B-PatRec:EC-ECRec:PN-PNRec:PNDT-DTdft=>B-PatRec:EC-ECRec:PN-PNRec:PNDT:DTdft\n",
      "3-4 SNdftGrn==>PNRec:SctName\n",
      "----> (input) B-PatRec:EC-ECRec:PN-PNRec:SctName-SNdftGrn\n",
      "   ----> (pipeline name) EL**B-PatRec:EC-ECRec:PN-PNRec:SctName-SNdftGrn=>B-PatRec:EC-ECRec:PN-PNRec:SctName-SNdft\n",
      "   ----> (pipeline name) RL**B-PatRec:EC-ECRec:PN-PNRec:SctName-SNdft=>B-PatRec:EC-ECRec:PN-PNRec:SctName:SNdft\n",
      "3-4 SctSent==>PNRec:SctText\n",
      "----> (input) B-PatRec:EC-ECRec:PN-PNRec:SctText-SctSent\n",
      "   ----> (pipeline name) RL**B-PatRec:EC-ECRec:PN-PNRec:SctText-SctSent=>B-PatRec:EC-ECRec:PN-PNRec:SctText:SctSent\n",
      "2-3 A1CRec:A1CDT^A1CRec:A1CV==>ECRec:A1C\n",
      "----> (input) B-PatRec:EC-ECRec:A1C-A1CRec:A1CDT\n",
      "----> (input) B-PatRec:EC-ECRec:A1C-A1CRec:A1CV\n",
      "----> (input) B-PatRec:EC-ECRec:A1C-A1CRec:A1CDT^B-PatRec:EC-ECRec:A1C-A1CRec:A1CV\n",
      "   ----> (pipeline name) ML**B-PatRec:EC-ECRec:A1C-A1CRec:A1CDT^B-PatRec:EC-ECRec:A1C-A1CRec:A1CV=>B-PatRec:EC-ECRec:A1C-A1CRec-A1CDT&A1CV\n",
      "   ----> (pipeline name) RL**B-PatRec:EC-ECRec:A1C-A1CRec-A1CDT&A1CV=>B-PatRec:EC-ECRec:A1C-A1CRec:A1CDT&A1CV\n",
      "   ----> (pipeline name) RL**B-PatRec:EC-ECRec:A1C-A1CRec:A1CDT&A1CV=>B-PatRec:EC-ECRec:A1C:A1CRec:A1CDT&A1CV\n",
      "2-3 DiagRec:DiagDT^DiagRec:DiagV==>ECRec:Diag\n",
      "----> (input) B-PatRec:EC-ECRec:Diag-DiagRec:DiagDT\n",
      "----> (input) B-PatRec:EC-ECRec:Diag-DiagRec:DiagV\n",
      "----> (input) B-PatRec:EC-ECRec:Diag-DiagRec:DiagDT^B-PatRec:EC-ECRec:Diag-DiagRec:DiagV\n",
      "   ----> (pipeline name) ML**B-PatRec:EC-ECRec:Diag-DiagRec:DiagDT^B-PatRec:EC-ECRec:Diag-DiagRec:DiagV=>B-PatRec:EC-ECRec:Diag-DiagRec-DiagDT&DiagV\n",
      "   ----> (pipeline name) RL**B-PatRec:EC-ECRec:Diag-DiagRec-DiagDT&DiagV=>B-PatRec:EC-ECRec:Diag-DiagRec:DiagDT&DiagV\n",
      "   ----> (pipeline name) RL**B-PatRec:EC-ECRec:Diag-DiagRec:DiagDT&DiagV=>B-PatRec:EC-ECRec:Diag:DiagRec:DiagDT&DiagV\n",
      "2-3 MedRec:MedDT^MedRec:MedV==>ECRec:Med\n",
      "----> (input) B-PatRec:EC-ECRec:Med-MedRec:MedDT\n",
      "----> (input) B-PatRec:EC-ECRec:Med-MedRec:MedV\n",
      "----> (input) B-PatRec:EC-ECRec:Med-MedRec:MedDT^B-PatRec:EC-ECRec:Med-MedRec:MedV\n",
      "   ----> (pipeline name) ML**B-PatRec:EC-ECRec:Med-MedRec:MedDT^B-PatRec:EC-ECRec:Med-MedRec:MedV=>B-PatRec:EC-ECRec:Med-MedRec-MedDT&MedV\n",
      "   ----> (pipeline name) RL**B-PatRec:EC-ECRec:Med-MedRec-MedDT&MedV=>B-PatRec:EC-ECRec:Med-MedRec:MedDT&MedV\n",
      "   ----> (pipeline name) RL**B-PatRec:EC-ECRec:Med-MedRec:MedDT&MedV=>B-PatRec:EC-ECRec:Med:MedRec:MedDT&MedV\n",
      "2-3 PNRec:PNDT^PNRec:SctName^PNRec:SctText==>ECRec:PN\n",
      "----> (input) B-PatRec:EC-ECRec:PN-PNRec:PNDT\n",
      "----> (input) B-PatRec:EC-ECRec:PN-PNRec:SctName\n",
      "----> (input) B-PatRec:EC-ECRec:PN-PNRec:SctText\n",
      "----> (input) B-PatRec:EC-ECRec:PN-PNRec:PNDT^B-PatRec:EC-ECRec:PN-PNRec:SctName^B-PatRec:EC-ECRec:PN-PNRec:SctText\n",
      "   ----> (pipeline name) ML**B-PatRec:EC-ECRec:PN-PNRec:PNDT^B-PatRec:EC-ECRec:PN-PNRec:SctName^B-PatRec:EC-ECRec:PN-PNRec:SctText=>B-PatRec:EC-ECRec:PN-PNRec-PNDT&SctName&SctText\n",
      "   ----> (pipeline name) RL**B-PatRec:EC-ECRec:PN-PNRec-PNDT&SctName&SctText=>B-PatRec:EC-ECRec:PN-PNRec:PNDT&SctName&SctText\n",
      "   ----> (pipeline name) RL**B-PatRec:EC-ECRec:PN-PNRec:PNDT&SctName&SctText=>B-PatRec:EC-ECRec:PN:PNRec:PNDT&SctName&SctText\n",
      "1-2 ECRec:A1C^ECRec:Diag^ECRec:Med^ECRec:PN==>PatRec:EC\n",
      "----> (input) B-PatRec:EC-ECRec:A1C\n",
      "----> (input) B-PatRec:EC-ECRec:Diag\n",
      "----> (input) B-PatRec:EC-ECRec:Med\n",
      "----> (input) B-PatRec:EC-ECRec:PN\n",
      "----> (input) B-PatRec:EC-ECRec:A1C^B-PatRec:EC-ECRec:Diag^B-PatRec:EC-ECRec:Med^B-PatRec:EC-ECRec:PN\n",
      "   ----> (pipeline name) ML**B-PatRec:EC-ECRec:A1C^B-PatRec:EC-ECRec:Diag^B-PatRec:EC-ECRec:Med^B-PatRec:EC-ECRec:PN=>B-PatRec:EC-ECRec-A1C&Diag&Med&PN\n",
      "   ----> (pipeline name) RL**B-PatRec:EC-ECRec-A1C&Diag&Med&PN=>B-PatRec:EC-ECRec:A1C&Diag&Med&PN\n",
      "   ----> (pipeline name) RL**B-PatRec:EC-ECRec:A1C&Diag&Med&PN=>B-PatRec:EC:ECRec:A1C&Diag&Med&PN\n"
     ]
    }
   ],
   "source": [
    "StructName2Settings = {}\n",
    "for layername, struct_list in layer2modulelist.items():\n",
    "    # print(layername, struct_list)\n",
    "    for struct_name in struct_list:\n",
    "        print(layername, struct_name)\n",
    "        fullname_inputs, fullname_output, struct_model, NAME_2_FULLNAME = get_struct_info(struct_name, NAME_2_FULLNAME)\n",
    "        D_model, D_data = generate_structure(fullname_inputs, struct_model)\n",
    "        \n",
    "        d = {}\n",
    "        d['fullname_inputs'] = fullname_inputs\n",
    "        d['fullname_output'] = fullname_output\n",
    "        d['struct_model'] = struct_model\n",
    "        d['D_model'] = D_model\n",
    "        d['D_data'] = D_data\n",
    "        StructName2Settings[struct_name] = d\n",
    "        \n",
    "        for input_data, pipeline_list in StructName2Settings[struct_name]['D_model'].items():\n",
    "            print('----> (input)', input_data)\n",
    "            for pipeline_name in pipeline_list:\n",
    "                print('   ----> (pipeline name)', pipeline_name)\n",
    "                \n",
    "                sublayer_type, input_output = pipeline_name.split('**')\n",
    "                input_fullnames, output_fullname = input_output.split('=>')\n",
    "                input_fullname_list = input_fullnames.split('^')\n",
    "                \n",
    "                # print('       ----> (+)', sublayer_type)\n",
    "                # print('       ----> (+)', input_fullname_list)\n",
    "                # print('       ----> (+)', output_fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e4dc22b-016a-440c-9ea5-d321a607e497",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pprint(StructName2Settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eb52fd-c7ef-4da2-95b1-892bbefed583",
   "metadata": {},
   "source": [
    "# Pipeline Para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb725415-5d0a-4fba-8481-2bbfb03e38b8",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2faa90c3-6786-4cc8-8e8f-3b707ebbbc98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_fullname_from_inputs(fullname_list):\n",
    "    names = [i.split('-')[-1] for i in fullname_list]\n",
    "    \n",
    "    prefix = ['-'.join(i.split('-')[:-1]) for i in fullname_list][0]\n",
    "    \n",
    "    table_row_indicator = list(set([i.count(':') for i in names]))[0]\n",
    "    \n",
    "    if table_row_indicator == 0:\n",
    "        fullname = f'{prefix}-{\"&\".join(names)}'\n",
    "    elif table_row_indicator >= 1:\n",
    "        table_name = [':'.join(i.split(':')[:-1]) for i in names][0]\n",
    "        columns =  [i.split(':')[-1] for i in names]\n",
    "        fullname = f'{prefix}-{table_name}-{\"&\".join(columns)}'\n",
    "    else:\n",
    "        raise ValueError(f'\"table_row_indicator\" {table_row_indicator} if not correct')\n",
    "    return fullname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9adccec-d479-49e2-8184-3f87859135c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fieldnn.utils.parafn import get_expander_para, get_learner_para, get_reducer_para, get_merger_para\n",
    "# from fieldnn.utils.parafn import get_fullname_from_inputs\n",
    "# from .parafn import get_expander_para, get_learner_para, get_reducer_para, get_merger_para\n",
    "# from .parafn import get_fullname_from_inputs\n",
    "\n",
    "default_learner_para  = {\n",
    "    'nn_name': 'TFM',\n",
    "    'nn_para': {'num_encoder_layers': 6}\n",
    "}\n",
    "\n",
    "default_reducer_para  = {\n",
    "    'nn_name': 'Max',\n",
    "}\n",
    "\n",
    "\n",
    "def get_EL_sublayer_para_list(input_fullname_list, \n",
    "                              FLD_2_VOCABSIZE, \n",
    "                              embed_size,\n",
    "                              default_learner_para, \n",
    "                              expander_process, \n",
    "                              default_process, \n",
    "                              Ignore_PSN_Layers):\n",
    "    # print(input_fullname_list)\n",
    "    assert len(input_fullname_list) == 1\n",
    "    fullname = input_fullname_list[0]\n",
    "    output_fullname = fullname.replace('Grn', '')\n",
    "    ###########\n",
    "    nn_name = 'Embedding'\n",
    "    vocab_size = FLD_2_VOCABSIZE[fullname]\n",
    "    nn_para = {'input_size': vocab_size}\n",
    "    postprocess = expander_process\n",
    "    ###########\n",
    "    expander_layer_para = get_expander_para(fullname, nn_name, nn_para, embed_size, \n",
    "                                            Ignore_PSN_Layers, \n",
    "                                            postprocess\n",
    "                                           )\n",
    "    # print(expander_layer_para)\n",
    "    ###########\n",
    "    \n",
    "    nn_name = default_learner_para['nn_name']\n",
    "    nn_para = default_learner_para['nn_para']\n",
    "    input_size = embed_size\n",
    "    output_size = embed_size\n",
    "    embedprocess = default_process\n",
    "    postprocess = default_process\n",
    "    ###########\n",
    "    learner_layer_para  = get_learner_para(output_fullname, \n",
    "                                           nn_name, nn_para, \n",
    "                                           input_size, output_size, \n",
    "                                           Ignore_PSN_Layers, \n",
    "                                           embedprocess, postprocess\n",
    "                                          )\n",
    "    # print(learner_layer_para)\n",
    "    para_dict = {'Expander': expander_layer_para, 'Learner': learner_layer_para}\n",
    "    return para_dict\n",
    "\n",
    "\n",
    "\n",
    "def get_RL_sublayer_para_list(input_fullname_list, \n",
    "                              embed_size, \n",
    "                              default_learner_para,\n",
    "                              default_reducer_para,\n",
    "                              default_process,\n",
    "                              Ignore_PSN_Layers):\n",
    "    assert len(input_fullname_list) == 1\n",
    "    fullname = input_fullname_list[0]\n",
    "\n",
    "    #########\n",
    "    nn_name = default_reducer_para['nn_name'] # 'Max'\n",
    "    nn_para = {}\n",
    "    input_size = embed_size\n",
    "    output_size = embed_size if nn_name != 'concat' else embed_size * 3\n",
    "    postprocess = default_process\n",
    "    #########\n",
    "\n",
    "    reducer_layer_para = get_reducer_para(fullname, nn_name, nn_para, input_size, output_size, postprocess)\n",
    "    # print(reducer_layer_para)\n",
    "\n",
    "    ###########\n",
    "    output_fullname = '-'.join(fullname.split('-')[:-1]) + ':' + fullname.split('-')[-1]\n",
    "    \n",
    "    if len(output_fullname.split('-')) == 2:\n",
    "        # B and Obs: from tfm to linear\n",
    "        nn_name = 'linear'\n",
    "        nn_para = {}\n",
    "        embedprocess = {}\n",
    "        postprocess = default_process\n",
    "    \n",
    "    else:\n",
    "        nn_name = default_learner_para['nn_name']\n",
    "        nn_para = default_learner_para['nn_para']\n",
    "        embedprocess = default_process\n",
    "        postprocess = default_process\n",
    "    input_size = embed_size\n",
    "    output_size = embed_size\n",
    "    \n",
    "    ###########\n",
    "    learner_layer_para  = get_learner_para(output_fullname, \n",
    "                                           nn_name, nn_para, \n",
    "                                           input_size, output_size, \n",
    "                                           Ignore_PSN_Layers, \n",
    "                                           embedprocess, postprocess\n",
    "                                          )\n",
    "    # print(learner_layer_para)\n",
    "    para_dict = {'Reducer': reducer_layer_para, 'Learner': learner_layer_para}\n",
    "    return para_dict\n",
    "    \n",
    "\n",
    "def get_ML_sublayer_para_list(input_fullname_list,\n",
    "                              embed_size, \n",
    "                              default_learner_para,\n",
    "                              default_process, \n",
    "                              Ignore_PSN_Layers):\n",
    "    assert len(input_fullname_list) > 1\n",
    "    fullname = '^'.join(input_fullname_list) # input of M\n",
    "    # fullname = get_fullname_from_inputs(input_fullname_list)\n",
    "\n",
    "    #########\n",
    "    nn_name = 'Merger'\n",
    "    nn_para = {}\n",
    "    input_size = embed_size\n",
    "    output_size = embed_size\n",
    "    postprocess = default_process\n",
    "    #########\n",
    "\n",
    "    merger_layer_para = get_merger_para(fullname, nn_name, nn_para, input_size, output_size, postprocess)\n",
    "    # print(merger_layer_para)\n",
    "\n",
    "    ###########\n",
    "    # print(input_fullname_list, '<----get_ML_sublayer_para_list') \n",
    "    fullname = get_fullname_from_inputs(input_fullname_list) # input of L\n",
    "    # print(fullname, '<----get_ML_sublayer_para_list') \n",
    "    nn_name = default_learner_para['nn_name']\n",
    "    nn_para = default_learner_para['nn_para']\n",
    "    input_size = embed_size\n",
    "    output_size = embed_size\n",
    "    embedprocess = default_process\n",
    "    postprocess = default_process\n",
    "    ###########\n",
    "    learner_layer_para  = get_learner_para(fullname, \n",
    "                                           nn_name, nn_para, \n",
    "                                           input_size, output_size, \n",
    "                                           Ignore_PSN_Layers, \n",
    "                                           embedprocess, postprocess\n",
    "                                          )\n",
    "    # print(merger_layer_para)\n",
    "    para_dict = {'Merger': merger_layer_para, 'Learner': learner_layer_para}\n",
    "    return para_dict\n",
    "\n",
    "    \n",
    "\n",
    "def process_pipeline_name(sublayer_name, FLD_2_VOCABSIZE, embed_size, \n",
    "                          default_learner_para,  default_reducer_para,\n",
    "                          expander_process, default_process, Ignore_PSN_Layers):\n",
    "    # print('   ----> (sublayer name)', sublayer_name)   \n",
    "    sublayer_type, input_output = sublayer_name.split('**')\n",
    "    input_fullnames, output_fullname = input_output.split('=>')\n",
    "    input_fullname_list = input_fullnames.split('^')\n",
    "    # print('       ----> (+)', sublayer_type)\n",
    "    # print('       ----> (+)', input_fullname_list)\n",
    "    # print('       ----> (+)', output_fullname)\n",
    "\n",
    "    if 'EL' == sublayer_type:\n",
    "        para_dict = get_EL_sublayer_para_list(input_fullname_list, \n",
    "                                              FLD_2_VOCABSIZE, \n",
    "                                              embed_size,\n",
    "                                              default_learner_para, \n",
    "                                              expander_process, \n",
    "                                              default_process, \n",
    "                                              Ignore_PSN_Layers)\n",
    "    elif 'RL' == sublayer_type:\n",
    "        para_dict = get_RL_sublayer_para_list(input_fullname_list, \n",
    "                                              embed_size, \n",
    "                                              default_learner_para,\n",
    "                                              default_reducer_para,\n",
    "                                              default_process,\n",
    "                                              Ignore_PSN_Layers)\n",
    "    elif 'ML' == sublayer_type:\n",
    "        para_dict = get_ML_sublayer_para_list(input_fullname_list,\n",
    "                                              embed_size, \n",
    "                                              default_learner_para,\n",
    "                                              default_process, \n",
    "                                              Ignore_PSN_Layers)\n",
    "    else:\n",
    "        raise ValueError(f'The sublayer type {sublayer_type} is not available')\n",
    "        \n",
    "        \n",
    "    return input_fullname_list, output_fullname, para_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfd82b3-76c5-4d2d-b4fa-3b2f26e348fd",
   "metadata": {},
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7af5bff4-4422-4e3e-be7a-1a7ccce03338",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# from .expander import Expander_Layer\n",
    "# from .learner import Learner_Layer\n",
    "# from .merger import Merger_Layer\n",
    "\n",
    "from fieldnn.sublayer.expander import Expander_Layer\n",
    "from fieldnn.sublayer.learner import Learner_Layer\n",
    "from fieldnn.sublayer.merger import Merger_Layer\n",
    "from fieldnn.sublayer.reducer import Reducer_Layer\n",
    "\n",
    "\n",
    "class Pipeline_Layer(torch.nn.Module):\n",
    "    def __init__(self, pipeline_name, input_fullname, output_fullname, para_dict):\n",
    "        super(Pipeline_Layer, self).__init__()\n",
    "        \n",
    "        self.pipeline_name = pipeline_name\n",
    "        self.input_fullname = input_fullname\n",
    "        # self.input_fullname_list = input_fullname.split('^')\n",
    "        self.output_fullname = output_fullname\n",
    "        self.para_dict = para_dict\n",
    "        \n",
    "        self.Layers = torch.nn.ModuleDict()\n",
    "        for name, para in para_dict.items():\n",
    "            if name == 'Expander':\n",
    "                assert 'Grn' == input_fullname[-3:]\n",
    "                assert input_fullname.replace('Grn', '') == output_fullname\n",
    "                self.Layers[input_fullname] = Expander_Layer(input_fullname, output_fullname, para)\n",
    "        \n",
    "            elif name == 'Merger':\n",
    "                assert len(input_fullname.split('^')) > 1\n",
    "                self.Layers[input_fullname] = Merger_Layer(input_fullname, output_fullname, para)\n",
    "        \n",
    "            elif name == 'Reducer':\n",
    "                self.Layers[input_fullname] = Reducer_Layer(input_fullname, output_fullname, para)\n",
    "                \n",
    "            elif name == 'Learner':\n",
    "                assert output_fullname in para\n",
    "                self.Layers[output_fullname] = Learner_Layer(output_fullname, output_fullname, para)\n",
    "            else:\n",
    "                raise ValueError(f'The sublayer name \"{name}\" is not available')\n",
    "                \n",
    "    def forward(self, fullname2data):\n",
    "        for input_fullname, Layer in self.Layers.items():\n",
    "            \n",
    "            if '^' not in input_fullname:\n",
    "                # holder, info = fullname2data.pop(input_fullname)\n",
    "                # print(input_fullname, '<---input_fullname')\n",
    "                # print(type(Layer), '<---Layer type')\n",
    "                # print(Layer.input_fullname, '<---Layer type')\n",
    "                # print(Layer.output_fullname, '<---Layer type')\n",
    "                data = fullname2data.get(input_fullname)\n",
    "                holder, info = data['holder'], data['info']\n",
    "                # print(f'input_fullname: {input_fullname}, Layer Type {type(Layer)}')\n",
    "                # print(holder.max())\n",
    "                fullname, holder, info = Layer(input_fullname, holder, info)\n",
    "                # print(fullname, '<--- output fullname')\n",
    "                fullname2data[fullname] = {'holder': holder, 'info': info}\n",
    "            else:\n",
    "                input_fullname_list = input_fullname.split('^')\n",
    "                # print(input_fullname)\n",
    "                # fullname2data_copy = {k: fullname2data.pop(k) for k in input_fullname_list}\n",
    "                fullname2data_copy = {k: fullname2data.get(k) for k in input_fullname_list}\n",
    "                fullname, holder, info = Layer(input_fullname, fullname2data_copy)\n",
    "                fullname2data[fullname] = {'holder': holder, 'info': info}\n",
    "                \n",
    "        return fullname2data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a5556b-0162-4810-aad9-ec2a849752c8",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599af5a9-96bf-457b-91d6-1adb47828a06",
   "metadata": {},
   "source": [
    "### Simulate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "279e7fa3-1a3e-4ffa-aeeb-a643e38a692d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 2)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 4)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 5)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from fieldnn.utils.layerfn import traverse\n",
    "from fieldnn.utils.simulate import get_next_info, get_simulated_tensor_from_fldname\n",
    "\n",
    "B_lenP = 3\n",
    "B2P_lnEC = [6, 5, 2] # \n",
    "prefix_layers_num = 2\n",
    "vocab_size = 100\n",
    "Ignore_PSN_Layers = ['B', 'St']\n",
    "\n",
    "###############\n",
    "FLD_LIST = [\n",
    "'B-St-Tk:SlfGrn',\n",
    "'B-St-Tk:POSGrn',\n",
    "'B-St-Tk:AnnoGrn',\n",
    "'B-St-Tk:SubWord-CharGrn',\n",
    "'B-St-Tk:SubWord-SyllableGrn',\n",
    "'B-St-Tk:SubWord-PhonemeGrn',\n",
    "]\n",
    "\n",
    "# FLD_LIST = [\n",
    "# 'B-P-EC:Diag-DiagRec:DiagV-DiagVdftGrn',\n",
    "# 'B-P-EC:Diag-DiagRec:DiagDT-DiagDTdftGrn',\n",
    "# 'B-P-EC:Med-MedRec:MedV-MedVdftGrn',\n",
    "# 'B-P-EC:Med-MedRec:MedDT-MedDTdftGrn',\n",
    "# 'B-P-EC:A1C-A1CRec:A1CV-A1CVdftGrn',\n",
    "# 'B-P-EC:A1C-A1CRec:A1CDT-A1CDTdftGrn',\n",
    "# 'B-P-EC:PN-PNRec:SctName-SNdftGrn',\n",
    "# 'B-P-EC:PN-PNRec:SctText-SctSent-Tk:SelfGrn',\n",
    "# 'B-P-EC:PN-PNRec:SctText-SctSent-Tk:POSGrn',\n",
    "# 'B-P-EC:PN-PNRec:SctText-SctSent-Tk:SubWord-CharGrn',\n",
    "# ]\n",
    "\n",
    "###############\n",
    "NAME_2_FULLNAME = {i.split('-')[-1]:i for i in FLD_LIST}\n",
    "\n",
    "###############\n",
    "FLD_2_VOCABSIZE = {k: np.random.randint(5000) for k in FLD_LIST}\n",
    "\n",
    "#####################\n",
    "FLD_2_DATA = {}\n",
    "\n",
    "for fullname in FLD_LIST:\n",
    "    vocab_size = FLD_2_VOCABSIZE[fullname]\n",
    "    info_idx = get_simulated_tensor_from_fldname(fullname, B_lenP, B2P_lnEC, prefix_layers_num, vocab_size)\n",
    "    # print(info_idx.shape)\n",
    "    holder = torch.LongTensor(info_idx)\n",
    "    # info_idx = torch.LongTensor(info_idx)\n",
    "    FLD_2_DATA[fullname] = {'holder': holder, 'info': 'Empty'}\n",
    "    \n",
    "######################\n",
    "embed_size = 512\n",
    "expander_process = {# 'activator': 'gelu',\n",
    "           'dropout': {'p': 0.5, 'inplace': False},\n",
    "           'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "\n",
    "default_process = {'activator': 'gelu',\n",
    "           'dropout': {'p': 0.5, 'inplace': False},\n",
    "           'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "\n",
    "default_learner_para  = {\n",
    "    'nn_name': 'TFM',\n",
    "    'nn_para': {'num_encoder_layers': 6}\n",
    "}\n",
    "default_reducer_para  = {\n",
    "    'nn_name': 'Max',\n",
    "}\n",
    "##################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4676d24-b394-4900-886c-55b64a4fb7a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-St-Tk:SlfGrn',\n",
       " 'B-St-Tk:POSGrn',\n",
       " 'B-St-Tk:AnnoGrn',\n",
       " 'B-St-Tk:SubWord-CharGrn',\n",
       " 'B-St-Tk:SubWord-SyllableGrn',\n",
       " 'B-St-Tk:SubWord-PhonemeGrn']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in FLD_2_DATA]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e20ea6-2dac-4415-8c24-a7395ca63770",
   "metadata": {},
   "source": [
    "### Pipeline 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f83ca8d7-eb59-4654-b646-db80954cf22f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-St-Tk:SubWord-CharGrn\n",
      "B-St-Tk:SubWord-Char\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "pipeline_name = 'EL**B-St-Tk:SubWord-CharGrn=>B-St-Tk:SubWord-Char'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Char=>B-St-Tk:SubWord:Char'\n",
    "\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-PhonemeGrn=>B-St-Tk:SubWord-Phoneme'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Phoneme=>B-St-Tk:SubWord:Phoneme'\n",
    "\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-SyllableGrn=>B-St-Tk:SubWord-Syllable'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Syllable=>B-St-Tk:SubWord:Syllable'\n",
    "\n",
    "# pipeline_name = 'ML**B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable=>B-St-Tk:SubWord-Char&Phoneme&Syllable'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Char&Phoneme&Syllable=>B-St-Tk:SubWord:Char&Phoneme&Syllable'\n",
    "######################################################\n",
    "\n",
    "input_fullname_list, output_fullname, para_dict = process_pipeline_name(pipeline_name, FLD_2_VOCABSIZE, embed_size, \n",
    "                                                                        default_learner_para,  default_reducer_para,\n",
    "                                                                        expander_process, default_process, Ignore_PSN_Layers)\n",
    "\n",
    "input_fullname = '^'.join(input_fullname_list)\n",
    "\n",
    "print(input_fullname)\n",
    "print(output_fullname)\n",
    "# pprint(para_dict)\n",
    "PipeLine = Pipeline_Layer(pipeline_name, input_fullname, output_fullname, para_dict)\n",
    "\n",
    "# print(PipeLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d71a5691-967d-4aa9-a7a8-04ee0c001671",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PipeLine.Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03b82c93-e5d3-422a-9729-8070a64d3607",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char']\n"
     ]
    }
   ],
   "source": [
    "print([i for i in FLD_2_DATA])\n",
    "FLD_2_DATA = PipeLine(FLD_2_DATA)\n",
    "print([i for i in FLD_2_DATA]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4fa6d4e-40f3-4498-b5e5-5b512e20a9b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-St-Tk:SubWord-CharGrn\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 970,    0],\n",
       "         [1321,    0],\n",
       "         [ 912,    0],\n",
       "         [1930,  545],\n",
       "         [1907,    0],\n",
       "         [2025,    0]],\n",
       "\n",
       "        [[ 210,  634],\n",
       "         [1484,  357],\n",
       "         [ 547,    0],\n",
       "         [1829,    0],\n",
       "         [2058,  404],\n",
       "         [   0,    0]],\n",
       "\n",
       "        [[1459,  136],\n",
       "         [1414, 1421],\n",
       "         [   0,    0],\n",
       "         [   0,    0],\n",
       "         [   0,    0],\n",
       "         [   0,    0]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(input_fullname)\n",
    "data = FLD_2_DATA[input_fullname]\n",
    "holder = data['holder']\n",
    "holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7231193b-9e9e-4fc8-b6a0-b846a56d0a04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-St-Tk:SubWord-Char\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 970,    0],\n",
       "         [1321,    0],\n",
       "         [ 912,    0],\n",
       "         [1930,  545],\n",
       "         [1907,    0],\n",
       "         [2025,    0]],\n",
       "\n",
       "        [[ 210,  634],\n",
       "         [1484,  357],\n",
       "         [ 547,    0],\n",
       "         [1829,    0],\n",
       "         [2058,  404],\n",
       "         [   0,    0]],\n",
       "\n",
       "        [[1459,  136],\n",
       "         [1414, 1421],\n",
       "         [   0,    0],\n",
       "         [   0,    0],\n",
       "         [   0,    0],\n",
       "         [   0,    0]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(output_fullname)\n",
    "data = FLD_2_DATA[output_fullname]\n",
    "holder = data['holder']\n",
    "holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6ad5dbc-d2d0-4e72-9231-9b0266b5e6e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.2224e-03,  0.0000e+00],\n",
       "         [ 5.0582e-02,  0.0000e+00],\n",
       "         [ 3.0896e-02,  0.0000e+00],\n",
       "         [ 1.2161e+00,  1.9736e-02],\n",
       "         [ 1.2389e+00,  0.0000e+00],\n",
       "         [ 1.7513e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-1.1196e+00,  3.0390e-02],\n",
       "         [-1.0557e-03,  2.1408e+00],\n",
       "         [-1.9254e-02,  0.0000e+00],\n",
       "         [ 1.8443e-03,  0.0000e+00],\n",
       "         [ 3.4973e-01,  1.2583e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-1.8939e-02, -1.9298e+00],\n",
       "         [-2.1509e+00,  2.0860e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00]]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = data['info']\n",
    "info[:,:,:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f574b8b-1501-4e87-b4b2-cf07a3d8322b",
   "metadata": {},
   "source": [
    "### Pipeline 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0599370-a860-4fc2-99d1-3e88ce6986cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-St-Tk:SubWord-Char\n",
      "B-St-Tk:SubWord:Char\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-CharGrn=>B-St-Tk:SubWord-Char'\n",
    "pipeline_name = 'RL**B-St-Tk:SubWord-Char=>B-St-Tk:SubWord:Char'\n",
    "\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-PhonemeGrn=>B-St-Tk:SubWord-Phoneme'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Phoneme=>B-St-Tk:SubWord:Phoneme'\n",
    "\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-SyllableGrn=>B-St-Tk:SubWord-Syllable'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Syllable=>B-St-Tk:SubWord:Syllable'\n",
    "\n",
    "# pipeline_name = 'ML**B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable=>B-St-Tk:SubWord-Char&Phoneme&Syllable'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Char&Phoneme&Syllable=>B-St-Tk:SubWord:Char&Phoneme&Syllable'\n",
    "######################################################\n",
    "\n",
    "input_fullname_list, output_fullname, para_dict = process_pipeline_name(pipeline_name, FLD_2_VOCABSIZE, embed_size, \n",
    "                                                                        default_learner_para,  default_reducer_para,\n",
    "                                                                        expander_process, default_process, Ignore_PSN_Layers)\n",
    "\n",
    "input_fullname = '^'.join(input_fullname_list)\n",
    "\n",
    "print(input_fullname)\n",
    "print(output_fullname)\n",
    "# pprint(para_dict)\n",
    "PipeLine = Pipeline_Layer(pipeline_name, input_fullname, output_fullname, para_dict)\n",
    "\n",
    "# print(PipeLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3ba2947-63f4-4a3a-9b43-f32ed226e91b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char']\n"
     ]
    }
   ],
   "source": [
    "print([i for i in FLD_2_DATA])\n",
    "FLD_2_DATA = PipeLine(FLD_2_DATA)\n",
    "print([i for i in FLD_2_DATA]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32c99533-d59e-422e-8883-b30b4f749370",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-St-Tk:SubWord-Char\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 970,    0],\n",
       "         [1321,    0],\n",
       "         [ 912,    0],\n",
       "         [1930,  545],\n",
       "         [1907,    0],\n",
       "         [2025,    0]],\n",
       "\n",
       "        [[ 210,  634],\n",
       "         [1484,  357],\n",
       "         [ 547,    0],\n",
       "         [1829,    0],\n",
       "         [2058,  404],\n",
       "         [   0,    0]],\n",
       "\n",
       "        [[1459,  136],\n",
       "         [1414, 1421],\n",
       "         [   0,    0],\n",
       "         [   0,    0],\n",
       "         [   0,    0],\n",
       "         [   0,    0]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(input_fullname)\n",
    "data = FLD_2_DATA[input_fullname]\n",
    "holder = data['holder']\n",
    "holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db8bdda2-855c-42d5-b1f0-1f0377911715",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-St-Tk:SubWord:Char\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 2, 1, 1],\n",
       "        [2, 2, 1, 1, 2, 0],\n",
       "        [2, 2, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(output_fullname)\n",
    "data = FLD_2_DATA[output_fullname]\n",
    "holder = data['holder']\n",
    "holder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93d5ed7-e921-46b8-b003-294703db85e7",
   "metadata": {},
   "source": [
    "### Pipeline 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8fc2929c-2524-48fb-927f-5a8daebe42c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-St-Tk:SubWord-PhonemeGrn\n",
      "B-St-Tk:SubWord-Phoneme\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme']\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-CharGrn=>B-St-Tk:SubWord-Char'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Char=>B-St-Tk:SubWord:Char'\n",
    "\n",
    "pipeline_name = 'EL**B-St-Tk:SubWord-PhonemeGrn=>B-St-Tk:SubWord-Phoneme'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Phoneme=>B-St-Tk:SubWord:Phoneme'\n",
    "\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-SyllableGrn=>B-St-Tk:SubWord-Syllable'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Syllable=>B-St-Tk:SubWord:Syllable'\n",
    "\n",
    "# pipeline_name = 'ML**B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable=>B-St-Tk:SubWord-Char&Phoneme&Syllable'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Char&Phoneme&Syllable=>B-St-Tk:SubWord:Char&Phoneme&Syllable'\n",
    "######################################################\n",
    "\n",
    "input_fullname_list, output_fullname, para_dict = process_pipeline_name(pipeline_name, FLD_2_VOCABSIZE, embed_size, \n",
    "                                                                        default_learner_para,  default_reducer_para,\n",
    "                                                                        expander_process, default_process, Ignore_PSN_Layers)\n",
    "\n",
    "input_fullname = '^'.join(input_fullname_list)\n",
    "\n",
    "print(input_fullname)\n",
    "print(output_fullname)\n",
    "# pprint(para_dict)\n",
    "PipeLine = Pipeline_Layer(pipeline_name, input_fullname, output_fullname, para_dict)\n",
    "# print(PipeLine)\n",
    "\n",
    "print([i for i in FLD_2_DATA])\n",
    "FLD_2_DATA = PipeLine(FLD_2_DATA)\n",
    "print([i for i in FLD_2_DATA]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ec75b2-b7b7-47d9-af58-67c0917fa8bb",
   "metadata": {},
   "source": [
    "### Pipeline 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec98f743-7010-4e75-9115-628ccd148f3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-St-Tk:SubWord-Phoneme\n",
      "B-St-Tk:SubWord:Phoneme\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme']\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-CharGrn=>B-St-Tk:SubWord-Char'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Char=>B-St-Tk:SubWord:Char'\n",
    "\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-PhonemeGrn=>B-St-Tk:SubWord-Phoneme'\n",
    "pipeline_name = 'RL**B-St-Tk:SubWord-Phoneme=>B-St-Tk:SubWord:Phoneme'\n",
    "\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-SyllableGrn=>B-St-Tk:SubWord-Syllable'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Syllable=>B-St-Tk:SubWord:Syllable'\n",
    "\n",
    "# pipeline_name = 'ML**B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable=>B-St-Tk:SubWord-Char&Phoneme&Syllable'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Char&Phoneme&Syllable=>B-St-Tk:SubWord:Char&Phoneme&Syllable'\n",
    "######################################################\n",
    "\n",
    "input_fullname_list, output_fullname, para_dict = process_pipeline_name(pipeline_name, FLD_2_VOCABSIZE, embed_size, \n",
    "                                                                        default_learner_para,  default_reducer_para,\n",
    "                                                                        expander_process, default_process, Ignore_PSN_Layers)\n",
    "\n",
    "input_fullname = '^'.join(input_fullname_list)\n",
    "\n",
    "print(input_fullname)\n",
    "print(output_fullname)\n",
    "# pprint(para_dict)\n",
    "PipeLine = Pipeline_Layer(pipeline_name, input_fullname, output_fullname, para_dict)\n",
    "# print(PipeLine)\n",
    "\n",
    "print([i for i in FLD_2_DATA])\n",
    "FLD_2_DATA = PipeLine(FLD_2_DATA)\n",
    "print([i for i in FLD_2_DATA]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15f0942-963f-473a-9b32-880b44260755",
   "metadata": {},
   "source": [
    "### Pipeline 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5639b6f9-46fd-4f1f-831e-ebc0018321b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-St-Tk:SubWord-SyllableGrn\n",
      "B-St-Tk:SubWord-Syllable\n",
      "{'Expander': {'B-St-Tk:SubWord-SyllableGrn': ('Embedding',\n",
      "                                              {'embedding_size': 512,\n",
      "                                               'init': 'random',\n",
      "                                               'input_size': 2963}),\n",
      "              'Ignore_PSN_Layers': ['B', 'St'],\n",
      "              'input_size': None,\n",
      "              'output_size': 512,\n",
      "              'postprocess': {'dropout': {'inplace': False, 'p': 0.5},\n",
      "                              'layernorm': {'elementwise_affine': True,\n",
      "                                            'eps': 1e-05}}},\n",
      " 'Learner': {'B-St-Tk:SubWord-Syllable': ('TFM',\n",
      "                                          {'dim_feedforward': 2048,\n",
      "                                           'input_size': 512,\n",
      "                                           'nhead': 8,\n",
      "                                           'num_decoder_layers': 0,\n",
      "                                           'num_encoder_layers': 6,\n",
      "                                           'output_size': 512,\n",
      "                                           'tfm_activation': 'relu',\n",
      "                                           'tfm_dropout': 0.1}),\n",
      "             'Ignore_PSN_Layers': ['B', 'St'],\n",
      "             'embedprocess': {'activator': 'gelu',\n",
      "                              'dropout': {'inplace': False, 'p': 0.5},\n",
      "                              'layernorm': {'elementwise_affine': True,\n",
      "                                            'eps': 1e-05}},\n",
      "             'input_size': 512,\n",
      "             'output_size': 512,\n",
      "             'postprocess': {'activator': 'gelu',\n",
      "                             'dropout': {'inplace': False, 'p': 0.5},\n",
      "                             'layernorm': {'elementwise_affine': True,\n",
      "                                           'eps': 1e-05}},\n",
      "             'psn_layers': ['Syllable', 'Tk:SubWord']}}\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-CharGrn=>B-St-Tk:SubWord-Char'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Char=>B-St-Tk:SubWord:Char'\n",
    "\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-PhonemeGrn=>B-St-Tk:SubWord-Phoneme'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Phoneme=>B-St-Tk:SubWord:Phoneme'\n",
    "\n",
    "pipeline_name = 'EL**B-St-Tk:SubWord-SyllableGrn=>B-St-Tk:SubWord-Syllable'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Syllable=>B-St-Tk:SubWord:Syllable'\n",
    "\n",
    "# pipeline_name = 'ML**B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable=>B-St-Tk:SubWord-Char&Phoneme&Syllable'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Char&Phoneme&Syllable=>B-St-Tk:SubWord:Char&Phoneme&Syllable'\n",
    "######################################################\n",
    "\n",
    "input_fullname_list, output_fullname, para_dict = process_pipeline_name(pipeline_name, FLD_2_VOCABSIZE, embed_size, \n",
    "                                                                        default_learner_para,  default_reducer_para,\n",
    "                                                                        expander_process, default_process, Ignore_PSN_Layers)\n",
    "\n",
    "input_fullname = '^'.join(input_fullname_list)\n",
    "\n",
    "print(input_fullname)\n",
    "print(output_fullname)\n",
    "pprint(para_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7bbadc5c-2062-4de3-afdf-5b320c5d3ada",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "PipeLine = Pipeline_Layer(pipeline_name, input_fullname, output_fullname, para_dict)\n",
    "# print(PipeLine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea35d954-ffa4-4858-8745-ebb5e032c516",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2938)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = FLD_2_DATA[input_fullname]\n",
    "data['holder'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e9a2745-e74d-4756-838e-1e46438c5be8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print([i for i in FLD_2_DATA])\n",
    "FLD_2_DATA = PipeLine(FLD_2_DATA)\n",
    "print([i for i in FLD_2_DATA]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1afd80-a356-4bb7-af3f-ef7f1c44b875",
   "metadata": {},
   "source": [
    "### Pipeline 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb246545-cc5f-4681-b7a0-161ecbf47223",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-St-Tk:SubWord-Syllable\n",
      "B-St-Tk:SubWord:Syllable\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable']\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-CharGrn=>B-St-Tk:SubWord-Char'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Char=>B-St-Tk:SubWord:Char'\n",
    "\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-PhonemeGrn=>B-St-Tk:SubWord-Phoneme'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Phoneme=>B-St-Tk:SubWord:Phoneme'\n",
    "\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-SyllableGrn=>B-St-Tk:SubWord-Syllable'\n",
    "pipeline_name = 'RL**B-St-Tk:SubWord-Syllable=>B-St-Tk:SubWord:Syllable'\n",
    "\n",
    "# pipeline_name = 'ML**B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable=>B-St-Tk:SubWord-Char&Phoneme&Syllable'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Char&Phoneme&Syllable=>B-St-Tk:SubWord:Char&Phoneme&Syllable'\n",
    "######################################################\n",
    "\n",
    "input_fullname_list, output_fullname, para_dict = process_pipeline_name(pipeline_name, FLD_2_VOCABSIZE, embed_size, \n",
    "                                                                        default_learner_para,  default_reducer_para,\n",
    "                                                                        expander_process, default_process, Ignore_PSN_Layers)\n",
    "\n",
    "input_fullname = '^'.join(input_fullname_list)\n",
    "\n",
    "print(input_fullname)\n",
    "print(output_fullname)\n",
    "# pprint(para_dict)\n",
    "PipeLine = Pipeline_Layer(pipeline_name, input_fullname, output_fullname, para_dict)\n",
    "# print(PipeLine)\n",
    "\n",
    "print([i for i in FLD_2_DATA])\n",
    "FLD_2_DATA = PipeLine(FLD_2_DATA)\n",
    "print([i for i in FLD_2_DATA]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd469f2-137b-4cb7-b627-2b45f75255e5",
   "metadata": {},
   "source": [
    "### Pipeline 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f1127fc-0662-41df-8377-1abd64d9ef1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable\n",
      "B-St-Tk:SubWord-Char&Phoneme&Syllable\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-CharGrn=>B-St-Tk:SubWord-Char'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Char=>B-St-Tk:SubWord:Char'\n",
    "\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-PhonemeGrn=>B-St-Tk:SubWord-Phoneme'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Phoneme=>B-St-Tk:SubWord:Phoneme'\n",
    "\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-SyllableGrn=>B-St-Tk:SubWord-Syllable'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Syllable=>B-St-Tk:SubWord:Syllable'\n",
    "\n",
    "pipeline_name = 'ML**B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable=>B-St-Tk:SubWord-Char&Phoneme&Syllable'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Char&Phoneme&Syllable=>B-St-Tk:SubWord:Char&Phoneme&Syllable'\n",
    "######################################################\n",
    "\n",
    "input_fullname_list, output_fullname, para_dict = process_pipeline_name(pipeline_name, FLD_2_VOCABSIZE, embed_size, \n",
    "                                                                        default_learner_para,  default_reducer_para,\n",
    "                                                                        expander_process, default_process, Ignore_PSN_Layers)\n",
    "\n",
    "input_fullname = '^'.join(input_fullname_list)\n",
    "\n",
    "print(input_fullname)\n",
    "print(output_fullname)\n",
    "# pprint(para_dict)\n",
    "PipeLine = Pipeline_Layer(pipeline_name, input_fullname, output_fullname, para_dict)\n",
    "# print(PipeLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9158732-dd36-4724-840e-118c97a022a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PipeLine.Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e6bb23fe-0ffc-4159-8440-29d7cc708ab9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable']\n"
     ]
    }
   ],
   "source": [
    "print([i for i in FLD_2_DATA])\n",
    "FLD_2_DATA = PipeLine(FLD_2_DATA)\n",
    "print([i for i in FLD_2_DATA]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4c4b3a-2e86-49f3-a8a7-1c56ebb450e7",
   "metadata": {},
   "source": [
    "### Pipeline 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "77ab3910-5e2b-43f9-a550-cd3b84847811",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-St-Tk:SubWord-Char&Phoneme&Syllable\n",
      "B-St-Tk:SubWord:Char&Phoneme&Syllable\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable']\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-CharGrn=>B-St-Tk:SubWord-Char'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Char=>B-St-Tk:SubWord:Char'\n",
    "\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-PhonemeGrn=>B-St-Tk:SubWord-Phoneme'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Phoneme=>B-St-Tk:SubWord:Phoneme'\n",
    "\n",
    "# pipeline_name = 'EL**B-St-Tk:SubWord-SyllableGrn=>B-St-Tk:SubWord-Syllable'\n",
    "# pipeline_name = 'RL**B-St-Tk:SubWord-Syllable=>B-St-Tk:SubWord:Syllable'\n",
    "\n",
    "# pipeline_name = 'ML**B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable=>B-St-Tk:SubWord-Char&Phoneme&Syllable'\n",
    "pipeline_name = 'RL**B-St-Tk:SubWord-Char&Phoneme&Syllable=>B-St-Tk:SubWord:Char&Phoneme&Syllable'\n",
    "######################################################\n",
    "\n",
    "input_fullname_list, output_fullname, para_dict = process_pipeline_name(pipeline_name, FLD_2_VOCABSIZE, embed_size, \n",
    "                                                                        default_learner_para,  default_reducer_para,\n",
    "                                                                        expander_process, default_process, Ignore_PSN_Layers)\n",
    "\n",
    "input_fullname = '^'.join(input_fullname_list)\n",
    "\n",
    "print(input_fullname)\n",
    "print(output_fullname)\n",
    "# pprint(para_dict)\n",
    "PipeLine = Pipeline_Layer(pipeline_name, input_fullname, output_fullname, para_dict)\n",
    "# print(PipeLine)\n",
    "\n",
    "print([i for i in FLD_2_DATA])\n",
    "FLD_2_DATA = PipeLine(FLD_2_DATA)\n",
    "print([i for i in FLD_2_DATA]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "525173e2-8d78-4ccf-8634-632b2e5f6f0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-St-Tk:SubWord:Char&Phoneme&Syllable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[3, 3, 3, 3, 3, 3],\n",
       "        [3, 3, 3, 3, 3, 0],\n",
       "        [3, 3, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(output_fullname)\n",
    "data = FLD_2_DATA[output_fullname]\n",
    "holder = data['holder']\n",
    "holder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0f027c-d674-461f-935f-dabf9006d7d2",
   "metadata": {},
   "source": [
    "# Struct Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c0bce1-de1a-4586-a1bd-e35d401d1281",
   "metadata": {},
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9aa5b817-0b6b-47e8-8b0c-b88f040728db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# from .pipeline import Pipeline_Layer\n",
    "# from ..utils.parafn import process_sublayer_name\n",
    "\n",
    "class Struct_Layer(torch.nn.Module):\n",
    "    def __init__(self, struct_name, struct_para, meta_para):\n",
    "        super(Struct_Layer, self).__init__()\n",
    "        self.struct_name = struct_name\n",
    "        \n",
    "        self.final_fullname_output = struct_para['final_fullname_output']\n",
    "        self.D_model = struct_para['D_model'] \n",
    "        self.D_data = struct_para['D_data'] \n",
    "        \n",
    "        \n",
    "        self.FLD_2_VOCABSIZE = meta_para['FLD_2_VOCABSIZE']\n",
    "        self.embed_size = meta_para['embed_size']\n",
    "        self.default_learner_para = meta_para['default_learner_para']\n",
    "        self.default_reducer_para = meta_para['default_reducer_para']\n",
    "        self.expander_process = meta_para['expander_process']\n",
    "        self.default_process = meta_para['default_process']\n",
    "        self.Ignore_PSN_Layers = meta_para['Ignore_PSN_Layers']\n",
    "        \n",
    "        self.Layers = torch.nn.ModuleDict()\n",
    "        \n",
    "        for input_fullname, pipeline_list in self.D_model.items():\n",
    "            self.Layers[input_fullname] = torch.nn.ModuleDict() \n",
    "            # print(input_fullname)\n",
    "            for pipeline_name in pipeline_list:\n",
    "                # print(pipeline_name, '<---- pipeline_name')\n",
    "                input_fullname_list, output_fullname, para_dict = process_pipeline_name(pipeline_name, self.FLD_2_VOCABSIZE, self.embed_size, \n",
    "                                                                                        self.default_learner_para,  self.default_reducer_para,\n",
    "                                                                                        self.expander_process, self.default_process, self.Ignore_PSN_Layers)\n",
    "                pipe_input_fullname = '^'.join(input_fullname_list)\n",
    "                PipeLine = Pipeline_Layer(pipeline_name, pipe_input_fullname, output_fullname, para_dict)\n",
    "                self.Layers[input_fullname][pipeline_name] = PipeLine\n",
    "\n",
    "    def forward(self, FLD_2_DATA):\n",
    "        for input_fullname, output_full_name in self.D_data.items():\n",
    "            for pipeline_name, Pipeline in self.Layers[input_fullname].items():\n",
    "                print(f'\\npipeline_name <---------- {pipeline_name} ')\n",
    "                print([i for i in FLD_2_DATA])\n",
    "                FLD_2_DATA = Pipeline(FLD_2_DATA)\n",
    "                print([i for i in FLD_2_DATA])\n",
    "            assert output_full_name in FLD_2_DATA\n",
    "            \n",
    "        # update the new output name to final_fullname_output\n",
    "        assert self.final_fullname_output in output_full_name\n",
    "        # fullname2data[self.final_fullname_output] = fullname2data.pop(output_full_name)\n",
    "        FLD_2_DATA[self.final_fullname_output] = FLD_2_DATA.get(output_full_name)\n",
    "        print(f'\\n Final <---------- ')\n",
    "        print([i for i in FLD_2_DATA])\n",
    "        return FLD_2_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf23afff-6ca5-45d6-ac3d-3e2cdb6fa3ba",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "210e4467-600c-4602-aa91-3e4051cdaa71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 2)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 7)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from fieldnn.utils.layerfn import traverse\n",
    "from fieldnn.utils.simulate import get_next_info, get_simulated_tensor_from_fldname\n",
    "\n",
    "B_lenP = 3\n",
    "B2P_lnEC = [6, 5, 2] # \n",
    "prefix_layers_num = 2\n",
    "vocab_size = 100\n",
    "\n",
    "###############\n",
    "FLD_LIST = [\n",
    "'B-St-Tk:SlfGrn',\n",
    "'B-St-Tk:POSGrn',\n",
    "'B-St-Tk:AnnoGrn',\n",
    "'B-St-Tk:SubWord-CharGrn',\n",
    "'B-St-Tk:SubWord-SyllableGrn',\n",
    "'B-St-Tk:SubWord-PhonemeGrn',\n",
    "]\n",
    "\n",
    "# FLD_LIST = [\n",
    "# 'B-P-EC:Diag-DiagRec:DiagV-DiagVdftGrn',\n",
    "# 'B-P-EC:Diag-DiagRec:DiagDT-DiagDTdftGrn',\n",
    "# 'B-P-EC:Med-MedRec:MedV-MedVdftGrn',\n",
    "# 'B-P-EC:Med-MedRec:MedDT-MedDTdftGrn',\n",
    "# 'B-P-EC:A1C-A1CRec:A1CV-A1CVdftGrn',\n",
    "# 'B-P-EC:A1C-A1CRec:A1CDT-A1CDTdftGrn',\n",
    "# 'B-P-EC:PN-PNRec:SctName-SNdftGrn',\n",
    "# 'B-P-EC:PN-PNRec:SctText-SctSent-Tk:SelfGrn',\n",
    "# 'B-P-EC:PN-PNRec:SctText-SctSent-Tk:POSGrn',\n",
    "# 'B-P-EC:PN-PNRec:SctText-SctSent-Tk:SubWord-CharGrn',\n",
    "# ]\n",
    "\n",
    "###############\n",
    "\n",
    "Ignore_PSN_Layers = FLD_LIST[0].split('-')[:2]\n",
    "\n",
    "\n",
    "\n",
    "NAME_2_FULLNAME = {i.split('-')[-1]:i for i in FLD_LIST}\n",
    "\n",
    "###############\n",
    "FLD_2_VOCABSIZE = {k: np.random.randint(5000) for k in FLD_LIST}\n",
    "\n",
    "#####################\n",
    "FLD_2_DATA = {}\n",
    "\n",
    "for fullname in FLD_LIST:\n",
    "    vocab_size = FLD_2_VOCABSIZE[fullname]\n",
    "    info_idx = get_simulated_tensor_from_fldname(fullname, B_lenP, B2P_lnEC, prefix_layers_num, vocab_size)\n",
    "    # print(info_idx.shape)\n",
    "    holder = torch.LongTensor(info_idx)\n",
    "    # info_idx = torch.LongTensor(info_idx)\n",
    "    FLD_2_DATA[fullname] = {'holder': holder, 'info': 'Empty'}\n",
    "    \n",
    "######################\n",
    "embed_size = 512\n",
    "expander_process = {# 'activator': 'gelu',\n",
    "           'dropout': {'p': 0.5, 'inplace': False},\n",
    "           'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "\n",
    "default_process = {'activator': 'gelu',\n",
    "           'dropout': {'p': 0.5, 'inplace': False},\n",
    "           'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "\n",
    "default_learner_para  = {\n",
    "    'nn_name': 'TFM',\n",
    "    'nn_para': {'num_encoder_layers': 6}\n",
    "}\n",
    "default_reducer_para  = {\n",
    "    'nn_name': 'Max',\n",
    "}\n",
    "##################################\n",
    "\n",
    "\n",
    "meta_para = {}\n",
    "meta_para['FLD_2_VOCABSIZE'] = FLD_2_VOCABSIZE\n",
    "meta_para['embed_size'] = embed_size\n",
    "meta_para['expander_process'] = expander_process\n",
    "meta_para['default_process'] = default_process\n",
    "meta_para['default_learner_para'] = default_learner_para\n",
    "meta_para['default_reducer_para'] = default_reducer_para\n",
    "meta_para['Ignore_PSN_Layers'] = Ignore_PSN_Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "19e8445e-72a5-4595-bc43-01c54b7abaad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2-3': ['CharGrn^PhonemeGrn^SyllableGrn==>Tk:SubWord'],\n",
       " '1-2': ['Tk:AnnoGrn^Tk:POSGrn^Tk:SlfGrn^Tk:SubWord==>St']}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# name2fullname = {i.split('-')[-1]:i for i in fld_list}\n",
    "df_struct = get_structures_from_fldlist(FLD_LIST)\n",
    "# df_struct# .sort_values('layers', ascending = False)['struct_name'].to_list()\n",
    "\n",
    "tmp = df_struct.sort_values('layers', ascending = False)\n",
    "layer2modulelist = dict(zip(tmp['layers'].to_list(), tmp['struct_name'].to_list()))\n",
    "layer2modulelist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a0a64b-255e-4c1a-871e-052e51de7409",
   "metadata": {},
   "source": [
    "### Struct 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b586f11f-5087-4473-bf2e-16a8689de5f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-SyllableGrn']\n",
      "B-St-Tk:SubWord-CharGrn^B-St-Tk:SubWord-PhonemeGrn^B-St-Tk:SubWord-SyllableGrn\n",
      "B-St-Tk:SubWord\n",
      "RLMLRL\n",
      "{'B-St-Tk:SubWord-CharGrn': ['EL**B-St-Tk:SubWord-CharGrn=>B-St-Tk:SubWord-Char',\n",
      "                             'RL**B-St-Tk:SubWord-Char=>B-St-Tk:SubWord:Char'],\n",
      " 'B-St-Tk:SubWord-PhonemeGrn': ['EL**B-St-Tk:SubWord-PhonemeGrn=>B-St-Tk:SubWord-Phoneme',\n",
      "                                'RL**B-St-Tk:SubWord-Phoneme=>B-St-Tk:SubWord:Phoneme'],\n",
      " 'B-St-Tk:SubWord-SyllableGrn': ['EL**B-St-Tk:SubWord-SyllableGrn=>B-St-Tk:SubWord-Syllable',\n",
      "                                 'RL**B-St-Tk:SubWord-Syllable=>B-St-Tk:SubWord:Syllable'],\n",
      " 'B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable': ['ML**B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable=>B-St-Tk:SubWord-Char&Phoneme&Syllable',\n",
      "                                                                           'RL**B-St-Tk:SubWord-Char&Phoneme&Syllable=>B-St-Tk:SubWord:Char&Phoneme&Syllable']}\n",
      "{'B-St-Tk:SubWord-CharGrn': 'B-St-Tk:SubWord:Char',\n",
      " 'B-St-Tk:SubWord-PhonemeGrn': 'B-St-Tk:SubWord:Phoneme',\n",
      " 'B-St-Tk:SubWord-SyllableGrn': 'B-St-Tk:SubWord:Syllable',\n",
      " 'B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable': 'B-St-Tk:SubWord:Char&Phoneme&Syllable'}\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "struct_name = 'CharGrn^PhonemeGrn^SyllableGrn==>Tk:SubWord'\n",
    "# struct_name = 'Tk:AnnoGrn^Tk:POSGrn^Tk:SlfGrn^Tk:SubWord==>St'\n",
    "####################################\n",
    "\n",
    "fullname_input_list, final_fullname_output, struct_model, NAME_2_FULLNAME = get_struct_info(struct_name, NAME_2_FULLNAME)\n",
    "fullname_input = '^'.join(fullname_input_list)\n",
    "D_model, D_data = generate_structure(fullname_input_list, struct_model)\n",
    "\n",
    "struct_para = {}\n",
    "struct_para['fullname_input_list'] = fullname_input_list\n",
    "struct_para['fullname_input'] = fullname_input\n",
    "struct_para['final_fullname_output'] = final_fullname_output\n",
    "struct_para['struct_model'] = struct_model\n",
    "struct_para['D_model'] = D_model\n",
    "struct_para['D_data'] = D_data\n",
    "\n",
    "\n",
    "print(fullname_input_list)\n",
    "print(fullname_input)\n",
    "print(final_fullname_output)\n",
    "print(struct_model)\n",
    "# print(name2fullname)\n",
    "pprint(D_model)\n",
    "pprint(D_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1e10edec-04d9-4b07-9ea4-1105b64bef59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pipeline_name <---------- EL**B-St-Tk:SubWord-CharGrn=>B-St-Tk:SubWord-Char \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char']\n",
      "\n",
      "pipeline_name <---------- RL**B-St-Tk:SubWord-Char=>B-St-Tk:SubWord:Char \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char']\n",
      "\n",
      "pipeline_name <---------- EL**B-St-Tk:SubWord-PhonemeGrn=>B-St-Tk:SubWord-Phoneme \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme']\n",
      "\n",
      "pipeline_name <---------- RL**B-St-Tk:SubWord-Phoneme=>B-St-Tk:SubWord:Phoneme \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme']\n",
      "\n",
      "pipeline_name <---------- EL**B-St-Tk:SubWord-SyllableGrn=>B-St-Tk:SubWord-Syllable \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable']\n",
      "\n",
      "pipeline_name <---------- RL**B-St-Tk:SubWord-Syllable=>B-St-Tk:SubWord:Syllable \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable']\n",
      "\n",
      "pipeline_name <---------- ML**B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable=>B-St-Tk:SubWord-Char&Phoneme&Syllable \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable']\n",
      "\n",
      "pipeline_name <---------- RL**B-St-Tk:SubWord-Char&Phoneme&Syllable=>B-St-Tk:SubWord:Char&Phoneme&Syllable \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable']\n",
      "\n",
      " Final <---------- \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord']\n"
     ]
    }
   ],
   "source": [
    "Struct = Struct_Layer(struct_name, struct_para, meta_para)\n",
    "# print(Struct)\n",
    "FLD_2_DATA = Struct(FLD_2_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "08fdcb1b-da69-415a-a96d-5ccddbabd3de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 3, 3, 3, 3, 3],\n",
       "        [3, 3, 3, 3, 3, 0],\n",
       "        [3, 3, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = FLD_2_DATA[Struct.final_fullname_output]\n",
    "data['holder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "16d1303b-1ba9-401c-8415-feacfd3224ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.1376e-02, -4.9436e+00,  6.7262e-02, -2.7980e-01,  4.9913e-03,\n",
       "          8.9100e+00],\n",
       "        [-2.3257e-01, -2.2783e-02, -1.4839e+00,  6.6645e-04,  1.3279e+00,\n",
       "          0.0000e+00],\n",
       "        [-2.5941e-02, -4.9044e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['info'][:,:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4574391f-b91c-46fb-9d55-a3dbf1bd1528",
   "metadata": {},
   "source": [
    "### Struct 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4f70c150-4cf4-40b0-98d2-1dc19b117c41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-St-Tk:AnnoGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:SlfGrn', 'B-St-Tk:SubWord']\n",
      "B-St-Tk:AnnoGrn^B-St-Tk:POSGrn^B-St-Tk:SlfGrn^B-St-Tk:SubWord\n",
      "B-St\n",
      "MLRLRL\n",
      "{'B-St-Tk:AnnoGrn': ['EL**B-St-Tk:AnnoGrn=>B-St-Tk:Anno'],\n",
      " 'B-St-Tk:Anno^B-St-Tk:POS^B-St-Tk:Slf^B-St-Tk:SubWord': ['ML**B-St-Tk:Anno^B-St-Tk:POS^B-St-Tk:Slf^B-St-Tk:SubWord=>B-St-Tk-Anno&POS&Slf&SubWord',\n",
      "                                                          'RL**B-St-Tk-Anno&POS&Slf&SubWord=>B-St-Tk:Anno&POS&Slf&SubWord',\n",
      "                                                          'RL**B-St-Tk:Anno&POS&Slf&SubWord=>B-St:Tk:Anno&POS&Slf&SubWord'],\n",
      " 'B-St-Tk:POSGrn': ['EL**B-St-Tk:POSGrn=>B-St-Tk:POS'],\n",
      " 'B-St-Tk:SlfGrn': ['EL**B-St-Tk:SlfGrn=>B-St-Tk:Slf'],\n",
      " 'B-St-Tk:SubWord': []}\n",
      "{'B-St-Tk:AnnoGrn': 'B-St-Tk:Anno',\n",
      " 'B-St-Tk:Anno^B-St-Tk:POS^B-St-Tk:Slf^B-St-Tk:SubWord': 'B-St:Tk:Anno&POS&Slf&SubWord',\n",
      " 'B-St-Tk:POSGrn': 'B-St-Tk:POS',\n",
      " 'B-St-Tk:SlfGrn': 'B-St-Tk:Slf',\n",
      " 'B-St-Tk:SubWord': 'B-St-Tk:SubWord'}\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "# struct_name = 'CharGrn^PhonemeGrn^SyllableGrn==>Tk:SubWord'\n",
    "struct_name = 'Tk:AnnoGrn^Tk:POSGrn^Tk:SlfGrn^Tk:SubWord==>St'\n",
    "####################################\n",
    "\n",
    "fullname_input_list, final_fullname_output, struct_model, NAME_2_FULLNAME = get_struct_info(struct_name, NAME_2_FULLNAME)\n",
    "fullname_input = '^'.join(fullname_input_list)\n",
    "D_model, D_data = generate_structure(fullname_input_list, struct_model)\n",
    "\n",
    "struct_para = {}\n",
    "struct_para['fullname_input_list'] = fullname_input_list\n",
    "struct_para['fullname_input'] = fullname_input\n",
    "struct_para['final_fullname_output'] = final_fullname_output\n",
    "struct_para['struct_model'] = struct_model\n",
    "struct_para['D_model'] = D_model\n",
    "struct_para['D_data'] = D_data\n",
    "\n",
    "\n",
    "print(fullname_input_list)\n",
    "print(fullname_input)\n",
    "print(final_fullname_output)\n",
    "print(struct_model)\n",
    "# print(name2fullname)\n",
    "pprint(D_model)\n",
    "pprint(D_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f5d5ef3-c14d-4995-b7b3-d5c585952701",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pipeline_name <---------- EL**B-St-Tk:AnnoGrn=>B-St-Tk:Anno \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno']\n",
      "\n",
      "pipeline_name <---------- EL**B-St-Tk:POSGrn=>B-St-Tk:POS \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS']\n",
      "\n",
      "pipeline_name <---------- EL**B-St-Tk:SlfGrn=>B-St-Tk:Slf \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf']\n",
      "\n",
      "pipeline_name <---------- ML**B-St-Tk:Anno^B-St-Tk:POS^B-St-Tk:Slf^B-St-Tk:SubWord=>B-St-Tk-Anno&POS&Slf&SubWord \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord']\n",
      "\n",
      "pipeline_name <---------- RL**B-St-Tk-Anno&POS&Slf&SubWord=>B-St-Tk:Anno&POS&Slf&SubWord \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord']\n",
      "\n",
      "pipeline_name <---------- RL**B-St-Tk:Anno&POS&Slf&SubWord=>B-St:Tk:Anno&POS&Slf&SubWord \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord']\n",
      "\n",
      " Final <---------- \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n"
     ]
    }
   ],
   "source": [
    "Struct = Struct_Layer(struct_name, struct_para, meta_para)\n",
    "# print(Struct)\n",
    "FLD_2_DATA = Struct(FLD_2_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "53b999cb-208c-4454-b486-ff8390344763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RL**B-St-Tk:Anno&POS&Slf&SubWord=>B-St:Tk:Anno&POS&Slf&SubWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "222574a8-67aa-4784-80d8-55322304dc86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-St-Tk:AnnoGrn',\n",
       " 'B-St-Tk:POSGrn',\n",
       " 'B-St-Tk:SlfGrn',\n",
       " 'B-St-Tk:SubWord',\n",
       " 'B-St-Tk:Anno^B-St-Tk:POS^B-St-Tk:Slf^B-St-Tk:SubWord']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in Struct.Layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "de4b137a-5b9c-4669-9d55-a9ab043fad8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# input_fullname = 'B-St-Tk:Anno^B-St-Tk:POS^B-St-Tk:Slf^B-St-Tk:SubWord'\n",
    "# pipeline_name = 'RL**B-St-Tk:Anno&POS&Slf&SubWord=>B-St:Tk:Anno&POS&Slf&SubWord'\n",
    "\n",
    "\n",
    "# Pipeline = Struct.Layers[input_fullname][pipeline_name]\n",
    "# print(Pipeline.input_fullname)\n",
    "# print(Pipeline.output_fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "443c5719-5a98-4768-895d-76a4e3716c7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data = FLD_2_DATA[Pipeline.input_fullname]\n",
    "# data['holder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "59813680-4b1d-4fd2-a3bd-f58b39f68faa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data['info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b80657ca-d4f5-4faf-9e2c-1d7dfc7b1cfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7b7b20c6-5c61-4404-97b3-d81ea0aa59f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FLD_2_DATA = Pipeline(FLD_2_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2f5d2772-9c8f-494d-9273-da7d6464e030",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [i for i in FLD_2_DATA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0e7dae57-0d27-42fc-b795-7e3521d0feba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data = FLD_2_DATA['B-St:Tk:Anno&POS&Slf&SubWord']\n",
    "# data['holder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b00466f1-2f04-4c93-a378-29548f8b4f67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data['info'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fd6a7b-5525-4a5a-b04a-79cdbbac3f9e",
   "metadata": {},
   "source": [
    "# FieldRepr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab87c124-b29d-47d0-a253-42062135ab80",
   "metadata": {},
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b1e4e150-4841-445c-953f-41ec4e66932b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# from .pipeline import Pipeline_Layer\n",
    "# from ..utils.parafn import process_sublayer_name\n",
    "\n",
    "class FieldRepr_Layer(torch.nn.Module):\n",
    "    def __init__(self, FLD_LIST, FLD_END, meta_para):\n",
    "        super(FieldRepr_Layer, self).__init__()\n",
    "        \n",
    "        df_struct = get_structures_from_fldlist(FLD_LIST)\n",
    "        tmp = df_struct.sort_values('layers', ascending = False)\n",
    "        layer2structlist = dict(zip(tmp['layers'].to_list(), tmp['struct_name'].to_list()))\n",
    "        \n",
    "        NAME_2_FULLNAME = {i.split('-')[-1]:i for i in FLD_LIST}\n",
    "\n",
    "        self.FLD_LIST = FLD_LIST\n",
    "        self.FLD_END = FLD_END\n",
    "        self.NAME_2_FULLNAME = NAME_2_FULLNAME\n",
    "\n",
    "        self.LAYERS = torch.nn.ModuleDict()\n",
    "        for layer, structlist in layer2structlist.items():\n",
    "            self.LAYERS[layer] = torch.nn.ModuleDict()\n",
    "            for struct_name in structlist:\n",
    "                \n",
    "                # construct struct_para\n",
    "                fullname_input_list, final_fullname_output, struct_model, NAME_2_FULLNAME = get_struct_info(struct_name, NAME_2_FULLNAME)\n",
    "                fullname_input = '^'.join(fullname_input_list)\n",
    "                D_model, D_data = generate_structure(fullname_input_list, struct_model)\n",
    "                struct_para = {}\n",
    "                struct_para['fullname_input_list'] = fullname_input_list\n",
    "                struct_para['fullname_input'] = fullname_input\n",
    "                struct_para['final_fullname_output'] = final_fullname_output\n",
    "                struct_para['struct_model'] = struct_model\n",
    "                struct_para['D_model'] = D_model\n",
    "                struct_para['D_data'] = D_data\n",
    "                self.LAYERS[layer][struct_name] = Struct_Layer(struct_name, struct_para, meta_para)\n",
    "\n",
    "    def forward(self, FLD_2_DATA):\n",
    "        for layer, LayerDict in self.LAYERS.items():\n",
    "            for struct_name, StructLayer in LayerDict.items():\n",
    "                print(f'\\nstruct_name <---------- {struct_name} ')\n",
    "                print([i for i in FLD_2_DATA])\n",
    "                FLD_2_DATA = StructLayer(FLD_2_DATA)\n",
    "                print([i for i in FLD_2_DATA])\n",
    "                \n",
    "        assert self.FLD_END in FLD_2_DATA\n",
    "        return FLD_2_DATA[self.FLD_END]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358a8ea9-f294-49bb-b2e7-de457e2cca55",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bf5a0ff3-b80a-4353-8090-75ccdec7d042",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 9)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from fieldnn.utils.layerfn import traverse\n",
    "from fieldnn.utils.simulate import get_next_info, get_simulated_tensor_from_fldname\n",
    "\n",
    "B_lenP = 3\n",
    "B2P_lnEC = [6, 5, 2] # \n",
    "prefix_layers_num = 2\n",
    "vocab_size = 100\n",
    "\n",
    "##############\n",
    "FLD_LIST = [\n",
    "'B-St-Tk:SlfGrn',\n",
    "'B-St-Tk:POSGrn',\n",
    "'B-St-Tk:AnnoGrn',\n",
    "'B-St-Tk:SubWord-CharGrn',\n",
    "# 'B-St-Tk:SubWord-SyllableGrn',\n",
    "# 'B-St-Tk:SubWord-PhonemeGrn',\n",
    "]\n",
    "\n",
    "# FLD_END = 'B-St'\n",
    "\n",
    "# FLD_LIST = [\n",
    "# 'B-P-EC:Diag-DiagRec:DiagV-DiagVdftGrn',\n",
    "# 'B-P-EC:Diag-DiagRec:DiagDT-DiagDTdftGrn',\n",
    "    \n",
    "# 'B-P-EC:Med-MedRec:MedV-MedVdftGrn',\n",
    "# 'B-P-EC:Med-MedRec:MedDT-MedDTdftGrn',\n",
    "    \n",
    "# 'B-P-EC:A1C-A1CRec:A1CV-A1CVdftGrn',\n",
    "# 'B-P-EC:A1C-A1CRec:A1CDT-A1CDTdftGrn',\n",
    "    \n",
    "# 'B-P-EC:PN-PNRec:SctName-SNdftGrn',\n",
    "# 'B-P-EC:PN-PNRec:SctText-SctSent-Tk:SelfGrn',\n",
    "# 'B-P-EC:PN-PNRec:SctText-SctSent-Tk:POSGrn',\n",
    "# 'B-P-EC:PN-PNRec:SctText-SctSent-Tk:SubWord-CharGrn',\n",
    "# ]\n",
    "\n",
    "FLD_END = 'B-P'\n",
    "\n",
    "###############\n",
    "Ignore_PSN_Layers = FLD_LIST[0].split('-')[:2]\n",
    "\n",
    "\n",
    "\n",
    "NAME_2_FULLNAME = {i.split('-')[-1]:i for i in FLD_LIST}\n",
    "\n",
    "###############\n",
    "FLD_2_VOCABSIZE = {k: np.random.randint(5000) for k in FLD_LIST}\n",
    "\n",
    "#####################\n",
    "FLD_2_DATA = {}\n",
    "\n",
    "for fullname in FLD_LIST:\n",
    "    vocab_size = FLD_2_VOCABSIZE[fullname]\n",
    "    info_idx = get_simulated_tensor_from_fldname(fullname, B_lenP, B2P_lnEC, prefix_layers_num, vocab_size)\n",
    "    # print(info_idx.shape)\n",
    "    holder = torch.LongTensor(info_idx)\n",
    "    # info_idx = torch.LongTensor(info_idx)\n",
    "    FLD_2_DATA[fullname] = {'holder': holder, 'info': 'Empty'}\n",
    "    \n",
    "######################\n",
    "embed_size = 512\n",
    "expander_process = {# 'activator': 'gelu',\n",
    "           'dropout': {'p': 0.5, 'inplace': False},\n",
    "           'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "\n",
    "default_process = {'activator': 'gelu',\n",
    "           'dropout': {'p': 0.5, 'inplace': False},\n",
    "           'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "\n",
    "default_learner_para  = {\n",
    "    'nn_name': 'TFM',\n",
    "    'nn_para': {'num_encoder_layers': 6}\n",
    "}\n",
    "default_reducer_para  = {\n",
    "    'nn_name': 'Max',\n",
    "}\n",
    "##################################\n",
    "\n",
    "meta_para = {}\n",
    "meta_para['FLD_2_VOCABSIZE'] = FLD_2_VOCABSIZE\n",
    "meta_para['embed_size'] = embed_size\n",
    "meta_para['expander_process'] = expander_process\n",
    "meta_para['default_process'] = default_process\n",
    "meta_para['default_learner_para'] = default_learner_para\n",
    "meta_para['default_reducer_para'] = default_reducer_para\n",
    "meta_para['Ignore_PSN_Layers'] = Ignore_PSN_Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "30923986-093c-4633-8bdd-444c5790167a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2-3': ['CharGrn==>Tk:SubWord'],\n",
       " '1-2': ['Tk:AnnoGrn^Tk:POSGrn^Tk:SlfGrn^Tk:SubWord==>St']}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# name2fullname = {i.split('-')[-1]:i for i in fld_list}\n",
    "df_struct = get_structures_from_fldlist(FLD_LIST)\n",
    "# df_struct# .sort_values('layers', ascending = False)['struct_name'].to_list()\n",
    "\n",
    "tmp = df_struct.sort_values('layers', ascending = False)\n",
    "layer2structlist = dict(zip(tmp['layers'].to_list(), tmp['struct_name'].to_list()))\n",
    "layer2structlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a2e29643-e151-4159-ba79-5c304b98cfd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FieldRepr = FieldRepr_Layer(FLD_LIST, FLD_END, meta_para)\n",
    "# FieldRepr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "506ac7d0-f568-41a6-8309-d3224422abb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FieldRepr_Layer(\n",
       "  (LAYERS): ModuleDict(\n",
       "    (2-3): ModuleDict(\n",
       "      (CharGrn==>Tk:SubWord): Struct_Layer(\n",
       "        (Layers): ModuleDict(\n",
       "          (B-St-Tk:SubWord-CharGrn): ModuleDict(\n",
       "            (EL**B-St-Tk:SubWord-CharGrn=>B-St-Tk:SubWord-Char): Pipeline_Layer(\n",
       "              (Layers): ModuleDict(\n",
       "                (B-St-Tk:SubWord-CharGrn): Expander_Layer(\n",
       "                  (Embed): EmbeddingLayer(\n",
       "                    (embedding): Embedding(2001, 512, padding_idx=0)\n",
       "                  )\n",
       "                  (postprocess): ModuleDict(\n",
       "                    (dropout): Dropout(p=0.5, inplace=False)\n",
       "                    (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  )\n",
       "                )\n",
       "                (B-St-Tk:SubWord-Char): Learner_Layer(\n",
       "                  (Learner): TFMLayer(\n",
       "                    (transformer): Transformer(\n",
       "                      (encoder): TransformerEncoder(\n",
       "                        (layers): ModuleList(\n",
       "                          (0-5): 6 x TransformerEncoderLayer(\n",
       "                            (self_attn): MultiheadAttention(\n",
       "                              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "                            )\n",
       "                            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                            (dropout): Dropout(p=0.1, inplace=False)\n",
       "                            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "                            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "                          )\n",
       "                        )\n",
       "                        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                      )\n",
       "                      (decoder): TransformerDecoder(\n",
       "                        (layers): ModuleList()\n",
       "                        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (PSN_Embed_Dict): ModuleDict(\n",
       "                    (Char): EmbeddingLayer(\n",
       "                      (embedding): Embedding(101, 512, padding_idx=0)\n",
       "                    )\n",
       "                    (Tk:SubWord): EmbeddingLayer(\n",
       "                      (embedding): Embedding(101, 512, padding_idx=0)\n",
       "                    )\n",
       "                  )\n",
       "                  (embedprocess): ModuleDict(\n",
       "                    (dropout): Dropout(p=0.5, inplace=False)\n",
       "                    (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  )\n",
       "                  (postprocess): ModuleDict(\n",
       "                    (dropout): Dropout(p=0.5, inplace=False)\n",
       "                    (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (RL**B-St-Tk:SubWord-Char=>B-St-Tk:SubWord:Char): Pipeline_Layer(\n",
       "              (Layers): ModuleDict(\n",
       "                (B-St-Tk:SubWord-Char): Reducer_Layer(\n",
       "                  (reducer): RecuderMaxLayer()\n",
       "                  (postprocess): ModuleDict(\n",
       "                    (activator): GELU(approximate='none')\n",
       "                    (dropout): Dropout(p=0.5, inplace=False)\n",
       "                    (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  )\n",
       "                )\n",
       "                (B-St-Tk:SubWord:Char): Learner_Layer(\n",
       "                  (Learner): TFMLayer(\n",
       "                    (transformer): Transformer(\n",
       "                      (encoder): TransformerEncoder(\n",
       "                        (layers): ModuleList(\n",
       "                          (0-5): 6 x TransformerEncoderLayer(\n",
       "                            (self_attn): MultiheadAttention(\n",
       "                              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "                            )\n",
       "                            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                            (dropout): Dropout(p=0.1, inplace=False)\n",
       "                            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "                            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "                          )\n",
       "                        )\n",
       "                        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                      )\n",
       "                      (decoder): TransformerDecoder(\n",
       "                        (layers): ModuleList()\n",
       "                        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (PSN_Embed_Dict): ModuleDict(\n",
       "                    (Tk:SubWord:Char): EmbeddingLayer(\n",
       "                      (embedding): Embedding(101, 512, padding_idx=0)\n",
       "                    )\n",
       "                  )\n",
       "                  (embedprocess): ModuleDict(\n",
       "                    (dropout): Dropout(p=0.5, inplace=False)\n",
       "                    (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  )\n",
       "                  (postprocess): ModuleDict(\n",
       "                    (dropout): Dropout(p=0.5, inplace=False)\n",
       "                    (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1-2): ModuleDict(\n",
       "      (Tk:AnnoGrn^Tk:POSGrn^Tk:SlfGrn^Tk:SubWord==>St): Struct_Layer(\n",
       "        (Layers): ModuleDict(\n",
       "          (B-St-Tk:AnnoGrn): ModuleDict(\n",
       "            (EL**B-St-Tk:AnnoGrn=>B-St-Tk:Anno): Pipeline_Layer(\n",
       "              (Layers): ModuleDict(\n",
       "                (B-St-Tk:AnnoGrn): Expander_Layer(\n",
       "                  (Embed): EmbeddingLayer(\n",
       "                    (embedding): Embedding(535, 512, padding_idx=0)\n",
       "                  )\n",
       "                  (postprocess): ModuleDict(\n",
       "                    (dropout): Dropout(p=0.5, inplace=False)\n",
       "                    (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  )\n",
       "                )\n",
       "                (B-St-Tk:Anno): Learner_Layer(\n",
       "                  (Learner): TFMLayer(\n",
       "                    (transformer): Transformer(\n",
       "                      (encoder): TransformerEncoder(\n",
       "                        (layers): ModuleList(\n",
       "                          (0-5): 6 x TransformerEncoderLayer(\n",
       "                            (self_attn): MultiheadAttention(\n",
       "                              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "                            )\n",
       "                            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                            (dropout): Dropout(p=0.1, inplace=False)\n",
       "                            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "                            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "                          )\n",
       "                        )\n",
       "                        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                      )\n",
       "                      (decoder): TransformerDecoder(\n",
       "                        (layers): ModuleList()\n",
       "                        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (PSN_Embed_Dict): ModuleDict(\n",
       "                    (Tk:Anno): EmbeddingLayer(\n",
       "                      (embedding): Embedding(101, 512, padding_idx=0)\n",
       "                    )\n",
       "                  )\n",
       "                  (embedprocess): ModuleDict(\n",
       "                    (dropout): Dropout(p=0.5, inplace=False)\n",
       "                    (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  )\n",
       "                  (postprocess): ModuleDict(\n",
       "                    (dropout): Dropout(p=0.5, inplace=False)\n",
       "                    (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (B-St-Tk:POSGrn): ModuleDict(\n",
       "            (EL**B-St-Tk:POSGrn=>B-St-Tk:POS): Pipeline_Layer(\n",
       "              (Layers): ModuleDict(\n",
       "                (B-St-Tk:POSGrn): Expander_Layer(\n",
       "                  (Embed): EmbeddingLayer(\n",
       "                    (embedding): Embedding(3207, 512, padding_idx=0)\n",
       "                  )\n",
       "                  (postprocess): ModuleDict(\n",
       "                    (dropout): Dropout(p=0.5, inplace=False)\n",
       "                    (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  )\n",
       "                )\n",
       "                (B-St-Tk:POS): Learner_Layer(\n",
       "                  (Learner): TFMLayer(\n",
       "                    (transformer): Transformer(\n",
       "                      (encoder): TransformerEncoder(\n",
       "                        (layers): ModuleList(\n",
       "                          (0-5): 6 x TransformerEncoderLayer(\n",
       "                            (self_attn): MultiheadAttention(\n",
       "                              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "                            )\n",
       "                            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                            (dropout): Dropout(p=0.1, inplace=False)\n",
       "                            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "                            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "                          )\n",
       "                        )\n",
       "                        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                      )\n",
       "                      (decoder): TransformerDecoder(\n",
       "                        (layers): ModuleList()\n",
       "                        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (PSN_Embed_Dict): ModuleDict(\n",
       "                    (Tk:POS): EmbeddingLayer(\n",
       "                      (embedding): Embedding(101, 512, padding_idx=0)\n",
       "                    )\n",
       "                  )\n",
       "                  (embedprocess): ModuleDict(\n",
       "                    (dropout): Dropout(p=0.5, inplace=False)\n",
       "                    (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  )\n",
       "                  (postprocess): ModuleDict(\n",
       "                    (dropout): Dropout(p=0.5, inplace=False)\n",
       "                    (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (B-St-Tk:SlfGrn): ModuleDict(\n",
       "            (EL**B-St-Tk:SlfGrn=>B-St-Tk:Slf): Pipeline_Layer(\n",
       "              (Layers): ModuleDict(\n",
       "                (B-St-Tk:SlfGrn): Expander_Layer(\n",
       "                  (Embed): EmbeddingLayer(\n",
       "                    (embedding): Embedding(3609, 512, padding_idx=0)\n",
       "                  )\n",
       "                  (postprocess): ModuleDict(\n",
       "                    (dropout): Dropout(p=0.5, inplace=False)\n",
       "                    (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  )\n",
       "                )\n",
       "                (B-St-Tk:Slf): Learner_Layer(\n",
       "                  (Learner): TFMLayer(\n",
       "                    (transformer): Transformer(\n",
       "                      (encoder): TransformerEncoder(\n",
       "                        (layers): ModuleList(\n",
       "                          (0-5): 6 x TransformerEncoderLayer(\n",
       "                            (self_attn): MultiheadAttention(\n",
       "                              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "                            )\n",
       "                            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                            (dropout): Dropout(p=0.1, inplace=False)\n",
       "                            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "                            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "                          )\n",
       "                        )\n",
       "                        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                      )\n",
       "                      (decoder): TransformerDecoder(\n",
       "                        (layers): ModuleList()\n",
       "                        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (PSN_Embed_Dict): ModuleDict(\n",
       "                    (Tk:Slf): EmbeddingLayer(\n",
       "                      (embedding): Embedding(101, 512, padding_idx=0)\n",
       "                    )\n",
       "                  )\n",
       "                  (embedprocess): ModuleDict(\n",
       "                    (dropout): Dropout(p=0.5, inplace=False)\n",
       "                    (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  )\n",
       "                  (postprocess): ModuleDict(\n",
       "                    (dropout): Dropout(p=0.5, inplace=False)\n",
       "                    (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (B-St-Tk:SubWord): ModuleDict()\n",
       "          (B-St-Tk:Anno^B-St-Tk:POS^B-St-Tk:Slf^B-St-Tk:SubWord): ModuleDict(\n",
       "            (ML**B-St-Tk:Anno^B-St-Tk:POS^B-St-Tk:Slf^B-St-Tk:SubWord=>B-St-Tk-Anno&POS&Slf&SubWord): Pipeline_Layer(\n",
       "              (Layers): ModuleDict(\n",
       "                (B-St-Tk:Anno^B-St-Tk:POS^B-St-Tk:Slf^B-St-Tk:SubWord): Merger_Layer(\n",
       "                  (Merger): MergerLayer()\n",
       "                  (postprocess): ModuleDict(\n",
       "                    (activator): GELU(approximate='none')\n",
       "                    (dropout): Dropout(p=0.5, inplace=False)\n",
       "                    (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  )\n",
       "                )\n",
       "                (B-St-Tk-Anno&POS&Slf&SubWord): Learner_Layer(\n",
       "                  (Learner): TFMLayer(\n",
       "                    (transformer): Transformer(\n",
       "                      (encoder): TransformerEncoder(\n",
       "                        (layers): ModuleList(\n",
       "                          (0-5): 6 x TransformerEncoderLayer(\n",
       "                            (self_attn): MultiheadAttention(\n",
       "                              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "                            )\n",
       "                            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                            (dropout): Dropout(p=0.1, inplace=False)\n",
       "                            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "                            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "                          )\n",
       "                        )\n",
       "                        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                      )\n",
       "                      (decoder): TransformerDecoder(\n",
       "                        (layers): ModuleList()\n",
       "                        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (PSN_Embed_Dict): ModuleDict(\n",
       "                    (Anno&POS&Slf&SubWord): EmbeddingLayer(\n",
       "                      (embedding): Embedding(101, 512, padding_idx=0)\n",
       "                    )\n",
       "                    (Tk): EmbeddingLayer(\n",
       "                      (embedding): Embedding(101, 512, padding_idx=0)\n",
       "                    )\n",
       "                  )\n",
       "                  (embedprocess): ModuleDict(\n",
       "                    (dropout): Dropout(p=0.5, inplace=False)\n",
       "                    (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  )\n",
       "                  (postprocess): ModuleDict(\n",
       "                    (dropout): Dropout(p=0.5, inplace=False)\n",
       "                    (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (RL**B-St-Tk-Anno&POS&Slf&SubWord=>B-St-Tk:Anno&POS&Slf&SubWord): Pipeline_Layer(\n",
       "              (Layers): ModuleDict(\n",
       "                (B-St-Tk-Anno&POS&Slf&SubWord): Reducer_Layer(\n",
       "                  (reducer): RecuderMaxLayer()\n",
       "                  (postprocess): ModuleDict(\n",
       "                    (activator): GELU(approximate='none')\n",
       "                    (dropout): Dropout(p=0.5, inplace=False)\n",
       "                    (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  )\n",
       "                )\n",
       "                (B-St-Tk:Anno&POS&Slf&SubWord): Learner_Layer(\n",
       "                  (Learner): TFMLayer(\n",
       "                    (transformer): Transformer(\n",
       "                      (encoder): TransformerEncoder(\n",
       "                        (layers): ModuleList(\n",
       "                          (0-5): 6 x TransformerEncoderLayer(\n",
       "                            (self_attn): MultiheadAttention(\n",
       "                              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "                            )\n",
       "                            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                            (dropout): Dropout(p=0.1, inplace=False)\n",
       "                            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "                            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "                          )\n",
       "                        )\n",
       "                        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                      )\n",
       "                      (decoder): TransformerDecoder(\n",
       "                        (layers): ModuleList()\n",
       "                        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (PSN_Embed_Dict): ModuleDict(\n",
       "                    (Tk:Anno&POS&Slf&SubWord): EmbeddingLayer(\n",
       "                      (embedding): Embedding(101, 512, padding_idx=0)\n",
       "                    )\n",
       "                  )\n",
       "                  (embedprocess): ModuleDict(\n",
       "                    (dropout): Dropout(p=0.5, inplace=False)\n",
       "                    (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  )\n",
       "                  (postprocess): ModuleDict(\n",
       "                    (dropout): Dropout(p=0.5, inplace=False)\n",
       "                    (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (RL**B-St-Tk:Anno&POS&Slf&SubWord=>B-St:Tk:Anno&POS&Slf&SubWord): Pipeline_Layer(\n",
       "              (Layers): ModuleDict(\n",
       "                (B-St-Tk:Anno&POS&Slf&SubWord): Reducer_Layer(\n",
       "                  (reducer): RecuderMaxLayer()\n",
       "                  (postprocess): ModuleDict(\n",
       "                    (activator): GELU(approximate='none')\n",
       "                    (dropout): Dropout(p=0.5, inplace=False)\n",
       "                    (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  )\n",
       "                )\n",
       "                (B-St:Tk:Anno&POS&Slf&SubWord): Learner_Layer(\n",
       "                  (Learner): LinearLayer(\n",
       "                    (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  )\n",
       "                  (postprocess): ModuleDict(\n",
       "                    (dropout): Dropout(p=0.5, inplace=False)\n",
       "                    (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FieldRepr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0d410e8b-199e-4570-9fd7-b20a6fc31ccb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "struct_name <---------- CharGrn^PhonemeGrn^SyllableGrn==>Tk:SubWord \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn']\n",
      "\n",
      "pipeline_name <---------- EL**B-St-Tk:SubWord-CharGrn=>B-St-Tk:SubWord-Char \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char']\n",
      "\n",
      "pipeline_name <---------- RL**B-St-Tk:SubWord-Char=>B-St-Tk:SubWord:Char \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char']\n",
      "\n",
      "pipeline_name <---------- EL**B-St-Tk:SubWord-PhonemeGrn=>B-St-Tk:SubWord-Phoneme \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme']\n",
      "\n",
      "pipeline_name <---------- RL**B-St-Tk:SubWord-Phoneme=>B-St-Tk:SubWord:Phoneme \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme']\n",
      "\n",
      "pipeline_name <---------- EL**B-St-Tk:SubWord-SyllableGrn=>B-St-Tk:SubWord-Syllable \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable']\n",
      "\n",
      "pipeline_name <---------- RL**B-St-Tk:SubWord-Syllable=>B-St-Tk:SubWord:Syllable \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable']\n",
      "\n",
      "pipeline_name <---------- ML**B-St-Tk:SubWord:Char^B-St-Tk:SubWord:Phoneme^B-St-Tk:SubWord:Syllable=>B-St-Tk:SubWord-Char&Phoneme&Syllable \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable']\n",
      "\n",
      "pipeline_name <---------- RL**B-St-Tk:SubWord-Char&Phoneme&Syllable=>B-St-Tk:SubWord:Char&Phoneme&Syllable \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable']\n",
      "\n",
      " Final <---------- \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord']\n",
      "\n",
      "struct_name <---------- Tk:AnnoGrn^Tk:POSGrn^Tk:SlfGrn^Tk:SubWord==>St \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord']\n",
      "\n",
      "pipeline_name <---------- EL**B-St-Tk:AnnoGrn=>B-St-Tk:Anno \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno']\n",
      "\n",
      "pipeline_name <---------- EL**B-St-Tk:POSGrn=>B-St-Tk:POS \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS']\n",
      "\n",
      "pipeline_name <---------- EL**B-St-Tk:SlfGrn=>B-St-Tk:Slf \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf']\n",
      "\n",
      "pipeline_name <---------- ML**B-St-Tk:Anno^B-St-Tk:POS^B-St-Tk:Slf^B-St-Tk:SubWord=>B-St-Tk-Anno&POS&Slf&SubWord \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord']\n",
      "\n",
      "pipeline_name <---------- RL**B-St-Tk-Anno&POS&Slf&SubWord=>B-St-Tk:Anno&POS&Slf&SubWord \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord']\n",
      "\n",
      "pipeline_name <---------- RL**B-St-Tk:Anno&POS&Slf&SubWord=>B-St:Tk:Anno&POS&Slf&SubWord \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord']\n",
      "\n",
      " Final <---------- \n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n",
      "['B-St-Tk:SlfGrn', 'B-St-Tk:POSGrn', 'B-St-Tk:AnnoGrn', 'B-St-Tk:SubWord-CharGrn', 'B-St-Tk:SubWord-SyllableGrn', 'B-St-Tk:SubWord-PhonemeGrn', 'B-St-Tk:SubWord-Char', 'B-St-Tk:SubWord:Char', 'B-St-Tk:SubWord-Phoneme', 'B-St-Tk:SubWord:Phoneme', 'B-St-Tk:SubWord-Syllable', 'B-St-Tk:SubWord:Syllable', 'B-St-Tk:SubWord-Char&Phoneme&Syllable', 'B-St-Tk:SubWord:Char&Phoneme&Syllable', 'B-St-Tk:SubWord', 'B-St-Tk:Anno', 'B-St-Tk:POS', 'B-St-Tk:Slf', 'B-St-Tk-Anno&POS&Slf&SubWord', 'B-St-Tk:Anno&POS&Slf&SubWord', 'B-St:Tk:Anno&POS&Slf&SubWord', 'B-St']\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mFieldRepr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFLD_2_DATA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# data['info']\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/boost/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[65], line 48\u001b[0m, in \u001b[0;36mFieldRepr_Layer.forward\u001b[0;34m(self, FLD_2_DATA)\u001b[0m\n\u001b[1;32m     45\u001b[0m         FLD_2_DATA \u001b[38;5;241m=\u001b[39m StructLayer(FLD_2_DATA)\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28mprint\u001b[39m([i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m FLD_2_DATA])\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mFLD_END \u001b[38;5;129;01min\u001b[39;00m FLD_2_DATA\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m FLD_2_DATA[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mFLD_END]\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = FieldRepr(FLD_2_DATA)\n",
    "# data['info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c5e060-59c5-434f-b3e9-06560271aa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['info'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72463a80-0bf7-45ec-8c16-a98ab3abe00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in FieldRepr.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6abfd17-ddbf-40e1-8199-ee7c396fab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for para in FieldRepr.parameters():\n",
    "#     print(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7083cd6-c255-4d07-9ab3-a1ef9dd1a842",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in FieldRepr.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dd1b56-2824-4997-a778-c98700fe95f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "1b836e43c3ffb5910d870ded83ccc299b2a5f20935d0e517397c1f35feea326f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
