{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7588aa63-50a8-4f68-b40d-5e65e1783790",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/floydluo/Library/CloudStorage/GoogleDrive-jjluo@terpmail.umd.edu/.shortcut-targets-by-id/1qNzMmGHCg5Xa63Vw3aKbZdMXvkfT2CgC/MedStar/MS_CODE/FieldNN\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c7d713-7310-40cb-86f3-358ecf3274bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from fieldnn.utils.layerfn import traverse\n",
    "# from fieldnn.utils.simulate import get_next_info, get_simulated_tensor_from_fldname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f1850-8d92-40fd-ba69-6657f63ca703",
   "metadata": {},
   "source": [
    "# Prepare Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98e6de85-919d-4ffa-b1d6-0f286e9dc6f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/ProcData/TensorFolder/Task2YearXXX\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['A1C@DT-DTDftGrn',\n",
       " 'A1C@V-A1CNumeDftGrn',\n",
       " 'Diag@DT-DTDftGrn',\n",
       " 'Diag@Value-DiagDftGrn',\n",
       " 'EC@BasicInfo-BasicDftGrn',\n",
       " 'EC@DT_min-DTDftGrn',\n",
       " 'P@age-AgeNumeDftGrn',\n",
       " 'P@basicInfo-basicInfoDftGrn',\n",
       " 'PNSectSent@Sentence-Tk@TknzLLMGrn']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from recfldgrn.datapoint import load_df_data_from_folder\n",
    "from recfldgrn.utils import convert_relational_list_to_numpy\n",
    "\n",
    "###################### take this as given\n",
    "batch_PID_order = ['P1', 'P4', 'P5', 'P6']\n",
    "######################\n",
    "\n",
    "TaskTensor_folder = 'data/ProcData/TensorFolder/Task2YearXXX'\n",
    "print(TaskTensor_folder)\n",
    "\n",
    "l = sorted([i for i in os.listdir(TaskTensor_folder) if 'Grn' in i])\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70729ebd-a267-4acc-96e6-ef0ea85eb354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_full_recfldgrn(full_recfldgrn):\n",
    "    # suffix = full_recfldgrn.split('_')[-1]\n",
    "    recfld = [i for i in full_recfldgrn.split('-') if '@' in i][0]\n",
    "    rec, fld = recfld.split('@')\n",
    "    grn_suffix = [i for i in full_recfldgrn.split('-') if 'Grn' in i][0]\n",
    "    grn, suffix = grn_suffix.split('_')\n",
    "    prefix_ids = [i for i in full_recfldgrn.split('-') if 'Grn' not in i and '@' not in i]\n",
    "    return prefix_ids, rec, fld, grn, suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d944f1c-10e3-4e0d-a71e-40cd99cdc87f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# full_recfldgrn = 'P@age-AgeNumeDftGrn'\n",
    "# parse_full_recfldgrn(full_recfldgrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "148b0bee-5e48-47e4-abb7-eef0f9638c26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recfldgrn_list = [\n",
    "                  'P@age-AgeNumeDftGrn',\n",
    "                  'A1C@V-A1CNumeDftGrn',\n",
    "                  'Diag@DT-DTDftGrn',\n",
    "                  'Diag@Value-DiagDftGrn',\n",
    "                  'PNSectSent@Sentence-Tk@TknzLLMGrn'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f98dd28e-0fb5-43b2-ae78-5b07f07b814a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P@age-AgeNumeDftGrn_wgt (4, 19)\n",
      "B-P-EC-A1C@V-A1CNumeDftGrn_wgt (4, 25, 1, 37)\n",
      "B-P-EC-Diag@DT-DTDftGrn_idx (4, 25, 22, 7)\n",
      "B-P-EC-Diag@Value-DiagDftGrn_idx (4, 25, 22, 3)\n",
      "B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx (4, 25, 1, 14, 121, 11)\n"
     ]
    }
   ],
   "source": [
    "batch_rfg = {}\n",
    "\n",
    "for recfldgrn in recfldgrn_list:\n",
    "    \n",
    "    # (1) get tensor_folder\n",
    "    tensor_folder = os.path.join(TaskTensor_folder, recfldgrn)\n",
    "\n",
    "    # (2) get df_Pat and full_recfldgrn\n",
    "    df_Pat = load_df_data_from_folder(tensor_folder).set_index('PID')\n",
    "    full_recfldgrn = df_Pat.columns[0]\n",
    "    suffix = full_recfldgrn.split('_')[-1]\n",
    "    assert recfldgrn in full_recfldgrn\n",
    "\n",
    "    # (3) load batch: TODO: convert this to DataSet and DataLoader\n",
    "    df_batch = df_Pat.loc[batch_PID_order]\n",
    "\n",
    "    # (4) tensor batch as tensor_idx\n",
    "    new_full_recfldgrn = 'B-' + full_recfldgrn\n",
    "    values_list = df_batch[full_recfldgrn].to_list()\n",
    "    suffix = full_recfldgrn.split('_')[-1]\n",
    "    # print(suffix)\n",
    "    # print(new_full_recfldgrn)\n",
    "    D = convert_relational_list_to_numpy(values_list, new_full_recfldgrn, suffix)\n",
    "    tensor_idx = D[new_full_recfldgrn]\n",
    "    \n",
    "    batch_rfg[new_full_recfldgrn] = tensor_idx\n",
    "    \n",
    "for k, v in batch_rfg.items(): print(k, v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40584876-b4a9-4a9d-b019-c708af7ef283",
   "metadata": {
    "tags": []
   },
   "source": [
    "# EmbedTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c9467b0-f420-4485-9aab-e2b51a45ab98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P@age-AgeNumeDftGrn_wgt',\n",
       " 'B-P-EC-A1C@V-A1CNumeDftGrn_wgt',\n",
       " 'B-P-EC-Diag@DT-DTDftGrn_idx',\n",
       " 'B-P-EC-Diag@Value-DiagDftGrn_idx',\n",
       " 'B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fieldnn.sublayer.expander import Expander_Layer\n",
    "from fieldnn.configfn.expanderfn import get_expander_para\n",
    "\n",
    "full_recfldgrn_list = [\n",
    "                  i for i in batch_rfg\n",
    "                ]\n",
    "full_recfldgrn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03ac61bb-81c0-4e7c-b0e8-504ed8a2c911",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-P@age-AgeNumeDftGrn_wgt': {'vocabsize_tokenizer': 19, 'init': 'random'},\n",
       " 'B-P-EC-A1C@V-A1CNumeDftGrn_wgt': {'vocabsize_tokenizer': 37,\n",
       "  'init': 'random'},\n",
       " 'B-P-EC-Diag@DT-DTDftGrn_idx': {'vocabsize_tokenizer': 162, 'init': 'random'},\n",
       " 'B-P-EC-Diag@Value-DiagDftGrn_idx': {'vocabsize_tokenizer': 801,\n",
       "  'init': 'random'},\n",
       " 'B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx': {'vocabsize_tokenizer': BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}),\n",
       "  'init': 'bert-base-uncased'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_rfg_to_basicInfo = {}\n",
    "\n",
    "for full_recfldgrn in full_recfldgrn_list:\n",
    "    # (1) full recfldgrn information\n",
    "    prefix_ids, rec, fld, grn, suffix = parse_full_recfldgrn(full_recfldgrn)\n",
    "    recfldgrn = rec + '@' + fld + '-' + grn\n",
    "\n",
    "    # (2) get vocab information\n",
    "    fldgrn_folder = 'data/ProcData/FldGrnInfo'\n",
    "    fullfldgrn_file = os.path.join(fldgrn_folder, rec + '.p')\n",
    "    df_FieldGrainInfo = pd.read_pickle(fullfldgrn_file)\n",
    "\n",
    "    if 'LLM' in full_recfldgrn:\n",
    "        tokenizer = df_FieldGrainInfo[df_FieldGrainInfo['recfield2grain'] == recfldgrn].iloc[0]['Vocab']['v2idx']\n",
    "        vocab_tokenizer = tokenizer\n",
    "        init = tokenizer.name_or_path\n",
    "    else:\n",
    "        v2idx = df_FieldGrainInfo[df_FieldGrainInfo['recfield2grain'] == recfldgrn].iloc[0]['Vocab']['v2idx']\n",
    "        # TODO: also adding padding to v2idx\n",
    "        vocab_size = len(v2idx)\n",
    "        # print(vocab_size)\n",
    "        vocab_tokenizer = vocab_size\n",
    "        init = 'random'\n",
    "    \n",
    "    d = {'vocabsize_tokenizer': vocab_tokenizer, 'init': init}\n",
    "    full_rfg_to_basicInfo[full_recfldgrn] = d\n",
    "    \n",
    "full_rfg_to_basicInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bb1325b-3292-4426-900f-b4a48b90d600",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############################\n",
    "embed_size = 128\n",
    "process = {'activator': 'gelu',\n",
    "           'dropout': {'p': 0.5, 'inplace': False},\n",
    "           'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "############################\n",
    "\n",
    "full_rfg_to_ExpanderConfig = {}\n",
    "for full_recfldgrn in full_recfldgrn_list:\n",
    "    \n",
    "    # determine the nn_name\n",
    "    if '_idx' in full_recfldgrn and 'LLM' not in full_recfldgrn:\n",
    "        nn_name = 'CatEmbeddingLayer'\n",
    "    elif '_idx' in full_recfldgrn and 'LLM' in full_recfldgrn:\n",
    "        nn_name = 'LLMEmbeddingLayer'\n",
    "    elif '_wgt' in full_recfldgrn:\n",
    "        nn_name = 'NumEmbeddingLayer'\n",
    "    else:\n",
    "        raise ValueError(f'full_recfldgrn is not correct \"{full_recfldgrn}\"')\n",
    "    \n",
    "    d = full_rfg_to_basicInfo[full_recfldgrn]\n",
    "    expander_para = get_expander_para(full_recfldgrn, \n",
    "                                       nn_name,\n",
    "                                       embed_size, d['vocabsize_tokenizer'], d['init'], \n",
    "                                       process)\n",
    "    # print(expander_para)\n",
    "    output_recfld = full_recfldgrn.split('Grn')[0]\n",
    "    \n",
    "    full_rfg_to_ExpanderConfig[full_recfldgrn] = {\n",
    "        'full_recfldgrn': full_recfldgrn,\n",
    "        'output_recfld': output_recfld,\n",
    "        'expander_para': expander_para,\n",
    "    }\n",
    "    \n",
    "# full_rfg_to_ExpanderConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b702251-c619-4201-8ba6-62db69650d40",
   "metadata": {},
   "source": [
    "## init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36f4afd9-5ee5-4353-8ebc-afee95667596",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P@age-AgeNumeDftGrn_wgt\n",
      "Expander_Layer(\n",
      "  (Embed): NumEmbeddingLayer(\n",
      "    (embedding): Embedding(19, 128, padding_idx=0)\n",
      "  )\n",
      "  (postprocess): ModuleDict(\n",
      "    (activator): GELU(approximate='none')\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "B-P-EC-A1C@V-A1CNumeDftGrn_wgt\n",
      "Expander_Layer(\n",
      "  (Embed): NumEmbeddingLayer(\n",
      "    (embedding): Embedding(37, 128, padding_idx=0)\n",
      "  )\n",
      "  (postprocess): ModuleDict(\n",
      "    (activator): GELU(approximate='none')\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "B-P-EC-Diag@DT-DTDftGrn_idx\n",
      "Expander_Layer(\n",
      "  (Embed): CatEmbeddingLayer(\n",
      "    (embedding): Embedding(162, 128, padding_idx=0)\n",
      "  )\n",
      "  (postprocess): ModuleDict(\n",
      "    (activator): GELU(approximate='none')\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "B-P-EC-Diag@Value-DiagDftGrn_idx\n",
      "Expander_Layer(\n",
      "  (Embed): CatEmbeddingLayer(\n",
      "    (embedding): Embedding(801, 128, padding_idx=0)\n",
      "  )\n",
      "  (postprocess): ModuleDict(\n",
      "    (activator): GELU(approximate='none')\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx\n",
      "Expander_Layer(\n",
      "  (Embed): LLMEmbeddingLayer(\n",
      "    (LLM): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-11): 12 x BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (linear): Linear(in_features=768, out_features=128, bias=True)\n",
      "  )\n",
      "  (postprocess): ModuleDict(\n",
      "    (activator): GELU(approximate='none')\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "FullRFG_2_Embed = {}\n",
    "\n",
    "for full_recfldgrn, ExpanderConfig in full_rfg_to_ExpanderConfig.items():\n",
    "    \n",
    "    FullRFG_2_Embed[full_recfldgrn] = Expander_Layer(**ExpanderConfig)\n",
    "    print(full_recfldgrn)\n",
    "    print(FullRFG_2_Embed[full_recfldgrn])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162d3e1c-4932-4a13-9c90-170d4968191c",
   "metadata": {},
   "source": [
    "## prepare input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d248c563-25ca-4585-b4c8-f002cd384901",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P@age-AgeNumeDftGrn_wgt\n",
      "(4, 19)\n",
      "torch.Size([4, 19]) <------ holder shape\n",
      "torch.Size([4, 19]) <------ holder wgt information\n",
      "\n",
      "\n",
      "B-P-EC-A1C@V-A1CNumeDftGrn_wgt\n",
      "(4, 25, 1, 37)\n",
      "torch.Size([4, 25, 1, 37]) <------ holder shape\n",
      "torch.Size([4, 25, 1, 37]) <------ holder wgt information\n",
      "\n",
      "\n",
      "B-P-EC-Diag@DT-DTDftGrn_idx\n",
      "(4, 25, 22, 7)\n",
      "torch.Size([4, 25, 22, 7]) <------ holder shape\n",
      "Empty <------ holder wgt information\n",
      "\n",
      "\n",
      "B-P-EC-Diag@Value-DiagDftGrn_idx\n",
      "(4, 25, 22, 3)\n",
      "torch.Size([4, 25, 22, 3]) <------ holder shape\n",
      "Empty <------ holder wgt information\n",
      "\n",
      "\n",
      "B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx\n",
      "(4, 25, 1, 14, 121, 11)\n",
      "torch.Size([4, 25, 1, 14, 121, 11]) <------ holder shape\n",
      "Empty <------ holder wgt information\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for full_recfldgrn in full_recfldgrn_list:\n",
    "    # (1) get the info_raw from batch_rfg\n",
    "    info_raw = batch_rfg[full_recfldgrn]\n",
    "    print(full_recfldgrn)\n",
    "    print(info_raw.shape)\n",
    "\n",
    "    # (2) get the holder (input_idx) and holder_wgt (for nume embedding only)\n",
    "    if '_idx' in full_recfldgrn:\n",
    "        holder_wgt = 'Empty'\n",
    "        holder = torch.LongTensor(info_raw)\n",
    "    elif '_wgt' in full_recfldgrn:\n",
    "        holder_wgt = torch.FloatTensor(info_raw)\n",
    "        # ATTENTION: here holder_wgt could contain zeros in some valid positions.\n",
    "        holder = torch.ones_like(holder_wgt).cumsum(-1).masked_fill(holder_wgt == 0, 0).long()\n",
    "    else:\n",
    "        raise ValueError(f'Invalid suffix \"{suffix}\"')\n",
    "\n",
    "    print(holder.shape, '<------ holder shape')\n",
    "    if type(holder_wgt) == str: \n",
    "        print(holder_wgt, '<------ holder wgt information')\n",
    "    else:\n",
    "        print(holder_wgt.shape, '<------ holder wgt information')\n",
    "\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522e9dfa-cbf1-4e25-9ddc-61b612daa1f0",
   "metadata": {},
   "source": [
    "## I-NN-O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a588c5a0-a497-481b-a03f-035dd170df72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: B-P@age-AgeNumeDftGrn_wgt\n",
      "(4, 19)\n",
      "torch.Size([4, 19]) <------ holder shape\n",
      "torch.Size([4, 19]) <------ holder wgt information\n",
      "torch.Size([4, 19]) <----- holder shape\n",
      "Output: B-P@age-AgeNumeDft\n",
      "torch.Size([4, 19, 128]) <----- info shape\n",
      "\n",
      "\n",
      "Input: B-P-EC-A1C@V-A1CNumeDftGrn_wgt\n",
      "(4, 25, 1, 37)\n",
      "torch.Size([4, 25, 1, 37]) <------ holder shape\n",
      "torch.Size([4, 25, 1, 37]) <------ holder wgt information\n",
      "torch.Size([4, 25, 1, 37]) <----- holder shape\n",
      "Output: B-P-EC-A1C@V-A1CNumeDft\n",
      "torch.Size([4, 25, 1, 37, 128]) <----- info shape\n",
      "\n",
      "\n",
      "Input: B-P-EC-Diag@DT-DTDftGrn_idx\n",
      "(4, 25, 22, 7)\n",
      "torch.Size([4, 25, 22, 7]) <------ holder shape\n",
      "Empty <------ holder wgt information\n",
      "torch.Size([4, 25, 22, 7]) <----- holder shape\n",
      "Output: B-P-EC-Diag@DT-DTDft\n",
      "torch.Size([4, 25, 22, 7, 128]) <----- info shape\n",
      "\n",
      "\n",
      "Input: B-P-EC-Diag@Value-DiagDftGrn_idx\n",
      "(4, 25, 22, 3)\n",
      "torch.Size([4, 25, 22, 3]) <------ holder shape\n",
      "Empty <------ holder wgt information\n",
      "torch.Size([4, 25, 22, 3]) <----- holder shape\n",
      "Output: B-P-EC-Diag@Value-DiagDft\n",
      "torch.Size([4, 25, 22, 3, 128]) <----- info shape\n",
      "\n",
      "\n",
      "Input: B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx\n",
      "(4, 25, 1, 14, 121, 11)\n",
      "torch.Size([4, 25, 1, 14, 121, 11]) <------ holder shape\n",
      "Empty <------ holder wgt information\n",
      "torch.Size([4, 25, 1, 14, 121, 11]) <----- holder shape\n",
      "Output: B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLM\n",
      "torch.Size([4, 25, 1, 14, 121, 11, 128]) <----- info shape\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "full_recfldgrn_EmbedTensor = {}\n",
    "\n",
    "for full_recfldgrn in full_recfldgrn_list:\n",
    "    # (1) get the info_raw from batch_rfg\n",
    "    info_raw = batch_rfg[full_recfldgrn]\n",
    "    print('Input:',full_recfldgrn)\n",
    "    print(info_raw.shape)\n",
    "\n",
    "    # (2) get the holder (input_idx) and holder_wgt (for nume embedding only)\n",
    "    if '_idx' in full_recfldgrn:\n",
    "        holder_wgt = 'Empty'\n",
    "        holder = torch.LongTensor(info_raw)\n",
    "    elif '_wgt' in full_recfldgrn:\n",
    "        holder_wgt = torch.FloatTensor(info_raw)\n",
    "        # ATTENTION: here holder_wgt could contain zeros in some valid positions.\n",
    "        holder = torch.ones_like(holder_wgt).cumsum(-1).masked_fill(holder_wgt == 0, 0).long()\n",
    "    else:\n",
    "        raise ValueError(f'Invalid suffix \"{suffix}\"')\n",
    "\n",
    "    print(holder.shape, '<------ holder shape')\n",
    "    if type(holder_wgt) == str:  \n",
    "        print(holder_wgt, '<------ holder wgt information')\n",
    "    else:\n",
    "        print(holder_wgt.shape, '<------ holder wgt information')\n",
    "    \n",
    "    NN = FullRFG_2_Embed[full_recfldgrn] \n",
    "    print(holder.shape, '<----- holder shape')\n",
    "    output_recfld, holder, info = NN(full_recfldgrn, holder, holder_wgt)\n",
    "    print('Output:', output_recfld)\n",
    "    print(info.shape, '<----- info shape')\n",
    "    full_recfldgrn_EmbedTensor[output_recfld] = info\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2944002a-f342-4a23-b3f9-a18490226a31",
   "metadata": {},
   "source": [
    "# Learner Helper Fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0998059a-6282-4ea6-9795-3242b18c2444",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from fieldnn.utils.layerfn import traverse\n",
    "# from fieldnn.utils.simulate import get_next_info, get_simulated_tensor_from_fldname\n",
    "\n",
    "# # leng_mask = info_idx == 0\n",
    "\n",
    "# import torch\n",
    "\n",
    "# def get_Layer2Holder(fullname, holder, Ignore_PSN_Layers = ['B', 'P']):\n",
    "#     # holder = holder\n",
    "#     d = {}\n",
    "#     for layername in list(reversed(fullname.split('-'))):\n",
    "#         if layername in Ignore_PSN_Layers: continue\n",
    "#         leng_mask = holder == 0\n",
    "#         leng = (leng_mask == 0).sum(-1)\n",
    "#         psn_idx = (leng_mask == False).cumsum(-1).masked_fill(leng_mask, 0)\n",
    "#         d[layername] = {'holder': holder, \n",
    "#                         'leng_mask': leng_mask, \n",
    "#                         'leng': leng, \n",
    "#                         'psn_idx': psn_idx}\n",
    "#         # d[layername] = holder, psn_idx\n",
    "#         holder = leng\n",
    "#     Layer2Hoder = d\n",
    "#     return Layer2Hoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6345b911-5eed-4779-937e-bf7da222e7de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# def align_psn_idx(source_layer, current_layer, Layer2Idx, Layer2Holder):\n",
    "#     if source_layer == current_layer:\n",
    "#         psn_idx = Layer2Holder[current_layer]['psn_idx']\n",
    "#         return psn_idx\n",
    "#     else:\n",
    "#         source_psn_idx = Layer2Holder[source_layer]['psn_idx']\n",
    "#         current_leng_mask = Layer2Holder[current_layer]['leng_mask']\n",
    "#         gaps = Layer2Idx[current_layer] - Layer2Idx[source_layer]\n",
    "#         # print(gaps)\n",
    "#         # print(layername)\n",
    "#         # print(prev_info.shape)\n",
    "#         # print(leng_mask.shape)\n",
    "#         # print(leng.shape)\n",
    "#         # print(psn_idx.shape)\n",
    "#         shape0 = list(source_psn_idx.shape) + [1] * gaps\n",
    "#         shape1 = current_leng_mask.shape\n",
    "#         psn_idx = source_psn_idx.view(*shape0).expand(shape1).masked_fill(current_leng_mask, 0)\n",
    "#         # print(cpsn_idx.shape)\n",
    "#         return psn_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be4f167-ad4c-496c-ab26-ec56bd3c9dd2",
   "metadata": {},
   "source": [
    "# Learner Core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06fab7c-f81f-474a-8b5e-211197959235",
   "metadata": {},
   "source": [
    "## TFMLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07497e4f-e83a-43e2-9165-e4ca7c9ec391",
   "metadata": {},
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67c5a980-2f8b-4781-a61b-e24a6e5b4d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def _addindent(s_, numSpaces):\n",
    "    s = s_.split('\\n')\n",
    "    # don't do anything for single-line stuff\n",
    "    if len(s) == 1:\n",
    "        return s_\n",
    "    first = s.pop(0)\n",
    "    s = [(numSpaces * ' ') + line for line in s]\n",
    "    s = '\\n'.join(s)\n",
    "    s = first + '\\n' + s\n",
    "    return s\n",
    "\n",
    "class TFMLayer(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_size = 200, \n",
    "                 output_size = 200, # d_model\n",
    "                 nhead = 8,\n",
    "                 num_encoder_layers = 6, # only have encoder part\n",
    "                 num_decoder_layers = 0, # in default, we don't need decoder part. \n",
    "                 dim_feedforward = 2048, \n",
    "                 tfm_dropout = 0.1,\n",
    "                 tfm_activation = 'relu'):\n",
    "        \n",
    "        '''https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/transformer.py'''\n",
    "\n",
    "        super(TFMLayer,self).__init__()\n",
    "        self.num_encoder_layers = num_encoder_layers\n",
    "        self.num_decoder_layers = num_decoder_layers\n",
    "        self.input_size = input_size\n",
    "        self.tfm_input_size = input_size\n",
    "        self.n_directions = 1\n",
    "        self.output_size = output_size\n",
    "        assert output_size % self.n_directions == 0 \n",
    "        self.hidden_size = int(output_size / self.n_directions)\n",
    "        assert self.hidden_size == self.tfm_input_size\n",
    "        # self.psn_size = psn_size \n",
    "        \n",
    "        self.dim_feedforward = dim_feedforward\n",
    "        \n",
    "        self.transformer  = torch.nn.Transformer(d_model = self.hidden_size, \n",
    "                                                 nhead = nhead,\n",
    "                                                 num_encoder_layers = self.num_encoder_layers,\n",
    "                                                 num_decoder_layers = self.num_decoder_layers,\n",
    "                                                 dim_feedforward = dim_feedforward, \n",
    "                                                 dropout = tfm_dropout,\n",
    "                                                 activation = tfm_activation,\n",
    "                                                 batch_first = True,\n",
    "                                                 # src_mask_flag = False, # see all tokens in a sentence \n",
    "                                                 # # This IS THE NEW PART. NOT PyTorch.nn.\n",
    "                                                 ) \n",
    "\n",
    "\n",
    "    def forward(self, info, leng_mask):\n",
    "        info = self.transformer(info, info, \n",
    "                                src_key_padding_mask = leng_mask,  \n",
    "                                tgt_key_padding_mask = leng_mask)\n",
    "        # for layer in self.postprocess:\n",
    "        #     info = layer(info)\n",
    "        return info\n",
    "    \n",
    "    \n",
    "    def __repr__(self):\n",
    "        # We treat the extra repr like the sub-module, one item per line\n",
    "        extra_lines = []\n",
    "        extra_repr = self.extra_repr()\n",
    "        # empty string will be split into list ['']\n",
    "        if extra_repr:\n",
    "            extra_lines = extra_repr.split('\\n')\n",
    "        child_lines = []\n",
    "        for key, module in self._modules.items():\n",
    "            mod_str = repr(module)\n",
    "            mod_str = _addindent(mod_str, 2)\n",
    "            child_lines.append('(' + key + '): ' + mod_str)\n",
    "        lines = extra_lines + child_lines\n",
    "\n",
    "        main_str = self._get_name() + f'LEARNER(TFM): input({self.input_size}), output({self.output_size})'\n",
    "        lines = [f'(Encoder): EncoderLayer(layers_num={self.num_encoder_layers}, dim_feedforward={self.dim_feedforward})', \n",
    "                 f'(Decoder): DecoderLayer(layers_num={self.num_decoder_layers}, dim_feedforward={self.dim_feedforward})']\n",
    "        main_str += '\\n  ' + '\\n  '.join(lines) + '\\n'\n",
    "        \n",
    "        # if lines:\n",
    "        #     # simple one-liner info, which most builtin Modules will use\n",
    "        #     if len(extra_lines) == 1 and not child_lines:\n",
    "        #         main_str += extra_lines[0]\n",
    "        #     else:\n",
    "        #         main_str += '\\n  ' + '\\n  '.join(lines) + '\\n'\n",
    "        # main_str += ')'\n",
    "        return main_str\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a2a576-9e0a-43d2-b7ba-3e7366f7d40c",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa15c1dc-3fbf-4b60-91fd-ff16eb790a77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_size': 512,\n",
       " 'output_size': 512,\n",
       " 'nhead': 8,\n",
       " 'num_encoder_layers': 6,\n",
       " 'num_decoder_layers': 0,\n",
       " 'dim_feedforward': 2048,\n",
       " 'tfm_dropout': 0.1,\n",
       " 'tfm_activation': 'relu'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_para =  {'input_size': 512,\n",
    "             'output_size': 512,\n",
    "             'nhead': 8,\n",
    "             'num_encoder_layers': 6,\n",
    "             'num_decoder_layers': 0,\n",
    "             'dim_feedforward': 2048,\n",
    "             'tfm_dropout': 0.1,\n",
    "             'tfm_activation': 'relu'}\n",
    "tfm_para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69d4b65-17e4-4273-b63e-470cec593a59",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e154d5-24d4-49e7-9b72-afb35144603f",
   "metadata": {},
   "source": [
    "#### recfld information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f95cde1-19da-4184-b9a9-365d29414a79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P-EC-A1C@V-A1CNumeDft torch.Size([4, 25, 1, 37, 128])\n",
      "B-P-EC-Diag@Value-DiagDft torch.Size([4, 25, 22, 3, 128])\n",
      "B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLM torch.Size([4, 25, 1, 14, 121, 11, 128])\n"
     ]
    }
   ],
   "source": [
    "for recfld, EmbedTensor in full_recfldgrn_EmbedTensor.items():\n",
    "    print(recfld, EmbedTensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad2e4ed-f241-4c9d-bb55-c5c8a018e69d",
   "metadata": {},
   "source": [
    "#### get configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb4b00b-9981-4d0a-a6f1-c46ff8553c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b368c9c1-dde4-4caa-9284-c349ab129a80",
   "metadata": {},
   "source": [
    "#### init model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74464e80-7e6c-4eb5-a610-42c4c7eb63e1",
   "metadata": {},
   "source": [
    "#### prepare input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b7c7e639-5962-46a9-9c55-57024b9bd560",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm_layer = TFMLayer(**tfm_para)\n",
    "# tfm_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "734071a3-8ded-408b-9001-a70d6c910984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFMLayerLEARNER(TFM): input(512), output(512)\n",
       "  (Encoder): EncoderLayer(layers_num=6, dim_feedforward=2048)\n",
       "  (Decoder): DecoderLayer(layers_num=0, dim_feedforward=2048)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7999c7b-a506-4e82-b837-42ed7940737d",
   "metadata": {},
   "source": [
    "#### I-NN-O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483066b0-264f-474e-9962-8f53ba9c0d68",
   "metadata": {},
   "source": [
    "## LinearLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db28f87e-d545-498e-bdca-b7344eb3e542",
   "metadata": {},
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c12f30d1-6ce5-4e08-8a8c-0e1c6aedd3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LinearLayer(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 input_size  = 200, \n",
    "                 output_size = 200.\n",
    "                 ):\n",
    "\n",
    "        super(LinearLayer, self).__init__()\n",
    "    \n",
    "        self.input_size  = input_size\n",
    "        self.output_size = output_size\n",
    "        self.linear  = torch.nn.Linear(self.input_size, self.output_size)\n",
    "        self.init_weights()\n",
    "            \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.linear.bias.data.zero_()\n",
    "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, info):\n",
    "        info = self.linear(info)\n",
    "        return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa16a34c-007f-47b2-9e0f-7ff022c6566d",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d026cbbd-1790-4c32-864d-1a5934ac7f40",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37e8245-ae5a-468e-9fbc-e1bcce752aa9",
   "metadata": {},
   "source": [
    "#### recfld information "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c4c01f-006d-4013-a8f5-1faaa3eacdb2",
   "metadata": {},
   "source": [
    "#### get configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f284aaa8-3168-4580-a038-7ffafc001eb2",
   "metadata": {},
   "source": [
    "#### init model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76799d6-28b4-4ac6-b5e2-0cc268e0cb73",
   "metadata": {},
   "source": [
    "#### prepare input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b7ec6c-9e54-489c-a658-83b77ccdf095",
   "metadata": {},
   "source": [
    "#### I-NN-O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8b2b11-cc56-48ca-85ff-398d930e8618",
   "metadata": {},
   "source": [
    "# Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb94409e-3a5b-4195-bb71-1a043db19a89",
   "metadata": {},
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57b48f48-e1cf-4232-b2d9-aa1f2be6c516",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from fieldnn.nn.tfm import TFMLayer\n",
    "from fieldnn.nn.linear import LinearLayer\n",
    "from fieldnn.utils.layerfn import orderSeq, restoreSeq, align_psn_idx, get_Layer2Holder\n",
    "from fieldnn.utils.parafn import generate_psn_embed_para\n",
    "\n",
    "\n",
    "class Learner_Layer(torch.nn.Module):\n",
    "    def __init__(self, input_fullname, output_fullname, learner_layer_para, PSN_Embed_ModuleDict):\n",
    "        super(Learner_Layer, self).__init__()\n",
    "        \n",
    "        # Part 0: Meta\n",
    "        self.fullname = input_fullname\n",
    "        \n",
    "        self.input_fullname = input_fullname\n",
    "        self.output_fullname = output_fullname\n",
    "        assert self.input_fullname == self.output_fullname\n",
    "        \n",
    "        self.input_size = learner_layer_para['input_size']\n",
    "        self.output_size = learner_layer_para['output_size']\n",
    "        self.embed_size = self.input_size\n",
    "        self.max_leng = learner_layer_para['max_leng']\n",
    "        \n",
    "            \n",
    "        # Part 1: NN\n",
    "        nn_name, para = learner_layer_para[self.fullname]\n",
    "        self.nn_name == nn_name\n",
    "        \n",
    "        if nn_name.lower() == 'tfm':\n",
    "            assert self.input_size == self.output_size\n",
    "            self.Learner = TFMLayer(**para)\n",
    "            # Part a: PSN embedding\n",
    "            self.psn_embedding = torch.nn.Embedding(self.max_leng + 1, self.input_size, padding_idx = 0)\n",
    "            # Part b: EmbedProcess\n",
    "            self.embedprocess = torch.nn.ModuleDict()\n",
    "            for method, config in learner_layer_para['embedprocess'].items():\n",
    "                if method == 'dropout':\n",
    "                    self.embedprocess[method] = torch.nn.Dropout(**config)\n",
    "                elif method == 'layernorm':\n",
    "                    self.embedprocess[method] = torch.nn.LayerNorm(self.output_size, **config)\n",
    "                else:\n",
    "                    raise ValueError(f'no avialable embedprocess method {method}')\n",
    "                    \n",
    "            self.forward = self.forward_tfm\n",
    "                \n",
    "        elif nn_name.lower() == 'linear':\n",
    "            self.Learner = LinearLayer(**para)\n",
    "            self.forward = self.forward_lnr\n",
    "            \n",
    "        # elif nn_name.lower() == 'cnn':\n",
    "        #     self.Learner = CNNLayer(**para)\n",
    "        \n",
    "        # elif nn_name.lower() == 'rnn':\n",
    "        #     self.Learner = RNNLayer(**para)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f'NN \"{nn_name}\" is not available')\n",
    "        \n",
    "        # Part 2: PostProcess\n",
    "        self.postprocess = torch.nn.ModuleDict()\n",
    "        for method, config in learner_layer_para['postprocess'].items():\n",
    "            if method == 'dropout':\n",
    "                self.postprocess[method] = torch.nn.Dropout(**config)\n",
    "            elif method == 'layernorm':\n",
    "                self.postprocess[method] = torch.nn.LayerNorm(self.output_size, **config)\n",
    "\n",
    "        self.Ignore_PSN_Layers = learner_layer_para['Ignore_PSN_Layers']\n",
    "        \n",
    "    # def get_psn_embed_tensor(self, fullname, holder):\n",
    "    #     name = fullname.split('-')[-1]\n",
    "    #     Layer2Idx = {v:idx for idx, v in enumerate(fullname.split('-'))}\n",
    "    #     Layer2Holder = get_Layer2Holder(fullname, holder, self.Ignore_PSN_Layers)\n",
    "    #     psn_embed = 0\n",
    "    #     for source_layer, Embed in self.PSN_Embed_ModuleDict.items():\n",
    "    #         cpsn_idx = align_psn_idx(source_layer, name, Layer2Idx, Layer2Holder)\n",
    "    #         psn_embed = psn_embed + Embed(cpsn_idx)\n",
    "    #     return psn_embed\n",
    "    \n",
    "    def reshape(self, info, leng_mask):\n",
    "        nbs = np.array(info.shape[:-2]).prod()\n",
    "        ngrn, dim = info.shape[-2:]\n",
    "        # print(nbs, ngrn, dim)\n",
    "        \n",
    "        tmp_info = info.contiguous().view(nbs, ngrn, dim)\n",
    "        # print(tmp_info.shape)\n",
    "\n",
    "        tmp_leng_mask = leng_mask.contiguous().view(nbs, ngrn)\n",
    "        # print(tmp_leng_mask.shape)\n",
    "\n",
    "        tmp_leng = (tmp_leng_mask == 0).sum(-1)\n",
    "        # print(tmp_leng.shape)\n",
    "        \n",
    "        ord_info,      ord_leng, r_idx = orderSeq(tmp_info, tmp_leng)\n",
    "        ord_leng_mask, ord_leng, r_idx = orderSeq(tmp_leng_mask, tmp_leng)\n",
    "        return ord_info, ord_leng_mask, r_idx\n",
    "    \n",
    "    def restore(self, ord_info_output, leng_mask, r_idx):\n",
    "        info_new = restoreSeq(ord_info_output, r_idx)\n",
    "        output_size = info_new.shape[-1]\n",
    "        info_output = info_new.view(*list(leng_mask.shape) + [output_size])\n",
    "        return info_output\n",
    "        \n",
    "    def generate_locidx(self, holder):\n",
    "        leng_mask = holder == 0\n",
    "        # leng = (leng_mask == 0).sum(-1)\n",
    "        psn_idx = (leng_mask == False).cumsum(-1).masked_fill(leng_mask, 0)\n",
    "        return psn_idx\n",
    "    \n",
    "    def forward_tfm(self, fullname, holder, info):\n",
    "        assert self.input_fullname == fullname\n",
    "        \n",
    "        # (1) adding psn embed\n",
    "        psn_locid = self.generate_locidx(holder) #### TODO\n",
    "        psn_embed = self.psn_embedding(psn_locid)\n",
    "        for nn, layer in self.embedprocess.items(): \n",
    "            psn_embed = layer(psn_embed)\n",
    "        info = info + psn_embed\n",
    "        # TODO: process psn_embed? Do we need the further embed process? \n",
    "        \n",
    "        # (2) do the tfm calculation\n",
    "        leng_mask = holder == 0\n",
    "        ord_info, ord_leng_mask, r_ix = self.reshape(info, leng_mask)\n",
    "        ord_info_output = self.Learner(ord_info, ord_leng_mask)\n",
    "        info = self.restore(ord_info_output, leng_mask, r_ix)\n",
    "        \n",
    "        # (3) post-process\n",
    "        for nn_name, layer in self.postprocess.items():\n",
    "            info = layer(info)\n",
    "            \n",
    "        # we do not change the fullname and holder\n",
    "        return self.output_fullname, holder, info\n",
    "    \n",
    "    \n",
    "    def forward_lnr(self, fullname, holder, info):\n",
    "        assert self.input_fullname == fullname\n",
    "        # (1) learn the info\n",
    "        info = self.Learner(info)\n",
    "        \n",
    "        # (2) do the masked_leng because of non-zero bias\n",
    "        leng_mask = holder == 0\n",
    "        info = info.masked_fill(leng_mask.unsqueeze(-1), 0)\n",
    "    \n",
    "        # (3) post-process\n",
    "        for nn_name, layer in self.postprocess.items():\n",
    "            info = layer(info)\n",
    "            \n",
    "        # we do not change the fullname and holder\n",
    "        return self.output_fullname, holder, info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a976c1-42cc-4466-8be1-0cccf65418ae",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0070a723-cdce-4c29-a557-38262e8eea30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5eb045c8-4c59-42b5-a521-db7e80065f97",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd950f8-ad27-4e9a-9f47-e05f45ec9322",
   "metadata": {},
   "source": [
    "### recfld informaiton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9444ad58-9dd9-4a50-83f5-e5efd41a20d2",
   "metadata": {},
   "source": [
    "### get configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce20013-6062-4d10-9e5d-c20fbb4488a3",
   "metadata": {},
   "source": [
    "### init model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49295d3c-9abb-406a-872d-1642344f7e50",
   "metadata": {},
   "source": [
    "### prepare input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276c7cf8-6a60-4324-a8d9-c2d0ec6aaedd",
   "metadata": {},
   "source": [
    "### I-NN-O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a341b4c-c21d-4f64-817a-9802b96be6e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
