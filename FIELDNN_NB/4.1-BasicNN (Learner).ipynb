{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7588aa63-50a8-4f68-b40d-5e65e1783790",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/floydluo/Library/CloudStorage/OneDrive-JohnsHopkins/000Projects/0000-Infrastructure/0000-RecFld/FieldNN\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61bc989-f648-42f9-9580-fd91c5fddc0a",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "\n",
    "This is the for \n",
    "\n",
    "* module `fieldnn.basicnn.learner` module\n",
    "* module `fieldnn.configfn.learnerfn` module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f1850-8d92-40fd-ba69-6657f63ca703",
   "metadata": {},
   "source": [
    "# Prepare Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98e6de85-919d-4ffa-b1d6-0f286e9dc6f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 <---- dataset\n",
      "1 <---- dataset\n",
      "B-P-InfoGrn_wgt torch.Size([4, 43])\n",
      "B-P-InfoGrn_tknidx torch.Size([4, 43])\n",
      "B-P-InfoGrn_fldidx torch.Size([4, 43])\n",
      "B-P-EC-PNSect-TknzGrn_wgt torch.Size([4, 23, 14, 221])\n",
      "B-P-EC-PNSect-TknzGrn_tknidx torch.Size([4, 23, 14, 221])\n",
      "B-P-EC-PNSect-TknzGrn_fldidx torch.Size([4, 23, 14, 221])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from fieldnn.dataset import RFGDataset, my_collate_fn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "Tensor_folder = 'data/ProcData/FldGrnTensor/'\n",
    "recfldgrn_list = ['P-InfoGrn',  'P-EC-PNSect-TknzGrn']\n",
    "full_recfldgrn_list = ['B-' + i for i in recfldgrn_list]\n",
    "\n",
    "# from the get_grain_fn to get the Elig_Set.\n",
    "Elig_Set = ['P4', 'P5', 'P6', 'P7']\n",
    "\n",
    "dataset = RFGDataset(Tensor_folder, recfldgrn_list, Elig_Set, RecRootID = 'PID')\n",
    "print(len(dataset), '<---- dataset')\n",
    "dataloader = DataLoader(dataset, batch_size = 4, shuffle = True, collate_fn = my_collate_fn)\n",
    "print(len(dataloader), '<---- dataset')\n",
    "\n",
    "\n",
    "for idx, batch in enumerate(dataloader):\n",
    "    # print(f'\\n------ {idx}')\n",
    "    batch_rfg, batch_y = batch\n",
    "    for k, v in batch_rfg.items(): print(k, v.shape)\n",
    "    break\n",
    "    # for k, v in batch_rfg.items(): print(k, v.shape)\n",
    "    # print(batch_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70729ebd-a267-4acc-96e6-ef0ea85eb354",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P-InfoGrn', 'B-P-EC-PNSect-TknzGrn']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the Input\n",
    "RECFLD_TO_TENSOR = {}\n",
    "for full_recfldgrn in full_recfldgrn_list:\n",
    "    RECFLD_TO_TENSOR[full_recfldgrn] = {k: v for k, v in batch_rfg.items() if full_recfldgrn in k}\n",
    "    \n",
    "[i for i in RECFLD_TO_TENSOR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d944f1c-10e3-4e0d-a71e-40cd99cdc87f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubUnitName</th>\n",
       "      <th>input_names</th>\n",
       "      <th>output_name</th>\n",
       "      <th>output_layerid</th>\n",
       "      <th>SubUnit_BasicNN_List</th>\n",
       "      <th>SubUnit_DefaultBasicNN_List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E</td>\n",
       "      <td>[B-P-InfoGrn]</td>\n",
       "      <td>B-P-Info</td>\n",
       "      <td>3</td>\n",
       "      <td>[expander-CateEmbed]</td>\n",
       "      <td>[{'full_recfldgrn': 'B-P-InfoGrn', 'Info': ['P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E</td>\n",
       "      <td>[B-P-EC-PNSect-TknzGrn]</td>\n",
       "      <td>B-P-EC-PNSect-Tknz</td>\n",
       "      <td>5</td>\n",
       "      <td>[expander-LLMEmbed]</td>\n",
       "      <td>[{'full_recfldgrn': 'B-P-EC-PNSect-TknzGrn', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SubUnitName              input_names         output_name  output_layerid  \\\n",
       "0           E            [B-P-InfoGrn]            B-P-Info               3   \n",
       "1           E  [B-P-EC-PNSect-TknzGrn]  B-P-EC-PNSect-Tknz               5   \n",
       "\n",
       "   SubUnit_BasicNN_List                        SubUnit_DefaultBasicNN_List  \n",
       "0  [expander-CateEmbed]  [{'full_recfldgrn': 'B-P-InfoGrn', 'Info': ['P...  \n",
       "1   [expander-LLMEmbed]  [{'full_recfldgrn': 'B-P-EC-PNSect-TknzGrn', '...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fieldnn.dataflowfn.embedflowfn import get_EmbeddingBlock_SubUnit\n",
    "from fieldnn.dataflowfn.baseflowfn import mapping_SubUnitName_to_SubUnitNNList\n",
    "from fieldnn.dataflowfn.baseflowfn import get_SubUnit_Default_NNPara_List\n",
    "from fieldnn.dataflowfn.baseflowfn import get_SubUnit_BasicNN_Config_List\n",
    "\n",
    "############################################# Hyperparameters\n",
    "default_BasicNNtype_To_NNName = {\n",
    "    'expander': None, # will be updated according to the Grn Type\n",
    "    'reducer': 'ReduceMax',\n",
    "    'merger': 'MergeConcat',\n",
    "    'learner': None, # TODO: ignore this currently\n",
    "    \n",
    "}\n",
    "#############################################\n",
    "\n",
    "############################\n",
    "embed_size = 128\n",
    "process = {'activator': 'gelu',\n",
    "           'dropout': {'p': 0.5, 'inplace': False},\n",
    "           'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "############################\n",
    "\n",
    "\n",
    "default_SubUnitName = 'E'\n",
    "fldgrn_folder = 'data/ProcData/FldGrnInfo'\n",
    "learner_default_dict = {} # To update it in the future. \n",
    "\n",
    "\n",
    "df_SubUnit = get_EmbeddingBlock_SubUnit(full_recfldgrn_list, default_SubUnitName)\n",
    "\n",
    "s = df_SubUnit.apply(lambda x: mapping_SubUnitName_to_SubUnitNNList(x['SubUnitName'], \n",
    "                                                                    x['input_names'],\n",
    "                                                                    default_BasicNNtype_To_NNName), \n",
    "                    axis = 1)\n",
    "df_SubUnit['SubUnit_BasicNN_List'] = s\n",
    "s = df_SubUnit.apply(lambda x: get_SubUnit_Default_NNPara_List(x['SubUnit_BasicNN_List'], \n",
    "                                                               x['input_names'],\n",
    "                                                               fldgrn_folder, \n",
    "                                                               learner_default_dict), axis = 1)\n",
    "\n",
    "df_SubUnit['SubUnit_DefaultBasicNN_List'] = s\n",
    "df_SubUnit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f77f8519-8b95-4642-9877-a231880ffcf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'vocab_tokenizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[43mdf_SubUnit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_SubUnit_BasicNN_Config_List\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSubUnit_BasicNN_List\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSubUnit_DefaultBasicNN_List\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_names\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43membed_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m df_SubUnit[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSubUnit_BasicNN_Config_List\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m s\n\u001b[1;32m     10\u001b[0m df_SubUnit\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/boost/lib/python3.8/site-packages/pandas/core/frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9557\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9559\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m   9560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   9561\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9566\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   9567\u001b[0m )\n\u001b[0;32m-> 9568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/boost/lib/python3.8/site-packages/pandas/core/apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/boost/lib/python3.8/site-packages/pandas/core/apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 891\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/boost/lib/python3.8/site-packages/pandas/core/apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    906\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 907\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    909\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    910\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    911\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m s \u001b[38;5;241m=\u001b[39m df_SubUnit\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mget_SubUnit_BasicNN_Config_List\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSubUnit_BasicNN_List\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSubUnit_DefaultBasicNN_List\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_names\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43membed_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43m)\u001b[49m, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      9\u001b[0m df_SubUnit[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSubUnit_BasicNN_Config_List\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m s\n\u001b[1;32m     10\u001b[0m df_SubUnit\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-JohnsHopkins/000Projects/0000-Infrastructure/0000-RecFld/FieldNN/fieldnn/dataflowfn/baseflowfn.py:236\u001b[0m, in \u001b[0;36mget_SubUnit_BasicNN_Config_List\u001b[0;34m(SubUnit_BasicNN_List, SubUnit_DefaultBasicNN_List, SubUnit_input_names, SubUnit_output_name, embed_size, process)\u001b[0m\n\u001b[1;32m    232\u001b[0m default_nnpara \u001b[38;5;241m=\u001b[39m SubUnit_DefaultBasicNN_List[basic_nn_idx] \n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m##############\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m Basic_Config \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_BasicNN_Config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_type_nn_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43minput_names_nnlvl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mdefault_nnpara\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43membed_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m output_name_nnlvl \u001b[38;5;241m=\u001b[39m Basic_Config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_name_nnlvl\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    242\u001b[0m BasicNN_Config \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnn_type_nn_name\u001b[39m\u001b[38;5;124m'\u001b[39m: nn_type_nn_name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBasic_Config\u001b[39m\u001b[38;5;124m'\u001b[39m: Basic_Config}\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-JohnsHopkins/000Projects/0000-Infrastructure/0000-RecFld/FieldNN/fieldnn/dataflowfn/baseflowfn.py:117\u001b[0m, in \u001b[0;36mgenerate_BasicNN_Config\u001b[0;34m(nn_type_nn_name, input_names_nnlvl, default_nnpara, embed_size, process)\u001b[0m\n\u001b[1;32m    114\u001b[0m postprocess \u001b[38;5;241m=\u001b[39m process\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Derive the para\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m vocab_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mdefault_nnpara\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvocab_tokenizer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    118\u001b[0m init \u001b[38;5;241m=\u001b[39m default_nnpara[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    119\u001b[0m para \u001b[38;5;241m=\u001b[39m get_expander_para(nn_name, default_nnpara, \n\u001b[1;32m    120\u001b[0m                          embed_size, vocab_tokenizer, init, postprocess)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'vocab_tokenizer'"
     ]
    }
   ],
   "source": [
    "s = df_SubUnit.apply(lambda x: get_SubUnit_BasicNN_Config_List(x['SubUnit_BasicNN_List'], \n",
    "                                                               x['SubUnit_DefaultBasicNN_List'], \n",
    "                                                               x['input_names'], \n",
    "                                                               x['output_name'], \n",
    "                                                                embed_size, \n",
    "                                                                process, \n",
    "                                                               ), axis = 1)\n",
    "\n",
    "df_SubUnit['SubUnit_BasicNN_Config_List'] = s\n",
    "df_SubUnit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "148b0bee-5e48-47e4-abb7-eef0f9638c26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P-Info torch.Size([4, 43, 128])\n",
      "B-P-EC-PNSect-Tknz torch.Size([4, 23, 14, 221, 128])\n"
     ]
    }
   ],
   "source": [
    "from fieldnn.module.embedblock import EmbedBlockLayer\n",
    "\n",
    "EmbedBlock = EmbedBlockLayer(df_SubUnit)\n",
    "\n",
    "RECFLD_TO_EMBEDTESNOR = EmbedBlock(RECFLD_TO_TENSOR)\n",
    "\n",
    "for k, v in RECFLD_TO_EMBEDTESNOR.items():\n",
    "    print(k, v['info'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8412c749-070e-4227-9857-97bd243a9782",
   "metadata": {},
   "source": [
    "# Get Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dd4a94c-55cb-40ab-afa3-c56c36b50169",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P-Info torch.Size([4, 43, 128])\n",
      "B-P-EC-PNSect-Tknz torch.Size([4, 23, 14, 221, 128])\n"
     ]
    }
   ],
   "source": [
    "for full_recfld, info_dict in RECFLD_TO_EMBEDTESNOR.items():\n",
    "    print(full_recfld, info_dict['info'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "497b50ec-25de-44ff-a137-6bb55d92efb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_layer = max([len(i.split('-')) for i in RECFLD_TO_EMBEDTESNOR])\n",
    "max_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be4f167-ad4c-496c-ab26-ec56bd3c9dd2",
   "metadata": {},
   "source": [
    "# Learner: BasicNN Name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06fab7c-f81f-474a-8b5e-211197959235",
   "metadata": {},
   "source": [
    "## TFM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07497e4f-e83a-43e2-9165-e4ca7c9ec391",
   "metadata": {},
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67c5a980-2f8b-4781-a61b-e24a6e5b4d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from fieldnn.utils.layerfn import orderSeq, restoreSeq\n",
    "\n",
    "def _addindent(s_, numSpaces):\n",
    "    s = s_.split('\\n')\n",
    "    # don't do anything for single-line stuff\n",
    "    if len(s) == 1:\n",
    "        return s_\n",
    "    first = s.pop(0)\n",
    "    s = [(numSpaces * ' ') + line for line in s]\n",
    "    s = '\\n'.join(s)\n",
    "    s = first + '\\n' + s\n",
    "    return s\n",
    "\n",
    "class TFMLayer(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_size = 200, \n",
    "                 output_size = 200, # d_model\n",
    "                 nhead = 8,\n",
    "                 num_encoder_layers = 6, # only have encoder part\n",
    "                 num_decoder_layers = 0, # in default, we don't need decoder part. \n",
    "                 dim_feedforward = 2048, \n",
    "                 tfm_dropout = 0.1,\n",
    "                 tfm_activation = 'relu', \n",
    "                 psn_max = 512, \n",
    "                 psn_embedprocess = {}):\n",
    "        \n",
    "        '''https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/transformer.py'''\n",
    "\n",
    "        super(TFMLayer,self).__init__()\n",
    "        self.num_encoder_layers = num_encoder_layers\n",
    "        self.num_decoder_layers = num_decoder_layers\n",
    "        self.input_size = input_size\n",
    "        self.tfm_input_size = input_size\n",
    "        self.n_directions = 1\n",
    "        self.output_size = output_size\n",
    "        assert output_size % self.n_directions == 0 \n",
    "        self.hidden_size = int(output_size / self.n_directions)\n",
    "        assert self.hidden_size == self.tfm_input_size\n",
    "        # self.psn_size = psn_size \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.dim_feedforward = dim_feedforward\n",
    "        \n",
    "        self.transformer  = torch.nn.Transformer(d_model = self.hidden_size, \n",
    "                                                 nhead = nhead,\n",
    "                                                 num_encoder_layers = self.num_encoder_layers,\n",
    "                                                 num_decoder_layers = self.num_decoder_layers,\n",
    "                                                 dim_feedforward = dim_feedforward, \n",
    "                                                 dropout = tfm_dropout,\n",
    "                                                 activation = tfm_activation,\n",
    "                                                 batch_first = True,\n",
    "                                                 # src_mask_flag = False, # see all tokens in a sentence \n",
    "                                                 # # This IS THE NEW PART. NOT PyTorch.nn.\n",
    "                                                 )\n",
    "        \n",
    "        # Part a: PSN embedding\n",
    "        # (bs, xxx, psn_max, dim)\n",
    "        self.psn_max = psn_max\n",
    "        self.psn_embedding = torch.nn.Embedding(self.psn_max + 1, \n",
    "                                                self.input_size, \n",
    "                                                padding_idx = 0)\n",
    "        \n",
    "        # Part b: PSN EmbedProcess\n",
    "        self.psn_embedprocess = torch.nn.ModuleDict()\n",
    "        for method, config in psn_embedprocess.items():\n",
    "            if method == 'dropout':\n",
    "                self.psn_embedprocess[method] = torch.nn.Dropout(**config)\n",
    "            elif method == 'layernorm':\n",
    "                self.psn_embedprocess[method] = torch.nn.LayerNorm(self.output_size, **config)\n",
    "            else:\n",
    "                raise ValueError(f'no avialable embedprocess method {method}')\n",
    "                \n",
    "        # you can either choose v1 or v2 forward method.\n",
    "        # self.forward = self.forward_v1\n",
    "        self.forward = self.forward_v2\n",
    "    \n",
    "    def forward_v1(self, holder, info):\n",
    "        \n",
    "        # (1) get the leng_mask\n",
    "        leng_mask = holder == 0\n",
    "        \n",
    "        \n",
    "        # (2.1) get the psn_embed \n",
    "        psn_id = self.generate_psnidx(leng_mask) \n",
    "        psn_embed = self.psn_embedding(psn_id)\n",
    "        # print(psn_embed[0, 0, 0, :, 0], '<------------- psn_embed 1')\n",
    "        \n",
    "        # (2.2) TODO: process psn_embed? Do we need the further embed process? \n",
    "        for nn, layer in self.psn_embedprocess.items(): \n",
    "            psn_embed = layer(psn_embed)\n",
    "            \n",
    "        # print(psn_embed[0, 0, 0, :, 0], '<------------- psn_embed 2')\n",
    "        \n",
    "        # (2.3) add psn_embed to info\n",
    "        info = info + psn_embed\n",
    "        # print(info[0, 0, 0, :, 0], '<------------- info = info + psn_embed')\n",
    "        \n",
    "        \n",
    "        # (3) reshape\n",
    "        ord_info, ord_leng_mask, r_ix = self.reshape(info, leng_mask)\n",
    "        \n",
    "        # print(ord_info[0, :, 0], '<------------- ord_info')\n",
    "        \n",
    "        # (4) do the transformer calculator\n",
    "        ord_info_output = self.transformer(ord_info, ord_info, \n",
    "                                           src_key_padding_mask = ord_leng_mask,  \n",
    "                                           tgt_key_padding_mask = ord_leng_mask)\n",
    "        \n",
    "        # print(ord_info_output[0, :, 0], '<------------- ord_info_output')\n",
    "        \n",
    "        # (5) restore\n",
    "        info = self.restore(ord_info_output, leng_mask, r_ix)\n",
    "        # print(info[0, 0, 0, :, 0], '<------------- info = self.restore(ord_info_output, leng_mask, r_ix)')\n",
    "            \n",
    "        return holder, info\n",
    "    \n",
    "    \n",
    "    def forward_v2(self, holder, info):\n",
    "        # (1) get the leng_mask\n",
    "        leng_mask = holder == 0\n",
    "        \n",
    "        # print(info[0, 0, 0, :, 0], '<------------- info 1')\n",
    "        \n",
    "        \n",
    "        # (2) reshape \n",
    "        ord_info, ord_leng_mask, r_ix = self.reshape(info, leng_mask)\n",
    "        # print(ord_info[0, :, 0], '<------------- ord_info')\n",
    "        \n",
    "        # (3.1) get the psn_embed \n",
    "        psn_id = self.generate_psnidx(ord_leng_mask) \n",
    "        psn_embed = self.psn_embedding(psn_id)\n",
    "        # print(psn_embed[0, :, 0], '<------------- psn_embed 1')\n",
    "        \n",
    "        \n",
    "        # (3.2) TODO: process psn_embed? Do we need the further embed process? \n",
    "        for nn, layer in self.psn_embedprocess.items(): \n",
    "            psn_embed = layer(psn_embed)\n",
    "            \n",
    "        # print(psn_embed[0, :, 0], '<------------- psn_embed 2')\n",
    "        \n",
    "        \n",
    "        # (3.3) add psn_embed to info\n",
    "        ord_info = ord_info + psn_embed\n",
    "        \n",
    "        # print(ord_info[0, :, 0], '<------------- ord_info 1')\n",
    "        \n",
    "    \n",
    "        # (4) do the transformer calculator\n",
    "        ord_info_output = self.transformer(ord_info, ord_info, \n",
    "                                           src_key_padding_mask = ord_leng_mask,  \n",
    "                                           tgt_key_padding_mask = ord_leng_mask)\n",
    "        \n",
    "        # print(ord_info_output[0, :, 0], '<------------- ord_info_output 1')\n",
    "        \n",
    "        \n",
    "        # (5) restore\n",
    "        info = self.restore(ord_info_output, leng_mask, r_ix)\n",
    "        # print(info[0, 0, 0, :, 0], '<------------- info 2')\n",
    "        \n",
    "        return holder, info\n",
    "    \n",
    "    \n",
    "    def reshape(self, info, leng_mask):\n",
    "        nbs = int(np.array(info.shape[:-2]).prod())\n",
    "        # nbs = np.array(info.shape[:-2]).prod()\n",
    "        ngrn, dim = info.shape[-2:]\n",
    "        # print(nbs, ngrn, dim)\n",
    "        \n",
    "        tmp_info = info.contiguous().view(nbs, ngrn, dim)\n",
    "        # print(tmp_info.shape)\n",
    "\n",
    "        tmp_leng_mask = leng_mask.contiguous().view(nbs, ngrn)\n",
    "        # print(tmp_leng_mask.shape)\n",
    "\n",
    "        tmp_leng = (tmp_leng_mask == 0).sum(-1)\n",
    "        # print(tmp_leng.shape)\n",
    "        \n",
    "        ord_info,      ord_leng, r_idx = orderSeq(tmp_info, tmp_leng)\n",
    "        ord_leng_mask, ord_leng, r_idx = orderSeq(tmp_leng_mask, tmp_leng)\n",
    "        return ord_info, ord_leng_mask, r_idx\n",
    "    \n",
    "    def restore(self, ord_info_output, leng_mask, r_idx):\n",
    "        info_new = restoreSeq(ord_info_output, r_idx)\n",
    "        output_size = info_new.shape[-1]\n",
    "        info_output = info_new.view(*list(leng_mask.shape) + [output_size])\n",
    "        return info_output\n",
    "        \n",
    "    def generate_psnidx(self, leng_mask):\n",
    "        # leng_mask = holder == 0\n",
    "        psn_idx = (leng_mask == False).cumsum(-1).masked_fill(leng_mask, 0)\n",
    "        return psn_idx\n",
    "    \n",
    "    \n",
    "    def __repr__(self):\n",
    "        # We treat the extra repr like the sub-module, one item per line\n",
    "        extra_lines = []\n",
    "        extra_repr = self.extra_repr()\n",
    "        # empty string will be split into list ['']\n",
    "        if extra_repr:\n",
    "            extra_lines = extra_repr.split('\\n')\n",
    "        child_lines = []\n",
    "        for key, module in self._modules.items():\n",
    "            mod_str = repr(module)\n",
    "            mod_str = _addindent(mod_str, 2)\n",
    "            child_lines.append('(' + key + '): ' + mod_str)\n",
    "        lines = extra_lines + child_lines\n",
    "\n",
    "        main_str = self._get_name() + f'LEARNER(TFM): input({self.input_size}), output({self.output_size}): ('\n",
    "        lines = [f'(Encoder): EncoderLayer(layers_num={self.num_encoder_layers}, dim_feedforward={self.dim_feedforward})', \n",
    "                 f'(Decoder): DecoderLayer(layers_num={self.num_decoder_layers}, dim_feedforward={self.dim_feedforward})']\n",
    "        main_str += '\\n  ' + '\\n  '.join(lines) + '\\n' + ')'\n",
    "        \n",
    "        # if lines:\n",
    "        #     # simple one-liner info, which most builtin Modules will use\n",
    "        #     if len(extra_lines) == 1 and not child_lines:\n",
    "        #         main_str += extra_lines[0]\n",
    "        #     else:\n",
    "        #         main_str += '\\n  ' + '\\n  '.join(lines) + '\\n'\n",
    "        # main_str += ')'\n",
    "        return main_str\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a2a576-9e0a-43d2-b7ba-3e7366f7d40c",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa15c1dc-3fbf-4b60-91fd-ff16eb790a77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_tfm_para(input_size, default_tfm_para):\n",
    "    assert 'input_size' not in default_tfm_para\n",
    "    \n",
    "    tfm_para =  {'input_size': input_size,\n",
    "                 'output_size': input_size,\n",
    "                 'nhead': 8,\n",
    "                 'num_encoder_layers': 6,\n",
    "                 'num_decoder_layers': 0,\n",
    "                 'dim_feedforward': 2048,\n",
    "                 'tfm_dropout': 0.1,\n",
    "                 'tfm_activation': 'relu',\n",
    "                 'psn_max': 512, \n",
    "                 'psn_embedprocess': {}\n",
    "                }\n",
    "    \n",
    "    for k, v in default_tfm_para.items(): tfm_para[k] = v\n",
    "    return tfm_para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69d4b65-17e4-4273-b63e-470cec593a59",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e154d5-24d4-49e7-9b72-afb35144603f",
   "metadata": {},
   "source": [
    "**recfld information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f95cde1-19da-4184-b9a9-365d29414a79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P-Info torch.Size([4, 43, 128])\n",
      "B-P-EC-PNSect-Tknz torch.Size([4, 23, 14, 221, 128])\n"
     ]
    }
   ],
   "source": [
    "for recfld, EmbedTensor in RECFLD_TO_EMBEDTESNOR.items():\n",
    "    print(recfld, EmbedTensor['info'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad2e4ed-f241-4c9d-bb55-c5c8a018e69d",
   "metadata": {},
   "source": [
    "**get configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fb4b00b-9981-4d0a-a6f1-c46ff8553c82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_size': 128,\n",
       " 'output_size': 128,\n",
       " 'nhead': 8,\n",
       " 'num_encoder_layers': 3,\n",
       " 'num_decoder_layers': 0,\n",
       " 'dim_feedforward': 2048,\n",
       " 'tfm_dropout': 0.1,\n",
       " 'tfm_activation': 'relu',\n",
       " 'psn_max': 512,\n",
       " 'psn_embedprocess': {}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Main Config\n",
    "### others will change with each recfldgrn\n",
    "\n",
    "#######################\n",
    "psn_embedprocess = {\n",
    "    # 'activator': 'gelu',\n",
    "    # 'dropout': {'p': 0.5, 'inplace': False}, # maybe the dropout?\n",
    "    # 'layernorm': {'eps': 1e-05, 'elementwise_affine': True}\n",
    "}\n",
    "\n",
    "embed_size = 128\n",
    "default_tfm_para = {'psn_max': 512, \n",
    "                    'num_encoder_layers': 3,\n",
    "                    'psn_embedprocess': psn_embedprocess}\n",
    "#######################\n",
    "tfm_para = get_tfm_para(embed_size, default_tfm_para)\n",
    "tfm_para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b368c9c1-dde4-4caa-9284-c349ab129a80",
   "metadata": {},
   "source": [
    "**init model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7c7e639-5962-46a9-9c55-57024b9bd560",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFMLayerLEARNER(TFM): input(128), output(128): (\n",
       "  (Encoder): EncoderLayer(layers_num=3, dim_feedforward=2048)\n",
       "  (Decoder): DecoderLayer(layers_num=0, dim_feedforward=2048)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN = TFMLayer(**tfm_para)\n",
    "# tfm_layer\n",
    "NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74464e80-7e6c-4eb5-a610-42c4c7eb63e1",
   "metadata": {},
   "source": [
    "**prepare input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05169eec-262e-43d1-bc7a-f6588785d6be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P-Info', 'B-P-EC-PNSect-Tknz']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in RECFLD_TO_EMBEDTESNOR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa4fd716-6050-4e73-9d27-47e941a2fa2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 23, 14, 221]) <-----  holder.shape\n",
      "torch.Size([4, 23, 14, 221, 128]) <-----  info.shape\n"
     ]
    }
   ],
   "source": [
    "# recfld = 'B-P-EC-Diag@Value-DiagDft'\n",
    "\n",
    "recfld = 'B-P-EC-PNSect-Tknz'\n",
    "info_dict = RECFLD_TO_EMBEDTESNOR[recfld]\n",
    "holder, info = info_dict['holder'], info_dict['info']\n",
    "\n",
    "print(holder.shape, '<-----  holder.shape')\n",
    "print(info.shape, '<-----  info.shape')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752dd0d5-305e-4ab9-adea-7565c8204322",
   "metadata": {},
   "source": [
    "**I-NN-O**\n",
    "\n",
    "The following three should have the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3beff7e9-157f-46fb-bff1-14f198ae247e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3842, -1.2681,  0.2205, -0.5259,  0.2181, -0.1468,  3.5249, -0.6643,\n",
      "        -0.4277,  0.4361,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "holder_output, info_output_v1 = NN.forward_v1(holder, info)\n",
    "# info_output_v1\n",
    "if len(info.shape) == 5:\n",
    "    print(info_output_v1[0, 0, 0, :, 0])\n",
    "if len(info.shape) == 3:\n",
    "    print(info_output_v1[0, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7b6db2b-4752-40f2-aec9-dc6c37c3b196",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3842, -1.2681,  0.2205, -0.5259,  0.2181, -0.1468,  3.5249, -0.6643,\n",
      "        -0.4277,  0.4361,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "holder_output, info_output_v2 = NN.forward_v2(holder, info)\n",
    "if len(info.shape) == 5:\n",
    "    print(info_output_v2[0, 0, 0, :, 0])\n",
    "if len(info.shape) == 3:\n",
    "    print(info_output_v2[0, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26f24050-81fb-42c5-b8ec-9796138e55f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3842, -1.2681,  0.2205, -0.5259,  0.2181, -0.1468,  3.5249, -0.6643,\n",
      "        -0.4277,  0.4361,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "holder_output, info_output = NN(holder, info)\n",
    "if len(info.shape) == 5:\n",
    "    print(info_output[0, 0, 0, :, 0])\n",
    "if len(info.shape) == 3:\n",
    "    print(info_output[0, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483066b0-264f-474e-9962-8f53ba9c0d68",
   "metadata": {},
   "source": [
    "## Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db28f87e-d545-498e-bdca-b7344eb3e542",
   "metadata": {},
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c12f30d1-6ce5-4e08-8a8c-0e1c6aedd3c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class LinearLayer(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 input_size  = 200, \n",
    "                 output_size = 200,\n",
    "                 initrange = 0.1\n",
    "                 ):\n",
    "\n",
    "        super(LinearLayer, self).__init__()\n",
    "    \n",
    "        self.input_size  = input_size\n",
    "        self.output_size = output_size\n",
    "        self.linear  = torch.nn.Linear(self.input_size, self.output_size)\n",
    "        self.linear.bias.data.zero_()\n",
    "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    \n",
    "    def forward(self, holder, info):\n",
    "        # assert self.input_fullname == fullname\n",
    "        # (1) learn the info\n",
    "        info = self.linear(info)\n",
    "        \n",
    "        # (2) do the masked_leng because of non-zero bias\n",
    "        leng_mask = holder == 0\n",
    "        info = info.masked_fill(leng_mask.unsqueeze(-1), 0)\n",
    "    \n",
    "        # (3) post-process\n",
    "        # for nn_name, layer in self.postprocess.items():\n",
    "        #     info = layer(info)\n",
    "            \n",
    "        # we do not change the fullname and holder\n",
    "        return holder, info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa16a34c-007f-47b2-9e0f-7ff022c6566d",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f20faf37-7ec0-4b2b-a344-7d73d7c9996a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "default_linear_para = {'initrange': 0.1}\n",
    "\n",
    "def get_linear_para(input_size, output_size, default_linear_para):\n",
    "    linear_para =  {'input_size': input_size,\n",
    "                    'output_size': output_size}\n",
    "    \n",
    "    for k, v in default_linear_para.items(): linear_para[k] = v\n",
    "    return linear_para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d026cbbd-1790-4c32-864d-1a5934ac7f40",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37e8245-ae5a-468e-9fbc-e1bcce752aa9",
   "metadata": {},
   "source": [
    "**recfld information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28a4afd6-5b71-4aea-9b1c-08116b647f79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P-Info torch.Size([4, 43, 128])\n",
      "B-P-EC-PNSect-Tknz torch.Size([4, 23, 14, 221, 128])\n"
     ]
    }
   ],
   "source": [
    "for recfld, EmbedTensor in RECFLD_TO_EMBEDTESNOR.items():\n",
    "    print(recfld, EmbedTensor['info'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c4c01f-006d-4013-a8f5-1faaa3eacdb2",
   "metadata": {},
   "source": [
    "**get configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b4fe363-49d5-4b38-b540-31ea5515156a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_size': 128, 'output_size': 128, 'initrange': 0.1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "embed_size = embed_size\n",
    "default_linear_para = {'initrange': 0.1}\n",
    "############\n",
    "\n",
    "linear_para = get_linear_para(embed_size, embed_size, default_linear_para)\n",
    "linear_para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f284aaa8-3168-4580-a038-7ffafc001eb2",
   "metadata": {},
   "source": [
    "**init model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0b3d173-57ab-440b-b22b-445f08b72095",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearLayer(\n",
       "  (linear): Linear(in_features=128, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN = LinearLayer(**linear_para)\n",
    "NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76799d6-28b4-4ac6-b5e2-0cc268e0cb73",
   "metadata": {},
   "source": [
    "**prepare input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "077adef9-a6a5-49a5-b9cd-6fd2abb43d35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P-Info', 'B-P-EC-PNSect-Tknz']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in RECFLD_TO_EMBEDTESNOR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7aa52029-493c-4f47-9495-758f7e864435",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 23, 14, 221]) <-----  holder.shape\n",
      "torch.Size([4, 23, 14, 221, 128]) <-----  info.shape\n"
     ]
    }
   ],
   "source": [
    "recfld = 'B-P-EC-PNSect-Tknz'\n",
    "info_dict = RECFLD_TO_EMBEDTESNOR[recfld]\n",
    "info, holder = info_dict['info'], info_dict['holder']\n",
    "print(holder.shape, '<-----  holder.shape')\n",
    "print(info.shape, '<-----  info.shape')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b7ec6c-9e54-489c-a658-83b77ccdf095",
   "metadata": {},
   "source": [
    "**I-NN-O**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1398446-fdd9-4dae-ac16-458cf13887d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 23, 14, 221, 128])\n",
      "torch.Size([4, 23, 14, 221, 128])\n"
     ]
    }
   ],
   "source": [
    "# Problem: every time I run it, the result will change. \n",
    "holder_output, info_output = NN(holder, info)\n",
    "print(info_output.shape)\n",
    "# info_output.shape\n",
    "print(info_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8b2b11-cc56-48ca-85ff-398d930e8618",
   "metadata": {},
   "source": [
    "# Learner: Basic NN Type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb94409e-3a5b-4195-bb71-1a043db19a89",
   "metadata": {},
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57b48f48-e1cf-4232-b2d9-aa1f2be6c516",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# from fieldnn.basicnn.learner.tfm import TFMLayer\n",
    "# from fieldnn.basicnn.learner.linear import LinearLayer\n",
    "\n",
    "# from fieldnn.utils.layerfn import orderSeq, restoreSeq, align_psn_idx, get_Layer2Holder\n",
    "# from fieldnn.utils.parafn import generate_psn_embed_para\n",
    "\n",
    "\n",
    "class Learner_Layer(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_names_nnlvl, output_name_nnlvl, learner_layer_para,\n",
    "                ):\n",
    "        super(Learner_Layer, self).__init__()\n",
    "        \n",
    "        # Part 0: Meta\n",
    "        # here input_names and out_tensor just the tensor name, \n",
    "        # intead, the info_dict contains the corresponding real tensors.\n",
    "        assert len(input_names_nnlvl) == 1\n",
    "        self.input_names_nnlvl = input_names_nnlvl\n",
    "        self.input_name_nnlvl = input_names_nnlvl[0]\n",
    "        \n",
    "        # output_name should be generated from the input_names\n",
    "        self.output_name_nnlvl = output_name_nnlvl\n",
    "        \n",
    "        # the input feature dim size and output feature dim size\n",
    "        self.input_size = learner_layer_para['input_size']\n",
    "        self.output_size = learner_layer_para['output_size']\n",
    " \n",
    "        # Part 1: NN\n",
    "        nn_name, nn_para = learner_layer_para['nn_name'], learner_layer_para['nn_para']\n",
    "        \n",
    "        if nn_name.lower() == 'tfm':\n",
    "            assert self.input_size == self.output_size\n",
    "            self.Learner = TFMLayer(**nn_para)\n",
    "        elif nn_name.lower() == 'linear':\n",
    "            self.Learner = LinearLayer(**nn_para)\n",
    "        # elif nn_name.lower() == 'cnn':\n",
    "        #     self.Learner = CNNLayer(**nn_para)\n",
    "        # elif nn_name.lower() == 'rnn':\n",
    "        #     self.Learner = RNNLayer(**nn_para)\n",
    "        else:\n",
    "            raise ValueError(f'NN \"{nn_name}\" is not available')\n",
    "        \n",
    "        # Part 2: PostProcess\n",
    "        self.postprocess = torch.nn.ModuleDict()\n",
    "        for method, config in learner_layer_para['postprocess'].items():\n",
    "            if method == 'dropout':\n",
    "                self.postprocess[method] = torch.nn.Dropout(**config)\n",
    "            elif method == 'layernorm':\n",
    "                self.postprocess[method] = torch.nn.LayerNorm(self.output_size, **config)\n",
    "        # self.Ignore_PSN_Layers = learner_layer_para['Ignore_PSN_Layers']\n",
    "        \n",
    "    # def get_psn_embed_tensor(self, fullname, holder):\n",
    "    #     name = fullname.split('-')[-1]\n",
    "    #     Layer2Idx = {v:idx for idx, v in enumerate(fullname.split('-'))}\n",
    "    #     Layer2Holder = get_Layer2Holder(fullname, holder, self.Ignore_PSN_Layers)\n",
    "    #     psn_embed = 0\n",
    "    #     for source_layer, Embed in self.PSN_Embed_ModuleDict.items():\n",
    "    #         cpsn_idx = align_psn_idx(source_layer, name, Layer2Idx, Layer2Holder)\n",
    "    #         psn_embed = psn_embed + Embed(cpsn_idx)\n",
    "    #     return psn_embed\n",
    "    \n",
    "    def forward(self, input_names_nnlvl, INPUTS_TO_INFODICT):\n",
    "        # information preparation.\n",
    "        # 'INPUTS_TO_INFODICT` will come from SubUnit Layer.\n",
    "        assert len(input_names_nnlvl) == 1\n",
    "        input_name_nnlvl = input_names_nnlvl[0]\n",
    "        assert self.input_name_nnlvl == input_name_nnlvl\n",
    "        \n",
    "        info_dict = INPUTS_TO_INFODICT[input_name_nnlvl]\n",
    "        holder, info = info_dict['holder'], info_dict['info']\n",
    "        \n",
    "        # print(holder.shape, info.shape)\n",
    "        # the following part is the data proprocessing\n",
    "        holder, info = self.Learner(holder, info)\n",
    "        \n",
    "        for name, layer in self.postprocess.items():\n",
    "            info = layer(info)\n",
    "            \n",
    "        # we don't need to change the holder here.\n",
    "        return self.output_name_nnlvl, {'holder': holder, 'info': info}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a976c1-42cc-4466-8be1-0cccf65418ae",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0070a723-cdce-4c29-a557-38262e8eea30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_learner_para(nn_name, default_nn_para, \n",
    "                     input_size, output_size, \n",
    "                     postprocess):\n",
    "    \n",
    "    learner_para = {}\n",
    "    \n",
    "    # (1) \n",
    "    learner_para['nn_type'] = 'learner'  \n",
    "    learner_para['nn_name'] = nn_name # TFM or linear\n",
    "    \n",
    "    # (2)\n",
    "    if nn_name.lower() == 'tfm':\n",
    "        para = get_tfm_para(input_size, default_nn_para)\n",
    "    elif nn_name.lower() == 'linear':\n",
    "        para = get_linear_para(input_size, output_size, default_nn_para)\n",
    "    else:\n",
    "        raise ValueError(f'The NN \"{nn_name}\" is not available yet')\n",
    "    learner_para['nn_para'] = para\n",
    "    \n",
    "    # (3)\n",
    "    learner_para['input_size'] = input_size\n",
    "    learner_para['output_size'] = output_size\n",
    "    \n",
    "\n",
    "    # (4) Post Process\n",
    "    learner_para['postprocess'] = postprocess\n",
    "    \n",
    "    return learner_para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcac303-dbcd-4564-af95-0ca9f5501630",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e374fb6f-b847-4b32-96f0-1bfb7680910b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nn_type': 'learner',\n",
       " 'nn_name': 'tfm',\n",
       " 'nn_para': {'input_size': 128,\n",
       "  'output_size': 128,\n",
       "  'nhead': 8,\n",
       "  'num_encoder_layers': 3,\n",
       "  'num_decoder_layers': 0,\n",
       "  'dim_feedforward': 2048,\n",
       "  'tfm_dropout': 0.1,\n",
       "  'tfm_activation': 'relu',\n",
       "  'psn_max': 512,\n",
       "  'psn_embedprocess': {'dropout': {'p': 0.5, 'inplace': False},\n",
       "   'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}},\n",
       " 'input_size': 128,\n",
       " 'output_size': 128,\n",
       " 'postprocess': {'activator': 'gelu',\n",
       "  'dropout': {'p': 0.5, 'inplace': False},\n",
       "  'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#######################\n",
    "psn_embedprocess = {# 'activator': 'gelu',\n",
    "                    'dropout': {'p': 0.5, 'inplace': False},\n",
    "                    'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "\n",
    "process = {'activator': 'gelu',\n",
    "            'dropout': {'p': 0.5, 'inplace': False},\n",
    "            'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "\n",
    "\n",
    "embed_size = 128\n",
    "\n",
    "default_tfm_para = {'psn_max': 512, \n",
    "                    'num_encoder_layers': 3,\n",
    "                    'psn_embedprocess': psn_embedprocess}\n",
    "\n",
    "#######################\n",
    "\n",
    "\n",
    "\n",
    "nn_name = 'tfm'\n",
    "default_nn_para = default_tfm_para\n",
    "input_size = embed_size\n",
    "output_size = embed_size\n",
    "postprocess = process\n",
    "\n",
    "\n",
    "learner_para = get_learner_para(nn_name, default_nn_para, \n",
    "                                 input_size, output_size, \n",
    "                                 postprocess)\n",
    "\n",
    "learner_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c793c252-1809-45a0-8c28-f5c82501cfb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P-Info', 'B-P-EC-PNSect-Tknz']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in RECFLD_TO_EMBEDTESNOR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a5f7503-e0a8-45c9-9e8e-9170f34a0eab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recfldgrn = 'B-P-EC-PNSect-Tknz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39cff8a2-18de-40f1-837a-147cef9f6710",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner_Layer(\n",
       "  (Learner): TFMLayerLEARNER(TFM): input(128), output(128): (\n",
       "    (Encoder): EncoderLayer(layers_num=3, dim_feedforward=2048)\n",
       "    (Decoder): DecoderLayer(layers_num=0, dim_feedforward=2048)\n",
       "  )\n",
       "  (postprocess): ModuleDict(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_names_nnlvl = [recfldgrn]\n",
    "output_name_nnlvl = recfldgrn\n",
    "\n",
    "NN = Learner_Layer(input_names_nnlvl, output_name_nnlvl, learner_para)\n",
    "NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd950f8-ad27-4e9a-9f47-e05f45ec9322",
   "metadata": {},
   "source": [
    "**recfld informaiton**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "502541fe-9c70-4dda-8b77-b63fbb0c5ebd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P-EC-PNSect-Tknz']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_names_nnlvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d6efc2b-09fb-402d-b434-4fee433a9c47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUTS_TO_INFODICT = {}\n",
    "\n",
    "for inp in input_names_nnlvl:\n",
    "    INPUTS_TO_INFODICT[inp] = RECFLD_TO_EMBEDTESNOR[inp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9f57d3d-0301-4f07-880c-48e3c8b12c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# information preparation.\n",
    "# 'INPUTS_TO_INFODICT` will come from SubUnit Layer.\n",
    "assert len(input_names_nnlvl) == 1\n",
    "input_name_nnlvl = input_names_nnlvl[0]\n",
    "assert NN.input_name_nnlvl == input_name_nnlvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d1f1c7da-64f2-4e94-9b6b-b9493a2cc7ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 23, 14, 221, 128])\n"
     ]
    }
   ],
   "source": [
    "info_dict = INPUTS_TO_INFODICT[input_name_nnlvl]\n",
    "holder, info = info_dict['holder'], info_dict['info']\n",
    "print(info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e50adfd5-7fd4-46f0-baed-fdeada432431",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(holder.shape, info.shape)\n",
    "# the following part is the data proprocessing\n",
    "holder, info = NN.Learner(holder, info)\n",
    "\n",
    "for name, layer in NN.postprocess.items():\n",
    "    info = layer(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7cff84b1-f187-4b93-b0e8-c2b7b918ad71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 23, 14, 221, 128])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputname, info_dict = NN(input_names_nnlvl, INPUTS_TO_INFODICT)\n",
    "\n",
    "info_dict['info'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9d273d-7f64-42d6-ace2-142e064018f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
