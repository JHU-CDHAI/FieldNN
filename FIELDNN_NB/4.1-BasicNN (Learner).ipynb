{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7588aa63-50a8-4f68-b40d-5e65e1783790",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/floydluo/Library/CloudStorage/GoogleDrive-jjluo@terpmail.umd.edu/My Drive/0-Research-Project/MedStar/MS_CODE/FieldNN\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61bc989-f648-42f9-9580-fd91c5fddc0a",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "\n",
    "This is the for \n",
    "\n",
    "* module `fieldnn.basicnn.learner` module\n",
    "* module `fieldnn.configfn.learnerfn` module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f1850-8d92-40fd-ba69-6657f63ca703",
   "metadata": {},
   "source": [
    "# Prepare Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98e6de85-919d-4ffa-b1d6-0f286e9dc6f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/ProcData/TensorFolder/Task2YearXXX\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from recfldgrn.datapoint import load_df_data_from_folder\n",
    "from fieldnn.utils.layerfn import traverse, convert_relational_list_to_numpy\n",
    "\n",
    "###################### take this as given\n",
    "batch_PID_order = ['P1', 'P4', 'P5', 'P6']\n",
    "######################\n",
    "\n",
    "TaskTensor_folder = 'data/ProcData/TensorFolder/Task2YearXXX'\n",
    "print(TaskTensor_folder)\n",
    "\n",
    "l = sorted([i for i in os.listdir(TaskTensor_folder) if 'Grn' in i])\n",
    "# l\n",
    "\n",
    "recfldgrn_list =['P@age-AgeNumeDftGrn',\n",
    "                 'P@basicInfo-basicInfoDftGrn',\n",
    "                 \n",
    "                 'EC@BasicInfo-BasicDftGrn',\n",
    "                 'EC@DT_min-DTDftGrn',\n",
    "                 \n",
    "                 'A1C@DT-DTDftGrn',\n",
    "                 'A1C@V-A1CNumeDftGrn',\n",
    "                 \n",
    "                 'Diag@DT-DTDftGrn',\n",
    "                 'Diag@Value-DiagDftGrn',\n",
    "                 \n",
    "                 'PNSectSent@Sentence-Tk@TknzLLMGrn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70729ebd-a267-4acc-96e6-ef0ea85eb354",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/ProcData/TensorFolder/Task2YearXXX/P@age-AgeNumeDftGrn\n",
      "data/ProcData/TensorFolder/Task2YearXXX/P@basicInfo-basicInfoDftGrn\n",
      "data/ProcData/TensorFolder/Task2YearXXX/EC@BasicInfo-BasicDftGrn\n",
      "data/ProcData/TensorFolder/Task2YearXXX/EC@DT_min-DTDftGrn\n",
      "data/ProcData/TensorFolder/Task2YearXXX/A1C@DT-DTDftGrn\n",
      "data/ProcData/TensorFolder/Task2YearXXX/A1C@V-A1CNumeDftGrn\n",
      "data/ProcData/TensorFolder/Task2YearXXX/Diag@DT-DTDftGrn\n",
      "data/ProcData/TensorFolder/Task2YearXXX/Diag@Value-DiagDftGrn\n",
      "data/ProcData/TensorFolder/Task2YearXXX/PNSectSent@Sentence-Tk@TknzLLMGrn\n",
      "B-P@age-AgeNumeDftGrn_wgt (4, 19)\n",
      "B-P@basicInfo-basicInfoDftGrn_idx (4, 2)\n",
      "B-P-EC@BasicInfo-BasicDftGrn_idx (4, 25, 2)\n",
      "B-P-EC@DT_min-DTDftGrn_idx (4, 25, 7)\n",
      "B-P-EC-A1C@DT-DTDftGrn_idx (4, 25, 1, 7)\n",
      "B-P-EC-A1C@V-A1CNumeDftGrn_wgt (4, 25, 1, 37)\n",
      "B-P-EC-Diag@DT-DTDftGrn_idx (4, 25, 22, 7)\n",
      "B-P-EC-Diag@Value-DiagDftGrn_idx (4, 25, 22, 3)\n",
      "B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx (4, 25, 1, 14, 121, 11)\n"
     ]
    }
   ],
   "source": [
    "batch_rfg = {}\n",
    "\n",
    "for recfldgrn in recfldgrn_list:\n",
    "    \n",
    "    # (1) get tensor_folder\n",
    "    tensor_folder = os.path.join(TaskTensor_folder, recfldgrn)\n",
    "    print(tensor_folder)\n",
    "\n",
    "    # (2) get df_Pat and full_recfldgrn\n",
    "    df_Pat = load_df_data_from_folder(tensor_folder).set_index('PID')\n",
    "    full_recfldgrn = df_Pat.columns[0]\n",
    "    suffix = full_recfldgrn.split('_')[-1]\n",
    "    assert recfldgrn in full_recfldgrn\n",
    "\n",
    "    # (3) load batch: TODO: convert this to DataSet and DataLoader\n",
    "    df_batch = df_Pat.loc[batch_PID_order]\n",
    "\n",
    "    # (4) tensor batch as tensor_idx\n",
    "    new_full_recfldgrn = 'B-' + full_recfldgrn\n",
    "    values_list = df_batch[full_recfldgrn].to_list()\n",
    "    suffix = full_recfldgrn.split('_')[-1]\n",
    "    # print(suffix)\n",
    "    # print(new_full_recfldgrn)\n",
    "    D = convert_relational_list_to_numpy(values_list, new_full_recfldgrn, suffix)\n",
    "    tensor_idx = D[new_full_recfldgrn]\n",
    "    \n",
    "    batch_rfg[new_full_recfldgrn] = tensor_idx\n",
    "    \n",
    "for k, v in batch_rfg.items(): print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d944f1c-10e3-4e0d-a71e-40cd99cdc87f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P@age-AgeNumeDftGrn_wgt',\n",
       " 'B-P@basicInfo-basicInfoDftGrn_idx',\n",
       " 'B-P-EC@BasicInfo-BasicDftGrn_idx',\n",
       " 'B-P-EC@DT_min-DTDftGrn_idx',\n",
       " 'B-P-EC-A1C@DT-DTDftGrn_idx',\n",
       " 'B-P-EC-A1C@V-A1CNumeDftGrn_wgt',\n",
       " 'B-P-EC-Diag@DT-DTDftGrn_idx',\n",
       " 'B-P-EC-Diag@Value-DiagDftGrn_idx',\n",
       " 'B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_recfldgrn_list = [k for k in batch_rfg]\n",
    "full_recfldgrn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "148b0bee-5e48-47e4-abb7-eef0f9638c26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "RECFLD_TO_TENSOR = {}\n",
    "\n",
    "for full_recfldgrn in full_recfldgrn_list:\n",
    "    # (1) get the info_raw from batch_rfg\n",
    "    info_raw = batch_rfg[full_recfldgrn]\n",
    "   \n",
    "    # (2) get the holder (input_idx) and holder_wgt (for nume embedding only)\n",
    "    if '_idx' in full_recfldgrn:\n",
    "        holder_wgt = 'Empty'\n",
    "        holder = torch.LongTensor(info_raw)\n",
    "    elif '_wgt' in full_recfldgrn:\n",
    "        holder_wgt = torch.FloatTensor(info_raw)\n",
    "        # ATTENTION: here holder_wgt could contain zeros in some valid positions.\n",
    "        holder = torch.ones_like(holder_wgt).cumsum(-1).masked_fill(holder_wgt == 0, 0).long()\n",
    "    else:\n",
    "        raise ValueError(f'Invalid suffix \"{suffix}\"')\n",
    "\n",
    "    info_dict = {'holder': holder, 'holder_wgt': holder_wgt}\n",
    "    \n",
    "    RECFLD_TO_TENSOR[full_recfldgrn] = info_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f98dd28e-0fb5-43b2-ae78-5b07f07b814a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubUnitName</th>\n",
       "      <th>input_names</th>\n",
       "      <th>output_name</th>\n",
       "      <th>output_layerid</th>\n",
       "      <th>SubUnit_BasicNN_List</th>\n",
       "      <th>SubUnit_DefaultBasicNN_List</th>\n",
       "      <th>SubUnit_BasicNN_Config_List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E</td>\n",
       "      <td>[B-P@age-AgeNumeDftGrn_wgt]</td>\n",
       "      <td>B-P@age-AgeNumeDft</td>\n",
       "      <td>3</td>\n",
       "      <td>[expander-NumeEmbed]</td>\n",
       "      <td>[{'vocab_tokenizer': [1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[{'nn_type_nn_name': 'expander-NumeEmbed', 'Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E</td>\n",
       "      <td>[B-P@basicInfo-basicInfoDftGrn_idx]</td>\n",
       "      <td>B-P@basicInfo-basicInfoDft</td>\n",
       "      <td>3</td>\n",
       "      <td>[expander-CateEmbed]</td>\n",
       "      <td>[{'vocab_tokenizer': {'_padding': 0, 'Male': 1...</td>\n",
       "      <td>[{'nn_type_nn_name': 'expander-CateEmbed', 'Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E</td>\n",
       "      <td>[B-P-EC@BasicInfo-BasicDftGrn_idx]</td>\n",
       "      <td>B-P-EC@BasicInfo-BasicDft</td>\n",
       "      <td>4</td>\n",
       "      <td>[expander-CateEmbed]</td>\n",
       "      <td>[{'vocab_tokenizer': {'_padding': 0, 'X': 1, '...</td>\n",
       "      <td>[{'nn_type_nn_name': 'expander-CateEmbed', 'Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E</td>\n",
       "      <td>[B-P-EC@DT_min-DTDftGrn_idx]</td>\n",
       "      <td>B-P-EC@DT_min-DTDft</td>\n",
       "      <td>4</td>\n",
       "      <td>[expander-CateEmbed]</td>\n",
       "      <td>[{'vocab_tokenizer': {'_padding': 0, '_missing...</td>\n",
       "      <td>[{'nn_type_nn_name': 'expander-CateEmbed', 'Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>[B-P-EC-A1C@DT-DTDftGrn_idx]</td>\n",
       "      <td>B-P-EC-A1C@DT-DTDft</td>\n",
       "      <td>5</td>\n",
       "      <td>[expander-CateEmbed]</td>\n",
       "      <td>[{'vocab_tokenizer': {'_padding': 0, '_missing...</td>\n",
       "      <td>[{'nn_type_nn_name': 'expander-CateEmbed', 'Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>E</td>\n",
       "      <td>[B-P-EC-A1C@V-A1CNumeDftGrn_wgt]</td>\n",
       "      <td>B-P-EC-A1C@V-A1CNumeDft</td>\n",
       "      <td>5</td>\n",
       "      <td>[expander-NumeEmbed]</td>\n",
       "      <td>[{'vocab_tokenizer': [1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[{'nn_type_nn_name': 'expander-NumeEmbed', 'Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>E</td>\n",
       "      <td>[B-P-EC-Diag@DT-DTDftGrn_idx]</td>\n",
       "      <td>B-P-EC-Diag@DT-DTDft</td>\n",
       "      <td>5</td>\n",
       "      <td>[expander-CateEmbed]</td>\n",
       "      <td>[{'vocab_tokenizer': {'_padding': 0, '_missing...</td>\n",
       "      <td>[{'nn_type_nn_name': 'expander-CateEmbed', 'Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>E</td>\n",
       "      <td>[B-P-EC-Diag@Value-DiagDftGrn_idx]</td>\n",
       "      <td>B-P-EC-Diag@Value-DiagDft</td>\n",
       "      <td>5</td>\n",
       "      <td>[expander-CateEmbed]</td>\n",
       "      <td>[{'vocab_tokenizer': {'_padding': 0, '_missing...</td>\n",
       "      <td>[{'nn_type_nn_name': 'expander-CateEmbed', 'Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>E</td>\n",
       "      <td>[B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzL...</td>\n",
       "      <td>B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLM</td>\n",
       "      <td>7</td>\n",
       "      <td>[expander-LLMEmbed]</td>\n",
       "      <td>[{'vocab_tokenizer': BertTokenizerFast(name_or...</td>\n",
       "      <td>[{'nn_type_nn_name': 'expander-LLMEmbed', 'Bas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SubUnitName                                        input_names  \\\n",
       "0           E                        [B-P@age-AgeNumeDftGrn_wgt]   \n",
       "1           E                [B-P@basicInfo-basicInfoDftGrn_idx]   \n",
       "2           E                 [B-P-EC@BasicInfo-BasicDftGrn_idx]   \n",
       "3           E                       [B-P-EC@DT_min-DTDftGrn_idx]   \n",
       "4           E                       [B-P-EC-A1C@DT-DTDftGrn_idx]   \n",
       "5           E                   [B-P-EC-A1C@V-A1CNumeDftGrn_wgt]   \n",
       "6           E                      [B-P-EC-Diag@DT-DTDftGrn_idx]   \n",
       "7           E                 [B-P-EC-Diag@Value-DiagDftGrn_idx]   \n",
       "8           E  [B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzL...   \n",
       "\n",
       "                                       output_name  output_layerid  \\\n",
       "0                               B-P@age-AgeNumeDft               3   \n",
       "1                       B-P@basicInfo-basicInfoDft               3   \n",
       "2                        B-P-EC@BasicInfo-BasicDft               4   \n",
       "3                              B-P-EC@DT_min-DTDft               4   \n",
       "4                              B-P-EC-A1C@DT-DTDft               5   \n",
       "5                          B-P-EC-A1C@V-A1CNumeDft               5   \n",
       "6                             B-P-EC-Diag@DT-DTDft               5   \n",
       "7                        B-P-EC-Diag@Value-DiagDft               5   \n",
       "8  B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLM               7   \n",
       "\n",
       "   SubUnit_BasicNN_List                        SubUnit_DefaultBasicNN_List  \\\n",
       "0  [expander-NumeEmbed]  [{'vocab_tokenizer': [1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1  [expander-CateEmbed]  [{'vocab_tokenizer': {'_padding': 0, 'Male': 1...   \n",
       "2  [expander-CateEmbed]  [{'vocab_tokenizer': {'_padding': 0, 'X': 1, '...   \n",
       "3  [expander-CateEmbed]  [{'vocab_tokenizer': {'_padding': 0, '_missing...   \n",
       "4  [expander-CateEmbed]  [{'vocab_tokenizer': {'_padding': 0, '_missing...   \n",
       "5  [expander-NumeEmbed]  [{'vocab_tokenizer': [1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "6  [expander-CateEmbed]  [{'vocab_tokenizer': {'_padding': 0, '_missing...   \n",
       "7  [expander-CateEmbed]  [{'vocab_tokenizer': {'_padding': 0, '_missing...   \n",
       "8   [expander-LLMEmbed]  [{'vocab_tokenizer': BertTokenizerFast(name_or...   \n",
       "\n",
       "                         SubUnit_BasicNN_Config_List  \n",
       "0  [{'nn_type_nn_name': 'expander-NumeEmbed', 'Ba...  \n",
       "1  [{'nn_type_nn_name': 'expander-CateEmbed', 'Ba...  \n",
       "2  [{'nn_type_nn_name': 'expander-CateEmbed', 'Ba...  \n",
       "3  [{'nn_type_nn_name': 'expander-CateEmbed', 'Ba...  \n",
       "4  [{'nn_type_nn_name': 'expander-CateEmbed', 'Ba...  \n",
       "5  [{'nn_type_nn_name': 'expander-NumeEmbed', 'Ba...  \n",
       "6  [{'nn_type_nn_name': 'expander-CateEmbed', 'Ba...  \n",
       "7  [{'nn_type_nn_name': 'expander-CateEmbed', 'Ba...  \n",
       "8  [{'nn_type_nn_name': 'expander-LLMEmbed', 'Bas...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fieldnn.dataflowfn.embedflowfn import get_EmbeddingBlock_SubUnit\n",
    "\n",
    "from fieldnn.dataflowfn.baseflowfn import mapping_SubUnitName_to_SubUnitNNList\n",
    "from fieldnn.dataflowfn.baseflowfn import get_SubUnit_Default_NNPara_List\n",
    "from fieldnn.dataflowfn.baseflowfn import get_SubUnit_BasicNN_Config_List\n",
    "\n",
    "############################################# Hyperparameters\n",
    "default_BasicNNtype_To_NNName = {\n",
    "    'expander': None, # will be updated according to the Grn Type\n",
    "    'reducer': 'Max',\n",
    "    'merger': 'Merger',\n",
    "    'learner': None, # TODO: ignore this currently\n",
    "    \n",
    "}\n",
    "#############################################\n",
    "\n",
    "############################\n",
    "embed_size = 128\n",
    "process = {'activator': 'gelu',\n",
    "           'dropout': {'p': 0.5, 'inplace': False},\n",
    "           'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "############################\n",
    "\n",
    "\n",
    "default_SubUnitName = 'E'\n",
    "fldgrn_folder = 'data/ProcData/FldGrnInfo'\n",
    "learner_default_dict = {} # To update it in the future. \n",
    "\n",
    "\n",
    "\n",
    "default_E_subunit_name = 'E'\n",
    "df_SubUnit = get_EmbeddingBlock_SubUnit(full_recfldgrn_list, default_E_subunit_name)\n",
    "\n",
    "s = df_SubUnit.apply(lambda x: mapping_SubUnitName_to_SubUnitNNList(x['SubUnitName'], \n",
    "                                                                    x['input_names'],\n",
    "                                                                    default_BasicNNtype_To_NNName), \n",
    "                    axis = 1)\n",
    "df_SubUnit['SubUnit_BasicNN_List'] = s\n",
    "s = df_SubUnit.apply(lambda x: get_SubUnit_Default_NNPara_List(x['SubUnit_BasicNN_List'], \n",
    "                                                               x['input_names'],\n",
    "                                                               fldgrn_folder, \n",
    "                                                               learner_default_dict), axis = 1)\n",
    "\n",
    "df_SubUnit['SubUnit_DefaultBasicNN_List'] = s\n",
    "\n",
    "\n",
    "\n",
    "s = df_SubUnit.apply(lambda x: get_SubUnit_BasicNN_Config_List(x['SubUnit_BasicNN_List'], \n",
    "                                                               x['SubUnit_DefaultBasicNN_List'], \n",
    "                                                               x['input_names'], \n",
    "                                                               x['output_name'], \n",
    "                                                                embed_size, \n",
    "                                                                process, \n",
    "                                                               ), axis = 1)\n",
    "\n",
    "df_SubUnit['SubUnit_BasicNN_Config_List'] = s\n",
    "df_SubUnit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce199da2-8fc2-4a65-a76b-c0d2f5dca3ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from fieldnn.module.embedblock import EmbedBlockLayer\n",
    "\n",
    "EmbedBlock = EmbedBlockLayer(df_SubUnit)\n",
    "\n",
    "RECFLD_TO_EMBEDTESNOR = EmbedBlock(RECFLD_TO_TENSOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90b9d8ab-7a27-4e5d-a39c-d260046a35a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P@age-AgeNumeDft',\n",
       " 'B-P@basicInfo-basicInfoDft',\n",
       " 'B-P-EC@BasicInfo-BasicDft',\n",
       " 'B-P-EC@DT_min-DTDft',\n",
       " 'B-P-EC-A1C@DT-DTDft',\n",
       " 'B-P-EC-A1C@V-A1CNumeDft',\n",
       " 'B-P-EC-Diag@DT-DTDft',\n",
       " 'B-P-EC-Diag@Value-DiagDft',\n",
       " 'B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLM']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in RECFLD_TO_EMBEDTESNOR]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8412c749-070e-4227-9857-97bd243a9782",
   "metadata": {},
   "source": [
    "# Get Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dd4a94c-55cb-40ab-afa3-c56c36b50169",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P@age-AgeNumeDft torch.Size([4, 19, 128])\n",
      "B-P@basicInfo-basicInfoDft torch.Size([4, 2, 128])\n",
      "B-P-EC@BasicInfo-BasicDft torch.Size([4, 25, 2, 128])\n",
      "B-P-EC@DT_min-DTDft torch.Size([4, 25, 7, 128])\n",
      "B-P-EC-A1C@DT-DTDft torch.Size([4, 25, 1, 7, 128])\n",
      "B-P-EC-A1C@V-A1CNumeDft torch.Size([4, 25, 1, 37, 128])\n",
      "B-P-EC-Diag@DT-DTDft torch.Size([4, 25, 22, 7, 128])\n",
      "B-P-EC-Diag@Value-DiagDft torch.Size([4, 25, 22, 3, 128])\n",
      "B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLM torch.Size([4, 25, 1, 14, 121, 11, 128])\n"
     ]
    }
   ],
   "source": [
    "for full_recfld, info_dict in RECFLD_TO_EMBEDTESNOR.items():\n",
    "    print(full_recfld, info_dict['info'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be4f167-ad4c-496c-ab26-ec56bd3c9dd2",
   "metadata": {},
   "source": [
    "# Learner: BasicNN Name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06fab7c-f81f-474a-8b5e-211197959235",
   "metadata": {},
   "source": [
    "## TFM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07497e4f-e83a-43e2-9165-e4ca7c9ec391",
   "metadata": {},
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67c5a980-2f8b-4781-a61b-e24a6e5b4d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from fieldnn.utils.layerfn import orderSeq, restoreSeq\n",
    "\n",
    "def _addindent(s_, numSpaces):\n",
    "    s = s_.split('\\n')\n",
    "    # don't do anything for single-line stuff\n",
    "    if len(s) == 1:\n",
    "        return s_\n",
    "    first = s.pop(0)\n",
    "    s = [(numSpaces * ' ') + line for line in s]\n",
    "    s = '\\n'.join(s)\n",
    "    s = first + '\\n' + s\n",
    "    return s\n",
    "\n",
    "class TFMLayer(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_size = 200, \n",
    "                 output_size = 200, # d_model\n",
    "                 nhead = 8,\n",
    "                 num_encoder_layers = 6, # only have encoder part\n",
    "                 num_decoder_layers = 0, # in default, we don't need decoder part. \n",
    "                 dim_feedforward = 2048, \n",
    "                 tfm_dropout = 0.1,\n",
    "                 tfm_activation = 'relu', \n",
    "                 psn_max = 512, \n",
    "                 psn_embedprocess = {}):\n",
    "        \n",
    "        '''https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/transformer.py'''\n",
    "\n",
    "        super(TFMLayer,self).__init__()\n",
    "        self.num_encoder_layers = num_encoder_layers\n",
    "        self.num_decoder_layers = num_decoder_layers\n",
    "        self.input_size = input_size\n",
    "        self.tfm_input_size = input_size\n",
    "        self.n_directions = 1\n",
    "        self.output_size = output_size\n",
    "        assert output_size % self.n_directions == 0 \n",
    "        self.hidden_size = int(output_size / self.n_directions)\n",
    "        assert self.hidden_size == self.tfm_input_size\n",
    "        # self.psn_size = psn_size \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.dim_feedforward = dim_feedforward\n",
    "        \n",
    "        self.transformer  = torch.nn.Transformer(d_model = self.hidden_size, \n",
    "                                                 nhead = nhead,\n",
    "                                                 num_encoder_layers = self.num_encoder_layers,\n",
    "                                                 num_decoder_layers = self.num_decoder_layers,\n",
    "                                                 dim_feedforward = dim_feedforward, \n",
    "                                                 dropout = tfm_dropout,\n",
    "                                                 activation = tfm_activation,\n",
    "                                                 batch_first = True,\n",
    "                                                 # src_mask_flag = False, # see all tokens in a sentence \n",
    "                                                 # # This IS THE NEW PART. NOT PyTorch.nn.\n",
    "                                                 )\n",
    "        \n",
    "        # Part a: PSN embedding\n",
    "        # (bs, xxx, psn_max, dim)\n",
    "        self.psn_max = psn_max\n",
    "        self.psn_embedding = torch.nn.Embedding(self.psn_max + 1, \n",
    "                                                self.input_size, \n",
    "                                                padding_idx = 0)\n",
    "        \n",
    "        # Part b: PSN EmbedProcess\n",
    "        self.psn_embedprocess = torch.nn.ModuleDict()\n",
    "        for method, config in psn_embedprocess.items():\n",
    "            if method == 'dropout':\n",
    "                self.psn_embedprocess[method] = torch.nn.Dropout(**config)\n",
    "            elif method == 'layernorm':\n",
    "                self.psn_embedprocess[method] = torch.nn.LayerNorm(self.output_size, **config)\n",
    "            else:\n",
    "                raise ValueError(f'no avialable embedprocess method {method}')\n",
    "                \n",
    "        # you can either choose v1 or v2 forward method.\n",
    "        # self.forward = self.forward_v1\n",
    "        self.forward = self.forward_v2\n",
    "    \n",
    "    def forward_v1(self, holder, info):\n",
    "        \n",
    "        # (1) get the leng_mask\n",
    "        leng_mask = holder == 0\n",
    "        \n",
    "        \n",
    "        # (2.1) get the psn_embed \n",
    "        psn_id = self.generate_psnidx(leng_mask) \n",
    "        psn_embed = self.psn_embedding(psn_id)\n",
    "        # print(psn_embed[0, 0, 0, :, 0], '<------------- psn_embed 1')\n",
    "        \n",
    "        # (2.2) TODO: process psn_embed? Do we need the further embed process? \n",
    "        for nn, layer in self.psn_embedprocess.items(): \n",
    "            psn_embed = layer(psn_embed)\n",
    "            \n",
    "        # print(psn_embed[0, 0, 0, :, 0], '<------------- psn_embed 2')\n",
    "        \n",
    "        # (2.3) add psn_embed to info\n",
    "        info = info + psn_embed\n",
    "        # print(info[0, 0, 0, :, 0], '<------------- info = info + psn_embed')\n",
    "        \n",
    "        \n",
    "        # (3) reshape\n",
    "        ord_info, ord_leng_mask, r_ix = self.reshape(info, leng_mask)\n",
    "        \n",
    "        # print(ord_info[0, :, 0], '<------------- ord_info')\n",
    "        \n",
    "        # (4) do the transformer calculator\n",
    "        ord_info_output = self.transformer(ord_info, ord_info, \n",
    "                                           src_key_padding_mask = ord_leng_mask,  \n",
    "                                           tgt_key_padding_mask = ord_leng_mask)\n",
    "        \n",
    "        # print(ord_info_output[0, :, 0], '<------------- ord_info_output')\n",
    "        \n",
    "        # (5) restore\n",
    "        info = self.restore(ord_info_output, leng_mask, r_ix)\n",
    "        # print(info[0, 0, 0, :, 0], '<------------- info = self.restore(ord_info_output, leng_mask, r_ix)')\n",
    "            \n",
    "        return holder, info\n",
    "    \n",
    "    \n",
    "    def forward_v2(self, holder, info):\n",
    "        # (1) get the leng_mask\n",
    "        leng_mask = holder == 0\n",
    "        \n",
    "        # print(info[0, 0, 0, :, 0], '<------------- info 1')\n",
    "        \n",
    "        \n",
    "        # (2) reshape \n",
    "        ord_info, ord_leng_mask, r_ix = self.reshape(info, leng_mask)\n",
    "        # print(ord_info[0, :, 0], '<------------- ord_info')\n",
    "        \n",
    "        # (3.1) get the psn_embed \n",
    "        psn_id = self.generate_psnidx(ord_leng_mask) \n",
    "        psn_embed = self.psn_embedding(psn_id)\n",
    "        # print(psn_embed[0, :, 0], '<------------- psn_embed 1')\n",
    "        \n",
    "        \n",
    "        # (3.2) TODO: process psn_embed? Do we need the further embed process? \n",
    "        for nn, layer in self.psn_embedprocess.items(): \n",
    "            psn_embed = layer(psn_embed)\n",
    "            \n",
    "        # print(psn_embed[0, :, 0], '<------------- psn_embed 2')\n",
    "        \n",
    "        \n",
    "        # (3.3) add psn_embed to info\n",
    "        ord_info = ord_info + psn_embed\n",
    "        \n",
    "        # print(ord_info[0, :, 0], '<------------- ord_info 1')\n",
    "        \n",
    "    \n",
    "        # (4) do the transformer calculator\n",
    "        ord_info_output = self.transformer(ord_info, ord_info, \n",
    "                                           src_key_padding_mask = ord_leng_mask,  \n",
    "                                           tgt_key_padding_mask = ord_leng_mask)\n",
    "        \n",
    "        # print(ord_info_output[0, :, 0], '<------------- ord_info_output 1')\n",
    "        \n",
    "        \n",
    "        # (5) restore\n",
    "        info = self.restore(ord_info_output, leng_mask, r_ix)\n",
    "        # print(info[0, 0, 0, :, 0], '<------------- info 2')\n",
    "        \n",
    "        return holder, info\n",
    "    \n",
    "    \n",
    "    \n",
    "    def reshape(self, info, leng_mask):\n",
    "        nbs = int(np.array(info.shape[:-2]).prod())\n",
    "        # nbs = np.array(info.shape[:-2]).prod()\n",
    "        ngrn, dim = info.shape[-2:]\n",
    "        # print(nbs, ngrn, dim)\n",
    "        \n",
    "        tmp_info = info.contiguous().view(nbs, ngrn, dim)\n",
    "        # print(tmp_info.shape)\n",
    "\n",
    "        tmp_leng_mask = leng_mask.contiguous().view(nbs, ngrn)\n",
    "        # print(tmp_leng_mask.shape)\n",
    "\n",
    "        tmp_leng = (tmp_leng_mask == 0).sum(-1)\n",
    "        # print(tmp_leng.shape)\n",
    "        \n",
    "        ord_info,      ord_leng, r_idx = orderSeq(tmp_info, tmp_leng)\n",
    "        ord_leng_mask, ord_leng, r_idx = orderSeq(tmp_leng_mask, tmp_leng)\n",
    "        return ord_info, ord_leng_mask, r_idx\n",
    "    \n",
    "    def restore(self, ord_info_output, leng_mask, r_idx):\n",
    "        info_new = restoreSeq(ord_info_output, r_idx)\n",
    "        output_size = info_new.shape[-1]\n",
    "        info_output = info_new.view(*list(leng_mask.shape) + [output_size])\n",
    "        return info_output\n",
    "        \n",
    "    def generate_psnidx(self, leng_mask):\n",
    "        # leng_mask = holder == 0\n",
    "        psn_idx = (leng_mask == False).cumsum(-1).masked_fill(leng_mask, 0)\n",
    "        return psn_idx\n",
    "    \n",
    "    \n",
    "    def __repr__(self):\n",
    "        # We treat the extra repr like the sub-module, one item per line\n",
    "        extra_lines = []\n",
    "        extra_repr = self.extra_repr()\n",
    "        # empty string will be split into list ['']\n",
    "        if extra_repr:\n",
    "            extra_lines = extra_repr.split('\\n')\n",
    "        child_lines = []\n",
    "        for key, module in self._modules.items():\n",
    "            mod_str = repr(module)\n",
    "            mod_str = _addindent(mod_str, 2)\n",
    "            child_lines.append('(' + key + '): ' + mod_str)\n",
    "        lines = extra_lines + child_lines\n",
    "\n",
    "        main_str = self._get_name() + f'LEARNER(TFM): input({self.input_size}), output({self.output_size}): ('\n",
    "        lines = [f'(Encoder): EncoderLayer(layers_num={self.num_encoder_layers}, dim_feedforward={self.dim_feedforward})', \n",
    "                 f'(Decoder): DecoderLayer(layers_num={self.num_decoder_layers}, dim_feedforward={self.dim_feedforward})']\n",
    "        main_str += '\\n  ' + '\\n  '.join(lines) + '\\n' + ')'\n",
    "        \n",
    "        # if lines:\n",
    "        #     # simple one-liner info, which most builtin Modules will use\n",
    "        #     if len(extra_lines) == 1 and not child_lines:\n",
    "        #         main_str += extra_lines[0]\n",
    "        #     else:\n",
    "        #         main_str += '\\n  ' + '\\n  '.join(lines) + '\\n'\n",
    "        # main_str += ')'\n",
    "        return main_str\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a2a576-9e0a-43d2-b7ba-3e7366f7d40c",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa15c1dc-3fbf-4b60-91fd-ff16eb790a77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_tfm_para(input_size, default_tfm_para):\n",
    "    assert 'input_size' not in default_tfm_para\n",
    "    \n",
    "    tfm_para =  {'input_size': input_size,\n",
    "                 'output_size': input_size,\n",
    "                 'nhead': 8,\n",
    "                 'num_encoder_layers': 6,\n",
    "                 'num_decoder_layers': 0,\n",
    "                 'dim_feedforward': 2048,\n",
    "                 'tfm_dropout': 0.1,\n",
    "                 'tfm_activation': 'relu',\n",
    "                 'psn_max': 512, \n",
    "                 'psn_embedprocess': {}\n",
    "                }\n",
    "    \n",
    "    for k, v in default_tfm_para.items(): tfm_para[k] = v\n",
    "    return tfm_para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69d4b65-17e4-4273-b63e-470cec593a59",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e154d5-24d4-49e7-9b72-afb35144603f",
   "metadata": {},
   "source": [
    "**recfld information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f95cde1-19da-4184-b9a9-365d29414a79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P@age-AgeNumeDft torch.Size([4, 19, 128])\n",
      "B-P@basicInfo-basicInfoDft torch.Size([4, 2, 128])\n",
      "B-P-EC@BasicInfo-BasicDft torch.Size([4, 25, 2, 128])\n",
      "B-P-EC@DT_min-DTDft torch.Size([4, 25, 7, 128])\n",
      "B-P-EC-A1C@DT-DTDft torch.Size([4, 25, 1, 7, 128])\n",
      "B-P-EC-A1C@V-A1CNumeDft torch.Size([4, 25, 1, 37, 128])\n",
      "B-P-EC-Diag@DT-DTDft torch.Size([4, 25, 22, 7, 128])\n",
      "B-P-EC-Diag@Value-DiagDft torch.Size([4, 25, 22, 3, 128])\n",
      "B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLM torch.Size([4, 25, 1, 14, 121, 11, 128])\n"
     ]
    }
   ],
   "source": [
    "for recfld, EmbedTensor in RECFLD_TO_EMBEDTESNOR.items():\n",
    "    print(recfld, EmbedTensor['info'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad2e4ed-f241-4c9d-bb55-c5c8a018e69d",
   "metadata": {},
   "source": [
    "**get configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fb4b00b-9981-4d0a-a6f1-c46ff8553c82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_size': 128,\n",
       " 'output_size': 128,\n",
       " 'nhead': 8,\n",
       " 'num_encoder_layers': 6,\n",
       " 'num_decoder_layers': 0,\n",
       " 'dim_feedforward': 2048,\n",
       " 'tfm_dropout': 0.1,\n",
       " 'tfm_activation': 'relu',\n",
       " 'psn_max': 512,\n",
       " 'psn_embedprocess': {}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Main Config\n",
    "### others will change with each recfldgrn\n",
    "\n",
    "#######################\n",
    "psn_embedprocess = {\n",
    "    # 'activator': 'gelu',\n",
    "    # 'dropout': {'p': 0.5, 'inplace': False}, # maybe the dropout?\n",
    "    # 'layernorm': {'eps': 1e-05, 'elementwise_affine': True}\n",
    "}\n",
    "\n",
    "embed_size = 128\n",
    "default_tfm_para = {'psn_max': 512, \n",
    "                    'psn_embedprocess': psn_embedprocess}\n",
    "#######################\n",
    "tfm_para = get_tfm_para(embed_size, default_tfm_para)\n",
    "tfm_para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b368c9c1-dde4-4caa-9284-c349ab129a80",
   "metadata": {},
   "source": [
    "**init model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7c7e639-5962-46a9-9c55-57024b9bd560",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFMLayerLEARNER(TFM): input(128), output(128): (\n",
       "  (Encoder): EncoderLayer(layers_num=6, dim_feedforward=2048)\n",
       "  (Decoder): DecoderLayer(layers_num=0, dim_feedforward=2048)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN = TFMLayer(**tfm_para)\n",
    "# tfm_layer\n",
    "NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74464e80-7e6c-4eb5-a610-42c4c7eb63e1",
   "metadata": {},
   "source": [
    "**prepare input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa4fd716-6050-4e73-9d27-47e941a2fa2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 19]) <-----  holder.shape\n",
      "torch.Size([4, 19, 128]) <-----  info.shape\n"
     ]
    }
   ],
   "source": [
    "# recfld = 'B-P-EC-Diag@Value-DiagDft'\n",
    "\n",
    "recfld = 'B-P@age-AgeNumeDft'\n",
    "info_dict = RECFLD_TO_EMBEDTESNOR[recfld]\n",
    "holder, info = info_dict['holder'], info_dict['info']\n",
    "\n",
    "print(holder.shape, '<-----  holder.shape')\n",
    "print(info.shape, '<-----  info.shape')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752dd0d5-305e-4ab9-adea-7565c8204322",
   "metadata": {},
   "source": [
    "**I-NN-O**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3beff7e9-157f-46fb-bff1-14f198ae247e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0469,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "holder_output, info_output_v1 = NN.forward_v1(holder, info)\n",
    "# info_output_v1\n",
    "if len(info.shape) == 5:\n",
    "    print(info_output_v1[0, 0, 0, :, 0])\n",
    "if len(info.shape) == 3:\n",
    "    print(info_output_v1[0, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7b6db2b-4752-40f2-aec9-dc6c37c3b196",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0469,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "holder_output, info_output_v2 = NN.forward_v2(holder, info)\n",
    "if len(info.shape) == 5:\n",
    "    print(info_output_v2[0, 0, 0, :, 0])\n",
    "if len(info.shape) == 3:\n",
    "    print(info_output_v2[0, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26f24050-81fb-42c5-b8ec-9796138e55f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0469,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "holder_output, info_output = NN(holder, info)\n",
    "if len(info.shape) == 5:\n",
    "    print(info_output[0, 0, 0, :, 0])\n",
    "if len(info.shape) == 3:\n",
    "    print(info_output[0, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483066b0-264f-474e-9962-8f53ba9c0d68",
   "metadata": {},
   "source": [
    "## Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db28f87e-d545-498e-bdca-b7344eb3e542",
   "metadata": {},
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c12f30d1-6ce5-4e08-8a8c-0e1c6aedd3c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class LinearLayer(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 input_size  = 200, \n",
    "                 output_size = 200,\n",
    "                 initrange = 0.1\n",
    "                 ):\n",
    "\n",
    "        super(LinearLayer, self).__init__()\n",
    "    \n",
    "        self.input_size  = input_size\n",
    "        self.output_size = output_size\n",
    "        self.linear  = torch.nn.Linear(self.input_size, self.output_size)\n",
    "        self.linear.bias.data.zero_()\n",
    "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    \n",
    "    def forward(self, holder, info):\n",
    "        # assert self.input_fullname == fullname\n",
    "        # (1) learn the info\n",
    "        info = self.linear(info)\n",
    "        \n",
    "        # (2) do the masked_leng because of non-zero bias\n",
    "        leng_mask = holder == 0\n",
    "        info = info.masked_fill(leng_mask.unsqueeze(-1), 0)\n",
    "    \n",
    "        # (3) post-process\n",
    "        # for nn_name, layer in self.postprocess.items():\n",
    "        #     info = layer(info)\n",
    "            \n",
    "        # we do not change the fullname and holder\n",
    "        return holder, info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa16a34c-007f-47b2-9e0f-7ff022c6566d",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f20faf37-7ec0-4b2b-a344-7d73d7c9996a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "default_linear_para = {'initrange': 0.1}\n",
    "\n",
    "def get_linear_para(input_size, output_size, default_linear_para):\n",
    "    linear_para =  {'input_size': input_size,\n",
    "                    'output_size': output_size}\n",
    "    \n",
    "    for k, v in default_linear_para.items(): linear_para[k] = v\n",
    "    return linear_para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d026cbbd-1790-4c32-864d-1a5934ac7f40",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37e8245-ae5a-468e-9fbc-e1bcce752aa9",
   "metadata": {},
   "source": [
    "**recfld information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28a4afd6-5b71-4aea-9b1c-08116b647f79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P@age-AgeNumeDft torch.Size([4, 19, 128])\n",
      "B-P@basicInfo-basicInfoDft torch.Size([4, 2, 128])\n",
      "B-P-EC@BasicInfo-BasicDft torch.Size([4, 25, 2, 128])\n",
      "B-P-EC@DT_min-DTDft torch.Size([4, 25, 7, 128])\n",
      "B-P-EC-A1C@DT-DTDft torch.Size([4, 25, 1, 7, 128])\n",
      "B-P-EC-A1C@V-A1CNumeDft torch.Size([4, 25, 1, 37, 128])\n",
      "B-P-EC-Diag@DT-DTDft torch.Size([4, 25, 22, 7, 128])\n",
      "B-P-EC-Diag@Value-DiagDft torch.Size([4, 25, 22, 3, 128])\n",
      "B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLM torch.Size([4, 25, 1, 14, 121, 11, 128])\n"
     ]
    }
   ],
   "source": [
    "for recfld, EmbedTensor in RECFLD_TO_EMBEDTESNOR.items():\n",
    "    print(recfld, EmbedTensor['info'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c4c01f-006d-4013-a8f5-1faaa3eacdb2",
   "metadata": {},
   "source": [
    "**get configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b4fe363-49d5-4b38-b540-31ea5515156a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_size': 128, 'output_size': 128, 'initrange': 0.1}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "embed_size = embed_size\n",
    "default_linear_para = {'initrange': 0.1}\n",
    "############\n",
    "\n",
    "linear_para = get_linear_para(embed_size, embed_size, default_linear_para)\n",
    "linear_para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f284aaa8-3168-4580-a038-7ffafc001eb2",
   "metadata": {},
   "source": [
    "**init model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0b3d173-57ab-440b-b22b-445f08b72095",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearLayer(\n",
       "  (linear): Linear(in_features=128, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN = LinearLayer(**linear_para)\n",
    "NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76799d6-28b4-4ac6-b5e2-0cc268e0cb73",
   "metadata": {},
   "source": [
    "**prepare input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7aa52029-493c-4f47-9495-758f7e864435",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2]) <-----  holder.shape\n",
      "torch.Size([4, 2, 128]) <-----  info.shape\n"
     ]
    }
   ],
   "source": [
    "recfld = 'B-P@basicInfo-basicInfoDft'\n",
    "info_dict = RECFLD_TO_EMBEDTESNOR[recfld]\n",
    "info, holder = info_dict['info'], info_dict['holder']\n",
    "print(holder.shape, '<-----  holder.shape')\n",
    "print(info.shape, '<-----  info.shape')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b7ec6c-9e54-489c-a658-83b77ccdf095",
   "metadata": {},
   "source": [
    "**I-NN-O**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1398446-fdd9-4dae-ac16-458cf13887d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0211, -0.9180, -0.6459,  ...,  0.5810, -0.5451, -0.2727],\n",
       "         [ 0.9918, -1.0760, -0.8198,  ...,  1.0739, -0.2542, -0.6560]],\n",
       "\n",
       "        [[-1.1719,  0.8070, -0.3654,  ..., -0.3696, -0.0316,  0.0692],\n",
       "         [ 0.3357, -0.1931, -0.4071,  ...,  0.3242, -0.1918, -0.7566]],\n",
       "\n",
       "        [[-0.1401,  0.2694,  1.1852,  ..., -0.2132, -0.8237,  0.1233],\n",
       "         [ 0.4198,  0.5447, -0.8063,  ...,  0.2503,  0.1053, -0.5188]],\n",
       "\n",
       "        [[ 0.0639,  0.5080,  0.8615,  ..., -0.4055, -0.2118, -0.0889],\n",
       "         [-2.0946, -1.2461, -0.3083,  ...,  0.5666,  1.5504,  0.9192]]],\n",
       "       grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problem: every time I run it, the result will change. \n",
    "holder_output, info_output = NN(holder, info)\n",
    "print(info_output.shape)\n",
    "# info_output.shape\n",
    "info_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8b2b11-cc56-48ca-85ff-398d930e8618",
   "metadata": {},
   "source": [
    "# Learner: Basic NN Type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb94409e-3a5b-4195-bb71-1a043db19a89",
   "metadata": {},
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57b48f48-e1cf-4232-b2d9-aa1f2be6c516",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# from fieldnn.basicnn.learner.tfm import TFMLayer\n",
    "# from fieldnn.basicnn.learner.linear import LinearLayer\n",
    "\n",
    "# from fieldnn.utils.layerfn import orderSeq, restoreSeq, align_psn_idx, get_Layer2Holder\n",
    "# from fieldnn.utils.parafn import generate_psn_embed_para\n",
    "\n",
    "\n",
    "class Learner_Layer(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_names_nnlvl, output_name_nnlvl, learner_layer_para,\n",
    "                ):\n",
    "        super(Learner_Layer, self).__init__()\n",
    "        \n",
    "        # Part 0: Meta\n",
    "        # here input_names and out_tensor just the tensor name, \n",
    "        # intead, the info_dict contains the corresponding real tensors.\n",
    "        assert len(input_names_nnlvl) == 1\n",
    "        self.input_names_nnlvl = input_names_nnlvl\n",
    "        self.input_name_nnlvl = input_names_nnlvl[0]\n",
    "        \n",
    "        # output_name should be generated from the input_names\n",
    "        self.output_name_nnlvl = output_name_nnlvl\n",
    "        \n",
    "        # the input feature dim size and output feature dim size\n",
    "        self.input_size = learner_layer_para['input_size']\n",
    "        self.output_size = learner_layer_para['output_size']\n",
    " \n",
    "        # Part 1: NN\n",
    "        nn_name, nn_para = learner_layer_para['nn_name'], learner_layer_para['nn_para']\n",
    "        \n",
    "        if nn_name.lower() == 'tfm':\n",
    "            assert self.input_size == self.output_size\n",
    "            self.Learner = TFMLayer(**nn_para)\n",
    "        elif nn_name.lower() == 'linear':\n",
    "            self.Learner = LinearLayer(**nn_para)\n",
    "        # elif nn_name.lower() == 'cnn':\n",
    "        #     self.Learner = CNNLayer(**nn_para)\n",
    "        # elif nn_name.lower() == 'rnn':\n",
    "        #     self.Learner = RNNLayer(**nn_para)\n",
    "        else:\n",
    "            raise ValueError(f'NN \"{nn_name}\" is not available')\n",
    "        \n",
    "        # Part 2: PostProcess\n",
    "        self.postprocess = torch.nn.ModuleDict()\n",
    "        for method, config in learner_layer_para['postprocess'].items():\n",
    "            if method == 'dropout':\n",
    "                self.postprocess[method] = torch.nn.Dropout(**config)\n",
    "            elif method == 'layernorm':\n",
    "                self.postprocess[method] = torch.nn.LayerNorm(self.output_size, **config)\n",
    "        # self.Ignore_PSN_Layers = learner_layer_para['Ignore_PSN_Layers']\n",
    "        \n",
    "    # def get_psn_embed_tensor(self, fullname, holder):\n",
    "    #     name = fullname.split('-')[-1]\n",
    "    #     Layer2Idx = {v:idx for idx, v in enumerate(fullname.split('-'))}\n",
    "    #     Layer2Holder = get_Layer2Holder(fullname, holder, self.Ignore_PSN_Layers)\n",
    "    #     psn_embed = 0\n",
    "    #     for source_layer, Embed in self.PSN_Embed_ModuleDict.items():\n",
    "    #         cpsn_idx = align_psn_idx(source_layer, name, Layer2Idx, Layer2Holder)\n",
    "    #         psn_embed = psn_embed + Embed(cpsn_idx)\n",
    "    #     return psn_embed\n",
    "    \n",
    "    def forward(self, input_names_nnlvl, INPUTS_TO_INFODICT):\n",
    "        # information preparation.\n",
    "        # 'INPUTS_TO_INFODICT` will come from SubUnit Layer.\n",
    "        assert len(input_names_nnlvl) == 1\n",
    "        input_name_nnlvl = input_names_nnlvl[0]\n",
    "        assert self.input_name_nnlvl == input_name_nnlvl\n",
    "        \n",
    "        info_dict = INPUTS_TO_INFODICT[input_name_nnlvl]\n",
    "        holder, info = info_dict['holder'], info_dict['info']\n",
    "        \n",
    "        # print(holder.shape, info.shape)\n",
    "        # the following part is the data proprocessing\n",
    "        holder, info = self.Learner(holder, info)\n",
    "        \n",
    "        for name, layer in self.postprocess.items():\n",
    "            info = layer(info)\n",
    "            \n",
    "        # we don't need to change the holder here.\n",
    "        return self.output_name_nnlvl, {'holder': holder, 'info': info}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a976c1-42cc-4466-8be1-0cccf65418ae",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0070a723-cdce-4c29-a557-38262e8eea30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_learner_para(nn_name, default_nn_para, \n",
    "                     input_size, output_size, \n",
    "                     postprocess):\n",
    "    \n",
    "    learner_para = {}\n",
    "    \n",
    "    # (1) \n",
    "    learner_para['nn_type'] = 'learner'  \n",
    "    learner_para['nn_name'] = nn_name # TFM or linear\n",
    "    \n",
    "    # (2)\n",
    "    if nn_name.lower() == 'tfm':\n",
    "        para = get_tfm_para(input_size, default_nn_para)\n",
    "    elif nn_name.lower() == 'linear':\n",
    "        para = get_linear_para(input_size, output_size, default_nn_para)\n",
    "    else:\n",
    "        raise ValueError(f'The NN \"{nn_name}\" is not available yet')\n",
    "    learner_para['nn_para'] = para\n",
    "    \n",
    "    # (3)\n",
    "    learner_para['input_size'] = input_size\n",
    "    learner_para['output_size'] = output_size\n",
    "    \n",
    "\n",
    "    # (4) Post Process\n",
    "    learner_para['postprocess'] = postprocess\n",
    "    \n",
    "    return learner_para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcac303-dbcd-4564-af95-0ca9f5501630",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e374fb6f-b847-4b32-96f0-1bfb7680910b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nn_type': 'learner',\n",
       " 'nn_name': 'tfm',\n",
       " 'nn_para': {'input_size': 128,\n",
       "  'output_size': 128,\n",
       "  'nhead': 8,\n",
       "  'num_encoder_layers': 6,\n",
       "  'num_decoder_layers': 0,\n",
       "  'dim_feedforward': 2048,\n",
       "  'tfm_dropout': 0.1,\n",
       "  'tfm_activation': 'relu',\n",
       "  'psn_max': 512,\n",
       "  'psn_embedprocess': {'dropout': {'p': 0.5, 'inplace': False},\n",
       "   'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}},\n",
       " 'input_size': 128,\n",
       " 'output_size': 128,\n",
       " 'postprocess': {'activator': 'gelu',\n",
       "  'dropout': {'p': 0.5, 'inplace': False},\n",
       "  'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#######################\n",
    "psn_embedprocess = {# 'activator': 'gelu',\n",
    "                    'dropout': {'p': 0.5, 'inplace': False},\n",
    "                    'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "\n",
    "process = {'activator': 'gelu',\n",
    "            'dropout': {'p': 0.5, 'inplace': False},\n",
    "            'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "\n",
    "\n",
    "embed_size = 128\n",
    "default_tfm_para = {'psn_max': 512, \n",
    "                    'psn_embedprocess': psn_embedprocess}\n",
    "#######################\n",
    "\n",
    "\n",
    "\n",
    "nn_name = 'tfm'\n",
    "default_nn_para = default_tfm_para\n",
    "input_size = embed_size\n",
    "output_size = embed_size\n",
    "postprocess = process\n",
    "\n",
    "\n",
    "learner_para = get_learner_para(nn_name, default_nn_para, \n",
    "                                 input_size, output_size, \n",
    "                                 postprocess)\n",
    "\n",
    "learner_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c793c252-1809-45a0-8c28-f5c82501cfb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P@age-AgeNumeDft',\n",
       " 'B-P@basicInfo-basicInfoDft',\n",
       " 'B-P-EC@BasicInfo-BasicDft',\n",
       " 'B-P-EC@DT_min-DTDft',\n",
       " 'B-P-EC-A1C@DT-DTDft',\n",
       " 'B-P-EC-A1C@V-A1CNumeDft',\n",
       " 'B-P-EC-Diag@DT-DTDft',\n",
       " 'B-P-EC-Diag@Value-DiagDft',\n",
       " 'B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLM']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in RECFLD_TO_EMBEDTESNOR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb2f3609-18d0-4500-9390-6560dfd9d567",
   "metadata": {},
   "outputs": [],
   "source": [
    "recfld = 'B-P-EC-Diag@Value-DiagDft'\n",
    "recfld = 'B-P@age-AgeNumeDft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39cff8a2-18de-40f1-837a-147cef9f6710",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner_Layer(\n",
       "  (Learner): TFMLayerLEARNER(TFM): input(128), output(128): (\n",
       "    (Encoder): EncoderLayer(layers_num=6, dim_feedforward=2048)\n",
       "    (Decoder): DecoderLayer(layers_num=0, dim_feedforward=2048)\n",
       "  )\n",
       "  (postprocess): ModuleDict(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_names_nnlvl = [recfld]\n",
    "output_name_nnlvl = recfld\n",
    "\n",
    "NN = Learner_Layer(input_names_nnlvl, output_name_nnlvl, learner_para)\n",
    "NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd950f8-ad27-4e9a-9f47-e05f45ec9322",
   "metadata": {},
   "source": [
    "**recfld informaiton**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "502541fe-9c70-4dda-8b77-b63fbb0c5ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P@age-AgeNumeDft']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_names_nnlvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d6efc2b-09fb-402d-b434-4fee433a9c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUTS_TO_INFODICT = {}\n",
    "\n",
    "for inp in input_names_nnlvl:\n",
    "    INPUTS_TO_INFODICT[inp] = RECFLD_TO_EMBEDTESNOR[inp]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9f57d3d-0301-4f07-880c-48e3c8b12c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# information preparation.\n",
    "# 'INPUTS_TO_INFODICT` will come from SubUnit Layer.\n",
    "assert len(input_names_nnlvl) == 1\n",
    "input_name_nnlvl = input_names_nnlvl[0]\n",
    "assert NN.input_name_nnlvl == input_name_nnlvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1f1c7da-64f2-4e94-9b6b-b9493a2cc7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 19, 128])\n"
     ]
    }
   ],
   "source": [
    "info_dict = INPUTS_TO_INFODICT[input_name_nnlvl]\n",
    "holder, info = info_dict['holder'], info_dict['info']\n",
    "print(info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e50adfd5-7fd4-46f0-baed-fdeada432431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(holder.shape, info.shape)\n",
    "# the following part is the data proprocessing\n",
    "holder, info = NN.Learner(holder, info)\n",
    "\n",
    "for name, layer in NN.postprocess.items():\n",
    "    info = layer(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7cff84b1-f187-4b93-b0e8-c2b7b918ad71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 19, 128])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputname, info_dict = NN(input_names_nnlvl, INPUTS_TO_INFODICT)\n",
    "\n",
    "info_dict['info'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
