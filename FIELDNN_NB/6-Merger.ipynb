{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d85de7ae-af36-4d22-8e78-6d53cf43ec6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\.shortcut-targets-by-id\\1qNzMmGHCg5Xa63Vw3aKbZdMXvkfT2CgC\\MedStar\\MS_CODE\\FieldNN\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beb79ef-c5ce-423d-bc4b-73b4cab4e43c",
   "metadata": {},
   "source": [
    "# Prepare Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66eb4992-cf60-4626-92df-e23c1f7890f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/ProcData/TensorFolder/Task2YearXXX\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['A1C@DT-DTDftGrn',\n",
       " 'A1C@V-A1CNumeDftGrn',\n",
       " 'Diag@DT-DTDftGrn',\n",
       " 'Diag@Value-DiagDftGrn',\n",
       " 'EC@BasicInfo-BasicDftGrn',\n",
       " 'EC@DT_min-DTDftGrn',\n",
       " 'P@age-AgeNumeDftGrn',\n",
       " 'P@basicInfo-basicInfoDftGrn',\n",
       " 'PN@DT-DTDftGrn',\n",
       " 'PNSect@SectName-PNSctNmDftGrn',\n",
       " 'PNSectSent@Sentence-Tk@TknzLLMGrn',\n",
       " 'Smoking@DT-DTDftGrn',\n",
       " 'Smoking@V-SmokingDftGrn']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from recfldgrn.datapoint import load_df_data_from_folder\n",
    "from fieldnn.utils.layerfn import traverse, convert_relational_list_to_numpy\n",
    "\n",
    "###################### take this as given\n",
    "batch_PID_order = ['P1', 'P4', 'P5', 'P6']\n",
    "######################\n",
    "\n",
    "TaskTensor_folder = 'data/ProcData/TensorFolder/Task2YearXXX'\n",
    "print(TaskTensor_folder)\n",
    "\n",
    "l = sorted([i for i in os.listdir(TaskTensor_folder) if 'Grn' in i])\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e2ce4a0-6b52-4bb9-82f0-ac2359ee27ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recfldgrn_list =['P@age-AgeNumeDftGrn',\n",
    "                 'P@basicInfo-basicInfoDftGrn',\n",
    "                 \n",
    "                 'EC@BasicInfo-BasicDftGrn',\n",
    "                 'EC@DT_min-DTDftGrn',\n",
    "                 \n",
    "                 'A1C@DT-DTDftGrn',\n",
    "                 'A1C@V-A1CNumeDftGrn',\n",
    "                 \n",
    "                 'Diag@DT-DTDftGrn',\n",
    "                 'Diag@Value-DiagDftGrn',\n",
    "                 \n",
    "                 'PNSectSent@Sentence-Tk@TknzLLMGrn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28c06578-45a9-4e2a-996d-3a583d42e298",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P@age-AgeNumeDftGrn_wgt (4, 19)\n",
      "B-P@basicInfo-basicInfoDftGrn_idx (4, 2)\n",
      "B-P-EC@BasicInfo-BasicDftGrn_idx (4, 25, 2)\n",
      "B-P-EC@DT_min-DTDftGrn_idx (4, 25, 7)\n",
      "B-P-EC-A1C@DT-DTDftGrn_idx (4, 25, 1, 7)\n",
      "B-P-EC-A1C@V-A1CNumeDftGrn_wgt (4, 25, 1, 37)\n",
      "B-P-EC-Diag@DT-DTDftGrn_idx (4, 25, 22, 7)\n",
      "B-P-EC-Diag@Value-DiagDftGrn_idx (4, 25, 22, 3)\n",
      "B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx (4, 25, 1, 14, 121, 11)\n"
     ]
    }
   ],
   "source": [
    "batch_rfg = {}\n",
    "\n",
    "for recfldgrn in recfldgrn_list:\n",
    "    \n",
    "    # (1) get tensor_folder\n",
    "    tensor_folder = os.path.join(TaskTensor_folder, recfldgrn)\n",
    "\n",
    "    # (2) get df_Pat and full_recfldgrn\n",
    "    df_Pat = load_df_data_from_folder(tensor_folder).set_index('PID')\n",
    "    full_recfldgrn = df_Pat.columns[0]\n",
    "    suffix = full_recfldgrn.split('_')[-1]\n",
    "    assert recfldgrn in full_recfldgrn\n",
    "\n",
    "    # (3) load batch: TODO: convert this to DataSet and DataLoader\n",
    "    df_batch = df_Pat.loc[batch_PID_order]\n",
    "\n",
    "    # (4) tensor batch as tensor_idx\n",
    "    new_full_recfldgrn = 'B-' + full_recfldgrn\n",
    "    values_list = df_batch[full_recfldgrn].to_list()\n",
    "    suffix = full_recfldgrn.split('_')[-1]\n",
    "    # print(suffix)\n",
    "    # print(new_full_recfldgrn)\n",
    "    D = convert_relational_list_to_numpy(values_list, new_full_recfldgrn, suffix)\n",
    "    tensor_idx = D[new_full_recfldgrn]\n",
    "    \n",
    "    batch_rfg[new_full_recfldgrn] = tensor_idx\n",
    "    \n",
    "for k, v in batch_rfg.items(): print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30ba8cdc-f621-4760-b1b4-61a326095105",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P@age-AgeNumeDftGrn_wgt',\n",
       " 'B-P@basicInfo-basicInfoDftGrn_idx',\n",
       " 'B-P-EC@BasicInfo-BasicDftGrn_idx',\n",
       " 'B-P-EC@DT_min-DTDftGrn_idx',\n",
       " 'B-P-EC-A1C@DT-DTDftGrn_idx',\n",
       " 'B-P-EC-A1C@V-A1CNumeDftGrn_wgt',\n",
       " 'B-P-EC-Diag@DT-DTDftGrn_idx',\n",
       " 'B-P-EC-Diag@Value-DiagDftGrn_idx',\n",
       " 'B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fieldnn.sublayer.expander import Expander_Layer\n",
    "from fieldnn.configfn.expanderfn import get_expander_para\n",
    "\n",
    "full_recfldgrn_list = [\n",
    "                  i for i in batch_rfg\n",
    "                ]\n",
    "full_recfldgrn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "193fa70c-78b3-4042-a278-799c05d92b03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_rfg_to_basicInfo = {}\n",
    "\n",
    "for full_recfldgrn in full_recfldgrn_list:\n",
    "    # (1) full recfldgrn information\n",
    "    recfld = [i for i in full_recfldgrn.split('-') if '@' in i][0]\n",
    "    rec, fld = recfld.split('@')\n",
    "    grn_suffix = [i for i in full_recfldgrn.split('-') if 'Grn' in i][0]\n",
    "    grn, suffix = grn_suffix.split('_')\n",
    "    prefix_ids = [i for i in full_recfldgrn.split('-') if 'Grn' not in i and '@' not in i]\n",
    "    recfldgrn = rec + '@' + fld + '-' + grn\n",
    "\n",
    "    # (2) get vocab information\n",
    "    fldgrn_folder = 'data/ProcData/FldGrnInfo'\n",
    "    fullfldgrn_file = os.path.join(fldgrn_folder, rec + '.p')\n",
    "    df_FieldGrainInfo = pd.read_pickle(fullfldgrn_file)\n",
    "\n",
    "    # no matter what type of grain, in the end, we will have vocab_tokenizer.\n",
    "    if 'LLM' in full_recfldgrn:\n",
    "        vocab_tokenizer = df_FieldGrainInfo[df_FieldGrainInfo['recfield2grain'] == recfldgrn].iloc[0]['Vocab']['v2idx']\n",
    "        # vocab_size = len(vocab_tokenizer)\n",
    "        # print(vocab_size)\n",
    "        init = vocab_tokenizer.name_or_path\n",
    "    else:\n",
    "        vocab_tokenizer = df_FieldGrainInfo[df_FieldGrainInfo['recfield2grain'] == recfldgrn].iloc[0]['Vocab']['v2idx']\n",
    "        # vocab_size = len(vocab_tokenizer)\n",
    "        # print(vocab_size)\n",
    "        init = 'random'\n",
    "    \n",
    "    d = {'vocabsize_tokenizer': vocab_tokenizer, 'init': init}\n",
    "    full_rfg_to_basicInfo[full_recfldgrn] = d\n",
    "    \n",
    "    \n",
    "len(full_rfg_to_basicInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31abf433-cc9e-4001-8672-7c1594fd40f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############################\n",
    "embed_size = 128\n",
    "process = {'activator': 'gelu',\n",
    "           'dropout': {'p': 0.5, 'inplace': False},\n",
    "           'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "############################\n",
    "\n",
    "\n",
    "full_rfg_to_ExpanderConfig = {}\n",
    "\n",
    "for full_recfldgrn in full_recfldgrn_list:\n",
    "    \n",
    "    # determine the nn_name\n",
    "    if '_idx' in full_recfldgrn and 'LLM' not in full_recfldgrn:\n",
    "        nn_name = 'CateEmbed'\n",
    "\n",
    "    elif '_idx' in full_recfldgrn and 'LLM' in full_recfldgrn:\n",
    "        nn_name = 'LLMEmbed'\n",
    "\n",
    "    elif '_wgt' in full_recfldgrn:\n",
    "        nn_name = 'NumeEmbed'\n",
    "    else:\n",
    "        raise ValueError(f'full_recfldgrn is not correct \"{full_recfldgrn}\"')\n",
    "    \n",
    "    d = full_rfg_to_basicInfo[full_recfldgrn]\n",
    "    \n",
    "    # print('\\n----')\n",
    "    # print(full_recfldgrn)\n",
    "    # print(d)\n",
    "    # print(nn_name)\n",
    "    expander_para = get_expander_para(full_recfldgrn, \n",
    "                                       nn_name,\n",
    "                                       embed_size, d['vocabsize_tokenizer'], d['init'], \n",
    "                                       process)\n",
    "    # print(expander_para)\n",
    "    output_recfld = full_recfldgrn.split('Grn')[0]\n",
    "    \n",
    "    full_rfg_to_ExpanderConfig[full_recfldgrn] = {\n",
    "        'full_recfldgrn': full_recfldgrn,\n",
    "        'output_recfld': output_recfld,\n",
    "        'expander_para': expander_para,\n",
    "    }\n",
    "    \n",
    "    \n",
    "# full_rfg_to_ExpanderConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68881c4f-277c-4522-aae2-0f27d0f824eb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P@age-AgeNumeDftGrn_wgt\n",
      "Expander_Layer(\n",
      "  (Embed): NumeEmbeddingLayer(\n",
      "    (embedding): Embedding(19, 128, padding_idx=0)\n",
      "  )\n",
      "  (postprocess): ModuleDict(\n",
      "    (activator): GELU(approximate=none)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "B-P@basicInfo-basicInfoDftGrn_idx\n",
      "Expander_Layer(\n",
      "  (Embed): CateEmbeddingLayer(\n",
      "    (embedding): Embedding(7, 128, padding_idx=0)\n",
      "  )\n",
      "  (postprocess): ModuleDict(\n",
      "    (activator): GELU(approximate=none)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "B-P-EC@BasicInfo-BasicDftGrn_idx\n",
      "Expander_Layer(\n",
      "  (Embed): CateEmbeddingLayer(\n",
      "    (embedding): Embedding(9, 128, padding_idx=0)\n",
      "  )\n",
      "  (postprocess): ModuleDict(\n",
      "    (activator): GELU(approximate=none)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "B-P-EC@DT_min-DTDftGrn_idx\n",
      "Expander_Layer(\n",
      "  (Embed): CateEmbeddingLayer(\n",
      "    (embedding): Embedding(162, 128, padding_idx=0)\n",
      "  )\n",
      "  (postprocess): ModuleDict(\n",
      "    (activator): GELU(approximate=none)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "B-P-EC-A1C@DT-DTDftGrn_idx\n",
      "Expander_Layer(\n",
      "  (Embed): CateEmbeddingLayer(\n",
      "    (embedding): Embedding(162, 128, padding_idx=0)\n",
      "  )\n",
      "  (postprocess): ModuleDict(\n",
      "    (activator): GELU(approximate=none)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "B-P-EC-A1C@V-A1CNumeDftGrn_wgt\n",
      "Expander_Layer(\n",
      "  (Embed): NumeEmbeddingLayer(\n",
      "    (embedding): Embedding(37, 128, padding_idx=0)\n",
      "  )\n",
      "  (postprocess): ModuleDict(\n",
      "    (activator): GELU(approximate=none)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "B-P-EC-Diag@DT-DTDftGrn_idx\n",
      "Expander_Layer(\n",
      "  (Embed): CateEmbeddingLayer(\n",
      "    (embedding): Embedding(162, 128, padding_idx=0)\n",
      "  )\n",
      "  (postprocess): ModuleDict(\n",
      "    (activator): GELU(approximate=none)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "B-P-EC-Diag@Value-DiagDftGrn_idx\n",
      "Expander_Layer(\n",
      "  (Embed): CateEmbeddingLayer(\n",
      "    (embedding): Embedding(801, 128, padding_idx=0)\n",
      "  )\n",
      "  (postprocess): ModuleDict(\n",
      "    (activator): GELU(approximate=none)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx\n",
      "Expander_Layer(\n",
      "  (Embed): LLMEmbeddingLayer(\n",
      "    (LLM): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (linear): Linear(in_features=768, out_features=128, bias=True)\n",
      "  )\n",
      "  (postprocess): ModuleDict(\n",
      "    (activator): GELU(approximate=none)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# TODO: this dictionary `FullRFG_2_Embed` will be turned to the a FieldEmbed_Layer in the near future.\n",
    "\n",
    "FullRFG_2_Embed = {}\n",
    "\n",
    "for full_recfldgrn, ExpanderConfig in full_rfg_to_ExpanderConfig.items():\n",
    "    \n",
    "    FullRFG_2_Embed[full_recfldgrn] = Expander_Layer(**ExpanderConfig)\n",
    "    print(full_recfldgrn)\n",
    "    print(FullRFG_2_Embed[full_recfldgrn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38131ee1-558f-4f02-9577-01fa24bb7f3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P@age-AgeNumeDftGrn_wgt\n",
      "(4, 19)\n",
      "torch.Size([4, 19]) <------ holder shape\n",
      "torch.Size([4, 19]) <------ holder wgt information\n",
      "\n",
      "\n",
      "B-P@basicInfo-basicInfoDftGrn_idx\n",
      "(4, 2)\n",
      "torch.Size([4, 2]) <------ holder shape\n",
      "Empty <------ holder wgt information\n",
      "\n",
      "\n",
      "B-P-EC@BasicInfo-BasicDftGrn_idx\n",
      "(4, 25, 2)\n",
      "torch.Size([4, 25, 2]) <------ holder shape\n",
      "Empty <------ holder wgt information\n",
      "\n",
      "\n",
      "B-P-EC@DT_min-DTDftGrn_idx\n",
      "(4, 25, 7)\n",
      "torch.Size([4, 25, 7]) <------ holder shape\n",
      "Empty <------ holder wgt information\n",
      "\n",
      "\n",
      "B-P-EC-A1C@DT-DTDftGrn_idx\n",
      "(4, 25, 1, 7)\n",
      "torch.Size([4, 25, 1, 7]) <------ holder shape\n",
      "Empty <------ holder wgt information\n",
      "\n",
      "\n",
      "B-P-EC-A1C@V-A1CNumeDftGrn_wgt\n",
      "(4, 25, 1, 37)\n",
      "torch.Size([4, 25, 1, 37]) <------ holder shape\n",
      "torch.Size([4, 25, 1, 37]) <------ holder wgt information\n",
      "\n",
      "\n",
      "B-P-EC-Diag@DT-DTDftGrn_idx\n",
      "(4, 25, 22, 7)\n",
      "torch.Size([4, 25, 22, 7]) <------ holder shape\n",
      "Empty <------ holder wgt information\n",
      "\n",
      "\n",
      "B-P-EC-Diag@Value-DiagDftGrn_idx\n",
      "(4, 25, 22, 3)\n",
      "torch.Size([4, 25, 22, 3]) <------ holder shape\n",
      "Empty <------ holder wgt information\n",
      "\n",
      "\n",
      "B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx\n",
      "(4, 25, 1, 14, 121, 11)\n",
      "torch.Size([4, 25, 1, 14, 121, 11]) <------ holder shape\n",
      "Empty <------ holder wgt information\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for full_recfldgrn in full_recfldgrn_list:\n",
    "    # (1) get the info_raw from batch_rfg\n",
    "    info_raw = batch_rfg[full_recfldgrn]\n",
    "    print(full_recfldgrn)\n",
    "    print(info_raw.shape)\n",
    "\n",
    "    # (2) get the holder (input_idx) and holder_wgt (for nume embedding only)\n",
    "    if '_idx' in full_recfldgrn:\n",
    "        holder_wgt = 'Empty'\n",
    "        holder = torch.LongTensor(info_raw)\n",
    "    elif '_wgt' in full_recfldgrn:\n",
    "        holder_wgt = torch.FloatTensor(info_raw)\n",
    "        # ATTENTION: here holder_wgt could contain zeros in some valid positions.\n",
    "        holder = torch.ones_like(holder_wgt).cumsum(-1).masked_fill(holder_wgt == 0, 0).long()\n",
    "    else:\n",
    "        raise ValueError(f'Invalid suffix \"{suffix}\"')\n",
    "\n",
    "    print(holder.shape, '<------ holder shape')\n",
    "    if type(holder_wgt) == str: \n",
    "        print(holder_wgt, '<------ holder wgt information')\n",
    "    else:\n",
    "        print(holder_wgt.shape, '<------ holder wgt information')\n",
    "\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a49a0206-ff6e-41f8-80e0-0e8d342e0ff3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: B-P@age-AgeNumeDftGrn_wgt\n",
      "(4, 19)\n",
      "torch.Size([4, 19]) <------ holder shape\n",
      "torch.Size([4, 19]) <------ holder wgt information\n",
      "torch.Size([4, 19]) <----- holder shape\n",
      "Output: B-P@age-AgeNumeDft\n",
      "torch.Size([4, 19, 128]) <----- info shape\n",
      "\n",
      "\n",
      "Input: B-P@basicInfo-basicInfoDftGrn_idx\n",
      "(4, 2)\n",
      "torch.Size([4, 2]) <------ holder shape\n",
      "Empty <------ holder wgt information\n",
      "torch.Size([4, 2]) <----- holder shape\n",
      "Output: B-P@basicInfo-basicInfoDft\n",
      "torch.Size([4, 2, 128]) <----- info shape\n",
      "\n",
      "\n",
      "Input: B-P-EC@BasicInfo-BasicDftGrn_idx\n",
      "(4, 25, 2)\n",
      "torch.Size([4, 25, 2]) <------ holder shape\n",
      "Empty <------ holder wgt information\n",
      "torch.Size([4, 25, 2]) <----- holder shape\n",
      "Output: B-P-EC@BasicInfo-BasicDft\n",
      "torch.Size([4, 25, 2, 128]) <----- info shape\n",
      "\n",
      "\n",
      "Input: B-P-EC@DT_min-DTDftGrn_idx\n",
      "(4, 25, 7)\n",
      "torch.Size([4, 25, 7]) <------ holder shape\n",
      "Empty <------ holder wgt information\n",
      "torch.Size([4, 25, 7]) <----- holder shape\n",
      "Output: B-P-EC@DT_min-DTDft\n",
      "torch.Size([4, 25, 7, 128]) <----- info shape\n",
      "\n",
      "\n",
      "Input: B-P-EC-A1C@DT-DTDftGrn_idx\n",
      "(4, 25, 1, 7)\n",
      "torch.Size([4, 25, 1, 7]) <------ holder shape\n",
      "Empty <------ holder wgt information\n",
      "torch.Size([4, 25, 1, 7]) <----- holder shape\n",
      "Output: B-P-EC-A1C@DT-DTDft\n",
      "torch.Size([4, 25, 1, 7, 128]) <----- info shape\n",
      "\n",
      "\n",
      "Input: B-P-EC-A1C@V-A1CNumeDftGrn_wgt\n",
      "(4, 25, 1, 37)\n",
      "torch.Size([4, 25, 1, 37]) <------ holder shape\n",
      "torch.Size([4, 25, 1, 37]) <------ holder wgt information\n",
      "torch.Size([4, 25, 1, 37]) <----- holder shape\n",
      "Output: B-P-EC-A1C@V-A1CNumeDft\n",
      "torch.Size([4, 25, 1, 37, 128]) <----- info shape\n",
      "\n",
      "\n",
      "Input: B-P-EC-Diag@DT-DTDftGrn_idx\n",
      "(4, 25, 22, 7)\n",
      "torch.Size([4, 25, 22, 7]) <------ holder shape\n",
      "Empty <------ holder wgt information\n",
      "torch.Size([4, 25, 22, 7]) <----- holder shape\n",
      "Output: B-P-EC-Diag@DT-DTDft\n",
      "torch.Size([4, 25, 22, 7, 128]) <----- info shape\n",
      "\n",
      "\n",
      "Input: B-P-EC-Diag@Value-DiagDftGrn_idx\n",
      "(4, 25, 22, 3)\n",
      "torch.Size([4, 25, 22, 3]) <------ holder shape\n",
      "Empty <------ holder wgt information\n",
      "torch.Size([4, 25, 22, 3]) <----- holder shape\n",
      "Output: B-P-EC-Diag@Value-DiagDft\n",
      "torch.Size([4, 25, 22, 3, 128]) <----- info shape\n",
      "\n",
      "\n",
      "Input: B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx\n",
      "(4, 25, 1, 14, 121, 11)\n",
      "torch.Size([4, 25, 1, 14, 121, 11]) <------ holder shape\n",
      "Empty <------ holder wgt information\n",
      "torch.Size([4, 25, 1, 14, 121, 11]) <----- holder shape\n",
      "Output: B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLM\n",
      "torch.Size([4, 25, 1, 14, 121, 11, 128]) <----- info shape\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "full_recfldgrn_EmbedTensor = {}\n",
    "\n",
    "for full_recfldgrn in full_recfldgrn_list:\n",
    "    # (1) get the info_raw from batch_rfg\n",
    "    info_raw = batch_rfg[full_recfldgrn]\n",
    "    print('Input:',full_recfldgrn)\n",
    "    print(info_raw.shape)\n",
    "\n",
    "    # (2) get the holder (input_idx) and holder_wgt (for nume embedding only)\n",
    "    if '_idx' in full_recfldgrn:\n",
    "        holder_wgt = 'Empty'\n",
    "        holder = torch.LongTensor(info_raw)\n",
    "    elif '_wgt' in full_recfldgrn:\n",
    "        holder_wgt = torch.FloatTensor(info_raw)\n",
    "        # ATTENTION: here holder_wgt could contain zeros in some valid positions.\n",
    "        holder = torch.ones_like(holder_wgt).cumsum(-1).masked_fill(holder_wgt == 0, 0).long()\n",
    "    else:\n",
    "        raise ValueError(f'Invalid suffix \"{suffix}\"')\n",
    "\n",
    "    print(holder.shape, '<------ holder shape')\n",
    "    if type(holder_wgt) == str:  \n",
    "        print(holder_wgt, '<------ holder wgt information')\n",
    "    else:\n",
    "        print(holder_wgt.shape, '<------ holder wgt information')\n",
    "    \n",
    "    NN = FullRFG_2_Embed[full_recfldgrn] \n",
    "    print(holder.shape, '<----- holder shape')\n",
    "    output_recfld, holder, info = NN(full_recfldgrn, holder, holder_wgt)\n",
    "    print('Output:', output_recfld)\n",
    "    print(info.shape, '<----- info shape')\n",
    "    full_recfldgrn_EmbedTensor[output_recfld] = {'holder': holder, 'info': info}\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ef871e5-a117-4c99-ace5-870e3dd89e7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: write a function to make the RECFLD_TO_TENSOR more clear.\n",
    "# specifically, change 'B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLM' to 'B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk'\n",
    "\n",
    "full_recfldgrn_EmbedTensor['B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk'] = full_recfldgrn_EmbedTensor.pop('B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLM')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6751dd1d-0f73-4cd3-a461-47b845440601",
   "metadata": {},
   "source": [
    "# Get the Starting Tensor and Tensor Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76d07eb3-d998-4bf4-b879-a02cf083a62e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fieldnn.utils.dataflowfn import get_dataflow_table, update_df_dataflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f19cc942-c754-4d64-a618-605709572c1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P@age-AgeNumeDft torch.Size([4, 19, 128])\n",
      "B-P@basicInfo-basicInfoDft torch.Size([4, 2, 128])\n",
      "B-P-EC@BasicInfo-BasicDft torch.Size([4, 25, 2, 128])\n",
      "B-P-EC@DT_min-DTDft torch.Size([4, 25, 7, 128])\n",
      "B-P-EC-A1C@DT-DTDft torch.Size([4, 25, 1, 7, 128])\n",
      "B-P-EC-A1C@V-A1CNumeDft torch.Size([4, 25, 1, 37, 128])\n",
      "B-P-EC-Diag@DT-DTDft torch.Size([4, 25, 22, 7, 128])\n",
      "B-P-EC-Diag@Value-DiagDft torch.Size([4, 25, 22, 3, 128])\n",
      "B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk torch.Size([4, 25, 1, 14, 121, 11, 128])\n"
     ]
    }
   ],
   "source": [
    "# full_recfldgrn_EmbedTensor = {}\n",
    "RECFLD_TO_TENSOR = {}\n",
    "\n",
    "for full_recfld, info_dict in full_recfldgrn_EmbedTensor.items():\n",
    "    print(full_recfld, info_dict['info'].shape)\n",
    "    RECFLD_TO_TENSOR[full_recfld] = info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f34181b-110a-422f-b6d3-3187ae0be33f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P@age-AgeNumeDft',\n",
       " 'B-P@basicInfo-basicInfoDft',\n",
       " 'B-P-EC@BasicInfo-BasicDft',\n",
       " 'B-P-EC@DT_min-DTDft',\n",
       " 'B-P-EC-A1C@DT-DTDft',\n",
       " 'B-P-EC-A1C@V-A1CNumeDft',\n",
       " 'B-P-EC-Diag@DT-DTDft',\n",
       " 'B-P-EC-Diag@Value-DiagDft',\n",
       " 'B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in RECFLD_TO_TENSOR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0bd915d-13b9-4e47-b9d8-0669cf02ce6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_layer = max([len(i.split('-')) for i in RECFLD_TO_TENSOR])\n",
    "max_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dcbfe9c-2a15-496d-bc94-de5f1abca616",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P@age-AgeNumeDft',\n",
       " 'B-P@basicInfo-basicInfoDft',\n",
       " 'B-P-EC@BasicInfo-BasicDft',\n",
       " 'B-P-EC@DT_min-DTDft',\n",
       " 'B-P-EC-A1C@DT-DTDft',\n",
       " 'B-P-EC-A1C@V-A1CNumeDft',\n",
       " 'B-P-EC-Diag@DT-DTDft',\n",
       " 'B-P-EC-Diag@Value-DiagDft',\n",
       " 'B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_recfldgrn_list = [i for i in RECFLD_TO_TENSOR]\n",
    "full_recfldgrn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90eaa671-8a59-41d0-9bb1-8564eb146e30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>6</th>\n",
       "      <th>5</th>\n",
       "      <th>4</th>\n",
       "      <th>3</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recfldgrn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P@age-AgeNumeDft</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-P@age-AgeNumeDft</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@basicInfo-basicInfoDft</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-P@basicInfo-basicInfoDft</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC@BasicInfo-BasicDft</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-P-EC@BasicInfo-BasicDft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC@DT_min-DTDft</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-P-EC@DT_min-DTDft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1C@DT-DTDft</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-P-EC-A1C@DT-DTDft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1C@V-A1CNumeDft</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-P-EC-A1C@V-A1CNumeDft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diag@DT-DTDft</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-P-EC-Diag@DT-DTDft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diag@Value-DiagDft</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-P-EC-Diag@Value-DiagDft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PNSectSent@Sentence-Tk</th>\n",
       "      <td>B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                7   6  \\\n",
       "recfldgrn                                                               \n",
       "P@age-AgeNumeDft                                              NaN NaN   \n",
       "P@basicInfo-basicInfoDft                                      NaN NaN   \n",
       "EC@BasicInfo-BasicDft                                         NaN NaN   \n",
       "EC@DT_min-DTDft                                               NaN NaN   \n",
       "A1C@DT-DTDft                                                  NaN NaN   \n",
       "A1C@V-A1CNumeDft                                              NaN NaN   \n",
       "Diag@DT-DTDft                                                 NaN NaN   \n",
       "Diag@Value-DiagDft                                            NaN NaN   \n",
       "PNSectSent@Sentence-Tk    B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk NaN   \n",
       "\n",
       "                                                  5  \\\n",
       "recfldgrn                                             \n",
       "P@age-AgeNumeDft                                NaN   \n",
       "P@basicInfo-basicInfoDft                        NaN   \n",
       "EC@BasicInfo-BasicDft                           NaN   \n",
       "EC@DT_min-DTDft                                 NaN   \n",
       "A1C@DT-DTDft                    B-P-EC-A1C@DT-DTDft   \n",
       "A1C@V-A1CNumeDft            B-P-EC-A1C@V-A1CNumeDft   \n",
       "Diag@DT-DTDft                  B-P-EC-Diag@DT-DTDft   \n",
       "Diag@Value-DiagDft        B-P-EC-Diag@Value-DiagDft   \n",
       "PNSectSent@Sentence-Tk                          NaN   \n",
       "\n",
       "                                                  4  \\\n",
       "recfldgrn                                             \n",
       "P@age-AgeNumeDft                                NaN   \n",
       "P@basicInfo-basicInfoDft                        NaN   \n",
       "EC@BasicInfo-BasicDft     B-P-EC@BasicInfo-BasicDft   \n",
       "EC@DT_min-DTDft                 B-P-EC@DT_min-DTDft   \n",
       "A1C@DT-DTDft                                    NaN   \n",
       "A1C@V-A1CNumeDft                                NaN   \n",
       "Diag@DT-DTDft                                   NaN   \n",
       "Diag@Value-DiagDft                              NaN   \n",
       "PNSectSent@Sentence-Tk                          NaN   \n",
       "\n",
       "                                                   3   2  \n",
       "recfldgrn                                                 \n",
       "P@age-AgeNumeDft                  B-P@age-AgeNumeDft NaN  \n",
       "P@basicInfo-basicInfoDft  B-P@basicInfo-basicInfoDft NaN  \n",
       "EC@BasicInfo-BasicDft                            NaN NaN  \n",
       "EC@DT_min-DTDft                                  NaN NaN  \n",
       "A1C@DT-DTDft                                     NaN NaN  \n",
       "A1C@V-A1CNumeDft                                 NaN NaN  \n",
       "Diag@DT-DTDft                                    NaN NaN  \n",
       "Diag@Value-DiagDft                               NaN NaN  \n",
       "PNSectSent@Sentence-Tk                           NaN NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataflow = get_dataflow_table(full_recfldgrn_list)\n",
    "df_dataflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18d054b7-da17-433a-802e-f2073ad3bc6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>6</th>\n",
       "      <th>5</th>\n",
       "      <th>4</th>\n",
       "      <th>3</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recfldgrn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P@age-AgeNumeDft</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-P@age-AgeNumeDft</td>\n",
       "      <td>B-P@age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@basicInfo-basicInfoDft</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-P@basicInfo-basicInfoDft</td>\n",
       "      <td>B-P@basicInfo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC@BasicInfo-BasicDft</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-P-EC@BasicInfo-BasicDft</td>\n",
       "      <td>B-P-EC@BasicInfo</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC@DT_min-DTDft</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-P-EC@DT_min-DTDft</td>\n",
       "      <td>B-P-EC@DT_min</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1C@DT-DTDft</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-P-EC-A1C@DT-DTDft</td>\n",
       "      <td>B-P-EC-A1C@DT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1C@V-A1CNumeDft</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-P-EC-A1C@V-A1CNumeDft</td>\n",
       "      <td>B-P-EC-A1C@V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Merge)A1C@DT&amp;V</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-P-EC-A1C</td>\n",
       "      <td>B-P-EC@A1C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diag@DT-DTDft</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-P-EC-Diag@DT-DTDft</td>\n",
       "      <td>B-P-EC-Diag@DT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diag@Value-DiagDft</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-P-EC-Diag@Value-DiagDft</td>\n",
       "      <td>B-P-EC-Diag@Value</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Merge)Diag@DT&amp;Value</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-P-EC-Diag</td>\n",
       "      <td>B-P-EC@Diag</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PNSectSent@Sentence-Tk</th>\n",
       "      <td>B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk</td>\n",
       "      <td>B-P-EC-PN-PNSect-PNSectSent</td>\n",
       "      <td>B-P-EC-PN-PNSect</td>\n",
       "      <td>B-P-EC-PN</td>\n",
       "      <td>B-P-EC@PN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Merge)EC@BasicInfo&amp;DT_min&amp;A1C&amp;Diag&amp;PN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-P-EC</td>\n",
       "      <td>B-P@EC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Merge)P@age&amp;basicInfo&amp;EC</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B-P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              7  \\\n",
       "recfldgrn                                                                         \n",
       "P@age-AgeNumeDft                                                            NaN   \n",
       "P@basicInfo-basicInfoDft                                                    NaN   \n",
       "EC@BasicInfo-BasicDft                                                       NaN   \n",
       "EC@DT_min-DTDft                                                             NaN   \n",
       "A1C@DT-DTDft                                                                NaN   \n",
       "A1C@V-A1CNumeDft                                                            NaN   \n",
       "(Merge)A1C@DT&V                                                             NaN   \n",
       "Diag@DT-DTDft                                                               NaN   \n",
       "Diag@Value-DiagDft                                                          NaN   \n",
       "(Merge)Diag@DT&Value                                                        NaN   \n",
       "PNSectSent@Sentence-Tk                  B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk   \n",
       "(Merge)EC@BasicInfo&DT_min&A1C&Diag&PN                                      NaN   \n",
       "(Merge)P@age&basicInfo&EC                                                   NaN   \n",
       "\n",
       "                                                                  6  \\\n",
       "recfldgrn                                                             \n",
       "P@age-AgeNumeDft                                                NaN   \n",
       "P@basicInfo-basicInfoDft                                        NaN   \n",
       "EC@BasicInfo-BasicDft                                           NaN   \n",
       "EC@DT_min-DTDft                                                 NaN   \n",
       "A1C@DT-DTDft                                                    NaN   \n",
       "A1C@V-A1CNumeDft                                                NaN   \n",
       "(Merge)A1C@DT&V                                                 NaN   \n",
       "Diag@DT-DTDft                                                   NaN   \n",
       "Diag@Value-DiagDft                                              NaN   \n",
       "(Merge)Diag@DT&Value                                            NaN   \n",
       "PNSectSent@Sentence-Tk                  B-P-EC-PN-PNSect-PNSectSent   \n",
       "(Merge)EC@BasicInfo&DT_min&A1C&Diag&PN                          NaN   \n",
       "(Merge)P@age&basicInfo&EC                                       NaN   \n",
       "\n",
       "                                                                5  \\\n",
       "recfldgrn                                                           \n",
       "P@age-AgeNumeDft                                              NaN   \n",
       "P@basicInfo-basicInfoDft                                      NaN   \n",
       "EC@BasicInfo-BasicDft                                         NaN   \n",
       "EC@DT_min-DTDft                                               NaN   \n",
       "A1C@DT-DTDft                                  B-P-EC-A1C@DT-DTDft   \n",
       "A1C@V-A1CNumeDft                          B-P-EC-A1C@V-A1CNumeDft   \n",
       "(Merge)A1C@DT&V                                               NaN   \n",
       "Diag@DT-DTDft                                B-P-EC-Diag@DT-DTDft   \n",
       "Diag@Value-DiagDft                      B-P-EC-Diag@Value-DiagDft   \n",
       "(Merge)Diag@DT&Value                                          NaN   \n",
       "PNSectSent@Sentence-Tk                           B-P-EC-PN-PNSect   \n",
       "(Merge)EC@BasicInfo&DT_min&A1C&Diag&PN                        NaN   \n",
       "(Merge)P@age&basicInfo&EC                                     NaN   \n",
       "\n",
       "                                                                4  \\\n",
       "recfldgrn                                                           \n",
       "P@age-AgeNumeDft                                              NaN   \n",
       "P@basicInfo-basicInfoDft                                      NaN   \n",
       "EC@BasicInfo-BasicDft                   B-P-EC@BasicInfo-BasicDft   \n",
       "EC@DT_min-DTDft                               B-P-EC@DT_min-DTDft   \n",
       "A1C@DT-DTDft                                        B-P-EC-A1C@DT   \n",
       "A1C@V-A1CNumeDft                                     B-P-EC-A1C@V   \n",
       "(Merge)A1C@DT&V                                        B-P-EC-A1C   \n",
       "Diag@DT-DTDft                                      B-P-EC-Diag@DT   \n",
       "Diag@Value-DiagDft                              B-P-EC-Diag@Value   \n",
       "(Merge)Diag@DT&Value                                  B-P-EC-Diag   \n",
       "PNSectSent@Sentence-Tk                                  B-P-EC-PN   \n",
       "(Merge)EC@BasicInfo&DT_min&A1C&Diag&PN                        NaN   \n",
       "(Merge)P@age&basicInfo&EC                                     NaN   \n",
       "\n",
       "                                                                 3  \\\n",
       "recfldgrn                                                            \n",
       "P@age-AgeNumeDft                                B-P@age-AgeNumeDft   \n",
       "P@basicInfo-basicInfoDft                B-P@basicInfo-basicInfoDft   \n",
       "EC@BasicInfo-BasicDft                             B-P-EC@BasicInfo   \n",
       "EC@DT_min-DTDft                                      B-P-EC@DT_min   \n",
       "A1C@DT-DTDft                                                   NaN   \n",
       "A1C@V-A1CNumeDft                                               NaN   \n",
       "(Merge)A1C@DT&V                                         B-P-EC@A1C   \n",
       "Diag@DT-DTDft                                                  NaN   \n",
       "Diag@Value-DiagDft                                             NaN   \n",
       "(Merge)Diag@DT&Value                                   B-P-EC@Diag   \n",
       "PNSectSent@Sentence-Tk                                   B-P-EC@PN   \n",
       "(Merge)EC@BasicInfo&DT_min&A1C&Diag&PN                      B-P-EC   \n",
       "(Merge)P@age&basicInfo&EC                                      NaN   \n",
       "\n",
       "                                                    2  \n",
       "recfldgrn                                              \n",
       "P@age-AgeNumeDft                              B-P@age  \n",
       "P@basicInfo-basicInfoDft                B-P@basicInfo  \n",
       "EC@BasicInfo-BasicDft                             NaN  \n",
       "EC@DT_min-DTDft                                   NaN  \n",
       "A1C@DT-DTDft                                      NaN  \n",
       "A1C@V-A1CNumeDft                                  NaN  \n",
       "(Merge)A1C@DT&V                                   NaN  \n",
       "Diag@DT-DTDft                                     NaN  \n",
       "Diag@Value-DiagDft                                NaN  \n",
       "(Merge)Diag@DT&Value                              NaN  \n",
       "PNSectSent@Sentence-Tk                            NaN  \n",
       "(Merge)EC@BasicInfo&DT_min&A1C&Diag&PN         B-P@EC  \n",
       "(Merge)P@age&basicInfo&EC                         B-P  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_dataflow_new = update_df_dataflow(df_dataflow, style = 'ReducerOnly')\n",
    "df_dataflow_new = update_df_dataflow(df_dataflow, style = 'Reducer&Merger')\n",
    "\n",
    "df_dataflow_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd364706-286d-4d25-816e-1adacd98e678",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubUnitName</th>\n",
       "      <th>input_names</th>\n",
       "      <th>output_name</th>\n",
       "      <th>input_layerid</th>\n",
       "      <th>output_layerid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk]</td>\n",
       "      <td>B-P-EC-PN-PNSect-PNSectSent</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P-EC-PN-PNSect-PNSectSent]</td>\n",
       "      <td>B-P-EC-PN-PNSect</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P-EC-A1C@DT-DTDft]</td>\n",
       "      <td>B-P-EC-A1C@DT</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P-EC-A1C@V-A1CNumeDft]</td>\n",
       "      <td>B-P-EC-A1C@V</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P-EC-Diag@DT-DTDft]</td>\n",
       "      <td>B-P-EC-Diag@DT</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P-EC-Diag@Value-DiagDft]</td>\n",
       "      <td>B-P-EC-Diag@Value</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P-EC-PN-PNSect]</td>\n",
       "      <td>B-P-EC-PN</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MERGER</td>\n",
       "      <td>[B-P-EC-A1C@DT, B-P-EC-A1C@V]</td>\n",
       "      <td>B-P-EC-A1C</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MERGER</td>\n",
       "      <td>[B-P-EC-Diag@DT, B-P-EC-Diag@Value]</td>\n",
       "      <td>B-P-EC-Diag</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P-EC@BasicInfo-BasicDft]</td>\n",
       "      <td>B-P-EC@BasicInfo</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P-EC@DT_min-DTDft]</td>\n",
       "      <td>B-P-EC@DT_min</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P-EC-A1C]</td>\n",
       "      <td>B-P-EC@A1C</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P-EC-Diag]</td>\n",
       "      <td>B-P-EC@Diag</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P-EC-PN]</td>\n",
       "      <td>B-P-EC@PN</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MERGER</td>\n",
       "      <td>[B-P-EC@BasicInfo, B-P-EC@DT_min, B-P-EC@A1C, ...</td>\n",
       "      <td>B-P-EC</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P@age-AgeNumeDft]</td>\n",
       "      <td>B-P@age</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P@basicInfo-basicInfoDft]</td>\n",
       "      <td>B-P@basicInfo</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P-EC]</td>\n",
       "      <td>B-P@EC</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MERGER</td>\n",
       "      <td>[B-P@age, B-P@basicInfo, B-P@EC]</td>\n",
       "      <td>B-P</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SubUnitName                                        input_names  \\\n",
       "0      REDUCER          [B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk]   \n",
       "1      REDUCER                      [B-P-EC-PN-PNSect-PNSectSent]   \n",
       "2      REDUCER                              [B-P-EC-A1C@DT-DTDft]   \n",
       "3      REDUCER                          [B-P-EC-A1C@V-A1CNumeDft]   \n",
       "4      REDUCER                             [B-P-EC-Diag@DT-DTDft]   \n",
       "5      REDUCER                        [B-P-EC-Diag@Value-DiagDft]   \n",
       "6      REDUCER                                 [B-P-EC-PN-PNSect]   \n",
       "7       MERGER                      [B-P-EC-A1C@DT, B-P-EC-A1C@V]   \n",
       "8       MERGER                [B-P-EC-Diag@DT, B-P-EC-Diag@Value]   \n",
       "9      REDUCER                        [B-P-EC@BasicInfo-BasicDft]   \n",
       "10     REDUCER                              [B-P-EC@DT_min-DTDft]   \n",
       "11     REDUCER                                       [B-P-EC-A1C]   \n",
       "12     REDUCER                                      [B-P-EC-Diag]   \n",
       "13     REDUCER                                        [B-P-EC-PN]   \n",
       "14      MERGER  [B-P-EC@BasicInfo, B-P-EC@DT_min, B-P-EC@A1C, ...   \n",
       "15     REDUCER                               [B-P@age-AgeNumeDft]   \n",
       "16     REDUCER                       [B-P@basicInfo-basicInfoDft]   \n",
       "17     REDUCER                                           [B-P-EC]   \n",
       "18      MERGER                   [B-P@age, B-P@basicInfo, B-P@EC]   \n",
       "\n",
       "                    output_name  input_layerid  output_layerid  \n",
       "0   B-P-EC-PN-PNSect-PNSectSent              7               6  \n",
       "1              B-P-EC-PN-PNSect              6               5  \n",
       "2                 B-P-EC-A1C@DT              5               4  \n",
       "3                  B-P-EC-A1C@V              5               4  \n",
       "4                B-P-EC-Diag@DT              5               4  \n",
       "5             B-P-EC-Diag@Value              5               4  \n",
       "6                     B-P-EC-PN              5               4  \n",
       "7                    B-P-EC-A1C              4               4  \n",
       "8                   B-P-EC-Diag              4               4  \n",
       "9              B-P-EC@BasicInfo              4               3  \n",
       "10                B-P-EC@DT_min              4               3  \n",
       "11                   B-P-EC@A1C              4               3  \n",
       "12                  B-P-EC@Diag              4               3  \n",
       "13                    B-P-EC@PN              4               3  \n",
       "14                       B-P-EC              3               3  \n",
       "15                      B-P@age              3               2  \n",
       "16                B-P@basicInfo              3               2  \n",
       "17                       B-P@EC              3               2  \n",
       "18                          B-P              2               2  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fieldnn.utils.dataflowfn import get_NN_List\n",
    "\n",
    "# actually, we should call this df_SubUnits\n",
    "df_SubUnits = get_NN_List(df_dataflow_new)\n",
    "df_SubUnits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbd8185-8fbb-494f-a054-f2c08322343d",
   "metadata": {},
   "source": [
    "# Focus One SubUnit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80955c4c-e5ae-4654-a240-4e3deb2b1594",
   "metadata": {},
   "source": [
    "## Select SubUnit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ff83835-5e82-48a1-94a8-5502b06143f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SubUnitName                                         REDUCER\n",
       "input_names       [B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk]\n",
       "output_name                     B-P-EC-PN-PNSect-PNSectSent\n",
       "input_layerid                                             7\n",
       "output_layerid                                            6\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can focus on one specific SubUnit\n",
    "# definitely, in the future, we will loop this SubUnit\n",
    "SubUnit_info = df_SubUnits.iloc[0]\n",
    "SubUnit_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "395f886e-27f0-432b-a16d-7f4dd61d966b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk'] <--- SubUnit_input_names\n",
      "B-P-EC-PN-PNSect-PNSectSent <--- SubUnit_output_name\n"
     ]
    }
   ],
   "source": [
    "SubUnitName = SubUnit_info['SubUnitName'] \n",
    "# SubUnitName = SubUnit_info['SubUnitName'] \n",
    "# here we want to generate the para_list. \n",
    "SubUnit_input_names = SubUnit_info['input_names']\n",
    "SubUnit_output_name = SubUnit_info['output_name']\n",
    "SubUnit_input_layerid = SubUnit_info['input_layerid']\n",
    "SubUnit_output_layerid = SubUnit_info['output_layerid']\n",
    "\n",
    "print(SubUnit_input_names, '<--- SubUnit_input_names')\n",
    "print(SubUnit_output_name, '<--- SubUnit_output_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616bcdf0-9a00-4c5e-93ff-2d90cc86f2c1",
   "metadata": {},
   "source": [
    "##  BasicNN in SubUnit\n",
    "\n",
    "One SubUnit Layer can have a OrderDictionary of NN List\n",
    "\n",
    "\n",
    "\n",
    "Here we only consider the simpliest case:\n",
    "\n",
    "```\n",
    "SubUnit: [ reducer ]\n",
    "```\n",
    "\n",
    "\n",
    "We will also have the other cases and will discuss about that in further cases.\n",
    "\n",
    "```\n",
    "SubUnit: [ merger + reducer ] # this one will be studied in the Merger Part. \n",
    "\n",
    "SubUnit: [ reducer + learner ] # these two will be studied in the next notebook.\n",
    "\n",
    "SubUnit: [ merger + learner + reducer + learner ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69de178f-1d64-4c82-ba1f-4266fb671530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One SubUnit would contains multiple Basic NN\n",
    "# currently, we focus on one specific NN - reducer's Max\n",
    "# prepare your input here\n",
    "############################\n",
    "embed_size = 128\n",
    "process = {'activator': 'gelu',\n",
    "           'dropout': {'p': 0.5, 'inplace': False},\n",
    "           'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "default_nnpara = {}\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e6023f3-2161-4d21-bbb2-0860f18fb5f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Time we Focus on This\n",
    "\n",
    "SubUnit_NN_List = ['reducer-Max']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc59e1c-6dc0-4625-b41f-6e6ede9a8bec",
   "metadata": {},
   "source": [
    "# Reducer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ac97ef-4ae7-45c6-9866-4366b74db14b",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5f58a5f-0de5-4a01-b91b-258724303a3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_reducer_para(nn_name, nn_para, input_size, output_size, postprocess):\n",
    "    # reducer is type of BasicNN.\n",
    "    reducer_layer_para = {}\n",
    "    reducer_layer_para['nn_type'] = 'reducer'\n",
    "    reducer_layer_para['nn_name'] = nn_name\n",
    "    reducer_layer_para['nn_para'] = nn_para\n",
    "    reducer_layer_para['input_size'] = input_size\n",
    "    reducer_layer_para['output_size'] = output_size\n",
    "    reducer_layer_para['postprocess'] = postprocess\n",
    "    return reducer_layer_para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48cc10f-5f19-4d2c-acdd-7a7b92d8f6ea",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1583459-8326-443d-861b-98c2ca67a541",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P@age-AgeNumeDft torch.Size([4, 19, 128])\n",
      "B-P@basicInfo-basicInfoDft torch.Size([4, 2, 128])\n",
      "B-P-EC@BasicInfo-BasicDft torch.Size([4, 25, 2, 128])\n",
      "B-P-EC@DT_min-DTDft torch.Size([4, 25, 7, 128])\n",
      "B-P-EC-A1C@DT-DTDft torch.Size([4, 25, 1, 7, 128])\n",
      "B-P-EC-A1C@V-A1CNumeDft torch.Size([4, 25, 1, 37, 128])\n",
      "B-P-EC-Diag@DT-DTDft torch.Size([4, 25, 22, 7, 128])\n",
      "B-P-EC-Diag@Value-DiagDft torch.Size([4, 25, 22, 3, 128])\n",
      "B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk torch.Size([4, 25, 1, 14, 121, 11, 128])\n"
     ]
    }
   ],
   "source": [
    "# set up the RECFLD_TO_TENSOR\n",
    "\n",
    "RECFLD_TO_TENSOR = {}\n",
    "\n",
    "for full_recfld, info_dict in full_recfldgrn_EmbedTensor.items():\n",
    "    print(full_recfld, info_dict['info'].shape)\n",
    "    RECFLD_TO_TENSOR[full_recfld] = info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ae0097a-1883-4f62-87e6-96a893a2a505",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P@age-AgeNumeDft',\n",
       " 'B-P@basicInfo-basicInfoDft',\n",
       " 'B-P-EC@BasicInfo-BasicDft',\n",
       " 'B-P-EC@DT_min-DTDft',\n",
       " 'B-P-EC-A1C@DT-DTDft',\n",
       " 'B-P-EC-A1C@V-A1CNumeDft',\n",
       " 'B-P-EC-Diag@DT-DTDft',\n",
       " 'B-P-EC-Diag@Value-DiagDft',\n",
       " 'B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in RECFLD_TO_TENSOR]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d4006c-e3c9-4987-9088-32e7542461a7",
   "metadata": {},
   "source": [
    "### From SubUnit to BasicNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f6eb021-99a1-4257-a871-289d2b64ab1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "SubUnit_BasicNN_List = ['reducer-Max']\n",
    "# # You can also change this to others. To Mean, Median, etc. as a reducer method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e0e4e5f-2a93-469e-a05d-efaac1c5f360",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk'] <--------- input_names_nnlvl\n",
      "B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk <--------- output_name_nnlvl\n"
     ]
    }
   ],
   "source": [
    "BasicNN_idx = 0\n",
    "\n",
    "# Next Time we will loop this\n",
    "#### Getting the BasicNN information.\n",
    "nn_type_nn_name = SubUnit_BasicNN_List[BasicNN_idx]\n",
    "\n",
    "nn_type, nn_name = nn_type_nn_name.split('-')\n",
    "# Image here you are in the loop already.\n",
    "# Current Iteration is 0\n",
    "\n",
    "# actually, the following code only deals with nn_type == 'reducer'\n",
    "# We will add the following condition in the whole loop.\n",
    "# if nn_type == 'reducer': \n",
    "assert len(SubUnit_input_names) == 1\n",
    "\n",
    "# Get the input_names_nnlvl\n",
    "input_names_nnlvl = SubUnit_input_names # this assigments only works for the first iteration\n",
    "\n",
    "# Get the output_name_nnlvl\n",
    "output_name_nnlvl = input_names_nnlvl[0].replace('-' + fld, '@' + fld)\n",
    "\n",
    "\n",
    "# Prepare the para for the NN layer\n",
    "nn_para = default_nnpara # this will be updated.\n",
    "\n",
    "# Get the input_size\n",
    "input_size = embed_size\n",
    "\n",
    "# Get the output_size\n",
    "if nn_name.lower() == 'concat':\n",
    "    # this types of merger only happened in the R in MLRL. \n",
    "    # you can skip this part safely if you haven't encountered M. \n",
    "    fld_childflds = input_names_nnlvl[0].split('-')[-1]\n",
    "    assert '@' in fld_childflds\n",
    "    childflds = fld_childflds.split('@')[-1]\n",
    "    childflds = childflds.split('&')\n",
    "    output_size = len(childflds) * embed_size\n",
    "else:\n",
    "    # usually the most case. \n",
    "    output_size = embed_size \n",
    "\n",
    "# Get the postprocess\n",
    "postprocess = process\n",
    "\n",
    "# Derive the para\n",
    "para = get_reducer_para(nn_name, nn_para, input_size, output_size, postprocess)  \n",
    "\n",
    "# have a look at the para here. \n",
    "print(input_names_nnlvl, '<--------- input_names_nnlvl')\n",
    "print(output_name_nnlvl, '<--------- output_name_nnlvl')\n",
    "para\n",
    "\n",
    "\n",
    "\n",
    "SubUnit_Config = {'input_names_nnlvl': input_names_nnlvl, \n",
    "                  'output_name_nnlvl': output_name_nnlvl, \n",
    "                  'para': para}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45fc9c1d-7694-4f8a-975e-6afd6d74edf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the above block to a function\n",
    "\n",
    "def generate_BasicNN_Config(nn_type_nn_name):\n",
    "    nn_type, nn_name = nn_type_nn_name.split('-')\n",
    "\n",
    "    # Image here you are in the loop already.\n",
    "    # Current Iteration is 0\n",
    "\n",
    "    # actually, the following code only deals with nn_type == 'reducer'\n",
    "    # We will add the following condition in the whole loop.\n",
    "    if nn_type == 'reducer': \n",
    "        assert len(SubUnit_input_names) == 1\n",
    "        # Get the input_names_nnlvl\n",
    "        input_names_nnlvl = SubUnit_input_names # this assigments only works for the first iteration\n",
    "\n",
    "        # Get the output_name_nnlvl\n",
    "        output_name_nnlvl = input_names_nnlvl[0].replace('-' + fld, '@' + fld)\n",
    "\n",
    "        # Prepare the para for the NN layer\n",
    "        nn_para = default_nnpara # this will be updated.\n",
    "\n",
    "        # Get the input_size\n",
    "        input_size = embed_size\n",
    "\n",
    "        # Get the output_size\n",
    "        if nn_name.lower() == 'concat':\n",
    "            # this types of merger only happened in the R in MLRL. \n",
    "            # you can skip this part safely if you haven't encountered M. \n",
    "            fld_childflds = input_names_nnlvl[0].split('-')[-1]\n",
    "            assert '@' in fld_childflds\n",
    "            childflds = fld_childflds.split('@')[-1]\n",
    "            childflds = childflds.split('&')\n",
    "            output_size = len(childflds) * embed_size\n",
    "        else:\n",
    "            # usually the most case. \n",
    "            output_size = embed_size \n",
    "\n",
    "        # Get the postprocess\n",
    "        postprocess = process\n",
    "\n",
    "        # Derive the para\n",
    "        para = get_reducer_para(nn_name, nn_para, input_size, output_size, postprocess)  \n",
    "        \n",
    "    else:\n",
    "        raise ValueError('nn_type')\n",
    "\n",
    "    # have a look at the para here. \n",
    "    # print(input_names_nnlvl, '<--------- input_names_nnlvl')\n",
    "    # print(output_name_nnlvl, '<--------- output_name_nnlvl')\n",
    "    # para\n",
    "\n",
    "    Basic_Config = {'input_names_nnlvl': input_names_nnlvl, \n",
    "                      'output_name_nnlvl': output_name_nnlvl, \n",
    "                      f'{nn_type}_para': para}\n",
    "    \n",
    "    return Basic_Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "945d9a20-83a5-4694-9c41-c735159bfa62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['reducer-Max']\n",
      "reducer-Max\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'nn_type_nn_name': 'reducer-Max',\n",
       "  'Basic_Config': {'input_names_nnlvl': ['B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk'],\n",
       "   'output_name_nnlvl': 'B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk',\n",
       "   'reducer_para': {'nn_type': 'reducer',\n",
       "    'nn_name': 'Max',\n",
       "    'nn_para': {},\n",
       "    'input_size': 128,\n",
       "    'output_size': 128,\n",
       "    'postprocess': {'activator': 'gelu',\n",
       "     'dropout': {'p': 0.5, 'inplace': False},\n",
       "     'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}}}}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the question is how to create the SubUnit_BasicNN_List for each SubUnit\n",
    "# we will turn to this later. \n",
    "print(SubUnit_BasicNN_List)\n",
    "\n",
    "SubUnit_BasicNN_Config_List = []\n",
    "for nn_type_nn_name in SubUnit_BasicNN_List:\n",
    "\n",
    "    print(nn_type_nn_name)\n",
    "    Basic_Config = generate_BasicNN_Config(nn_type_nn_name)\n",
    "    BasicNN_Config = {'nn_type_nn_name': nn_type_nn_name, 'Basic_Config': Basic_Config}\n",
    "    SubUnit_BasicNN_Config_List.append(BasicNN_Config)\n",
    "    \n",
    "SubUnit_BasicNN_Config_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c580e342-306d-4419-82dc-a3058585aa3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk']\n",
      "B-P-EC-PN-PNSect-PNSectSent\n",
      "\n",
      "The output_name_nnlvl now is the fullname version for SubUnit_output_name\n",
      "\tB-P-EC-PN-PNSect-PNSectSent@Sentence-Tk   <-------- output_name_nnlvl\n",
      "\tB-P-EC-PN-PNSect-PNSectSent   <-------- SubUnit_output_name\n"
     ]
    }
   ],
   "source": [
    "# Have a close validation\n",
    "print(SubUnit_input_names)\n",
    "print(SubUnit_output_name)\n",
    "\n",
    "if SubUnit_output_name in output_name_nnlvl:\n",
    "    print('\\nThe output_name_nnlvl now is the fullname version for SubUnit_output_name')\n",
    "    print(f'\\t{output_name_nnlvl}   <-------- output_name_nnlvl')\n",
    "    print(f'\\t{SubUnit_output_name}   <-------- SubUnit_output_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec12811c-1d23-4640-99d6-36c61f074c17",
   "metadata": {},
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b11c1e-d21e-4dd3-ab93-345e1f1192bc",
   "metadata": {},
   "source": [
    "### Basic NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ea603792-ea4b-44a1-84ff-c3f01c892053",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ReduceSumLayer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReduceSumLayer, self).__init__()   \n",
    "\n",
    "    def forward(self, info, leng_mask):\n",
    "        # (bs, xxx, l, dim) --> (bs, xxx, dim)\n",
    "        info = torch.sum(info, -2)\n",
    "        return info\n",
    "\n",
    "class ReduceMeanLayer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReduceMeanLayer, self).__init__()\n",
    "  \n",
    "    def forward(self, info, leng_mask):\n",
    "        leng = (leng_mask == 0).sum(-1).unsqueeze(-1).float()\n",
    "        leng[leng == 0.] = 1.0 # change pad to any non-zeros to be dominators.\n",
    "        info = torch.sum(info, -2) # (bs, xxx, l, dim) --> (bs, xxx, dim)\n",
    "        info = info/leng           # (bs, xxx, dim)    --> (bs, xxx, dim)\n",
    "        return info\n",
    "\n",
    "class RecuderMaxLayer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RecuderMaxLayer, self).__init__()\n",
    "\n",
    "    def forward(self, info, leng_mask):\n",
    "        info = info.masked_fill(leng_mask.unsqueeze(-1), -10000) # double check this.\n",
    "        a, b = info.max(-2) # not necessary, all the values could be smaller than 0.\n",
    "        return a\n",
    "    \n",
    "\n",
    "class ConcatenateLayer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConcatenateLayer, self).__init__()\n",
    "\n",
    "    def forward(self, info, leng_mask):\n",
    "        l, dim = info.shape[-2:]\n",
    "        info = info.view(*info.shape[:-2],  l*dim)\n",
    "        return info   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4f2d1a-dac4-4dd3-81ca-74fe79ce7827",
   "metadata": {},
   "source": [
    "### NN Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1d001da9-c39b-4879-8afb-13813113c909",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# from ..nn.operator.op import ReduceMeanLayer, ReduceSumLayer, RecuderMaxLayer, ConcatenateLayer\n",
    "# from fieldnn.nn.operator.op import ReduceMeanLayer, ReduceSumLayer, RecuderMaxLayer, ConcatenateLayer\n",
    "\n",
    "class Reducer_Layer(torch.nn.Module):\n",
    "    def __init__(self, input_names_nnlvl, output_name_nnlvl, reducer_layer_para):\n",
    "        super(Reducer_Layer, self).__init__()\n",
    "        \n",
    "        # Part 0: Meta\n",
    "        # here input_names and out_tensor just the tensor name, \n",
    "        # they are not the real tensors\n",
    "        # intead, the info_dict contains the corresponding real tensors.\n",
    "        assert len(input_names_nnlvl) == 1\n",
    "        self.input_names_nnlvl = input_names_nnlvl\n",
    "        self.input_name_nnlvl = input_names_nnlvl[0]\n",
    "        \n",
    "        # output_name should be generated from the input_names\n",
    "        self.output_name_nnlvl = output_name_nnlvl\n",
    "        # self.output_name = output_name\n",
    "\n",
    "        # the input feature dim size and output feature dim size\n",
    "        self.input_size = reducer_layer_para['input_size']\n",
    "        self.output_size = reducer_layer_para['output_size']\n",
    "\n",
    "        # Part 1: NN\n",
    "        nn_name, nn_para = reducer_layer_para['nn_name'], reducer_layer_para['nn_para']\n",
    "        if nn_name.lower() == 'mean':\n",
    "            self.reducer = ReduceMeanLayer()\n",
    "        elif nn_name.lower() == 'sum':\n",
    "            self.reducer = ReduceSumLayer()\n",
    "        elif nn_name.lower() == 'max':\n",
    "            self.reducer = RecuderMaxLayer()\n",
    "        elif nn_name.lower() == 'concat':\n",
    "            self.reducer = ConcatenateLayer()\n",
    "            # TODO: need to assert something\n",
    "            assert self.output_size % self.input_size == 0\n",
    "        else:\n",
    "            raise ValueError(f'There is no layer for \"{nn_name}\"')\n",
    "            \n",
    "        # Part 2: PostProcess\n",
    "        self.postprocess = torch.nn.ModuleDict()\n",
    "        for method, config in reducer_layer_para['postprocess'].items():\n",
    "            if method == 'activator':\n",
    "                activator = config\n",
    "                if activator.lower() == 'relu': \n",
    "                    self.postprocess[method] = torch.nn.ReLU()\n",
    "                elif activator.lower() == 'tanh': \n",
    "                    self.postprocess[method] = torch.nn.Tanh()\n",
    "                elif activator.lower() == 'gelu':\n",
    "                    self.postprocess[method] = torch.nn.GELU()\n",
    "            elif method == 'dropout':\n",
    "                self.postprocess[method] = torch.nn.Dropout(**config)\n",
    "            elif method == 'layernorm':\n",
    "                self.postprocess[method] = torch.nn.LayerNorm(self.output_size, **config)\n",
    "            \n",
    "    def forward(self, input_names_nnlvl, INPUTS_TO_INFODICT):\n",
    "        # information preparation.\n",
    "        # 'INPUTS_TO_INFODICT` will come from SubUnit Layer.\n",
    "        assert len(input_names_nnlvl) == 1\n",
    "        input_name_nnlvl = input_names_nnlvl[0]\n",
    "        assert self.input_name_nnlvl == input_name_nnlvl\n",
    "        \n",
    "        info_dict = INPUTS_TO_INFODICT[input_name_nnlvl]\n",
    "        holder, info = info_dict['holder'], info_dict['info']\n",
    "        \n",
    "        # print(holder.shape, info.shape)\n",
    "        # the following part is the data proprocessing\n",
    "        leng_mask = holder == 0\n",
    "        info = self.reducer(info, leng_mask)\n",
    "        \n",
    "        for name, layer in self.postprocess.items():\n",
    "            info = layer(info)\n",
    "            \n",
    "        holder = (leng_mask == 0).sum(-1)\n",
    "        \n",
    "        # output_name_nnlvl is not necessarily to be stored in the \n",
    "        return self.output_name_nnlvl, {'holder': holder, 'info': info}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa29e4ec-4682-46d7-a8da-35a58698a99b",
   "metadata": {},
   "source": [
    "### Get Reducer_Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f8576664-c05d-434b-b4a3-96fa2db10ac3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk']\n",
      "B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk\n",
      "{'nn_type': 'reducer', 'nn_name': 'Max', 'nn_para': {}, 'input_size': 128, 'output_size': 128, 'postprocess': {'activator': 'gelu', 'dropout': {'p': 0.5, 'inplace': False}, 'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}}\n"
     ]
    }
   ],
   "source": [
    "print(input_names_nnlvl)\n",
    "print(output_name_nnlvl)\n",
    "\n",
    "reducer_layer_para = para\n",
    "print(reducer_layer_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e8113976-72a4-4b11-831f-0d2bdca6f1ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reducer_Layer(\n",
       "  (reducer): RecuderMaxLayer()\n",
       "  (postprocess): ModuleDict(\n",
       "    (activator): GELU(approximate='none')\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN = Reducer_Layer(input_names_nnlvl, output_name_nnlvl, reducer_layer_para)\n",
    "NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ccf299-c0db-4225-8f45-20b2f5418234",
   "metadata": {},
   "source": [
    "### I-NN-O\n",
    "\n",
    "NN mean the Neural Network before.\n",
    "\n",
    "I is the input.\n",
    "\n",
    "O is the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c9dddbea-7d5e-42a1-a2bb-92d988fc5dc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk']\n",
      "B-P-EC-PN-PNSect-PNSectSent\n"
     ]
    }
   ],
   "source": [
    "print(SubUnit_input_names)\n",
    "print(SubUnit_output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "18f3d114-9f17-4d5e-b232-8e5bed7ecd3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "info_dict = RECFLD_TO_TENSOR[SubUnit_input_names[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "800ceb60-1180-4864-b082-60b3cd8be50c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 25, 1, 14, 121, 11, 128])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info, holder = info_dict['info'], info_dict['holder']\n",
    "info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7a370258-5b3b-475f-8abb-9f5e6f4d919e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SubUnit Layer Information\n",
    "INPUTS_TO_INFODICT = {} \n",
    "for input_name in SubUnit_input_names:\n",
    "    INPUTS_TO_INFODICT[input_name] = RECFLD_TO_TENSOR[input_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5e6947d0-1bf1-4a7d-8c22-3637290268b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecuderMaxLayer()"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3857659b-97cf-4d12-8149-98a18862bb7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensor = info_dict['info']\n",
    "# tensor.unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "94ccf11c-069d-4f90-8ea0-39626040b133",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk\n"
     ]
    }
   ],
   "source": [
    "output_name_nnlvl, info_dict = NN(input_names_nnlvl, INPUTS_TO_INFODICT)\n",
    "print(output_name_nnlvl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e3a038ae-a694-4203-94db-356e39e49814",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 25, 1, 14, 121, 128])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = info_dict['info']\n",
    "info.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877cbcb8-f2f1-43f6-bd7e-11cc0f5be8d0",
   "metadata": {},
   "source": [
    "# Focus Other SubUnits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b50526b-5f7f-49f6-a71d-3662eeb13f59",
   "metadata": {},
   "source": [
    "## Load Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7ee2f228-c671-4d13-9cc7-c0898a0a4229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fieldnn.sublayer.reducer import Reducer_Layer\n",
    "from fieldnn.configfn.reducerfn import get_reducer_para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4804d09-5d41-497d-8154-1ccc5dd05394",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cf38377d-6c9a-4528-845a-0b9faaa87134",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubUnitName</th>\n",
       "      <th>input_names</th>\n",
       "      <th>output_name</th>\n",
       "      <th>input_layerid</th>\n",
       "      <th>output_layerid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk]</td>\n",
       "      <td>B-P-EC-PN-PNSect-PNSectSent</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P-EC-PN-PNSect-PNSectSent]</td>\n",
       "      <td>B-P-EC-PN-PNSect</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P-EC-A1C@DT-DTDft]</td>\n",
       "      <td>B-P-EC-A1C@DT</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P-EC-A1C@V-A1CNumeDft]</td>\n",
       "      <td>B-P-EC-A1C@V</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P-EC-Diag@DT-DTDft]</td>\n",
       "      <td>B-P-EC-Diag@DT</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P-EC-Diag@Value-DiagDft]</td>\n",
       "      <td>B-P-EC-Diag@Value</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P-EC-PN-PNSect]</td>\n",
       "      <td>B-P-EC-PN</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MERGER</td>\n",
       "      <td>[B-P-EC-A1C@DT, B-P-EC-A1C@V]</td>\n",
       "      <td>B-P-EC-A1C</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MERGER</td>\n",
       "      <td>[B-P-EC-Diag@DT, B-P-EC-Diag@Value]</td>\n",
       "      <td>B-P-EC-Diag</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P-EC@BasicInfo-BasicDft]</td>\n",
       "      <td>B-P-EC@BasicInfo</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P-EC@DT_min-DTDft]</td>\n",
       "      <td>B-P-EC@DT_min</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P-EC-A1C]</td>\n",
       "      <td>B-P-EC@A1C</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P-EC-Diag]</td>\n",
       "      <td>B-P-EC@Diag</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P-EC-PN]</td>\n",
       "      <td>B-P-EC@PN</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MERGER</td>\n",
       "      <td>[B-P-EC@BasicInfo, B-P-EC@DT_min, B-P-EC@A1C, ...</td>\n",
       "      <td>B-P-EC</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P@age-AgeNumeDft]</td>\n",
       "      <td>B-P@age</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P@basicInfo-basicInfoDft]</td>\n",
       "      <td>B-P@basicInfo</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>REDUCER</td>\n",
       "      <td>[B-P-EC]</td>\n",
       "      <td>B-P@EC</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MERGER</td>\n",
       "      <td>[B-P@age, B-P@basicInfo, B-P@EC]</td>\n",
       "      <td>B-P</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SubUnitName                                        input_names  \\\n",
       "0      REDUCER          [B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk]   \n",
       "1      REDUCER                      [B-P-EC-PN-PNSect-PNSectSent]   \n",
       "2      REDUCER                              [B-P-EC-A1C@DT-DTDft]   \n",
       "3      REDUCER                          [B-P-EC-A1C@V-A1CNumeDft]   \n",
       "4      REDUCER                             [B-P-EC-Diag@DT-DTDft]   \n",
       "5      REDUCER                        [B-P-EC-Diag@Value-DiagDft]   \n",
       "6      REDUCER                                 [B-P-EC-PN-PNSect]   \n",
       "7       MERGER                      [B-P-EC-A1C@DT, B-P-EC-A1C@V]   \n",
       "8       MERGER                [B-P-EC-Diag@DT, B-P-EC-Diag@Value]   \n",
       "9      REDUCER                        [B-P-EC@BasicInfo-BasicDft]   \n",
       "10     REDUCER                              [B-P-EC@DT_min-DTDft]   \n",
       "11     REDUCER                                       [B-P-EC-A1C]   \n",
       "12     REDUCER                                      [B-P-EC-Diag]   \n",
       "13     REDUCER                                        [B-P-EC-PN]   \n",
       "14      MERGER  [B-P-EC@BasicInfo, B-P-EC@DT_min, B-P-EC@A1C, ...   \n",
       "15     REDUCER                               [B-P@age-AgeNumeDft]   \n",
       "16     REDUCER                       [B-P@basicInfo-basicInfoDft]   \n",
       "17     REDUCER                                           [B-P-EC]   \n",
       "18      MERGER                   [B-P@age, B-P@basicInfo, B-P@EC]   \n",
       "\n",
       "                    output_name  input_layerid  output_layerid  \n",
       "0   B-P-EC-PN-PNSect-PNSectSent              7               6  \n",
       "1              B-P-EC-PN-PNSect              6               5  \n",
       "2                 B-P-EC-A1C@DT              5               4  \n",
       "3                  B-P-EC-A1C@V              5               4  \n",
       "4                B-P-EC-Diag@DT              5               4  \n",
       "5             B-P-EC-Diag@Value              5               4  \n",
       "6                     B-P-EC-PN              5               4  \n",
       "7                    B-P-EC-A1C              4               4  \n",
       "8                   B-P-EC-Diag              4               4  \n",
       "9              B-P-EC@BasicInfo              4               3  \n",
       "10                B-P-EC@DT_min              4               3  \n",
       "11                   B-P-EC@A1C              4               3  \n",
       "12                  B-P-EC@Diag              4               3  \n",
       "13                    B-P-EC@PN              4               3  \n",
       "14                       B-P-EC              3               3  \n",
       "15                      B-P@age              3               2  \n",
       "16                B-P@basicInfo              3               2  \n",
       "17                       B-P@EC              3               2  \n",
       "18                          B-P              2               2  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "bc800c4a-3066-454b-a903-cb7b70f54824",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SubUnit Information for idx: 2\n",
      "['B-P-EC-A1C@DT-DTDft'] <--- SubUnit_input_names\n",
      "B-P-EC-A1C@DT <--- SubUnit_output_name\n",
      "\n",
      "SubUnit Information for idx: 3\n",
      "['B-P-EC-A1C@V-A1CNumeDft'] <--- SubUnit_input_names\n",
      "B-P-EC-A1C@V <--- SubUnit_output_name\n"
     ]
    }
   ],
   "source": [
    "selected_SubUnit_id = [2, 3]\n",
    "\n",
    "for subunit_id in selected_SubUnit_id: \n",
    "    print(f'\\nSubUnit Information for idx: {subunit_id}')\n",
    "    SubUnit_info = df_NN.iloc[subunit_id]\n",
    "    \n",
    "    \n",
    "    # Enrich the SubUnit Information\n",
    "    SubUnitName = SubUnit_info['SubUnitName'] \n",
    "    # SubUnitName = SubUnit_info['SubUnitName'] \n",
    "    # here we want to generate the para_list. \n",
    "    SubUnit_input_names = SubUnit_info['input_names']\n",
    "    SubUnit_output_name = SubUnit_info['output_name']\n",
    "    SubUnit_input_layerid = SubUnit_info['input_layerid']\n",
    "    SubUnit_output_layerid = SubUnit_info['output_layerid']\n",
    "\n",
    "    print(SubUnit_input_names, '<--- SubUnit_input_names')\n",
    "    print(SubUnit_output_name, '<--- SubUnit_output_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b5874c28-b931-47aa-9a92-b1fe890351a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One SubUnit would contains multiple Basic NN\n",
    "# currently, we focus on one specific NN - reducer's Max\n",
    "# prepare your input here\n",
    "############################\n",
    "embed_size = 128\n",
    "process = {'activator': 'gelu',\n",
    "           'dropout': {'p': 0.5, 'inplace': False},\n",
    "           'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "default_nnpara = {}\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a5e6f795-c646-48d6-ba64-1c54704c6365",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Time we Focus on This\n",
    "SubUnit_NN_List = ['reducer-Max']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac1cbe9-07a9-48cd-8968-7e47c3c40778",
   "metadata": {},
   "source": [
    "## Create Config and NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c8c45060-a043-4e4c-97e9-b2d25096b45e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SubUnit Information for idx: 2\n",
      "['B-P-EC-A1C@DT-DTDft'] <--- SubUnit_input_names\n",
      "B-P-EC-A1C@DT <--- SubUnit_output_name\n",
      "['B-P-EC-A1C@DT-DTDft'] <--------- input_names_nnlvl\n",
      "B-P-EC-A1C@DT-DTDft <--------- output_name_nnlvl\n",
      "{'nn_type': 'reducer', 'nn_name': 'Max', 'nn_para': {}, 'input_size': 128, 'output_size': 128, 'postprocess': {'activator': 'gelu', 'dropout': {'p': 0.5, 'inplace': False}, 'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}}\n",
      "\n",
      "SubUnit Information for idx: 3\n",
      "['B-P-EC-A1C@V-A1CNumeDft'] <--- SubUnit_input_names\n",
      "B-P-EC-A1C@V <--- SubUnit_output_name\n",
      "['B-P-EC-A1C@V-A1CNumeDft'] <--------- input_names_nnlvl\n",
      "B-P-EC-A1C@V-A1CNumeDft <--------- output_name_nnlvl\n",
      "{'nn_type': 'reducer', 'nn_name': 'Max', 'nn_para': {}, 'input_size': 128, 'output_size': 128, 'postprocess': {'activator': 'gelu', 'dropout': {'p': 0.5, 'inplace': False}, 'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}}\n"
     ]
    }
   ],
   "source": [
    "selected_SubUnit_id = [2, 3]\n",
    "\n",
    "SubUnit_Config_Dictionary = {}\n",
    "\n",
    "for subunit_id in selected_SubUnit_id: \n",
    "    print(f'\\nSubUnit Information for idx: {subunit_id}')\n",
    "    SubUnit_info = df_NN.iloc[subunit_id]\n",
    "    \n",
    "    # Enrich the SubUnit Information\n",
    "    SubUnitName = SubUnit_info['SubUnitName'] \n",
    "    # SubUnitName = SubUnit_info['SubUnitName'] \n",
    "    # here we want to generate the para_list. \n",
    "    SubUnit_input_names = SubUnit_info['input_names']\n",
    "    SubUnit_output_name = SubUnit_info['output_name']\n",
    "    SubUnit_input_layerid = SubUnit_info['input_layerid']\n",
    "    SubUnit_output_layerid = SubUnit_info['output_layerid']\n",
    "\n",
    "    print(SubUnit_input_names, '<--- SubUnit_input_names')\n",
    "    print(SubUnit_output_name, '<--- SubUnit_output_name')\n",
    "\n",
    "    # Next Time we will loop this\n",
    "    # nn_type_nn_name = SubUnit_NN_List[0]\n",
    "    \n",
    "    \n",
    "    SubUnit_NN_Config_List = []\n",
    "    for idx, nn_type_nn_name in enumerate(SubUnit_NN_List):\n",
    "        nn_type, nn_name = nn_type_nn_name.split('-')\n",
    "\n",
    "        # actually, the following code only deals with nn_type == 'reducer'\n",
    "        # We will add the following condition in the whole loop.\n",
    "        if nn_type == 'reducer': \n",
    "            assert len(SubUnit_input_names) == 1\n",
    "\n",
    "            # Get the input_names_nnlvl\n",
    "            input_names_nnlvl = SubUnit_input_names # this assigments only works for the first iteration\n",
    "\n",
    "            # Get the output_name_nnlvl\n",
    "            output_name_nnlvl = input_names_nnlvl[0].replace('-' + fld, '@' + fld)\n",
    "\n",
    "            # Prepare the para for the NN layer\n",
    "            nn_para = default_nnpara # this will be updated.\n",
    "\n",
    "            # Get the input_size\n",
    "            input_size = embed_size\n",
    "\n",
    "            # Get the output_size\n",
    "            if nn_name.lower() == 'concat':\n",
    "                # this types of merger only happened in the R in MLRL. \n",
    "                # you can skip this part safely if you haven't encountered M. \n",
    "                fld_childflds = input_names_nnlvl[0].split('-')[-1]\n",
    "                assert '@' in fld_childflds\n",
    "                childflds = fld_childflds.split('@')[-1]\n",
    "                childflds = childflds.split('&')\n",
    "                output_size = len(childflds) * embed_size\n",
    "            else:\n",
    "                # usually the most case. \n",
    "                output_size = embed_size \n",
    "\n",
    "            # Get the postprocess\n",
    "            postprocess = process\n",
    "\n",
    "            # Derive the para\n",
    "            para = get_reducer_para(nn_name, nn_para, input_size, output_size, postprocess) \n",
    "        else:\n",
    "            # TODO\n",
    "            pass\n",
    "\n",
    "        # So in this NN from SubUnit_NN_List\n",
    "        # we have the following information \n",
    "        print(input_names_nnlvl, '<--------- input_names_nnlvl')\n",
    "        print(output_name_nnlvl, '<--------- output_name_nnlvl')\n",
    "        print(para)\n",
    "        \n",
    "        SubUnit_NN_Config_List.append([input_names_nnlvl, output_name_nnlvl, para])\n",
    "        \n",
    "    SubUnit_Config_Dictionary[subunit_id] = SubUnit_NN_Config_List\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092d6fba-4a31-461b-9296-d45a3b2cf3a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d4bbf5-a5b3-4b86-9b21-b9e7e974d050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afe2179-e1f9-47ec-b20e-1a99fdba54de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8459f0e6-a4d4-48f7-aea6-58f68b353cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e211e2-7d2a-450e-9580-f506ce6e99b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68f171b3-05b6-4199-9d50-2298abd7c7d2",
   "metadata": {},
   "source": [
    "# (Skip) Merger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11caa8a2-68ea-474c-9bff-eff960f29db0",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3e08df09-4676-45ab-9fc0-1018fb2e4bcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_merger_para(nn_name, nn_para, input_size, output_size, postprocess):\n",
    "    para = {}\n",
    "    para['nn_type'] = 'merger'\n",
    "    para['nn_name'] = nn_name\n",
    "    para['nn_para'] = nn_para\n",
    "    para['input_size'] = input_size\n",
    "    para['output_size'] = output_size\n",
    "    para['postprocess'] = postprocess\n",
    "    return para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6710f604-71bb-470a-ab7f-21cf29ce5b30",
   "metadata": {},
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "620f43e9-d4c1-42e7-9310-61ee1e23a959",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class MergerLayer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MergerLayer, self).__init__()\n",
    "    \n",
    "    def forward(self, tensor_list, order = -2):\n",
    "        info = torch.cat([i.unsqueeze(order) for i in tensor_list], order)\n",
    "        return info   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3f065929-cf0a-49d5-9811-11869b739562",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from fieldnn.nn.operator.op import MergerLayer\n",
    "# from ..nn.op import MergerLayer\n",
    "\n",
    "class Merger_Layer(torch.nn.Module):\n",
    "    def __init__(self, input_names_nnlvl, output_name_nnlvl, merger_layer_para):\n",
    "        super(Merger_Layer, self).__init__()\n",
    "        \n",
    "        # the input_names_nnlvl\n",
    "        self.input_names_nnlvl = input_names_nnlvl\n",
    "        # output_name should be generated from the input_names\n",
    "        self.output_name_nnlvl = output_name_nnlvl\n",
    "        \n",
    "        self.input_size = merger_layer_para['input_size']\n",
    "        self.output_size = merger_layer_para['output_size']\n",
    "        \n",
    "        # Part 1: NN\n",
    "        nn_name = merger_layer_para['nn_name']\n",
    "        nn_para = merger_layer_para['nn_para']\n",
    "        \n",
    "        if nn_name.lower() == 'merger':\n",
    "            self.merger = MergerLayer()\n",
    "        else:\n",
    "            raise ValueError(f'The NN \"{nn_name}\" is not available')\n",
    "        \n",
    "        # Part 2: PostProcess\n",
    "        self.postprocess = torch.nn.ModuleDict()\n",
    "        for method, config in merger_layer_para['postprocess'].items():\n",
    "            if method == 'activator':\n",
    "                activator = config\n",
    "                if activator.lower() == 'relu': \n",
    "                    self.postprocess[method] = torch.nn.ReLU()\n",
    "                elif activator.lower() == 'tanh': \n",
    "                    self.postprocess[method] = torch.nn.Tanh()\n",
    "                elif activator.lower() == 'gelu':\n",
    "                    self.postprocess[method] = torch.nn.GELU()\n",
    "            elif method == 'dropout':\n",
    "                self.postprocess[method] = torch.nn.Dropout(**config)\n",
    "            elif method == 'layernorm':\n",
    "                self.postprocess[method] = torch.nn.LayerNorm(self.output_size, **config)\n",
    "                \n",
    "    def forward(self, input_names_nnlvl, INPUTS_TO_INFODICT):\n",
    "        \n",
    "        INPUTS = {k:v for k, v in INPUTS_TO_INFODICT.items() if k in input_names_nnlvl}\n",
    "\n",
    "        # (1) holder\n",
    "        holder = self.merger([data['holder'] for fld, data in INPUTS.items()], -1)\n",
    "        \n",
    "        # (2) merge data\n",
    "        info = self.merger([data['info'] for fld, data in INPUTS.items()], -2)\n",
    "        \n",
    "        # (3) post-process\n",
    "        for name, layer in self.postprocess.items():\n",
    "            info = layer(info)\n",
    "\n",
    "        return self.output_name_nnlvl, {'holder': holder, 'info': info}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b8fc5b-f735-4dbe-8213-ba4f487f5d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011aa3a7-fca6-4601-bd33-189dd997984d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad2f3dc-898f-4102-8ec6-20c6b1d5a6db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48780ee5-e079-451c-b5ec-086c1bd56800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc4bbd6-9678-4f2d-b321-069a5acd1d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcb32ac-2d53-44ef-bc7d-ce4b30f0c479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2785e4ae-629f-4dde-ac56-62f6112d6ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd235652-0035-45cf-84f6-af88f6ad3a8f",
   "metadata": {},
   "source": [
    "# SubUnit_Layer\n",
    "\n",
    "We will keep updating the SubLayer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fc1761d7-1b8f-49a8-8fd1-3722c6835d9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class SubUnit_Layer(torch.nn.Module):\n",
    "    def __init__(self, nninfo):\n",
    "        super(SubUnit_Layer, self).__init__()\n",
    "        \n",
    "        self.nninfo = nninfo\n",
    "        self.SubUnitName = nninfo['SubUnitName']\n",
    "        \n",
    "        # input_names = nninfo['input_names']; assert len(input_names) == 1\n",
    "        self.input_names = input_names # input_names[0]\n",
    "        self.output_name = nninfo['output_name']\n",
    "        \n",
    "        \n",
    "        self.LayerDict = torch.nn.ModuleDict()\n",
    "        para_list = nninfo['para_list']\n",
    "        for para in para_list:\n",
    "            nn_type = para['nn_type']\n",
    "            if nn_type == 'reducer':\n",
    "                self.layer = Reducer_Layer(**para)\n",
    "            else:\n",
    "                raise ValueError(f'For nn_type within SubUnit_Layer, \\\n",
    "                                 {nn_type} is not available')\n",
    "                \n",
    "\n",
    "        \n",
    "    def forward(self, RECFLD_TO_TENSOR):\n",
    "        \n",
    "        input_tensor = RECFLD_TO_TENSOR[self.input_name]\n",
    "        \n",
    "        # output_tensor = self.layer(self.input_names)\n",
    "        \n",
    "        \n",
    "        assert self.input_fullname == fullname\n",
    "        leng_mask = holder == 0\n",
    "        info = self.reducer(info, leng_mask)\n",
    "        \n",
    "        # (3) post-process\n",
    "        for name, layer in self.postprocess.items():\n",
    "            info = layer(info)\n",
    "            \n",
    "        # fullname = self.fullname\n",
    "        holder = (leng_mask == 0).sum(-1)\n",
    "        return self.output_fullname, holder, info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd62cf97-40da-4bf2-b954-5c523a782df0",
   "metadata": {},
   "source": [
    "# FieldRepr_Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b8d3cb49-1c42-43f0-aa34-bc56e0e6a564",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (223751853.py, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[53], line 17\u001b[0;36m\u001b[0m\n\u001b[0;31m    self.SubLayerDict[output_name] =\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# from ..nn.operator.op import ReduceMeanLayer, ReduceSumLayer, RecuderMaxLayer, ConcatenateLayer\n",
    "# from fieldnn.nn.operator.op import ReduceMeanLayer, ReduceSumLayer, RecuderMaxLayer, ConcatenateLayer\n",
    "\n",
    "class FieldRepr_Layer(torch.nn.Module):\n",
    "    def __init__(self, df_NN):\n",
    "        super(FieldRepr_Layer, self).__init__()\n",
    "        \n",
    "        self.df_NN = df_NN\n",
    "        \n",
    "        self.SubLayerDict = torch.nn.ModuleDict()\n",
    "        \n",
    "        for idx, nninfo in df_NN.items():\n",
    "            output_name = nninfo['output_name']\n",
    "            para = nninfo['para']\n",
    "            self.SubLayerDict[output_name] = \n",
    "        \n",
    "    def forward(self, RECFLD_TO_TENSOR):\n",
    "        \n",
    "        \n",
    "        assert self.input_fullname == fullname\n",
    "        leng_mask = holder == 0\n",
    "        info = self.reducer(info, leng_mask)\n",
    "        \n",
    "        # (3) post-process\n",
    "        for name, layer in self.postprocess.items():\n",
    "            info = layer(info)\n",
    "            \n",
    "        # fullname = self.fullname\n",
    "        holder = (leng_mask == 0).sum(-1)\n",
    "        return self.output_fullname, holder, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a24ae5-6965-40a3-9945-daddd5e984e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aece9d3f-ce60-4ade-9350-4cefd58590c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd73fbfb-91ce-47a4-bbbd-d9b2c2f234bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426920dc-01be-43b0-91f1-dee0562701c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b73a95a-91cc-4617-a55d-8ae6a8853a33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7a520b-6657-4037-9e5e-68ba0030ae90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cbb8c8c-db93-4f86-afbe-d96d07b96f42",
   "metadata": {},
   "source": [
    "# --- Parking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2696843-b46a-47a0-ab61-7a9e35be7507",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rename a tensor from: \n",
      "\tB-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLM, to \n",
      "\tB-P-EC-PN-PNSect-PNSectSent@Sentence-Tk\n"
     ]
    }
   ],
   "source": [
    "def get_prefix_rec_info(fullname):\n",
    "    fld = fullname.split('-')[-1]\n",
    "    if '@' not in fld:\n",
    "        return fullname\n",
    "    else:\n",
    "        singlefld = fld.split('@')[-1]\n",
    "        rec = fld.replace('@' + singlefld, '')\n",
    "        return fullname.replace('@' + singlefld, '')\n",
    "\n",
    "# update the recfld name. \n",
    "tmp = pd.DataFrame([{'old': i, 'new': get_prefix_rec_info(i)} for i in RECFLD_TO_TENSOR])\n",
    "new2old = tmp.groupby('new').apply(lambda x: x['old'].to_list()).to_dict()\n",
    "for new, old_list in new2old.items():\n",
    "    \n",
    "    if len(old_list) == 1 and new != old_list[0]:\n",
    "        # print(f'Rename a tensor from: \\n\\t{old_list[0]}, to \\n\\t{new}')\n",
    "        RECFLD_TO_TENSOR[new] = RECFLD_TO_TENSOR.pop(old_list[0])\n",
    "        # RECFLD_TO_TENSOR[new] = RECFLD_TO_TENSOR.get(old_list[0])\n",
    "    \n",
    "    elif len(old_list) == 1 and new == old_list[0]:\n",
    "        continue\n",
    "    else:\n",
    "        print('TODO: for the merger layer')\n",
    "        print(new, old_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f092760-be9a-4350-8e38-1430f7a0c721",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P@age-AgeNumeDft torch.Size([4, 19, 128])\n",
      "B-P@basicInfo-basicInfoDft torch.Size([4, 2, 128])\n",
      "B-P-EC@BasicInfo-BasicDft torch.Size([4, 25, 2, 128])\n",
      "B-P-EC@DT_min-DTDft torch.Size([4, 25, 7, 128])\n",
      "B-P-EC-A1C@DT-DTDft torch.Size([4, 25, 1, 7, 128])\n",
      "B-P-EC-A1C@V-A1CNumeDft torch.Size([4, 25, 1, 37, 128])\n",
      "B-P-EC-Diag@DT-DTDft torch.Size([4, 25, 22, 7, 128])\n",
      "B-P-EC-Diag@Value-DiagDft torch.Size([4, 25, 22, 3, 128])\n",
      "B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk torch.Size([4, 25, 1, 14, 121, 11, 128])\n"
     ]
    }
   ],
   "source": [
    "for full_recfld, info_dict in RECFLD_TO_TENSOR.items():\n",
    "    print(full_recfld, info_dict['info'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "803ee720-5e33-49e8-85b1-8f27c96e4d07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P@age-AgeNumeDft\n",
      "B-P@age@AgeNumeDft\n",
      "torch.Size([4, 19, 128])\n",
      "torch.Size([4, 128])\n",
      "\n",
      "\n",
      "B-P@basicInfo-basicInfoDft\n",
      "B-P@basicInfo@basicInfoDft\n",
      "torch.Size([4, 2, 128])\n",
      "torch.Size([4, 128])\n",
      "\n",
      "\n",
      "B-P-EC@BasicInfo-BasicDft\n",
      "B-P-EC@BasicInfo@BasicDft\n",
      "torch.Size([4, 25, 2, 128])\n",
      "torch.Size([4, 25, 128])\n",
      "\n",
      "\n",
      "B-P-EC@DT_min-DTDft\n",
      "B-P-EC@DT_min@DTDft\n",
      "torch.Size([4, 25, 7, 128])\n",
      "torch.Size([4, 25, 128])\n",
      "\n",
      "\n",
      "B-P-EC-A1C@DT-DTDft\n",
      "B-P-EC-A1C@DT@DTDft\n",
      "torch.Size([4, 25, 1, 7, 128])\n",
      "torch.Size([4, 25, 1, 128])\n",
      "\n",
      "\n",
      "B-P-EC-A1C@V-A1CNumeDft\n",
      "B-P-EC-A1C@V@A1CNumeDft\n",
      "torch.Size([4, 25, 1, 37, 128])\n",
      "torch.Size([4, 25, 1, 128])\n",
      "\n",
      "\n",
      "B-P-EC-Diag@DT-DTDft\n",
      "B-P-EC-Diag@DT@DTDft\n",
      "torch.Size([4, 25, 22, 7, 128])\n",
      "torch.Size([4, 25, 22, 128])\n",
      "\n",
      "\n",
      "B-P-EC-Diag@Value-DiagDft\n",
      "B-P-EC-Diag@Value@DiagDft\n",
      "torch.Size([4, 25, 22, 3, 128])\n",
      "torch.Size([4, 25, 22, 128])\n",
      "\n",
      "\n",
      "B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk\n",
      "B-P-EC-PN-PNSect-PNSectSent@Sentence@Tk\n",
      "torch.Size([4, 25, 1, 14, 121, 11, 128])\n",
      "torch.Size([4, 25, 1, 14, 121, 128])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RECFLD_TO_REDUCER = {}\n",
    "NEXT_RECFLD_TO_TENSOR = {}\n",
    "\n",
    "for fullname in RECFLD_TO_TENSOR:\n",
    "    if '@' in fullname.split('-')[-1]:\n",
    "        print('\\nSkip this', fullname, '\\n')\n",
    "        continue\n",
    "        \n",
    "    input_fullname = fullname\n",
    "    output_fullname = '-'.join(fullname.split('-')[:-1]) + '@' + fullname.split('-')[- 1]\n",
    "    # fields = input_fullname.split('-')[-1].split('&')\n",
    "    # print(input_fullname)\n",
    "    # print(output_fullname)\n",
    "    # print(fields)\n",
    "    \n",
    "    \n",
    "    # init the reducer\n",
    "    #########\n",
    "    nn_name = 'Max'\n",
    "    nn_para = {}\n",
    "    input_size = embed_size\n",
    "    output_size = embed_size if nn_name != 'concat' else embed_size * 3\n",
    "    postprocess = process\n",
    "    #########\n",
    "    \n",
    "    reducer_layer_para = get_reducer_para(input_fullname, nn_name, nn_para, input_size, output_size, postprocess)\n",
    "    # print(reducer_layer_para)\n",
    "    Reducer = Reducer_Layer(input_fullname, output_fullname, reducer_layer_para)\n",
    "    \n",
    "    RECFLD_TO_REDUCER[fullname] = Reducer\n",
    "    \n",
    "    \n",
    "    info_dict = RECFLD_TO_TENSOR[fullname]\n",
    "    output_fullname, holder_new, info_new = Reducer(input_fullname, \n",
    "                                                    info_dict['holder'], \n",
    "                                                    info_dict['info'])\n",
    "    print(input_fullname)\n",
    "    print(output_fullname)\n",
    "    print(info_dict['info'].shape)\n",
    "    print(info_new.shape)\n",
    "    print('\\n')\n",
    "\n",
    "    NEXT_RECFLD_TO_TENSOR[output_fullname] = {'info': info_new, 'holder': holder_new}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35000abb-272e-4ede-9369-8cded33a8b6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P@age@AgeNumeDft torch.Size([4, 128])\n",
      "B-P-EC-A1C@V@A1CNumeDft torch.Size([4, 25, 1, 128])\n",
      "B-P-EC-Diag@DT@DTDft torch.Size([4, 25, 22, 128])\n",
      "B-P-EC-Diag@Value@DiagDft torch.Size([4, 25, 22, 128])\n",
      "B-P-EC-PN-PNSect-PNSectSent@Sentence@Tk torch.Size([4, 25, 1, 14, 121, 128])\n"
     ]
    }
   ],
   "source": [
    "for recfld, info_dict in NEXT_RECFLD_TO_TENSOR.items():\n",
    "    print(recfld, info_dict['info'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2151e9a6-0df5-41ab-a5e1-3dc6051bdd8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m RECFLD_TO_TENSOR\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(k, \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "for k, v in RECFLD_TO_TENSOR.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e618e59b-9325-4c92-ab9e-0a23faf3de75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_fullname, holder_new, info_new = Reducer(input_fullname, holder, info)\n",
    "print(output_fullname)\n",
    "print(holder_new.shape)\n",
    "print(info_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3461f1f3-2128-4636-8cf5-21ac8d262e58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RECFLD_TO_TENSOR[output_fullname] = info_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11bf253-cd86-4d62-90f1-c186c66672b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fullname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47bab84-4405-4652-a8ea-a8379764910c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_fullname = fullname\n",
    "output_fullname = '-'.join(fullname.split('-')[:-1]) + ':' + fullname.split('-')[- 1]\n",
    "# fields = fullname_input.split('-')[-1].split('&')\n",
    "print(input_fullname)\n",
    "print(output_fullname)\n",
    "# print(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6821c8da-dcf1-4d8e-aed0-68bef88432d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########\n",
    "nn_name = 'Max'\n",
    "nn_para = {}\n",
    "input_size = embed_size\n",
    "output_size = embed_size if nn_name != 'concat' else embed_size * 3\n",
    "postprocess = process\n",
    "#########\n",
    "\n",
    "reducer_layer_para = get_reducer_para(input_fullname, nn_name, nn_para, input_size, output_size, postprocess)\n",
    "print(reducer_layer_para)\n",
    "Reducer = Reducer_Layer(input_fullname, output_fullname, reducer_layer_para)\n",
    "Reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e6c661-b8d1-497e-bc16-04793a5436e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_fullname, holder_new, info_new = Reducer(input_fullname, holder, info)\n",
    "print(output_fullname)\n",
    "print(holder_new.shape)\n",
    "print(info_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb2986d-eb83-4d14-bdb7-cb1c4724069b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_fullname = output_fullname\n",
    "output_fullname = input_fullname\n",
    "holder = holder_new\n",
    "info = info_new\n",
    "\n",
    "\n",
    "###########\n",
    "nn_name = 'TFM'\n",
    "nn_para = {'num_encoder_layers': 6}\n",
    "input_size = embed_size\n",
    "output_size = embed_size\n",
    "embedprocess = process\n",
    "postprocess = process\n",
    "###########\n",
    "learner_layer_para  = get_learner_para(input_fullname, \n",
    "                                       nn_name, nn_para, \n",
    "                                       input_size, output_size, \n",
    "                                       Ignore_PSN_Layers, \n",
    "                                       embedprocess, postprocess\n",
    "                                      )\n",
    "print(fullname)\n",
    "print(learner_layer_para)\n",
    "Learner = Learner_Layer(input_fullname, output_fullname, learner_layer_para)\n",
    "\n",
    "\n",
    "fullname, holder, info = Learner(input_fullname, holder, info)\n",
    "print(info.shape)\n",
    "print(fullname)\n",
    "print(holder.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ee8d01-e92a-42e9-90f9-07507b5939b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e2eb86-d2d4-4f4b-b520-ad6fbf76e9cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
