{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7588aa63-50a8-4f68-b40d-5e65e1783790",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\My Drive\\0-Research-Project\\MedStar\\MS_CODE\\FieldNN\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f03f057-7e2d-4fd4-9066-39c8f70cc115",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "\n",
    "This is the for \n",
    "\n",
    "* module `fieldnn.basicnn.expander` module\n",
    "* module `fieldnn.configfn.expanderfn` module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f1850-8d92-40fd-ba69-6657f63ca703",
   "metadata": {},
   "source": [
    "# Real Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98e6de85-919d-4ffa-b1d6-0f286e9dc6f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/ProcData/TensorFolder/Task2YearXXX\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['A1C@DT-DTDftGrn',\n",
       " 'A1C@V-A1CNumeDftGrn',\n",
       " 'Diag@DT-DTDftGrn',\n",
       " 'Diag@Value-DiagDftGrn',\n",
       " 'EC@BasicInfo-BasicDftGrn',\n",
       " 'EC@DT_min-DTDftGrn',\n",
       " 'P@age-AgeNumeDftGrn',\n",
       " 'P@basicInfo-basicInfoDftGrn',\n",
       " 'PN@DT-DTDftGrn',\n",
       " 'PNSect@SectName-PNSctNmDftGrn',\n",
       " 'PNSectSent@Sentence-Tk@TknzLLMGrn',\n",
       " 'Smoking@DT-DTDftGrn',\n",
       " 'Smoking@V-SmokingDftGrn']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from recfldgrn.datapoint import load_df_data_from_folder\n",
    "from fieldnn.utils.layerfn import traverse, convert_relational_list_to_numpy\n",
    "\n",
    "###################### take this as given\n",
    "batch_PID_order = ['P1', 'P4', 'P5', 'P6']\n",
    "######################\n",
    "\n",
    "TaskTensor_folder = 'data/ProcData/TensorFolder/Task2YearXXX'\n",
    "print(TaskTensor_folder)\n",
    "\n",
    "l = sorted([i for i in os.listdir(TaskTensor_folder) if 'Grn' in i])\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "148b0bee-5e48-47e4-abb7-eef0f9638c26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recfldgrn_list = [\n",
    "                  'A1C@V-A1CNumeDftGrn',\n",
    "                  'Diag@DT-DTDftGrn',\n",
    "                  'Diag@Value-DiagDftGrn',\n",
    "                  'PNSectSent@Sentence-Tk@TknzLLMGrn'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f98dd28e-0fb5-43b2-ae78-5b07f07b814a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/ProcData/TensorFolder/Task2YearXXX\\A1C@V-A1CNumeDftGrn\n",
      "data/ProcData/TensorFolder/Task2YearXXX\\Diag@DT-DTDftGrn\n",
      "data/ProcData/TensorFolder/Task2YearXXX\\Diag@Value-DiagDftGrn\n",
      "data/ProcData/TensorFolder/Task2YearXXX\\PNSectSent@Sentence-Tk@TknzLLMGrn\n",
      "B-P-EC-A1C@V-A1CNumeDftGrn_wgt (4, 25, 1, 37)\n",
      "B-P-EC-Diag@DT-DTDftGrn_idx (4, 25, 22, 7)\n",
      "B-P-EC-Diag@Value-DiagDftGrn_idx (4, 25, 22, 3)\n",
      "B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx (4, 25, 1, 14, 121, 11)\n"
     ]
    }
   ],
   "source": [
    "batch_rfg = {}\n",
    "\n",
    "for recfldgrn in recfldgrn_list:\n",
    "    \n",
    "    # (1) get tensor_folder\n",
    "    tensor_folder = os.path.join(TaskTensor_folder, recfldgrn)\n",
    "    print(tensor_folder)\n",
    "\n",
    "    # (2) get df_Pat and full_recfldgrn\n",
    "    df_Pat = load_df_data_from_folder(tensor_folder).set_index('PID')\n",
    "    full_recfldgrn = df_Pat.columns[0]\n",
    "    suffix = full_recfldgrn.split('_')[-1]\n",
    "    assert recfldgrn in full_recfldgrn\n",
    "\n",
    "    # (3) load batch: TODO: convert this to DataSet and DataLoader\n",
    "    df_batch = df_Pat.loc[batch_PID_order]\n",
    "\n",
    "    # (4) tensor batch as tensor_idx\n",
    "    new_full_recfldgrn = 'B-' + full_recfldgrn\n",
    "    values_list = df_batch[full_recfldgrn].to_list()\n",
    "    suffix = full_recfldgrn.split('_')[-1]\n",
    "    # print(suffix)\n",
    "    # print(new_full_recfldgrn)\n",
    "    D = convert_relational_list_to_numpy(values_list, new_full_recfldgrn, suffix)\n",
    "    tensor_idx = D[new_full_recfldgrn]\n",
    "    \n",
    "    batch_rfg[new_full_recfldgrn] = tensor_idx\n",
    "    \n",
    "for k, v in batch_rfg.items(): print(k, v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecda0376-dbf4-4701-88e4-f372159d4a8e",
   "metadata": {},
   "source": [
    "## Analyze One RecFldGrn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ca8134-54bf-4143-89c2-97d479f590f5",
   "metadata": {},
   "source": [
    "**Understand Holder**\n",
    "\n",
    "\n",
    "Introduction to Holder.\n",
    "\n",
    "You can treat the holder as the position holder.\n",
    "\n",
    "One holder is always with a info (tensor vectors).\n",
    "\n",
    "We can have two types of holder:\n",
    "\n",
    "(a) the grain_idx. **for example: **\n",
    "    \n",
    "```python\n",
    "holder: [[123,   333,  123,  333], [ 56,  24,  23, 0],[ 24,  23, 0]]\n",
    "info:   [[v123, v333, v123, v333], [v56, v24, v23, 0],[v24, v23, 0]]  \n",
    "```\n",
    "\n",
    "(b) the length of chidren for the focal element. **for example: after we process the above tensor to the sentence-level tensor. we will have this:**\n",
    "       \n",
    "```python\n",
    "holder: [4,   3,  2]\n",
    "info:   [s1, s2, s3]  # (here s1 is a sentence-level vector from [v123, v333, v123, v333]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dba031b-a1fc-4439-bbd0-149b944e631a",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Relationships between leng_mask, leng, holder, and info**\n",
    "\n",
    "1. Current Layer:\n",
    "\n",
    "```python\n",
    "leng_mask = holder == 0 # \n",
    "# for leng_mask: if with real value, then False, if with padding, then True\n",
    "# in the real mask, we need to unsqueeze() the last dim. \n",
    "leng = (leng_mask == 0).sum(-1) # in leng_mask: 0 means a real position\n",
    "``` \n",
    "\n",
    "2. Transfer\n",
    "\n",
    "```python # \n",
    "holder = leng # (for next iteration)\n",
    "```\n",
    "\n",
    "\n",
    "3. Next Layer\n",
    "```python\n",
    "leng_mask = holder == 0\n",
    "leng = (leng_mask == 0).sum(-1) # in leng_mask: 0 means a real position\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63e47c3d-c151-43be-a641-ac417599fcdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 25, 22, 3)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "full_recfldgrn = 'B-P-EC-Diag@Value-DiagDftGrn_idx'\n",
    "info_idx = batch_rfg[full_recfldgrn]\n",
    "print(info_idx.shape)\n",
    "holder = torch.LongTensor(info_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d08ac0d5-7d8b-4160-9cb3-c1ccb252aba0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P-EC-Diag@Value-DiagDftGrn_idx <-- full_recfldgrn\n",
      "Diag@Value-DiagDftGrn <---- recfldgrn\n",
      "['B', 'P', 'EC'] <---- recfldgrn\n",
      "Diag <---- rec\n",
      "Value <---- fld\n",
      "DiagDftGrn <---- grn\n",
      "idx <---- suffix\n"
     ]
    }
   ],
   "source": [
    "print(full_recfldgrn, '<-- full_recfldgrn')\n",
    "\n",
    "recfld = [i for i in full_recfldgrn.split('-') if '@' in i][0]\n",
    "rec, fld = recfld.split('@')\n",
    "grn_suffix = [i for i in full_recfldgrn.split('-') if 'Grn' in i][0]\n",
    "grn, suffix = grn_suffix.split('_')\n",
    "prefix_ids = [i for i in full_recfldgrn.split('-') if 'Grn' not in i and '@' not in i]\n",
    "recfldgrn = rec + '@' + fld + '-' + grn\n",
    "\n",
    "print(recfldgrn, '<---- recfldgrn')\n",
    "print(prefix_ids, '<---- recfldgrn')\n",
    "print(rec, '<---- rec')\n",
    "print(fld, '<---- fld')\n",
    "print(grn, '<---- grn')\n",
    "print(suffix, '<---- suffix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8746e2-b284-4678-8296-af91de24c40e",
   "metadata": {},
   "source": [
    "# BasicNN Name\n",
    "\n",
    "Expander try to convert GRN_idx (or GRN_wgt) to embedding vectors.\n",
    "\n",
    "It is from idx to vector.\n",
    "\n",
    "It is a type of order-increase. \n",
    "\n",
    "\n",
    "Here the core include: CateEmbedding, NumeEmbedding, and LLMEmbed. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c46d1e8-572e-4144-9cea-07f7ffa37024",
   "metadata": {},
   "source": [
    "## CateEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efbdd72-00cf-4032-a9fe-f03dbe0d21a4",
   "metadata": {},
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "734f6b6b-7a1e-443e-b5fb-5aa3cab8a7de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class CateEmbeddingLayer(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 vocab_size, \n",
    "                 embedding_size, \n",
    "                 init = 'random', \n",
    "                 freeze = False):\n",
    "        \n",
    "        super(CateEmbeddingLayer, self).__init__()\n",
    "        \n",
    "        # create embedding\n",
    "        if init == 'random':\n",
    "            # c. initial from random initialization\n",
    "            self.embedding = torch.nn.Embedding(vocab_size, embedding_size, padding_idx = 0)\n",
    "        \n",
    "        elif type(init) == np.ndarray:\n",
    "            # a. load from pretrained array. Here init is an array.\n",
    "            weight = torch.FloatTensor(init)\n",
    "            assert weight.shape == (vocab_size, embedding_size)\n",
    "            self.embedding = torch.nn.Embedding.from_pretrained(weight, freeze = freeze)\n",
    "            \n",
    "        elif os.path.isfile(init):\n",
    "            # b. load from the pretrained array file.\n",
    "            weight = torch.FloatTensor(np.load(init))\n",
    "            assert tuple(weight.shape) == (vocab_size, embedding_size)\n",
    "            self.embedding = torch.nn.Embedding.from_pretrained(weight, freeze = freeze)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f'In correct init method \"{init}\"')\n",
    "        \n",
    "    def forward(self, holder):\n",
    "        # info is the grain\n",
    "        info = self.embedding(holder)\n",
    "        return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c037187-afc8-488f-a05b-ea6e63f0bc2c",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f025b352-c680-4634-a62d-8a86fb6bbbf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Main Config\n",
    "### others will change with each recfldgrn\n",
    "\n",
    "#######################\n",
    "embed_size = 512\n",
    "init = 'random'\n",
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95dbdf0c-dca2-42b9-846c-c0b8952c1fec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cateembed_para(embed_size, vocab_tokenizer, init = 'random'):\n",
    "    embed_para =  {'embedding_size': embed_size,\n",
    "                   'init': init, \n",
    "                   'vocab_size': len(vocab_tokenizer)}\n",
    "    return embed_para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e9c31a-8e65-41a1-ba35-9db4d56cf9d4",
   "metadata": {},
   "source": [
    "### Usage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "253476f7-4414-4131-b7bc-113fe054d5fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# (1) full recfldgrn information (we have discussed it already)\n",
    "full_recfldgrn = 'B-P-EC-Diag@Value-DiagDftGrn_idx'\n",
    "\n",
    "recfld = [i for i in full_recfldgrn.split('-') if '@' in i][0]\n",
    "rec, fld = recfld.split('@')\n",
    "grn_suffix = [i for i in full_recfldgrn.split('-') if 'Grn' in i][0]\n",
    "grn, suffix = grn_suffix.split('_')\n",
    "prefix_ids = [i for i in full_recfldgrn.split('-') if 'Grn' not in i and '@' not in i]\n",
    "recfldgrn = rec + '@' + fld + '-' + grn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e78ecc94-1413-4faf-9aea-3f26df9f2647",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801\n"
     ]
    }
   ],
   "source": [
    "# (2) get vocab information, in the `recfldgrn` task, we have already created the FldGrnInfo\n",
    "fldgrn_folder = 'data/ProcData/FldGrnInfo'\n",
    "fullfldgrn_file = os.path.join(fldgrn_folder, rec + '.p')\n",
    "df_FieldGrainInfo = pd.read_pickle(fullfldgrn_file)\n",
    "\n",
    "# (3) Query the v2idx_tokenizer information from the df_FieldGrainInfo\n",
    "# here v2idx could be a vocab dictionary for categorical data, or tokenizer for the texutal data.\n",
    "vocab_tokenizer = df_FieldGrainInfo[df_FieldGrainInfo['recfield2grain'] == recfldgrn].iloc[0]['Vocab']['v2idx']\n",
    "\n",
    "# (4) get the vocab_size for the v2idx_tokenizer. \n",
    "# ps. even tokenizer (from huggingface) can have use len().\n",
    "vocab_size = len(vocab_tokenizer)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7a655e-c2b7-4c7f-818c-d3aa41dfe598",
   "metadata": {},
   "source": [
    "**get configuration**\n",
    "\n",
    "\n",
    "Here we want to get the embedding configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6d5135c-6426-4a69-94ec-00d8e7c15f6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_size': 512, 'init': 'random', 'vocab_size': 801}\n"
     ]
    }
   ],
   "source": [
    "embed_para = get_cateembed_para(embed_size, vocab_tokenizer, init)\n",
    "print(embed_para)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c442a153-d28e-456a-9967-0e77219248b2",
   "metadata": {},
   "source": [
    "**init NN model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5de858f5-2214-4274-858f-a9bd2668ea12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CateEmbeddingLayer(\n",
      "  (embedding): Embedding(801, 512, padding_idx=0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if suffix == 'idx':\n",
    "    NN = CateEmbeddingLayer(**embed_para)\n",
    "    print(NN)\n",
    "else:\n",
    "    raise ValueError(f'suffix is not correct \"{suffix}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709fea05-7bce-4dcf-9211-8ff9a29af647",
   "metadata": {},
   "source": [
    "**prepare input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95855eec-9dc9-4a91-b852-1b686221c026",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 25, 22, 3) <---- info_raw for full_recfldgrn\n",
      "torch.Size([4, 25, 22, 3]) <------ holder shape\n",
      "Empty <------ holder wgt information\n"
     ]
    }
   ],
   "source": [
    "# (1) get the info_raw from batch_rfg\n",
    "info_raw = batch_rfg[full_recfldgrn]\n",
    "print(info_raw.shape, '<---- info_raw for full_recfldgrn' )\n",
    "\n",
    "# (2) get the holder (input_idx) and holder_wgt (for nume embedding only)\n",
    "\n",
    "# here you may wonder what is holder.\n",
    "# You can treat the holder as the position holder.\n",
    "# One holder is always with a info (tensor vectors).\n",
    "\n",
    "# We can have two types of holder:\n",
    "# (a) the grain_idx \n",
    "#     for example: \n",
    "#        holder: [[123,   333,  123,  333], [ 56,  24,  23, 0],[ 24,  23, 0]]\n",
    "#        info:   [[v123, v333, v123, v333], [v56, v24, v23, 0],[v24, v23, 0]]  \n",
    "#\n",
    "# (b) the length of chidren for the focal element.\n",
    "#     for example: after we process the above tensor to the sentence-level tensor.\n",
    "#                  we will have this:\n",
    "#        holder: [4,   3,  2]\n",
    "#        info:   [s1, s2, s3]  (here s1 is a sentence-level vector from [v123, v333, v123, v333]\n",
    "# \n",
    "\n",
    "# depending on the input type, we will create holder, and holder_wgt accordingly.\n",
    "if suffix == 'idx':\n",
    "    holder_wgt = 'Empty'\n",
    "    holder = torch.LongTensor(info_raw)\n",
    "elif suffix == 'wgt':\n",
    "    holder_wgt = torch.FloatTensor(info_raw)\n",
    "    # ATTENTION: here holder_wgt could contain zeros in some valid positions.\n",
    "    holder = torch.ones_like(holder_wgt).cumsum(-1).masked_fill(holder_wgt == 0, 0).long()\n",
    "else:\n",
    "    raise ValueError(f'Invalid suffix \"{suffix}\"')\n",
    "    \n",
    "print(holder.shape, '<------ holder shape')\n",
    "if type(holder_wgt) == str: \n",
    "    print(holder_wgt, '<------ holder wgt information')\n",
    "else:\n",
    "    print(holder_wgt.shape, '<------ holder wgt information')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef61e65-601b-4054-a73a-3768a97c7645",
   "metadata": {},
   "source": [
    "**I-NN-O**\n",
    "\n",
    "Here I-NN-O means `Input - (Neural Network) --> Output`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62bd8ff2-e0ce-479a-ba21-9f8d61346315",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 25, 22, 3]) <----- holder shape\n",
      "torch.Size([4, 25, 22, 3, 512]) <----- info shape\n"
     ]
    }
   ],
   "source": [
    "print(holder.shape, '<----- holder shape')\n",
    "info = NN(holder)\n",
    "print(info.shape, '<----- info shape')\n",
    "\n",
    "if type(holder_wgt) != str:\n",
    "    info = info * holder_wgt.unsqueeze(-1)\n",
    "    print(info.shape, '<----- updated by holder_wgt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c17849d-c27e-4727-9ad7-404799e4e3c0",
   "metadata": {},
   "source": [
    "## NumeEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4a4aad-7350-4c0d-a4f8-5dac8d501834",
   "metadata": {},
   "source": [
    "### Module\n",
    "\n",
    "\n",
    "Actually, `NumeEmbedding` is just the same as the `CateEmbedding`. \n",
    "\n",
    "However, in the future, we can defintely create the new customized embeddings for the numeric rec@fld grains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffe4d991-5fba-4bbe-bfd2-98d7ae5f8196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class NumeEmbeddingLayer(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 vocab_size, \n",
    "                 embedding_size, \n",
    "                 init = 'random', \n",
    "                 freeze = False):\n",
    "        \n",
    "        super(NumeEmbeddingLayer, self).__init__()\n",
    "        \n",
    "        # create embedding\n",
    "        if init == 'random':\n",
    "            # c. initial from random initialization\n",
    "            self.embedding = torch.nn.Embedding(vocab_size, embedding_size, padding_idx = 0)\n",
    "        \n",
    "        elif type(init) == np.ndarray:\n",
    "            # a. load from pretrained array. Here init is an array.\n",
    "            weight = torch.FloatTensor(init)\n",
    "            assert weight.shape == (vocab_size, embedding_size)\n",
    "            self.embedding = torch.nn.Embedding.from_pretrained(weight, freeze = freeze)\n",
    "            \n",
    "        elif os.path.isfile(init):\n",
    "            # b. load from the pretrained array file.\n",
    "            weight = torch.FloatTensor(np.load(init))\n",
    "            assert tuple(weight.shape) == (vocab_size, embedding_size)\n",
    "            self.embedding = torch.nn.Embedding.from_pretrained(weight, freeze = freeze)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f'In correct init method \"{init}\"')\n",
    "        \n",
    "    def forward(self, holder):\n",
    "        # info is the grain\n",
    "        info = self.embedding(holder)\n",
    "        return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fcb5d2-ca55-45e5-bc22-3e14d25de19c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Config\n",
    "\n",
    "Actually, currently, the config function for the NumeEmbedding is exactly the same as the CateEmbedding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b5c5fc3-3c57-4fba-9e73-573aadfb3ef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# same as CateEmbedding\n",
    "\n",
    "def get_numeembed_para(embed_size, vocab_tokenizer, init = 'random'):\n",
    "    embed_para =  {'embedding_size': embed_size,\n",
    "                   'init': init, \n",
    "                   'vocab_size': len(vocab_tokenizer)}\n",
    "    return embed_para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b38e5aa-ffeb-4c8b-84e3-e3f5eb02ef27",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deeaa95-e4de-42f7-bb8a-b73cae8b5e68",
   "metadata": {},
   "source": [
    "**recfldgrn information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15498ebf-7d38-4899-badb-89c6e54c9a29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "# (1) full recfldgrn information\n",
    "full_recfldgrn = 'B-P-EC-A1C@V-A1CNumeDftGrn_wgt'\n",
    "recfld = [i for i in full_recfldgrn.split('-') if '@' in i][0]\n",
    "rec, fld = recfld.split('@')\n",
    "grn_suffix = [i for i in full_recfldgrn.split('-') if 'Grn' in i][0]\n",
    "grn, suffix = grn_suffix.split('_')\n",
    "prefix_ids = [i for i in full_recfldgrn.split('-') if 'Grn' not in i and '@' not in i]\n",
    "recfldgrn = rec + '@' + fld + '-' + grn\n",
    "\n",
    "\n",
    "\n",
    "# (2) get vocab information\n",
    "fldgrn_folder = 'data/ProcData/FldGrnInfo'\n",
    "fullfldgrn_file = os.path.join(fldgrn_folder, rec + '.p')\n",
    "df_FieldGrainInfo = pd.read_pickle(fullfldgrn_file)\n",
    "vocab_tokenizer = df_FieldGrainInfo[df_FieldGrainInfo['recfield2grain'] == recfldgrn].iloc[0]['Vocab']['v2idx']\n",
    "# TODO: also adding padding to v2idx\n",
    "vocab_size = len(vocab_tokenizer)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c6ce27-e1cf-4fcb-9f32-a753bec2c51a",
   "metadata": {},
   "source": [
    "**get configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da9e4d1f-fdfa-4ffb-88c4-7b1ecde4bbd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_size': 512, 'init': 'random', 'vocab_size': 37}\n"
     ]
    }
   ],
   "source": [
    "embed_para = get_numeembed_para(embed_size, vocab_tokenizer, init)\n",
    "print(embed_para)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b146f8-2f1d-4d6a-b5fb-1cc0e1d73aa7",
   "metadata": {},
   "source": [
    "**init NN model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db19885a-45d8-4ef1-8b4c-24cc9e176ddc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumeEmbeddingLayer(\n",
      "  (embedding): Embedding(37, 512, padding_idx=0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if suffix == 'idx':\n",
    "    NN = CateEmbeddingLayer(**embed_para)\n",
    "    print(NN)\n",
    "elif suffix == 'wgt':\n",
    "    NN = NumeEmbeddingLayer(**embed_para)\n",
    "    print(NN)\n",
    "else:\n",
    "    raise ValueError(f'suffix is not correct \"{suffix}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa183c8-1bfc-481c-9e23-6af06107f898",
   "metadata": {},
   "source": [
    "**prepare input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a96719a-f784-413b-bcc6-d72ac0d83f1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 25, 1, 37)\n",
      "torch.Size([4, 25, 1, 37]) <------ holder shape\n",
      "torch.Size([4, 25, 1, 37]) <------ holder wgt information\n"
     ]
    }
   ],
   "source": [
    "# (1) get the info_raw from batch_rfg\n",
    "info_raw = batch_rfg[full_recfldgrn]\n",
    "print(info_raw.shape)\n",
    "\n",
    "# (2) get the holder (input_idx) and holder_wgt (for nume embedding only)\n",
    "if suffix == 'idx':\n",
    "    holder_wgt = 'Empty'\n",
    "    holder = torch.LongTensor(info_raw)\n",
    "elif suffix == 'wgt':\n",
    "    holder_wgt = torch.FloatTensor(info_raw)\n",
    "    # ATTENTION: here holder_wgt could contain zeros in some valid positions.\n",
    "    holder = torch.ones_like(holder_wgt).cumsum(-1).masked_fill(holder_wgt == 0, 0).long()\n",
    "else:\n",
    "    raise ValueError(f'Invalid suffix \"{suffix}\"')\n",
    "    \n",
    "print(holder.shape, '<------ holder shape')\n",
    "if type(holder_wgt) == str: \n",
    "    print(holder_wgt, '<------ holder wgt information')\n",
    "else:\n",
    "    print(holder_wgt.shape, '<------ holder wgt information')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "114bb9a5-8124-4760-bff8-71181aefb12b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  0,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
       "         0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holder[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27aa91a5-d9aa-4288-978a-f74380f3ab20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  0.,  0.,  0., 11.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " holder_wgt[0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a793d750-59c6-4f97-9889-1b957cf54ac1",
   "metadata": {},
   "source": [
    "**I-NN-O**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62a10901-4694-4215-b0de-1fd6ca880c42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 25, 1, 37]) <----- holder shape\n",
      "torch.Size([4, 25, 1, 37, 512]) <----- info shape\n",
      "torch.Size([4, 25, 1, 37, 512]) <----- updated by holder_wgt\n"
     ]
    }
   ],
   "source": [
    "print(holder.shape, '<----- holder shape')\n",
    "info = NN(holder)\n",
    "print(info.shape, '<----- info shape')\n",
    "\n",
    "if type(holder_wgt) != str:\n",
    "    info_wgt = info * holder_wgt.unsqueeze(-1)\n",
    "    print(info_wgt.shape, '<----- updated by holder_wgt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef324f6c-9125-420e-841d-73cb0e1bb149",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  0,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
       "         0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holder[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "389a1db2-aafe-4c12-a402-c91dacca18e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  0.,  0.,  0., 11.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holder_wgt[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1155811-5822-49f5-bb29-3c08066d500c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -0.0326, -0.5205, -0.7393,  0.4972,\n",
       "         1.1058,  0.0822,  0.6718,  1.5901, -0.2112,  0.1481,  1.2041, -0.8224,\n",
       "         0.4747,  0.5145, -0.1339, -2.1765, -0.6981,  1.5316, -0.3123, -0.9307,\n",
       "         0.3096, -0.1674,  0.9595, -2.0493, -0.2045, -1.1049, -1.2157,  1.3847,\n",
       "         1.0433,  0.8592,  1.7395, -0.7385,  0.0000],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info[0, 0, 0][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "378f4c23-9b02-403d-ac97-c68619274366",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -0.3589, -0.5205, -0.7393,  0.4972,\n",
       "         1.1058,  0.0822,  0.6718,  1.5901, -0.2112,  0.1481,  1.2041, -0.8224,\n",
       "         0.4747,  0.5145, -0.1339, -2.1765, -0.6981,  1.5316, -0.3123, -0.9307,\n",
       "         0.3096, -0.1674,  0.9595, -2.0493, -0.2045, -1.1049, -1.2157,  1.3847,\n",
       "         1.0433,  0.8592,  1.7395, -0.7385,  0.0000],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_wgt[0, 0, 0][:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3b98f4-6655-4341-994f-e2b565a96d5c",
   "metadata": {},
   "source": [
    "## LLMEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37b782b-9367-41cd-b83c-3e51a08aa4b7",
   "metadata": {},
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "647216ab-990c-46bd-8cf8-2b8f9c423438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "# from ...utils.layerfn import orderSeq, restoreSeq\n",
    "from fieldnn.utils.layerfn import orderSeq, restoreSeq\n",
    "from transformers import AutoModel\n",
    "\n",
    "\n",
    "class LLMEmbeddingLayer(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 tokenizer, \n",
    "                 embedding_size, \n",
    "                 init, \n",
    "                 freeze = False):\n",
    "        \n",
    "        super(LLMEmbeddingLayer, self).__init__()\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        assert init == tokenizer.name_or_path \n",
    "        \n",
    "        self.LLM = AutoModel.from_pretrained(init)\n",
    "        self.hidden_size = self.LLM.config.hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        self.linear  = torch.nn.Linear(self.hidden_size, self.embedding_size)\n",
    "        self.init_linear_weights()\n",
    "            \n",
    "    def init_linear_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.linear.bias.data.zero_()\n",
    "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "        \n",
    "    def forward(self, holder):\n",
    "        # 1. get leng_mask\n",
    "        leng_mask = holder == 0\n",
    "        \n",
    "        # 2. get ordered holder\n",
    "        ord_holder, ord_leng_mask, r_idx = self.reshape(holder, leng_mask)\n",
    "        \n",
    "        # 3. embedding ordered holder by LLM\n",
    "        # expanding by the HuggingFace Language Model\n",
    "        \n",
    "        # 3.1 we might want to freeze LLM here\n",
    "        output = self.LLM(ord_holder)\n",
    "        # 3.2 adjust the hidden dimension\n",
    "        ord_info_output = output['last_hidden_state']\n",
    "        ord_info_output = self.linear(ord_info_output) # bias might not be zeros.\n",
    "        ord_info_output = ord_info_output.masked_fill(ord_leng_mask.unsqueeze(-1), 0)\n",
    "    \n",
    "        # 4. restore orderded output to original shape\n",
    "        info = self.restore(ord_info_output, leng_mask, r_idx)\n",
    "        \n",
    "        return info\n",
    "    \n",
    "    \n",
    "    def reshape(self, holder, leng_mask):\n",
    "        nbs = np.array(holder.shape[:-1]).prod()\n",
    "        ngrn = holder.shape[-1]\n",
    "        # print(nbs, ngrn, dim)\n",
    "        \n",
    "        tmp_holder = holder.contiguous().view(nbs, ngrn)\n",
    "        # print(tmp_info.shape)\n",
    "\n",
    "        tmp_leng_mask = leng_mask.contiguous().view(nbs, ngrn)\n",
    "        # print(tmp_leng_mask.shape)\n",
    "\n",
    "        tmp_leng = (tmp_leng_mask == 0).sum(-1)\n",
    "        # print(tmp_leng.shape)\n",
    "        \n",
    "        ord_holder,    ord_leng, r_idx = orderSeq(tmp_holder, tmp_leng)\n",
    "        ord_leng_mask, ord_leng, r_idx = orderSeq(tmp_leng_mask, tmp_leng)\n",
    "        return ord_holder, ord_leng_mask, r_idx\n",
    "    \n",
    "    \n",
    "    \n",
    "    def restore(self, ord_info_output, leng_mask, r_idx):\n",
    "        info_new = restoreSeq(ord_info_output, r_idx)\n",
    "        output_size = info_new.shape[-1]\n",
    "        info_output = info_new.view(*list(leng_mask.shape) + [output_size])\n",
    "        return info_output\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4137e457-a469-4434-a5dd-130e1a4e8f0c",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62d17f8e-4bd8-4868-9d44-53a6fa19326c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_llmembed_para(embed_size, tokenizer, init):\n",
    "    embed_para =  {'embedding_size': embed_size,\n",
    "                   'init': init, \n",
    "                   'tokenizer': tokenizer}\n",
    "    return embed_para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a225d743-5e17-4f68-94ea-cf718fb8b352",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcc0ecc-2683-4fda-8984-cf39fcdf2c69",
   "metadata": {},
   "source": [
    "**recfldgrn information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c73c30b5-43bc-436c-b9ca-ccae4b20d630",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P-EC-A1C@V-A1CNumeDftGrn_wgt',\n",
       " 'B-P-EC-Diag@DT-DTDftGrn_idx',\n",
       " 'B-P-EC-Diag@Value-DiagDftGrn_idx',\n",
       " 'B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in batch_rfg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c1793cd-979d-4d4e-8288-b5a07e6f0994",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30522\n"
     ]
    }
   ],
   "source": [
    "# (1) full recfldgrn information\n",
    "full_recfldgrn = 'B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx'\n",
    "recfld = [i for i in full_recfldgrn.split('-') if '@' in i][0]\n",
    "rec, fld = recfld.split('@')\n",
    "grn_suffix = [i for i in full_recfldgrn.split('-') if 'Grn' in i][0]\n",
    "grn, suffix = grn_suffix.split('_')\n",
    "prefix_ids = [i for i in full_recfldgrn.split('-') if 'Grn' not in i and '@' not in i]\n",
    "recfldgrn = rec + '@' + fld + '-' + grn\n",
    "\n",
    "\n",
    "# (2) get vocab information\n",
    "fldgrn_folder = 'data/ProcData/FldGrnInfo'\n",
    "fullfldgrn_file = os.path.join(fldgrn_folder, rec + '.p')\n",
    "df_FieldGrainInfo = pd.read_pickle(fullfldgrn_file)\n",
    "\n",
    "if 'LLM' in full_recfldgrn:\n",
    "    vocab_tokenizer = df_FieldGrainInfo[df_FieldGrainInfo['recfield2grain'] == recfldgrn].iloc[0]['Vocab']['v2idx']\n",
    "    # TODO: also adding padding to v2idx\n",
    "    vocab_size = len(vocab_tokenizer)\n",
    "    print(vocab_size)\n",
    "else:\n",
    "    vocab_tokenizer = df_FieldGrainInfo[df_FieldGrainInfo['recfield2grain'] == recfldgrn].iloc[0]['Vocab']['v2idx']\n",
    "    # TODO: also adding padding to v2idx\n",
    "    vocab_size = len(vocab_tokenizer)\n",
    "    print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592e72d8-ace7-4fb4-af49-bcdfb7485db7",
   "metadata": {},
   "source": [
    "**get configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6b257ae-84cc-4a87-af1f-c932f299ff98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding_size': 512,\n",
       " 'init': 'bert-base-uncased',\n",
       " 'tokenizer': PreTrainedTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = vocab_tokenizer.name_or_path\n",
    "embed_para = get_llmembed_para(embed_size, vocab_tokenizer, init)\n",
    "embed_para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78333f24-d16b-4c24-8597-e4860f5f9160",
   "metadata": {},
   "source": [
    "**init NN model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6fc910ac-d6b7-4908-9ecf-6b7df6b8e9ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "if suffix == 'idx' and 'LLM' not in recfldgrn:\n",
    "    NN = CateEmbeddingLayer(**embed_para)\n",
    "    print(NN)\n",
    "    \n",
    "elif suffix == 'idx' and 'LLM' in recfldgrn:\n",
    "    NN = LLMEmbeddingLayer(**embed_para)\n",
    "    \n",
    "elif suffix == 'wgt':\n",
    "    NN = NumeEmbeddingLayer(**embed_para)\n",
    "    print(NN)\n",
    "else:\n",
    "    raise ValueError(f'suffix is not correct \"{suffix}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688c514a-b73f-4fb2-8539-b91689195d3b",
   "metadata": {},
   "source": [
    "**prepare input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7d728e8-5c8d-4c01-9b34-e80cc56774a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 25, 1, 14, 121, 11)\n",
      "torch.Size([4, 25, 1, 14, 121, 11]) <------ holder shape\n",
      "Empty <------ holder wgt information\n"
     ]
    }
   ],
   "source": [
    "# (1) get the info_raw from batch_rfg\n",
    "info_raw = batch_rfg[full_recfldgrn]\n",
    "print(info_raw.shape)\n",
    "\n",
    "# (2) get the holder (input_idx) and holder_wgt (for nume embedding only)\n",
    "if suffix == 'idx':\n",
    "    holder_wgt = 'Empty'\n",
    "    holder = torch.LongTensor(info_raw)\n",
    "elif suffix == 'wgt':\n",
    "    holder_wgt = torch.FloatTensor(info_raw)\n",
    "    # ATTENTION: here holder_wgt could contain zeros in some valid positions.\n",
    "    holder = torch.ones_like(holder_wgt).cumsum(-1).masked_fill(holder_wgt == 0, 0).long()\n",
    "else:\n",
    "    raise ValueError(f'Invalid suffix \"{suffix}\"')\n",
    "    \n",
    "print(holder.shape, '<------ holder shape')\n",
    "if type(holder_wgt) == str: \n",
    "    print(holder_wgt, '<------ holder wgt information')\n",
    "else:\n",
    "    print(holder_wgt.shape, '<------ holder wgt information')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08a5262-e7e3-4c54-8acb-856324f34666",
   "metadata": {},
   "source": [
    "**I-NN-O**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a456aed7-f7ea-4158-a38f-397938388b1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 25, 1, 14, 121, 11]) <----- holder shape\n",
      "torch.Size([4, 25, 1, 14, 121, 11, 512]) <----- info shape\n"
     ]
    }
   ],
   "source": [
    "print(holder.shape, '<----- holder shape')\n",
    "info = NN(holder)\n",
    "print(info.shape, '<----- info shape')\n",
    "\n",
    "if type(holder_wgt) != str:\n",
    "    info_wgt = info * holder_wgt.unsqueeze(-1)\n",
    "    print(info_wgt.shape, '<----- updated by holder_wgt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10bae60d-2d96-4f71-a326-8ae637d3a805",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 25, 1, 14, 121, 11])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leng_mask = holder == 0\n",
    "leng_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74edaea3-4a46-40c0-995b-9f1a7a0f0fbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 25, 1, 14, 121, 11, 512])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40584876-b4a9-4a9d-b019-c708af7ef283",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  *Basic NN Type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e24762-5519-45f2-a109-7cc23f4f5402",
   "metadata": {},
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0867d2ee-0680-4862-8fc4-64066212f1dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from fieldnn.basicnn.expander.cateembed import CateEmbeddingLayer\n",
    "from fieldnn.basicnn.expander.numeembed import NumeEmbeddingLayer \n",
    "from fieldnn.basicnn.expander.llmembed import LLMEmbeddingLayer\n",
    "\n",
    "# from .cateembed import CateEmbeddingLayer\n",
    "# from .numeembed import NumeEmbeddingLayer \n",
    "# from .llmembed import LLMEmbeddingLayer\n",
    "\n",
    "class Expander_Layer(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_names_nnlvl, output_name_nnlvl, expander_para):\n",
    "        super(Expander_Layer, self).__init__()\n",
    "        \n",
    "        assert len(input_names_nnlvl) == 1\n",
    "        self.input_names_nnlvl = input_names_nnlvl\n",
    "        self.input_name_nnlvl = input_names_nnlvl[0]\n",
    "        \n",
    "        # output_name should be generated from the input_names\n",
    "        self.output_name_nnlvl = output_name_nnlvl\n",
    "        # self.output_name = output_name\n",
    "\n",
    "        assert 'Grn' in self.input_name_nnlvl\n",
    "        assert self.input_name_nnlvl.split('Grn')[0] == self.output_name_nnlvl\n",
    "        \n",
    "        # the input feature dim size and output feature dim size\n",
    "        self.input_size = expander_para['input_size']\n",
    "        self.output_size = expander_para['output_size']\n",
    "        \n",
    "        # Part 1: NN\n",
    "        nn_name, nn_para = expander_para['nn_name'], expander_para['nn_para']\n",
    "        \n",
    "        if nn_name.lower() == 'cateembed':\n",
    "            assert 'idx' in self.input_name_nnlvl and 'LLM' not in self.input_name_nnlvl\n",
    "            self.Embed = CateEmbeddingLayer(**nn_para)\n",
    "        elif nn_name.lower() == 'llmembed':\n",
    "            assert 'idx' in self.input_name_nnlvl and 'LLM' in self.input_name_nnlvl\n",
    "            self.Embed = LLMEmbeddingLayer(**nn_para)\n",
    "        elif nn_name.lower() == 'numeembed':\n",
    "            assert 'wgt' in self.input_name_nnlvl\n",
    "            self.Embed = NumeEmbeddingLayer(**nn_para)\n",
    "        else:\n",
    "            raise ValueError(f'suffix is not correct \"{self.input_name_nnlvl}\"')\n",
    "\n",
    "        self.embed_size = self.output_size\n",
    "        \n",
    "        # Part 2: PostProcess\n",
    "        self.postprocess = torch.nn.ModuleDict()\n",
    "        for method, config in expander_para['postprocess'].items():\n",
    "            if method == 'dropout':\n",
    "                self.postprocess[method] = torch.nn.Dropout(**config)\n",
    "            elif method == 'activator':\n",
    "                activator = config\n",
    "                if activator.lower() == 'relu': \n",
    "                    self.postprocess[method] = torch.nn.ReLU()\n",
    "                elif activator.lower() == 'tanh': \n",
    "                    self.postprocess[method] = torch.nn.Tanh()\n",
    "                elif activator.lower() == 'gelu':\n",
    "                    self.postprocess[method] = torch.nn.GELU()\n",
    "            elif method == 'layernorm':\n",
    "                self.postprocess[method] = torch.nn.LayerNorm(self.embed_size, **config)\n",
    "\n",
    "    def forward(self, input_names_nnlvl, INPUTS_TO_INFODICT):\n",
    "        '''\n",
    "            info_dict\n",
    "            input_names_nnlvl: full name of field, GRN is here\n",
    "            holder: holder # i.e., info_idx\n",
    "            holder_wgt: holder_wgt\n",
    "        '''\n",
    "        input_name_nnlvl = input_names_nnlvl[0]\n",
    "        assert len(input_names_nnlvl) == 1\n",
    "        assert input_name_nnlvl == self.input_name_nnlvl\n",
    "        \n",
    "        info_dict = INPUTS_TO_INFODICT[input_name_nnlvl]\n",
    "        \n",
    "        # 1. holder information\n",
    "        holder = info_dict['holder']\n",
    "        leng_mask = holder == 0\n",
    "        embed = self.Embed(holder)\n",
    "        \n",
    "        # 2. holder_wgt information\n",
    "        holder_wgt = info_dict['holder_wgt']\n",
    "        if type(holder_wgt) != str:\n",
    "            embed = embed * holder_wgt.unsqueeze(-1)\n",
    "        \n",
    "        # 3. post process.\n",
    "        for nn, layer in self.postprocess.items():\n",
    "            embed = layer(embed)\n",
    "        \n",
    "        return self.output_name_nnlvl, {'holder': holder, 'info': embed}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b742218-976a-41d2-ae12-5f28851629bd",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1c10efe-46e7-43cd-a5fa-1ac6d15427bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_expander_para(nn_name, nn_para,\n",
    "                      embed_size, vocab_tokenizer, init, \n",
    "                      postprocess):\n",
    "    \n",
    "    expander_para = {}\n",
    "    \n",
    "    expander_para['nn_type'] = 'expander'\n",
    "    expander_para['nn_name'] = nn_name\n",
    "\n",
    "    # (1) get the parameters\n",
    "\n",
    "    if nn_name.lower() == 'cateembed':\n",
    "        para = get_cateembed_para(embed_size, vocab_tokenizer, init)\n",
    "    elif nn_name.lower() == 'numeembed':\n",
    "        para = get_numeembed_para(embed_size, vocab_tokenizer, init)\n",
    "    elif nn_name.lower() == 'llmembed':\n",
    "        para = get_llmembed_para(embed_size,  vocab_tokenizer, init)\n",
    "    else:\n",
    "        raise ValueError(f'The NN \"{nn_name}\" is not available yet')\n",
    "        \n",
    "    expander_para['nn_para'] = para\n",
    "    \n",
    "    \n",
    "    #(2) Input size, output size\n",
    "    expander_para['input_size'] = None\n",
    "    expander_para['output_size'] = embed_size\n",
    "\n",
    "    # (3) Post Process\n",
    "    expander_para['postprocess'] = postprocess\n",
    "    \n",
    "    return expander_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97df9cc7-1c24-4107-9831-0988a2c19def",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5464ff4a-aa9d-432d-990a-12776c5ba84f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": true,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
