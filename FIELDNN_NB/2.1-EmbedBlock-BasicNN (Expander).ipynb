{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7588aa63-50a8-4f68-b40d-5e65e1783790",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/floydluo/Library/CloudStorage/GoogleDrive-jjluo@terpmail.umd.edu/My Drive/0-Research-Project/MedStar/MS_CODE/FieldNN\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f03f057-7e2d-4fd4-9066-39c8f70cc115",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "\n",
    "This is the for \n",
    "\n",
    "* module `fieldnn.basicnn.expander` module\n",
    "* module `fieldnn.configfn.expanderfn` module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f1850-8d92-40fd-ba69-6657f63ca703",
   "metadata": {},
   "source": [
    "# Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98e6de85-919d-4ffa-b1d6-0f286e9dc6f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "Tensor_folder = 'data/ProcData/FldGrnTensor/'\n",
    "recfldgrn_list = ['P@PatEcInfo-InfoGrn',  'P-EC-PNSect@AllText-TknzGrn']\n",
    "\n",
    "# from the get_grain_fn to get the Elig_Set.\n",
    "Elig_Set = ['P4', 'P5', 'P6', 'P7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "148b0bee-5e48-47e4-abb7-eef0f9638c26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 <---- dataset\n",
      "1 <---- dataset\n"
     ]
    }
   ],
   "source": [
    "from fieldnn.dataset import RFGDataset, my_collate_fn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = RFGDataset(Tensor_folder, recfldgrn_list, Elig_Set, RecRootID = 'PID')\n",
    "print(len(dataset), '<---- dataset')\n",
    "dataloader = DataLoader(dataset, batch_size = 4, shuffle = True, collate_fn = my_collate_fn)\n",
    "print(len(dataloader), '<---- dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f98dd28e-0fb5-43b2-ae78-5b07f07b814a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P@PatEcInfo-InfoGrn_wgt torch.Size([4, 43])\n",
      "B-P@PatEcInfo-InfoGrn_tknidx torch.Size([4, 43])\n",
      "B-P@PatEcInfo-InfoGrn_fldidx torch.Size([4, 43])\n",
      "B-P-EC-PNSect@AllText-TknzGrn_wgt torch.Size([4, 23, 14, 221])\n",
      "B-P-EC-PNSect@AllText-TknzGrn_tknidx torch.Size([4, 23, 14, 221])\n",
      "B-P-EC-PNSect@AllText-TknzGrn_fldidx torch.Size([4, 23, 14, 221])\n"
     ]
    }
   ],
   "source": [
    "for idx, batch in enumerate(dataloader):\n",
    "    # print(f'\\n------ {idx}')\n",
    "    batch_rfg, batch_y = batch\n",
    "    for k, v in batch_rfg.items(): print(k, v.shape)\n",
    "    break\n",
    "    # for k, v in batch_rfg.items(): print(k, v.shape)\n",
    "    # print(batch_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "279e2de0-09be-4bb3-bf06-1456b821a85d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e07185c1-d4aa-4862-87c4-4b8828209558",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# batch_rfg\n",
    "# B - P - EC -PNSect@AllText-TknzGrn_tknidx \n",
    "# [ 4,    87,      15,     283]\n",
    "# batch_rfg['B-P-EC-PNSect@AllText-TknzGrn_tknidx']#[:, 0, 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecda0376-dbf4-4701-88e4-f372159d4a8e",
   "metadata": {},
   "source": [
    "## Analyze One RecFldGrn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ca8134-54bf-4143-89c2-97d479f590f5",
   "metadata": {},
   "source": [
    "**Understand Holder**\n",
    "\n",
    "\n",
    "Introduction to Holder.\n",
    "\n",
    "You can treat the holder as the position holder.\n",
    "\n",
    "One holder is always with a info (tensor vectors).\n",
    "\n",
    "We can have two types of holder:\n",
    "\n",
    "(a) the grain_idx. **for example: **\n",
    "    \n",
    "```python\n",
    "holder: [[123,   333,  123,  333], [ 56,  24,  23, 0],[ 24,  23, 0]]\n",
    "info:   [[v123, v333, v123, v333], [v56, v24, v23, 0],[v24, v23, 0]]  \n",
    "```\n",
    "\n",
    "(b) the length of chidren for the focal element. **for example: after we process the above tensor to the sentence-level tensor. we will have this:**\n",
    "       \n",
    "```python\n",
    "holder: [4,   3,  2]\n",
    "info:   [s1, s2, s3]  # (here s1 is a sentence-level vector from [v123, v333, v123, v333]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dba031b-a1fc-4439-bbd0-149b944e631a",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Relationships between leng_mask, leng, holder, and info**\n",
    "\n",
    "1. Current Layer:\n",
    "\n",
    "```python\n",
    "leng_mask = holder == 0 # \n",
    "# for leng_mask: if with real value, then False, if with padding, then True\n",
    "# in the real mask, we need to unsqueeze() the last dim. \n",
    "leng = (leng_mask == 0).sum(-1) # in leng_mask: 0 means a real position\n",
    "``` \n",
    "\n",
    "2. Transfer\n",
    "\n",
    "```python # \n",
    "holder = leng # (for next iteration)\n",
    "```\n",
    "\n",
    "\n",
    "3. Next Layer\n",
    "```python\n",
    "leng_mask = holder == 0\n",
    "leng = (leng_mask == 0).sum(-1) # in leng_mask: 0 means a real position\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11634702-68cb-4eea-9b90-4b9d06ae9d6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P@PatEcInfo-InfoGrn_wgt',\n",
       " 'B-P@PatEcInfo-InfoGrn_tknidx',\n",
       " 'B-P@PatEcInfo-InfoGrn_fldidx',\n",
       " 'B-P-EC-PNSect@AllText-TknzGrn_wgt',\n",
       " 'B-P-EC-PNSect@AllText-TknzGrn_tknidx',\n",
       " 'B-P-EC-PNSect@AllText-TknzGrn_fldidx']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in batch_rfg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25e37643-15e1-4bfc-90cd-2a36b298f4d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P@PatEcInfo-InfoGrn', 'P-EC-PNSect@AllText-TknzGrn']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recfldgrn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63e47c3d-c151-43be-a641-ac417599fcdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 23, 14, 221])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "recfldgrn = 'P-EC-PNSect@AllText-TknzGrn'\n",
    "full_recfldgrn = f'B-{recfldgrn}' # 'P-EC-PNSect@AllText-TknzGrn'\n",
    "\n",
    "full_recfldgrn_tknidx = f'{full_recfldgrn}_tknidx'\n",
    "info_idx = batch_rfg[full_recfldgrn_tknidx]\n",
    "print(info_idx.shape)\n",
    "holder = info_idx.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d08ac0d5-7d8b-4160-9cb3-c1ccb252aba0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P-EC-PNSect@AllText-TknzGrn <-- full_recfldgrn\n",
      "PNSect@AllText-TknzGrn <---- recfldgrn\n",
      "['B', 'P', 'EC'] <---- prefix_ids\n",
      "PNSect <---- rec\n",
      "AllText <---- fld\n",
      "TknzGrn <---- grn\n"
     ]
    }
   ],
   "source": [
    "print(full_recfldgrn, '<-- full_recfldgrn')\n",
    "\n",
    "recfld = [i for i in full_recfldgrn.split('-') if '@' in i][0]\n",
    "rec, fld = recfld.split('@')\n",
    "grn = [i for i in full_recfldgrn.split('-') if 'Grn' in i][0]\n",
    "prefix_ids = [i for i in full_recfldgrn.split('-') if 'Grn' not in i and '@' not in i]\n",
    "recfldgrn = rec + '@' + fld + '-' + grn\n",
    "\n",
    "print(recfldgrn, '<---- recfldgrn')\n",
    "print(prefix_ids, '<---- prefix_ids')\n",
    "print(rec, '<---- rec')\n",
    "print(fld, '<---- fld')\n",
    "print(grn, '<---- grn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8746e2-b284-4678-8296-af91de24c40e",
   "metadata": {},
   "source": [
    "# BasicNN Name\n",
    "\n",
    "Expander try to convert GRN_idx (or GRN_wgt) to embedding vectors.\n",
    "\n",
    "It is from idx to vector.\n",
    "\n",
    "It is a type of order-increase. \n",
    "\n",
    "\n",
    "Here the core include: CateEmbedding, NumeEmbedding, and LLMEmbed. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c46d1e8-572e-4144-9cea-07f7ffa37024",
   "metadata": {},
   "source": [
    "## CateEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efbdd72-00cf-4032-a9fe-f03dbe0d21a4",
   "metadata": {},
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "734f6b6b-7a1e-443e-b5fb-5aa3cab8a7de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class CateEmbeddingLayer(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 vocab_size, \n",
    "                 embedding_size, \n",
    "                 init = 'random', \n",
    "                 freeze = False):\n",
    "        \n",
    "        super(CateEmbeddingLayer, self).__init__()\n",
    "        \n",
    "        # create embedding\n",
    "        if init == 'random':\n",
    "            # c. initial from random initialization\n",
    "            self.embedding = torch.nn.Embedding(vocab_size, embedding_size, padding_idx = 0)\n",
    "        \n",
    "        elif type(init) == np.ndarray:\n",
    "            # a. load from pretrained array. Here init is an array.\n",
    "            weight = torch.FloatTensor(init)\n",
    "            assert weight.shape == (vocab_size, embedding_size)\n",
    "            self.embedding = torch.nn.Embedding.from_pretrained(weight, freeze = freeze)\n",
    "            \n",
    "        elif os.path.isfile(init):\n",
    "            # b. load from the pretrained array file.\n",
    "            weight = torch.FloatTensor(np.load(init))\n",
    "            assert tuple(weight.shape) == (vocab_size, embedding_size)\n",
    "            self.embedding = torch.nn.Embedding.from_pretrained(weight, freeze = freeze)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f'In correct init method \"{init}\"')\n",
    "        \n",
    "    def forward(self, holder):\n",
    "        # info is the grain\n",
    "        info = self.embedding(holder)\n",
    "        return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c037187-afc8-488f-a05b-ea6e63f0bc2c",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f025b352-c680-4634-a62d-8a86fb6bbbf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Main Config\n",
    "### others will change with each recfldgrn\n",
    "\n",
    "#######################\n",
    "embed_size = 128\n",
    "init = 'random'\n",
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95dbdf0c-dca2-42b9-846c-c0b8952c1fec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cateembed_para(embed_size, vocab_size, init = 'random'):\n",
    "    embed_para =  {'embedding_size': embed_size,\n",
    "                   'init': init, \n",
    "                   'vocab_size': vocab_size}\n",
    "    return embed_para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e9c31a-8e65-41a1-ba35-9db4d56cf9d4",
   "metadata": {},
   "source": [
    "### Usage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b3b28e0-c39d-49d0-aafc-076a26d49035",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 23, 14, 221])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "recfldgrn = 'P-EC-PNSect@AllText-TknzGrn'\n",
    "full_recfldgrn = f'B-{recfldgrn}'\n",
    "\n",
    "full_recfldgrn_tknidx = f'{full_recfldgrn}_tknidx'\n",
    "info_idx = batch_rfg[full_recfldgrn_tknidx]\n",
    "print(info_idx.shape)\n",
    "holder = info_idx.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "253476f7-4414-4131-b7bc-113fe054d5fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P-EC-PNSect@AllText-TknzGrn <-- full_recfldgrn\n",
      "PNSect@AllText-TknzGrn <---- recfldgrn\n",
      "['B', 'P', 'EC'] <---- prefix_ids\n",
      "PNSect <---- rec\n",
      "AllText <---- fld\n",
      "TknzGrn <---- grn\n"
     ]
    }
   ],
   "source": [
    "print(full_recfldgrn, '<-- full_recfldgrn')\n",
    "\n",
    "recfld = [i for i in full_recfldgrn.split('-') if '@' in i][0]\n",
    "rec, fld = recfld.split('@')\n",
    "grn = [i for i in full_recfldgrn.split('-') if 'Grn' in i][0]\n",
    "prefix_ids = [i for i in full_recfldgrn.split('-') if 'Grn' not in i and '@' not in i]\n",
    "recfldgrn = rec + '@' + fld + '-' + grn\n",
    "\n",
    "print(recfldgrn, '<---- recfldgrn')\n",
    "print(prefix_ids, '<---- prefix_ids')\n",
    "print(rec, '<---- rec')\n",
    "print(fld, '<---- fld')\n",
    "print(grn, '<---- grn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59fa80e4-d3ce-4d2d-bfe4-ab8c023819a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/ProcData/FldGrnInfo/P-EC-PNSect@AllText-TknzGrn.p\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RecLevel                                                          PNSect\n",
       "RecLevelID                                                      PNSectID\n",
       "SynFld                                                           AllText\n",
       "GrnName                                                          TknzGrn\n",
       "Rec2FldList_Dict       {'PNSect': ['SectName'], 'PNSectSent': ['Sente...\n",
       "prefix_ids                                                   [PID, ECID]\n",
       "focal_ids                                                     [PNSectID]\n",
       "rec_folder                                       data/ProcData/RecFolder\n",
       "recfldgrn                                         PNSect@AllText-TknzGrn\n",
       "prefix_recfldgrn                             P-EC-PNSect@AllText-TknzGrn\n",
       "grain_tkn_fn_string    def grain_tkn_fn(df_input):\\n    # (0) Set up....\n",
       "EmbedDict              {'tkn': {'embed_type': 'LLMEmbed', 'recfldgrn_...\n",
       "use_wgt                                                            False\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# (2) get vocab information, in the `recfldgrn` task, we have already created the FldGrnInfo\n",
    "fldgrn_folder = 'data/ProcData/FldGrnInfo/'\n",
    "fullfldgrn_file = os.path.join(fldgrn_folder, full_recfldgrn[2:] + '.p')\n",
    "print(fullfldgrn_file)\n",
    "Info = pd.read_pickle(fullfldgrn_file)\n",
    "Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7be4de10-4880-4a2e-82e6-69ca00c0a76a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fld\n"
     ]
    }
   ],
   "source": [
    "for sfx, para in Info['EmbedDict'].items():\n",
    "    if para['embed_type'] == 'CateEmbed':\n",
    "        print(sfx)\n",
    "        sfx, para\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5eeebab-15bb-4355-82cb-0fc7fc8223e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embed_type': 'CateEmbed',\n",
       " 'recfldgrn_sfx': 'PNSect@AllText-TknzGrn_fld',\n",
       " 'vocab_size': 3,\n",
       " 'Vocab': {'idx2v': {0: '_padding', 1: 'Sentence', 2: 'SectName'},\n",
       "  'v2idx': {'_padding': 0, 'Sentence': 1, 'SectName': 2},\n",
       "  'v2freq': {'_padding': 0, 'Sentence': 18002, 'SectName': 2368}},\n",
       " 'tknz': None}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e78ecc94-1413-4faf-9aea-3f26df9f2647",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # (3) Query the v2idx_tokenizer information from the df_FieldGrainInfo\n",
    "# # here v2idx could be a vocab dictionary for categorical data, or tokenizer for the texutal data.\n",
    "# vocab_tokenizer = Info['VocabDict']['tkn']['v2idx']\n",
    "\n",
    "# # (4) get the vocab_size for the v2idx_tokenizer. \n",
    "# # ps. even tokenizer (from huggingface) can have use len().\n",
    "# vocab_size = len(vocab_tokenizer)\n",
    "# print(vocab_size)\n",
    "vocab_size = para['vocab_size']\n",
    "vocab_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7a655e-c2b7-4c7f-818c-d3aa41dfe598",
   "metadata": {},
   "source": [
    "**get configuration**\n",
    "\n",
    "\n",
    "Here we want to get the embedding configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6d5135c-6426-4a69-94ec-00d8e7c15f6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_size': 128, 'init': 'random', 'vocab_size': 3}\n"
     ]
    }
   ],
   "source": [
    "embed_para = get_cateembed_para(embed_size, vocab_size, init)\n",
    "print(embed_para)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c442a153-d28e-456a-9967-0e77219248b2",
   "metadata": {},
   "source": [
    "**init NN model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5de858f5-2214-4274-858f-a9bd2668ea12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CateEmbeddingLayer(\n",
       "  (embedding): Embedding(3, 128, padding_idx=0)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN = CateEmbeddingLayer(**embed_para)\n",
    "NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709fea05-7bce-4dcf-9211-8ff9a29af647",
   "metadata": {},
   "source": [
    "**prepare input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afe0efe0-8a8b-434d-ac00-39f42690ae48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B-P-EC-PNSect@AllText-TknzGrn'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_recfldgrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9159ed47-3212-4951-8ab5-4d7015b8bda0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 23, 14, 221]) <---- info_raw for full_recfldgrn fld: B-P-EC-PNSect@AllText-TknzGrn_fldidx\n"
     ]
    }
   ],
   "source": [
    "# (1) get the info_raw from batch_rfg\n",
    "\n",
    "full_recfldgrn_sfx = full_recfldgrn + f'_{sfx}idx'\n",
    "info_raw = batch_rfg[full_recfldgrn_sfx]\n",
    "print(info_raw.shape, f'<---- info_raw for full_recfldgrn {sfx}: {full_recfldgrn_sfx}' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87104ce2-b6a5-415e-9559-7f59836cc6cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 23, 14, 221]) <---- full_recfldgrn wgt: B-P-EC-PNSect@AllText-TknzGrn_wgt\n"
     ]
    }
   ],
   "source": [
    "full_recfldgrn_wgt = full_recfldgrn + f'_wgt'\n",
    "info_wgt = batch_rfg[full_recfldgrn_wgt]\n",
    "print(info_wgt.shape, f'<---- full_recfldgrn wgt: {full_recfldgrn_wgt}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95855eec-9dc9-4a91-b852-1b686221c026",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 23, 14, 221]) <------ holder shape\n",
      "torch.Size([4, 23, 14, 221]) <------ holder wgt information\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# (2) get the holder (input_idx) and holder_wgt (for nume embedding only)\n",
    "\n",
    "# here you may wonder what is holder.\n",
    "# You can treat the holder as the position holder.\n",
    "# One holder is always with a info (tensor vectors).\n",
    "\n",
    "# We can have two types of holder:\n",
    "# (a) the grain_idx \n",
    "#     for example: \n",
    "#        holder: [[123,   333,  123,  333], [ 56,  24,  23, 0],[ 24,  23, 0]]\n",
    "#        info:   [[v123, v333, v123, v333], [v56, v24, v23, 0],[v24, v23, 0]]  \n",
    "#\n",
    "# (b) the length of chidren for the focal element.\n",
    "#     for example: after we process the above tensor to the sentence-level tensor.\n",
    "#                  we will have this:\n",
    "#        holder: [4,   3,  2]\n",
    "#        info:   [s1, s2, s3]  (here s1 is a sentence-level vector from [v123, v333, v123, v333]\n",
    "# \n",
    "\n",
    "# depending on the input type, we will create holder, and holder_wgt accordingly.\n",
    "\n",
    "holder = info_raw.long()\n",
    "holder_wgt = info_raw.float() # torch.FloatTensor(info_raw)\n",
    "    \n",
    "print(holder.shape, '<------ holder shape')\n",
    "print(holder_wgt.shape, '<------ holder wgt information')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef61e65-601b-4054-a73a-3768a97c7645",
   "metadata": {},
   "source": [
    "**I-NN-O**\n",
    "\n",
    "Here I-NN-O means `Input - (Neural Network) --> Output`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62bd8ff2-e0ce-479a-ba21-9f8d61346315",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 23, 14, 221]) <----- holder shape\n",
      "torch.Size([4, 23, 14, 221, 128]) <----- info shape\n",
      "torch.Size([4, 23, 14, 221, 128]) <----- updated by holder_wgt\n"
     ]
    }
   ],
   "source": [
    "print(holder.shape, '<----- holder shape')\n",
    "info = NN(holder)\n",
    "print(info.shape, '<----- info shape')\n",
    "\n",
    "info = info * holder_wgt.unsqueeze(-1)\n",
    "print(info.shape, '<----- updated by holder_wgt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3b98f4-6655-4341-994f-e2b565a96d5c",
   "metadata": {},
   "source": [
    "## LLMEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37b782b-9367-41cd-b83c-3e51a08aa4b7",
   "metadata": {},
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "647216ab-990c-46bd-8cf8-2b8f9c423438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "# from ...utils.layerfn import orderSeq, restoreSeq\n",
    "from fieldnn.utils.layerfn import orderSeq, restoreSeq\n",
    "from transformers import AutoModel\n",
    "\n",
    "\n",
    "class LLMEmbeddingLayer(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 tokenizer, \n",
    "                 embedding_size, \n",
    "                 init, \n",
    "                 freeze = False):\n",
    "        \n",
    "        super(LLMEmbeddingLayer, self).__init__()\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        assert init == tokenizer.name_or_path \n",
    "        \n",
    "        self.LLM = AutoModel.from_pretrained(init)\n",
    "        self.hidden_size = self.LLM.config.hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        self.linear  = torch.nn.Linear(self.hidden_size, self.embedding_size)\n",
    "        self.init_linear_weights()\n",
    "            \n",
    "    def init_linear_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.linear.bias.data.zero_()\n",
    "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "        \n",
    "    def forward(self, holder):\n",
    "        # 1. get leng_mask\n",
    "        leng_mask = holder == 0\n",
    "        \n",
    "        # 2. get ordered holder\n",
    "        ord_holder, ord_leng_mask, r_idx = self.reshape(holder, leng_mask)\n",
    "        \n",
    "        # 3. embedding ordered holder by LLM\n",
    "        # expanding by the HuggingFace Language Model\n",
    "        \n",
    "        # 3.1 we might want to freeze LLM here\n",
    "        # print(ord_holder.shape, '<--- ord_holder.shape')\n",
    "        output = self.LLM(ord_holder)\n",
    "        # 3.2 adjust the hidden dimension\n",
    "        ord_info_output = output['last_hidden_state']\n",
    "        ord_info_output = self.linear(ord_info_output) # bias might not be zeros.\n",
    "        ord_info_output = ord_info_output.masked_fill(ord_leng_mask.unsqueeze(-1), 0)\n",
    "    \n",
    "        # 4. restore orderded output to original shape\n",
    "        info = self.restore(ord_info_output, leng_mask, r_idx)\n",
    "        \n",
    "        return info\n",
    "    \n",
    "    \n",
    "    def reshape(self, holder, leng_mask):\n",
    "        nbs = np.array(holder.shape[:-1]).prod()\n",
    "        ngrn = holder.shape[-1]\n",
    "        # print(nbs, ngrn, dim)\n",
    "        \n",
    "        tmp_holder = holder.contiguous().view(nbs, ngrn)\n",
    "        # print(tmp_info.shape)\n",
    "\n",
    "        tmp_leng_mask = leng_mask.contiguous().view(nbs, ngrn)\n",
    "        # print(tmp_leng_mask.shape)\n",
    "\n",
    "        tmp_leng = (tmp_leng_mask == 0).sum(-1)\n",
    "        # print(tmp_leng.shape)\n",
    "        \n",
    "        ord_holder,    ord_leng, r_idx = orderSeq(tmp_holder, tmp_leng)\n",
    "        ord_leng_mask, ord_leng, r_idx = orderSeq(tmp_leng_mask, tmp_leng)\n",
    "        return ord_holder, ord_leng_mask, r_idx\n",
    "    \n",
    "    def restore(self, ord_info_output, leng_mask, r_idx):\n",
    "        info_new = restoreSeq(ord_info_output, r_idx)\n",
    "        output_size = info_new.shape[-1]\n",
    "        info_output = info_new.view(*list(leng_mask.shape) + [output_size])\n",
    "        return info_output\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4137e457-a469-4434-a5dd-130e1a4e8f0c",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62d17f8e-4bd8-4868-9d44-53a6fa19326c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_llmembed_para(embed_size, tokenizer, init):\n",
    "    embed_para =  {'embedding_size': embed_size,\n",
    "                   'init': init, \n",
    "                   'tokenizer': tokenizer}\n",
    "    return embed_para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a225d743-5e17-4f68-94ea-cf718fb8b352",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcc0ecc-2683-4fda-8984-cf39fcdf2c69",
   "metadata": {},
   "source": [
    "**recfldgrn information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c73c30b5-43bc-436c-b9ca-ccae4b20d630",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P@PatEcInfo-InfoGrn_wgt',\n",
       " 'B-P@PatEcInfo-InfoGrn_tknidx',\n",
       " 'B-P@PatEcInfo-InfoGrn_fldidx',\n",
       " 'B-P-EC-PNSect@AllText-TknzGrn_wgt',\n",
       " 'B-P-EC-PNSect@AllText-TknzGrn_tknidx',\n",
       " 'B-P-EC-PNSect@AllText-TknzGrn_fldidx']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in batch_rfg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f620c97-458a-4862-bfbf-11dc3d7d0563",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 23, 14, 221])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "recfldgrn = 'P-EC-PNSect@AllText-TknzGrn'\n",
    "full_recfldgrn = f'B-{recfldgrn}'\n",
    "\n",
    "full_recfldgrn_tknidx = f'{full_recfldgrn}_tknidx'\n",
    "info_idx = batch_rfg[full_recfldgrn_tknidx]\n",
    "print(info_idx.shape)\n",
    "holder = info_idx.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ab25bd3-f9a4-4294-b71c-d3d158755393",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P-EC-PNSect@AllText-TknzGrn <-- full_recfldgrn\n",
      "PNSect@AllText-TknzGrn <---- recfldgrn\n",
      "['B', 'P', 'EC'] <---- prefix_ids\n",
      "PNSect <---- rec\n",
      "AllText <---- fld\n",
      "TknzGrn <---- grn\n"
     ]
    }
   ],
   "source": [
    "print(full_recfldgrn, '<-- full_recfldgrn')\n",
    "\n",
    "recfld = [i for i in full_recfldgrn.split('-') if '@' in i][0]\n",
    "rec, fld = recfld.split('@')\n",
    "grn = [i for i in full_recfldgrn.split('-') if 'Grn' in i][0]\n",
    "prefix_ids = [i for i in full_recfldgrn.split('-') if 'Grn' not in i and '@' not in i]\n",
    "recfldgrn = rec + '@' + fld + '-' + grn\n",
    "\n",
    "print(recfldgrn, '<---- recfldgrn')\n",
    "print(prefix_ids, '<---- prefix_ids')\n",
    "print(rec, '<---- rec')\n",
    "print(fld, '<---- fld')\n",
    "print(grn, '<---- grn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88a9f144-4db4-4a11-8671-f6cdf3cb92d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/ProcData/FldGrnInfo/P-EC-PNSect@AllText-TknzGrn.p\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RecLevel                                                          PNSect\n",
       "RecLevelID                                                      PNSectID\n",
       "SynFld                                                           AllText\n",
       "GrnName                                                          TknzGrn\n",
       "Rec2FldList_Dict       {'PNSect': ['SectName'], 'PNSectSent': ['Sente...\n",
       "prefix_ids                                                   [PID, ECID]\n",
       "focal_ids                                                     [PNSectID]\n",
       "rec_folder                                       data/ProcData/RecFolder\n",
       "recfldgrn                                         PNSect@AllText-TknzGrn\n",
       "prefix_recfldgrn                             P-EC-PNSect@AllText-TknzGrn\n",
       "grain_tkn_fn_string    def grain_tkn_fn(df_input):\\n    # (0) Set up....\n",
       "EmbedDict              {'tkn': {'embed_type': 'LLMEmbed', 'recfldgrn_...\n",
       "use_wgt                                                            False\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# (2) get vocab information, in the `recfldgrn` task, we have already created the FldGrnInfo\n",
    "fldgrn_folder = 'data/ProcData/FldGrnInfo/'\n",
    "fullfldgrn_file = os.path.join(fldgrn_folder, full_recfldgrn[2:] + '.p')\n",
    "print(fullfldgrn_file)\n",
    "Info = pd.read_pickle(fullfldgrn_file)\n",
    "Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "164ff7aa-6a6b-4f15-811b-3c836bd5562f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tkn\n"
     ]
    }
   ],
   "source": [
    "for sfx, para in Info['EmbedDict'].items():\n",
    "    if para['embed_type'] == 'LLMEmbed':\n",
    "        print(sfx)\n",
    "        sfx, para\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c1793cd-979d-4d4e-8288-b5a07e6f0994",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = para['vocab_size']\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dfcb0ca4-c7cb-48a6-99d6-7be6977c8ea2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = para['tknz']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592e72d8-ace7-4fb4-af49-bcdfb7485db7",
   "metadata": {},
   "source": [
    "**get configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6b257ae-84cc-4a87-af1f-c932f299ff98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding_size': 128,\n",
       " 'init': 'bert-base-uncased',\n",
       " 'tokenizer': BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = tokenizer.name_or_path\n",
    "embed_para = get_llmembed_para(embed_size, tokenizer, init)\n",
    "embed_para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78333f24-d16b-4c24-8597-e4860f5f9160",
   "metadata": {},
   "source": [
    "**init NN model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6fc910ac-d6b7-4908-9ecf-6b7df6b8e9ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "NN = LLMEmbeddingLayer(**embed_para)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688c514a-b73f-4fb2-8539-b91689195d3b",
   "metadata": {},
   "source": [
    "**prepare input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7d728e8-5c8d-4c01-9b34-e80cc56774a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P-EC-PNSect@AllText-TknzGrn\n",
      "torch.Size([4, 23, 14, 221]) <---- info_raw for full_recfldgrn tkn: B-P-EC-PNSect@AllText-TknzGrn_tknidx\n",
      "torch.Size([4, 23, 14, 221]) <---- full_recfldgrn wgt: B-P-EC-PNSect@AllText-TknzGrn_wgt\n",
      "torch.Size([4, 23, 14, 221]) <------ holder shape\n",
      "torch.Size([4, 23, 14, 221]) <------ holder wgt information\n"
     ]
    }
   ],
   "source": [
    "print(full_recfldgrn)\n",
    "\n",
    "# (1) get the info_raw from batch_rfg\n",
    "full_recfldgrn_sfx = full_recfldgrn + f'_{sfx}idx'\n",
    "info_raw = batch_rfg[full_recfldgrn_sfx]\n",
    "print(info_raw.shape, f'<---- info_raw for full_recfldgrn {sfx}: {full_recfldgrn_sfx}' )\n",
    "\n",
    "full_recfldgrn_wgt = full_recfldgrn + f'_wgt'\n",
    "info_wgt = batch_rfg[full_recfldgrn_wgt]\n",
    "print(info_wgt.shape, f'<---- full_recfldgrn wgt: {full_recfldgrn_wgt}' )\n",
    "\n",
    "\n",
    "holder = info_raw.long()\n",
    "holder_wgt = info_raw.float() # torch.FloatTensor(info_raw)\n",
    "    \n",
    "print(holder.shape, '<------ holder shape')\n",
    "print(holder_wgt.shape, '<------ holder wgt information')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b27580f7-a2e1-4054-a4a6-c9b65109fc46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# holder[0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cea2d2dd-f2fe-4730-afa6-04492c323c46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# holder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08a5262-e7e3-4c54-8acb-856324f34666",
   "metadata": {},
   "source": [
    "**I-NN-O**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a456aed7-f7ea-4158-a38f-397938388b1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 23, 14, 221]) <----- holder shape\n",
      "torch.Size([4, 23, 14, 221, 128]) <----- info shape\n"
     ]
    }
   ],
   "source": [
    "print(holder.shape, '<----- holder shape')\n",
    "info = NN(holder)\n",
    "print(info.shape, '<----- info shape')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40584876-b4a9-4a9d-b019-c708af7ef283",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  *Basic NN Type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e24762-5519-45f2-a109-7cc23f4f5402",
   "metadata": {},
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0867d2ee-0680-4862-8fc4-64066212f1dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# from .cateembed import CateEmbeddingLayer\n",
    "# # from .numeembed import NumeEmbeddingLayer \n",
    "# from .llmembed import LLMEmbeddingLayer\n",
    "\n",
    "class Expander_Layer(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_names_nnlvl, output_name_nnlvl, expander_para):\n",
    "        super(Expander_Layer, self).__init__()\n",
    "        \n",
    "        \n",
    "        # the input feature dim size and output feature dim size\n",
    "        self.input_size = expander_para['input_size']\n",
    "        self.output_size = expander_para['output_size']\n",
    "        \n",
    "        # input information\n",
    "        assert len(input_names_nnlvl) == 1\n",
    "        self.input_names_nnlvl = input_names_nnlvl\n",
    "        self.input_name_nnlvl = input_names_nnlvl[0]\n",
    "        \n",
    "        # input with idx\n",
    "        self.input_names_nnlvl_idx = [i for i in expander_para if self.input_name_nnlvl in i and 'idx' in i]\n",
    "        \n",
    "        # output information\n",
    "        self.output_name_nnlvl = output_name_nnlvl\n",
    "    \n",
    "        # Part 1: NN\n",
    "        self.EmbedDict = torch.nn.ModuleDict()\n",
    "        for input_name_nnlvl_idx in self.input_names_nnlvl_idx:\n",
    "            # for each input_name_nnlvl_idx, we assume we can find them in the INPUTS_TO_INFODICT\n",
    "            assert 'Grn' in input_name_nnlvl_idx\n",
    "            embed_para = expander_para[input_name_nnlvl_idx]\n",
    "            \n",
    "            nn_name, nn_para = embed_para['nn_name'], embed_para['nn_para']\n",
    "\n",
    "            # input_name_nnlvl\n",
    "            if nn_name.lower() == 'cateembed':\n",
    "                Embed = CateEmbeddingLayer(**nn_para)\n",
    "                self.EmbedDict[input_name_nnlvl_idx] = Embed\n",
    "            elif nn_name.lower() == 'llmembed':\n",
    "                Embed = LLMEmbeddingLayer(**nn_para)\n",
    "                self.EmbedDict[input_name_nnlvl_idx] = Embed\n",
    "            # elif nn_name.lower() == 'numeembed':\n",
    "            #     # TODO: in the future\n",
    "            else:\n",
    "                raise ValueError(f'suffix is not correct \"{self.input_name_nnlvl}\"')\n",
    "\n",
    "            self.embed_size = self.output_size\n",
    "            \n",
    "        self.use_wgt = expander_para['use_wgt']\n",
    "        \n",
    "        # Part 2: PostProcess\n",
    "        self.postprocess = torch.nn.ModuleDict()\n",
    "        for method, config in expander_para['postprocess'].items():\n",
    "            if method == 'dropout':\n",
    "                self.postprocess[method] = torch.nn.Dropout(**config)\n",
    "            elif method == 'activator':\n",
    "                activator = config\n",
    "                if activator.lower() == 'relu': \n",
    "                    self.postprocess[method] = torch.nn.ReLU()\n",
    "                elif activator.lower() == 'tanh': \n",
    "                    self.postprocess[method] = torch.nn.Tanh()\n",
    "                elif activator.lower() == 'gelu':\n",
    "                    self.postprocess[method] = torch.nn.GELU()\n",
    "            elif method == 'layernorm':\n",
    "                self.postprocess[method] = torch.nn.LayerNorm(self.embed_size, **config)\n",
    "\n",
    "    def forward(self, input_names_nnlvl, INPUTS_TO_INFODICT):\n",
    "        # names\n",
    "        input_name_nnlvl = input_names_nnlvl[0]\n",
    "        assert len(input_names_nnlvl) == 1\n",
    "        assert input_name_nnlvl == self.input_name_nnlvl\n",
    "    \n",
    "        # get info_dict\n",
    "        info_dict = INPUTS_TO_INFODICT[input_name_nnlvl]\n",
    "        \n",
    "        \n",
    "        for input_name_nnlvl_idx in self.input_names_nnlvl_idx:\n",
    "            assert input_name_nnlvl_idx in info_dict\n",
    "        if self.use_wgt:\n",
    "            assert (input_name_nnlvl + '_wgt') in info_dict\n",
    "\n",
    "        # get embed\n",
    "        embed_list = []\n",
    "        for input_name_nnlvl_idx in self.input_names_nnlvl_idx:\n",
    "            # INPUTS_TO_INFODICT is a part of batch_rfg\n",
    "            holder = info_dict[input_name_nnlvl_idx]\n",
    "            holder = holder.long()\n",
    "            \n",
    "            # print(holder.shape, f'<----- {input_name_nnlvl}')\n",
    "            # leng_mask = holder == 0\n",
    "            embed = self.EmbedDict[input_name_nnlvl_idx](holder)\n",
    "            \n",
    "            if self.use_wgt == True: \n",
    "                holder_wgt = info_dict[input_name_nnlvl + '_wgt']\n",
    "                embed = embed * holder_wgt.unsqueeze(-1)\n",
    "                \n",
    "            # print(embed.shape, input_name_nnlvl)\n",
    "            embed_list.append(embed)\n",
    "            \n",
    "        embed = torch.stack(embed_list, -2).mean(-2)\n",
    "        \n",
    "        for nn, layer in self.postprocess.items():\n",
    "            embed = layer(embed)# masked_fill(leng_mask.unsqueeze(-1))\n",
    "        \n",
    "        return self.output_name_nnlvl, {'holder': holder, 'info': embed}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b742218-976a-41d2-ae12-5f28851629bd",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "354e3235-4d78-42c0-934f-a448a4d927e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_recfldgrn = 'B-P-EC-PNSect@AllText-TknzGrn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "e913167d-ca55-40fe-95e3-377cefed7db9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/ProcData/FldGrnInfo/P-EC-PNSect@AllText-TknzGrn.p\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tkn', 'fld']"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# (2) get vocab information, in the `recfldgrn` task, we have already created the FldGrnInfo\n",
    "fldgrn_folder = 'data/ProcData/FldGrnInfo/'\n",
    "fullfldgrn_file = os.path.join(fldgrn_folder, full_recfldgrn[2:] + '.p')\n",
    "print(fullfldgrn_file)\n",
    "Info = pd.read_pickle(fullfldgrn_file)\n",
    "EmbedDict = Info['EmbedDict']\n",
    "[i for i in EmbedDict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2268e307-626d-47b6-b7db-b9fe1b882e49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Info['use_wgt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b1c10efe-46e7-43cd-a5fa-1ac6d15427bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cateembed_para(embed_size, vocab_size, init = 'random'):\n",
    "    embed_para =  {'embedding_size': embed_size,\n",
    "                   'init': init, \n",
    "                   'vocab_size': vocab_size}\n",
    "    return embed_para\n",
    "\n",
    "\n",
    "def get_llmembed_para(embed_size, tokenizer, init):\n",
    "    embed_para =  {'embedding_size': embed_size,\n",
    "                   'init': init, \n",
    "                   'tokenizer': tokenizer}\n",
    "    return embed_para\n",
    "\n",
    "\n",
    "def get_expander_para(full_recfldgrn, Info, embed_size, postprocess):\n",
    "    \n",
    "    expander_para = {}\n",
    "    #(1) Input size, output size\n",
    "    expander_para['input_size'] = None\n",
    "    expander_para['output_size'] = embed_size\n",
    "    expander_para['nn_type'] = 'expander'\n",
    "    \n",
    "    # (2) Loop Embed Info for each sfx\n",
    "    EmbedDict = Info['EmbedDict']\n",
    "    \n",
    "    for sfx in EmbedDict:\n",
    "        # embed_para = expander_para[input_name_nnlvl]\n",
    "        input_name_nnlvl = full_recfldgrn + '_' + sfx + 'idx'\n",
    "        \n",
    "        EmbedConf = EmbedDict[sfx]\n",
    "        nn_name = EmbedConf['embed_type']\n",
    "        \n",
    "        embed_para = {}\n",
    "        embed_para['nn_name'] = nn_name\n",
    "        \n",
    "        if nn_name.lower() == 'cateembed':\n",
    "            vocab_size = EmbedConf['vocab_size']\n",
    "            init = 'random' # init = EmbedConf['init'] # TODO: to update in the future.\n",
    "            para = get_cateembed_para(embed_size, vocab_size, init)\n",
    "            embed_para['nn_para'] = para\n",
    "        elif nn_name.lower() == 'llmembed':\n",
    "            tokenizer = EmbedConf['tknz']\n",
    "            init = tokenizer.name_or_path\n",
    "            para = get_llmembed_para(embed_size, tokenizer, init)\n",
    "            embed_para['nn_para'] = para\n",
    "        else:\n",
    "            raise ValueError(f'The NN \"{nn_name}\" is not available yet')\n",
    "        \n",
    "        expander_para[input_name_nnlvl] = embed_para\n",
    "    \n",
    "    # (3) Post Process\n",
    "    expander_para['postprocess'] = postprocess\n",
    "    \n",
    "    \n",
    "    # (4) use_wgt\n",
    "    expander_para['use_wgt'] = Info.get('use_wgt', True)\n",
    "    \n",
    "    return expander_para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80561a21-2507-43cf-ba11-a31d66a590d1",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "5c42d8d0-3ec1-43cd-85f7-1e3ca2e26f81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/ProcData/FldGrnInfo/P-EC-PNSect@AllText-TknzGrn.p\n",
      "['tkn', 'fld']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "full_recfldgrn = 'B-P-EC-PNSect@AllText-TknzGrn'\n",
    "# (2) get vocab information, in the `recfldgrn` task, we have already created the FldGrnInfo\n",
    "fldgrn_folder = 'data/ProcData/FldGrnInfo/'\n",
    "fullfldgrn_file = os.path.join(fldgrn_folder, full_recfldgrn[2:] + '.p')\n",
    "print(fullfldgrn_file)\n",
    "Info = pd.read_pickle(fullfldgrn_file)\n",
    "EmbedDict = Info['EmbedDict']\n",
    "print([sfx for sfx in EmbedDict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5be2fa85-a04f-4ee7-a6d0-ab22633596e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B-P-EC-PNSect@AllText-TknzGrn'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_recfldgrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "5468c44a-2e9c-4dd9-b34b-9f6549553c87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P-EC-PNSect@AllText-TknzGrn']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_names_nnlvl = [full_recfldgrn]\n",
    "input_names_nnlvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "28ba4cb3-1e3e-4608-bdca-f674d5b122ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B-P-EC-PNSect@AllText-Tknz'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_name_nnlvl = full_recfldgrn.replace('Grn', '')\n",
    "output_name_nnlvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "97df9cc7-1c24-4107-9831-0988a2c19def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_size': None,\n",
       " 'output_size': 128,\n",
       " 'nn_type': 'expander',\n",
       " 'B-P-EC-PNSect@AllText-TknzGrn_tknidx': {'nn_name': 'LLMEmbed',\n",
       "  'nn_para': {'embedding_size': 128,\n",
       "   'init': 'bert-base-uncased',\n",
       "   'tokenizer': BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)}},\n",
       " 'B-P-EC-PNSect@AllText-TknzGrn_fldidx': {'nn_name': 'CateEmbed',\n",
       "  'nn_para': {'embedding_size': 128, 'init': 'random', 'vocab_size': 3}},\n",
       " 'postprocess': {},\n",
       " 'use_wgt': False}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_size = 128\n",
    "postprocess = {}\n",
    "\n",
    "expander_para = get_expander_para(full_recfldgrn, Info, embed_size, postprocess)\n",
    "expander_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "5bf48431-0388-4b47-a45d-188a8c3a5512",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P-EC-PNSect@AllText-TknzGrn']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_names_nnlvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "5464ff4a-aa9d-432d-990a-12776c5ba84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "NN = Expander_Layer(input_names_nnlvl, output_name_nnlvl, expander_para)\n",
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "7e59a77f-5973-4269-9ec2-430a5c56e64e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# batch_rfg\n",
    "\n",
    "INPUTS_TO_INFODICT = {}\n",
    "INPUTS_TO_INFODICT[full_recfldgrn] = {k: v for k, v in batch_rfg.items() if full_recfldgrn in k}\n",
    "# INPUTS_TO_INFODICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "4401e28b-13dc-4881-94ff-01fb0fda71a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# INPUTS_TO_INFODICT = {k:{'holder': v} for k, v in batch_rfg.items() if full_recfldgrn in k and 'idx' in k}\n",
    "# INPUTS_TO_INFODICT[f'{full_recfldgrn}_wgt'] = {'holder_wgt': batch_rfg[f'{full_recfldgrn}_wgt']}\n",
    "# [i for i in INPUTS_TO_INFODICT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "1f8c22f6-b19a-4f9b-b09a-25666b21e771",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = NN(input_names_nnlvl, INPUTS_TO_INFODICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "cfe2909f-9cde-4b25-9c8c-d3bd7c08c271",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name_nnlvl, info_dict = output\n",
    "# holder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "afd316a5-f528-4fac-a29b-eac4c9078f3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B-P-EC-PNSect@AllText-Tknz'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_name_nnlvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "7cf0d2b5-e681-4bb0-b16d-35f98fc59890",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 23, 14, 221])\n"
     ]
    }
   ],
   "source": [
    "holder = info_dict['holder']\n",
    "print(holder.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "30d02f7c-d373-4ec1-9cab-9e8f12e0606b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 23, 14, 221, 128])\n"
     ]
    }
   ],
   "source": [
    "embed = info_dict['info']\n",
    "print(embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "58d06b97-5e3f-40f2-b10e-ad0132664164",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P@PatEcInfo-InfoGrn_wgt',\n",
       " 'B-P@PatEcInfo-InfoGrn_tknidx',\n",
       " 'B-P@PatEcInfo-InfoGrn_fldidx',\n",
       " 'B-P-EC-PNSect@AllText-TknzGrn_wgt',\n",
       " 'B-P-EC-PNSect@AllText-TknzGrn_tknidx',\n",
       " 'B-P-EC-PNSect@AllText-TknzGrn_fldidx']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in batch_rfg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "7c58612d-951c-4ed2-b631-6b6e26e23b79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# batch_rfg['B-P-EC-PNSect@AllText-TknzGrn_tknidx'][:, 0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "7b3a3a73-6b4a-4991-9e28-c9e9a0b4598a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2139,  0.1847, -0.2423, -0.4179,  0.4112,  0.2471,  0.7898,  0.5596,\n",
       "          0.7678,  0.5092,  0.6823,  1.0100,  0.5633,  0.1970,  1.0344,  0.4116,\n",
       "          0.5255,  0.7157,  0.6562,  0.2446,  0.9512,  0.6135,  0.2989,  0.5979,\n",
       "          0.5434,  0.4153,  0.1040,  0.8499,  0.6465,  0.2747,  0.6040,  0.1042,\n",
       "          0.7627,  0.4801,  0.8360,  0.9201,  0.0298,  0.4416,  0.9291,  0.3996,\n",
       "         -0.0069,  0.6184,  0.7762,  0.9895,  0.8839,  0.7529,  0.4055, -0.1771,\n",
       "          0.2863,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0087,  0.4548,  0.6258,  0.0492, -0.0226,  0.6148,  1.0336,  1.3390,\n",
       "          0.7690,  0.6765,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0249,  0.1765,  0.4172, -0.1846,  0.6268,  0.8371,  0.5797,  1.4409,\n",
       "          0.7353,  0.3360, -0.1087,  0.5146,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0087,  0.4548,  0.6258,  0.0492, -0.0226,  0.6148,  1.0336,  1.3390,\n",
       "          0.7690,  0.6765,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed[:, 0, 0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "1436d063-100c-4e81-9d74-de5e9964a4c2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0],\n",
       "        [2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0],\n",
       "        [2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0],\n",
       "        [2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holder[:, 0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec78cc64-9829-4d03-b88e-8a9a9df665f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d852d08-371b-486b-963d-6f6f1a64fe08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb9d58f-3060-43b7-b907-d108f3a28296",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
