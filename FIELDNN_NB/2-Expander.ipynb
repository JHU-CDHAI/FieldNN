{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7588aa63-50a8-4f68-b40d-5e65e1783790",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/floydluo/Library/CloudStorage/GoogleDrive-jjluo@terpmail.umd.edu/.shortcut-targets-by-id/1qNzMmGHCg5Xa63Vw3aKbZdMXvkfT2CgC/MedStar/MS_CODE/FieldNN\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47a2660-824c-41fd-81e5-58a2207cbc74",
   "metadata": {},
   "source": [
    "# Simulate Data\n",
    "\n",
    "\n",
    "Given a field name, and first 2 dimensional numbes, simulate tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c7d713-7310-40cb-86f3-358ecf3274bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from fieldnn.utils.simulate import get_next_info, get_simulated_tensor_from_fldname\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f1850-8d92-40fd-ba69-6657f63ca703",
   "metadata": {},
   "source": [
    "# Real Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70729ebd-a267-4acc-96e6-ef0ea85eb354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_full_recfldgrn(full_recfldgrn):\n",
    "    # suffix = full_recfldgrn.split('_')[-1]\n",
    "    recfld = [i for i in full_recfldgrn.split('-') if '@' in i][0]\n",
    "    rec, fld = recfld.split('@')\n",
    "    grn_suffix = [i for i in full_recfldgrn.split('-') if 'Grn' in i][0]\n",
    "    grn, suffix = grn_suffix.split('_')\n",
    "    prefix_ids = [i for i in full_recfldgrn.split('-') if 'Grn' not in i and '@' not in i]\n",
    "    return prefix_ids, rec, fld, grn, suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98e6de85-919d-4ffa-b1d6-0f286e9dc6f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/ProcData/TensorFolder/Task2YearXXX\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['A1C@DT-DTDftGrn',\n",
       " 'A1C@V-A1CNumeDftGrn',\n",
       " 'Diag@DT-DTDftGrn',\n",
       " 'Diag@Value-DiagDftGrn',\n",
       " 'EC@BasicInfo-BasicDftGrn',\n",
       " 'EC@DT_min-DTDftGrn',\n",
       " 'P@age-AgeNumeDftGrn',\n",
       " 'P@basicInfo-basicInfoDftGrn',\n",
       " 'PN@DT-DTDftGrn',\n",
       " 'PNSect@SectName-PNSctNmDftGrn',\n",
       " 'PNSectSent@Sentence-Tk@TknzLLMGrn',\n",
       " 'Smoking@DT-DTDftGrn',\n",
       " 'Smoking@V-SmokingDftGrn']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from recfldgrn.datapoint import load_df_data_from_folder\n",
    "from fieldnn.utils.layerfn import traverse, convert_relational_list_to_numpy\n",
    "\n",
    "###################### take this as given\n",
    "batch_PID_order = ['P1', 'P4', 'P5', 'P6']\n",
    "######################\n",
    "\n",
    "TaskTensor_folder = 'data/ProcData/TensorFolder/Task2YearXXX'\n",
    "print(TaskTensor_folder)\n",
    "\n",
    "l = sorted([i for i in os.listdir(TaskTensor_folder) if 'Grn' in i])\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "148b0bee-5e48-47e4-abb7-eef0f9638c26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recfldgrn_list = [\n",
    "                  'A1C@V-A1CNumeDftGrn',\n",
    "                  'Diag@DT-DTDftGrn',\n",
    "                  'Diag@Value-DiagDftGrn',\n",
    "                  'PNSectSent@Sentence-Tk@TknzLLMGrn'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f98dd28e-0fb5-43b2-ae78-5b07f07b814a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P-EC-A1C@V-A1CNumeDftGrn_wgt (4, 25, 1, 37)\n",
      "B-P-EC-Diag@DT-DTDftGrn_idx (4, 25, 22, 7)\n",
      "B-P-EC-Diag@Value-DiagDftGrn_idx (4, 25, 22, 3)\n",
      "B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx (4, 25, 1, 14, 121, 11)\n"
     ]
    }
   ],
   "source": [
    "batch_rfg = {}\n",
    "\n",
    "for recfldgrn in recfldgrn_list:\n",
    "    \n",
    "    # (1) get tensor_folder\n",
    "    tensor_folder = os.path.join(TaskTensor_folder, recfldgrn)\n",
    "\n",
    "    # (2) get df_Pat and full_recfldgrn\n",
    "    df_Pat = load_df_data_from_folder(tensor_folder).set_index('PID')\n",
    "    full_recfldgrn = df_Pat.columns[0]\n",
    "    suffix = full_recfldgrn.split('_')[-1]\n",
    "    assert recfldgrn in full_recfldgrn\n",
    "\n",
    "    # (3) load batch: TODO: convert this to DataSet and DataLoader\n",
    "    df_batch = df_Pat.loc[batch_PID_order]\n",
    "\n",
    "    # (4) tensor batch as tensor_idx\n",
    "    new_full_recfldgrn = 'B-' + full_recfldgrn\n",
    "    values_list = df_batch[full_recfldgrn].to_list()\n",
    "    suffix = full_recfldgrn.split('_')[-1]\n",
    "    # print(suffix)\n",
    "    # print(new_full_recfldgrn)\n",
    "    D = convert_relational_list_to_numpy(values_list, new_full_recfldgrn, suffix)\n",
    "    tensor_idx = D[new_full_recfldgrn]\n",
    "    \n",
    "    batch_rfg[new_full_recfldgrn] = tensor_idx\n",
    "    \n",
    "for k, v in batch_rfg.items(): print(k, v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8746e2-b284-4678-8296-af91de24c40e",
   "metadata": {},
   "source": [
    "# Expander Core\n",
    "\n",
    "Expander try to convert GRN_idx (or GRN_wgt) to embedding vectors.\n",
    "\n",
    "It is from idx to vector.\n",
    "\n",
    "It is a type of order-increase. \n",
    "\n",
    "\n",
    "Here the core include: CateEmbedding, NumeEmbedding, and LLMEmbed. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c46d1e8-572e-4144-9cea-07f7ffa37024",
   "metadata": {},
   "source": [
    "## CateEmbedding (Expander)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efbdd72-00cf-4032-a9fe-f03dbe0d21a4",
   "metadata": {},
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "734f6b6b-7a1e-443e-b5fb-5aa3cab8a7de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fieldlm.nn.embedding\n",
    "from fieldnn.nn.embedding.catembedding import CatEmbeddingLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c037187-afc8-488f-a05b-ea6e63f0bc2c",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f025b352-c680-4634-a62d-8a86fb6bbbf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "embed_size = 512\n",
    "init = 'random'\n",
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95dbdf0c-dca2-42b9-846c-c0b8952c1fec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fieldnn.configfn.expanderfn import get_recfldgrn_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e9c31a-8e65-41a1-ba35-9db4d56cf9d4",
   "metadata": {},
   "source": [
    "### Usage "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be93e9b-9f71-47eb-9dc8-5d82be10c86c",
   "metadata": {},
   "source": [
    "#### recfldgrn information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "253476f7-4414-4131-b7bc-113fe054d5fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# (1) full recfldgrn information\n",
    "full_recfldgrn = 'B-P-EC-Diag@Value-DiagDftGrn_idx'\n",
    "\n",
    "prefix_ids, rec, fld, grn, suffix = parse_full_recfldgrn(full_recfldgrn)\n",
    "recfldgrn = rec + '@' + fld + '-' + grn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e78ecc94-1413-4faf-9aea-3f26df9f2647",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801\n"
     ]
    }
   ],
   "source": [
    "# (2) get vocab information\n",
    "fldgrn_folder = 'data/ProcData/FldGrnInfo'\n",
    "fullfldgrn_file = os.path.join(fldgrn_folder, rec + '.p')\n",
    "df_FieldGrainInfo = pd.read_pickle(fullfldgrn_file)\n",
    "v2idx = df_FieldGrainInfo[df_FieldGrainInfo['recfield2grain'] == recfldgrn].iloc[0]['Vocab']['v2idx']\n",
    "# TODO: also adding padding to v2idx\n",
    "vocab_size = len(v2idx)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7a655e-c2b7-4c7f-818c-d3aa41dfe598",
   "metadata": {},
   "source": [
    "#### get configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6d5135c-6426-4a69-94ec-00d8e7c15f6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_size': 512, 'init': 'random', 'vocab_size': 801}\n"
     ]
    }
   ],
   "source": [
    "embed_para = get_recfldgrn_embedding(recfldgrn, embed_size, vocab_size, init)\n",
    "print(embed_para)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c442a153-d28e-456a-9967-0e77219248b2",
   "metadata": {},
   "source": [
    "#### init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5de858f5-2214-4274-858f-a9bd2668ea12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatEmbeddingLayer(\n",
      "  (embedding): Embedding(801, 512, padding_idx=0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if suffix == 'idx':\n",
    "    NN = CatEmbeddingLayer(**embed_para)\n",
    "    print(NN)\n",
    "else:\n",
    "    raise ValueError(f'suffix is not correct \"{suffix}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709fea05-7bce-4dcf-9211-8ff9a29af647",
   "metadata": {},
   "source": [
    "#### prepare input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95855eec-9dc9-4a91-b852-1b686221c026",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 25, 22, 3)\n",
      "torch.Size([4, 25, 22, 3]) <------ holder shape\n",
      "Empty <------ holder wgt information\n"
     ]
    }
   ],
   "source": [
    "# (1) get the info_raw from batch_rfg\n",
    "info_raw = batch_rfg[full_recfldgrn]\n",
    "print(info_raw.shape)\n",
    "\n",
    "# (2) get the holder (input_idx) and holder_wgt (for nume embedding only)\n",
    "if suffix == 'idx':\n",
    "    holder_wgt = 'Empty'\n",
    "    holder = torch.LongTensor(info_raw)\n",
    "elif suffix == 'wgt':\n",
    "    holder_wgt = torch.FloatTensor(info_raw)\n",
    "    # ATTENTION: here holder_wgt could contain zeros in some valid positions.\n",
    "    holder = torch.ones_like(holder_wgt).cumsum(-1).masked_fill(holder_wgt == 0, 0).long()\n",
    "else:\n",
    "    raise ValueError(f'Invalid suffix \"{suffix}\"')\n",
    "    \n",
    "print(holder.shape, '<------ holder shape')\n",
    "if type(holder_wgt) == str: \n",
    "    print(holder_wgt, '<------ holder wgt information')\n",
    "else:\n",
    "    print(holder_wgt.shape, '<------ holder wgt information')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef61e65-601b-4054-a73a-3768a97c7645",
   "metadata": {},
   "source": [
    "#### I-NN-O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62bd8ff2-e0ce-479a-ba21-9f8d61346315",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 25, 22, 3]) <----- holder shape\n",
      "torch.Size([4, 25, 22, 3, 512]) <----- info shape\n"
     ]
    }
   ],
   "source": [
    "print(holder.shape, '<----- holder shape')\n",
    "info = NN(holder)\n",
    "print(info.shape, '<----- info shape')\n",
    "\n",
    "if type(holder_wgt) != str:\n",
    "    info = info * holder_wgt.unsqueeze(-1)\n",
    "    print(info.shape, '<----- updated by holder_wgt')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c17849d-c27e-4727-9ad7-404799e4e3c0",
   "metadata": {},
   "source": [
    "## NumeEmbedding (Expander)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4a4aad-7350-4c0d-a4f8-5dac8d501834",
   "metadata": {},
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdd85106-516a-4c1c-a724-b969bfbeb522",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fieldlm.nn.embedding\n",
    "from fieldnn.nn.embedding.numembedding import NumEmbeddingLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fcb5d2-ca55-45e5-bc22-3e14d25de19c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b5c5fc3-3c57-4fba-9e73-573aadfb3ef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# same as CateEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b38e5aa-ffeb-4c8b-84e3-e3f5eb02ef27",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deeaa95-e4de-42f7-bb8a-b73cae8b5e68",
   "metadata": {},
   "source": [
    "#### recfldgrn information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15498ebf-7d38-4899-badb-89c6e54c9a29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "# (1) full recfldgrn information\n",
    "full_recfldgrn = 'B-P-EC-A1C@V-A1CNumeDftGrn_wgt'\n",
    "prefix_ids, rec, fld, grn, suffix = parse_full_recfldgrn(full_recfldgrn)\n",
    "recfldgrn = rec + '@' + fld + '-' + grn\n",
    "\n",
    "\n",
    "# (2) get vocab information\n",
    "fldgrn_folder = 'data/ProcData/FldGrnInfo'\n",
    "fullfldgrn_file = os.path.join(fldgrn_folder, rec + '.p')\n",
    "df_FieldGrainInfo = pd.read_pickle(fullfldgrn_file)\n",
    "v2idx = df_FieldGrainInfo[df_FieldGrainInfo['recfield2grain'] == recfldgrn].iloc[0]['Vocab']['v2idx']\n",
    "# TODO: also adding padding to v2idx\n",
    "vocab_size = len(v2idx)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c6ce27-e1cf-4fcb-9f32-a753bec2c51a",
   "metadata": {},
   "source": [
    "#### get configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da9e4d1f-fdfa-4ffb-88c4-7b1ecde4bbd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_size': 512, 'init': 'random', 'vocab_size': 37}\n"
     ]
    }
   ],
   "source": [
    "embed_para = get_recfldgrn_embedding(recfldgrn, embed_size, vocab_size, init)\n",
    "print(embed_para)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b146f8-2f1d-4d6a-b5fb-1cc0e1d73aa7",
   "metadata": {},
   "source": [
    "#### init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db19885a-45d8-4ef1-8b4c-24cc9e176ddc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumEmbeddingLayer(\n",
      "  (embedding): Embedding(37, 512, padding_idx=0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if suffix == 'idx':\n",
    "    NN = CatEmbeddingLayer(**embed_para)\n",
    "    print(NN)\n",
    "elif suffix == 'wgt':\n",
    "    NN = NumEmbeddingLayer(**embed_para)\n",
    "    print(NN)\n",
    "else:\n",
    "    raise ValueError(f'suffix is not correct \"{suffix}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa183c8-1bfc-481c-9e23-6af06107f898",
   "metadata": {},
   "source": [
    "#### prepare input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a96719a-f784-413b-bcc6-d72ac0d83f1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 25, 1, 37)\n",
      "torch.Size([4, 25, 1, 37]) <------ holder shape\n",
      "torch.Size([4, 25, 1, 37]) <------ holder wgt information\n"
     ]
    }
   ],
   "source": [
    "# (1) get the info_raw from batch_rfg\n",
    "info_raw = batch_rfg[full_recfldgrn]\n",
    "print(info_raw.shape)\n",
    "\n",
    "# (2) get the holder (input_idx) and holder_wgt (for nume embedding only)\n",
    "if suffix == 'idx':\n",
    "    holder_wgt = 'Empty'\n",
    "    holder = torch.LongTensor(info_raw)\n",
    "elif suffix == 'wgt':\n",
    "    holder_wgt = torch.FloatTensor(info_raw)\n",
    "    # ATTENTION: here holder_wgt could contain zeros in some valid positions.\n",
    "    holder = torch.ones_like(holder_wgt).cumsum(-1).masked_fill(holder_wgt == 0, 0).long()\n",
    "else:\n",
    "    raise ValueError(f'Invalid suffix \"{suffix}\"')\n",
    "    \n",
    "print(holder.shape, '<------ holder shape')\n",
    "if type(holder_wgt) == str: \n",
    "    print(holder_wgt, '<------ holder wgt information')\n",
    "else:\n",
    "    print(holder_wgt.shape, '<------ holder wgt information')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "114bb9a5-8124-4760-bff8-71181aefb12b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  0,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
       "         0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holder[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27aa91a5-d9aa-4288-978a-f74380f3ab20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  0.,  0.,  0., 11.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " holder_wgt[0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a793d750-59c6-4f97-9889-1b957cf54ac1",
   "metadata": {},
   "source": [
    "#### I-NN-O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62a10901-4694-4215-b0de-1fd6ca880c42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 25, 1, 37]) <----- holder shape\n",
      "torch.Size([4, 25, 1, 37, 512]) <----- info shape\n",
      "torch.Size([4, 25, 1, 37, 512]) <----- updated by holder_wgt\n"
     ]
    }
   ],
   "source": [
    "print(holder.shape, '<----- holder shape')\n",
    "info = NN(holder)\n",
    "print(info.shape, '<----- info shape')\n",
    "\n",
    "if type(holder_wgt) != str:\n",
    "    info_wgt = info * holder_wgt.unsqueeze(-1)\n",
    "    print(info_wgt.shape, '<----- updated by holder_wgt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef324f6c-9125-420e-841d-73cb0e1bb149",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  0,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
       "         0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holder[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "389a1db2-aafe-4c12-a402-c91dacca18e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  0.,  0.,  0., 11.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holder_wgt[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1155811-5822-49f5-bb29-3c08066d500c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.5861e-01,\n",
       "         4.7504e-03,  1.1655e+00,  1.3496e+00,  6.4677e-01,  1.4808e+00,\n",
       "        -2.9573e-02, -1.4731e-01,  1.4732e+00, -1.1074e+00, -6.9226e-01,\n",
       "        -4.9935e-01,  1.0634e-02, -3.9562e-01,  1.8149e-01, -2.6261e-01,\n",
       "        -2.3695e-01,  8.5560e-01,  8.4573e-01,  2.3062e-01, -1.1472e+00,\n",
       "        -4.4550e-01,  2.0862e-01, -2.4059e-01, -5.5087e-01,  9.9755e-01,\n",
       "        -5.6289e-01, -1.4958e-01, -3.5014e-01,  1.3507e-03,  1.8485e+00,\n",
       "        -4.0584e-01,  0.0000e+00], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info[0, 0, 0][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "378f4c23-9b02-403d-ac97-c68619274366",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.9447e+00,\n",
       "         4.7504e-03,  1.1655e+00,  1.3496e+00,  6.4677e-01,  1.4808e+00,\n",
       "        -2.9573e-02, -1.4731e-01,  1.4732e+00, -1.1074e+00, -6.9226e-01,\n",
       "        -4.9935e-01,  1.0634e-02, -3.9562e-01,  1.8149e-01, -2.6261e-01,\n",
       "        -2.3695e-01,  8.5560e-01,  8.4573e-01,  2.3062e-01, -1.1472e+00,\n",
       "        -4.4550e-01,  2.0862e-01, -2.4059e-01, -5.5087e-01,  9.9755e-01,\n",
       "        -5.6289e-01, -1.4958e-01, -3.5014e-01,  1.3507e-03,  1.8485e+00,\n",
       "        -4.0584e-01,  0.0000e+00], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_wgt[0, 0, 0][:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3b98f4-6655-4341-994f-e2b565a96d5c",
   "metadata": {},
   "source": [
    "## LLMEmbedding (Expander)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37b782b-9367-41cd-b83c-3e51a08aa4b7",
   "metadata": {},
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d78309c-4779-4b37-a8e4-cb96f505678c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fieldlm.nn.embedding\n",
    "from fieldnn.nn.embedding.llmembedding import LLMEmbeddingLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4137e457-a469-4434-a5dd-130e1a4e8f0c",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62d17f8e-4bd8-4868-9d44-53a6fa19326c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fieldnn.configfn.expanderfn import get_recfldgrn_llmembedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a225d743-5e17-4f68-94ea-cf718fb8b352",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcc0ecc-2683-4fda-8984-cf39fcdf2c69",
   "metadata": {},
   "source": [
    "#### recfldgrn information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c73c30b5-43bc-436c-b9ca-ccae4b20d630",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P-EC-A1C@V-A1CNumeDftGrn_wgt',\n",
       " 'B-P-EC-Diag@DT-DTDftGrn_idx',\n",
       " 'B-P-EC-Diag@Value-DiagDftGrn_idx',\n",
       " 'B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in batch_rfg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c1793cd-979d-4d4e-8288-b5a07e6f0994",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30522\n"
     ]
    }
   ],
   "source": [
    "# (1) full recfldgrn information\n",
    "full_recfldgrn = 'B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx'\n",
    "prefix_ids, rec, fld, grn, suffix = parse_full_recfldgrn(full_recfldgrn)\n",
    "recfldgrn = rec + '@' + fld + '-' + grn\n",
    "\n",
    "\n",
    "# (2) get vocab information\n",
    "fldgrn_folder = 'data/ProcData/FldGrnInfo'\n",
    "fullfldgrn_file = os.path.join(fldgrn_folder, rec + '.p')\n",
    "df_FieldGrainInfo = pd.read_pickle(fullfldgrn_file)\n",
    "\n",
    "if 'LLM' in full_recfldgrn:\n",
    "    tokenizer = df_FieldGrainInfo[df_FieldGrainInfo['recfield2grain'] == recfldgrn].iloc[0]['Vocab']['v2idx']\n",
    "    # TODO: also adding padding to v2idx\n",
    "    vocab_size = len(tokenizer)\n",
    "    print(vocab_size)\n",
    "else:\n",
    "    v2idx = df_FieldGrainInfo[df_FieldGrainInfo['recfield2grain'] == recfldgrn].iloc[0]['Vocab']['v2idx']\n",
    "    # TODO: also adding padding to v2idx\n",
    "    vocab_size = len(v2idx)\n",
    "    print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592e72d8-ace7-4fb4-af49-bcdfb7485db7",
   "metadata": {},
   "source": [
    "#### get configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6b257ae-84cc-4a87-af1f-c932f299ff98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding_size': 512,\n",
       " 'init': 'bert-base-uncased',\n",
       " 'tokenizer': BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = tokenizer.name_or_path\n",
    "embed_para = get_recfldgrn_llmembedding(recfldgrn, embed_size, tokenizer, init)\n",
    "embed_para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78333f24-d16b-4c24-8597-e4860f5f9160",
   "metadata": {},
   "source": [
    "#### init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6fc910ac-d6b7-4908-9ecf-6b7df6b8e9ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "if suffix == 'idx' and 'LLM' not in recfldgrn:\n",
    "    NN = CatEmbeddingLayer(**embed_para)\n",
    "    print(NN)\n",
    "    \n",
    "elif suffix == 'idx' and 'LLM' in recfldgrn:\n",
    "    NN = LLMEmbeddingLayer(**embed_para)\n",
    "    \n",
    "elif suffix == 'wgt':\n",
    "    NN = NumEmbeddingLayer(**embed_para)\n",
    "    print(NN)\n",
    "else:\n",
    "    raise ValueError(f'suffix is not correct \"{suffix}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688c514a-b73f-4fb2-8539-b91689195d3b",
   "metadata": {},
   "source": [
    "#### prepare input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7d728e8-5c8d-4c01-9b34-e80cc56774a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 25, 1, 14, 121, 11)\n",
      "torch.Size([4, 25, 1, 14, 121, 11]) <------ holder shape\n",
      "Empty <------ holder wgt information\n"
     ]
    }
   ],
   "source": [
    "# (1) get the info_raw from batch_rfg\n",
    "info_raw = batch_rfg[full_recfldgrn]\n",
    "print(info_raw.shape)\n",
    "\n",
    "# (2) get the holder (input_idx) and holder_wgt (for nume embedding only)\n",
    "if suffix == 'idx':\n",
    "    holder_wgt = 'Empty'\n",
    "    holder = torch.LongTensor(info_raw)\n",
    "elif suffix == 'wgt':\n",
    "    holder_wgt = torch.FloatTensor(info_raw)\n",
    "    # ATTENTION: here holder_wgt could contain zeros in some valid positions.\n",
    "    holder = torch.ones_like(holder_wgt).cumsum(-1).masked_fill(holder_wgt == 0, 0).long()\n",
    "else:\n",
    "    raise ValueError(f'Invalid suffix \"{suffix}\"')\n",
    "    \n",
    "print(holder.shape, '<------ holder shape')\n",
    "if type(holder_wgt) == str: \n",
    "    print(holder_wgt, '<------ holder wgt information')\n",
    "else:\n",
    "    print(holder_wgt.shape, '<------ holder wgt information')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08a5262-e7e3-4c54-8acb-856324f34666",
   "metadata": {},
   "source": [
    "#### I-NN-O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a456aed7-f7ea-4158-a38f-397938388b1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 25, 1, 14, 121, 11]) <----- holder shape\n",
      "torch.Size([4, 25, 1, 14, 121, 11, 512]) <----- info shape\n"
     ]
    }
   ],
   "source": [
    "print(holder.shape, '<----- holder shape')\n",
    "info = NN(holder)\n",
    "print(info.shape, '<----- info shape')\n",
    "\n",
    "if type(holder_wgt) != str:\n",
    "    info_wgt = info * holder_wgt.unsqueeze(-1)\n",
    "    print(info_wgt.shape, '<----- updated by holder_wgt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10bae60d-2d96-4f71-a326-8ae637d3a805",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 25, 1, 14, 121, 11])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leng_mask = holder == 0\n",
    "leng_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74edaea3-4a46-40c0-995b-9f1a7a0f0fbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 25, 1, 14, 121, 11, 512])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "074a63ac-d75e-491d-8364-421d87396fbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: do the tensor validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40584876-b4a9-4a9d-b019-c708af7ef283",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Expander"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e24762-5519-45f2-a109-7cc23f4f5402",
   "metadata": {},
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7daec16-08b9-414d-aff3-9a4c4df7523a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fieldnn.sublayer.expander import Expander_Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b742218-976a-41d2-ae12-5f28851629bd",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e8df782-6d90-4f39-8c65-841daf57f1c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fieldnn.configfn.expanderfn import get_expander_para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba90527f-bf4d-4dcd-8fdd-fbd8b153c941",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc781d1-edf2-4cd2-8c5e-6f68a4a49417",
   "metadata": {},
   "source": [
    "### recfldgrn information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e7209fc-8b11-4168-b5f6-5fc10d39a3d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P-EC-A1C@V-A1CNumeDftGrn_wgt',\n",
       " 'B-P-EC-Diag@Value-DiagDftGrn_idx',\n",
       " 'B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_recfldgrn_list = ['B-P-EC-A1C@V-A1CNumeDftGrn_wgt',\n",
    "                       'B-P-EC-Diag@Value-DiagDftGrn_idx',\n",
    "                       'B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx']\n",
    "\n",
    "full_recfldgrn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "38ab0267-fc18-4cba-abd0-d6d997604dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03ac61bb-81c0-4e7c-b0e8-504ed8a2c911",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-P-EC-A1C@V-A1CNumeDftGrn_wgt': {'vocabsize_tokenizer': 37,\n",
       "  'init': 'random'},\n",
       " 'B-P-EC-Diag@Value-DiagDftGrn_idx': {'vocabsize_tokenizer': 801,\n",
       "  'init': 'random'},\n",
       " 'B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx': {'vocabsize_tokenizer': BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}),\n",
       "  'init': 'bert-base-uncased'}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_rfg_to_basicInfo = {}\n",
    "\n",
    "for full_recfldgrn in full_recfldgrn_list:\n",
    "    # (1) full recfldgrn information\n",
    "    prefix_ids, rec, fld, grn, suffix = parse_full_recfldgrn(full_recfldgrn)\n",
    "    recfldgrn = rec + '@' + fld + '-' + grn\n",
    "\n",
    "\n",
    "    # (2) get vocab information\n",
    "    fldgrn_folder = 'data/ProcData/FldGrnInfo'\n",
    "    fullfldgrn_file = os.path.join(fldgrn_folder, rec + '.p')\n",
    "    df_FieldGrainInfo = pd.read_pickle(fullfldgrn_file)\n",
    "\n",
    "    if 'LLM' in full_recfldgrn:\n",
    "        tokenizer = df_FieldGrainInfo[df_FieldGrainInfo['recfield2grain'] == recfldgrn].iloc[0]['Vocab']['v2idx']\n",
    "        # TODO: also adding padding to v2idx\n",
    "        # vocab_size = len(tokenizer)\n",
    "        # print(vocab_size)\n",
    "        vocab_tokenizer = tokenizer\n",
    "        init = tokenizer.name_or_path\n",
    "    else:\n",
    "        v2idx = df_FieldGrainInfo[df_FieldGrainInfo['recfield2grain'] == recfldgrn].iloc[0]['Vocab']['v2idx']\n",
    "        # TODO: also adding padding to v2idx\n",
    "        vocab_size = len(v2idx)\n",
    "        # print(vocab_size)\n",
    "        vocab_tokenizer = vocab_size\n",
    "        init = 'random'\n",
    "    \n",
    "    d = {'vocabsize_tokenizer': vocab_tokenizer, 'init': init}\n",
    "    full_rfg_to_basicInfo[full_recfldgrn] = d\n",
    "    \n",
    "    \n",
    "full_rfg_to_basicInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5301c3cc-6857-4455-866f-8595fe5943b9",
   "metadata": {},
   "source": [
    "### get configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8bb1325b-3292-4426-900f-b4a48b90d600",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############################\n",
    "embed_size = 128\n",
    "process = {'activator': 'gelu',\n",
    "           'dropout': {'p': 0.5, 'inplace': False},\n",
    "           'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "############################\n",
    "\n",
    "\n",
    "full_rfg_to_ExpanderConfig = {}\n",
    "\n",
    "for full_recfldgrn in full_recfldgrn_list:\n",
    "    \n",
    "    # determine the nn_name\n",
    "    if '_idx' in full_recfldgrn and 'LLM' not in full_recfldgrn:\n",
    "        nn_name = 'CatEmbeddingLayer'\n",
    "\n",
    "    elif '_idx' in full_recfldgrn and 'LLM' in full_recfldgrn:\n",
    "        nn_name = 'LLMEmbeddingLayer'\n",
    "\n",
    "    elif '_wgt' in full_recfldgrn:\n",
    "        nn_name = 'NumEmbeddingLayer'\n",
    "    else:\n",
    "        raise ValueError(f'full_recfldgrn is not correct \"{full_recfldgrn}\"')\n",
    "    \n",
    "    d = full_rfg_to_basicInfo[full_recfldgrn]\n",
    "    \n",
    "    # print('\\n----')\n",
    "    # print(full_recfldgrn)\n",
    "    # print(d)\n",
    "    # print(nn_name)\n",
    "    expander_para = get_expander_para(full_recfldgrn, \n",
    "                                       nn_name,\n",
    "                                       embed_size, d['vocabsize_tokenizer'], d['init'], \n",
    "                                       process)\n",
    "    # print(expander_para)\n",
    "    output_recfld = full_recfldgrn.split('Grn')[0]\n",
    "    \n",
    "    full_rfg_to_ExpanderConfig[full_recfldgrn] = {\n",
    "        'full_recfldgrn': full_recfldgrn,\n",
    "        'output_recfld': output_recfld,\n",
    "        'expander_para': expander_para,\n",
    "    }\n",
    "    \n",
    "    \n",
    "# full_rfg_to_ExpanderConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "174af83a-c3a7-4a8a-96f4-3364c667faf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# full_rfg_to_ExpanderConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b702251-c619-4201-8ba6-62db69650d40",
   "metadata": {},
   "source": [
    "### init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "36f4afd9-5ee5-4353-8ebc-afee95667596",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P-EC-A1C@V-A1CNumeDftGrn_wgt\n",
      "Expander_Layer(\n",
      "  (Embed): NumEmbeddingLayer(\n",
      "    (embedding): Embedding(37, 128, padding_idx=0)\n",
      "  )\n",
      "  (postprocess): ModuleDict(\n",
      "    (activator): GELU(approximate='none')\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "B-P-EC-Diag@Value-DiagDftGrn_idx\n",
      "Expander_Layer(\n",
      "  (Embed): CatEmbeddingLayer(\n",
      "    (embedding): Embedding(801, 128, padding_idx=0)\n",
      "  )\n",
      "  (postprocess): ModuleDict(\n",
      "    (activator): GELU(approximate='none')\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx\n",
      "Expander_Layer(\n",
      "  (Embed): LLMEmbeddingLayer(\n",
      "    (LLM): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-11): 12 x BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (linear): Linear(in_features=768, out_features=128, bias=True)\n",
      "  )\n",
      "  (postprocess): ModuleDict(\n",
      "    (activator): GELU(approximate='none')\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "FullRFG_2_Embed = {}\n",
    "\n",
    "for full_recfldgrn, ExpanderConfig in full_rfg_to_ExpanderConfig.items():\n",
    "    \n",
    "    FullRFG_2_Embed[full_recfldgrn] = Expander_Layer(**ExpanderConfig)\n",
    "    print(full_recfldgrn)\n",
    "    print(FullRFG_2_Embed[full_recfldgrn])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162d3e1c-4932-4a13-9c90-170d4968191c",
   "metadata": {},
   "source": [
    "### prepare input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d248c563-25ca-4585-b4c8-f002cd384901",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P-EC-A1C@V-A1CNumeDftGrn_wgt\n",
      "(4, 25, 1, 37)\n",
      "torch.Size([4, 25, 1, 37]) <------ holder shape\n",
      "torch.Size([4, 25, 1, 37]) <------ holder wgt information\n",
      "\n",
      "\n",
      "B-P-EC-Diag@Value-DiagDftGrn_idx\n",
      "(4, 25, 22, 3)\n",
      "torch.Size([4, 25, 22, 3]) <------ holder shape\n",
      "Empty <------ holder wgt information\n",
      "\n",
      "\n",
      "B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx\n",
      "(4, 25, 1, 14, 121, 11)\n",
      "torch.Size([4, 25, 1, 14, 121, 11]) <------ holder shape\n",
      "Empty <------ holder wgt information\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for full_recfldgrn in full_recfldgrn_list:\n",
    "    # (1) get the info_raw from batch_rfg\n",
    "    info_raw = batch_rfg[full_recfldgrn]\n",
    "    print(full_recfldgrn)\n",
    "    print(info_raw.shape)\n",
    "\n",
    "    # (2) get the holder (input_idx) and holder_wgt (for nume embedding only)\n",
    "    if '_idx' in full_recfldgrn:\n",
    "        holder_wgt = 'Empty'\n",
    "        holder = torch.LongTensor(info_raw)\n",
    "    elif '_wgt' in full_recfldgrn:\n",
    "        holder_wgt = torch.FloatTensor(info_raw)\n",
    "        # ATTENTION: here holder_wgt could contain zeros in some valid positions.\n",
    "        holder = torch.ones_like(holder_wgt).cumsum(-1).masked_fill(holder_wgt == 0, 0).long()\n",
    "    else:\n",
    "        raise ValueError(f'Invalid suffix \"{suffix}\"')\n",
    "\n",
    "    print(holder.shape, '<------ holder shape')\n",
    "    if type(holder_wgt) == str: \n",
    "        print(holder_wgt, '<------ holder wgt information')\n",
    "    else:\n",
    "        print(holder_wgt.shape, '<------ holder wgt information')\n",
    "\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522e9dfa-cbf1-4e25-9ddc-61b612daa1f0",
   "metadata": {},
   "source": [
    "### I-NN-O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a588c5a0-a497-481b-a03f-035dd170df72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: B-P-EC-A1C@V-A1CNumeDftGrn_wgt\n",
      "(4, 25, 1, 37)\n",
      "torch.Size([4, 25, 1, 37]) <------ holder shape\n",
      "torch.Size([4, 25, 1, 37]) <------ holder wgt information\n",
      "torch.Size([4, 25, 1, 37]) <----- holder shape\n",
      "Output: B-P-EC-A1C@V-A1CNumeDft\n",
      "torch.Size([4, 25, 1, 37, 128]) <----- info shape\n",
      "\n",
      "\n",
      "Input: B-P-EC-Diag@Value-DiagDftGrn_idx\n",
      "(4, 25, 22, 3)\n",
      "torch.Size([4, 25, 22, 3]) <------ holder shape\n",
      "Empty <------ holder wgt information\n",
      "torch.Size([4, 25, 22, 3]) <----- holder shape\n",
      "Output: B-P-EC-Diag@Value-DiagDft\n",
      "torch.Size([4, 25, 22, 3, 128]) <----- info shape\n",
      "\n",
      "\n",
      "Input: B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx\n",
      "(4, 25, 1, 14, 121, 11)\n",
      "torch.Size([4, 25, 1, 14, 121, 11]) <------ holder shape\n",
      "Empty <------ holder wgt information\n",
      "torch.Size([4, 25, 1, 14, 121, 11]) <----- holder shape\n",
      "Output: B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLM\n",
      "torch.Size([4, 25, 1, 14, 121, 11, 128]) <----- info shape\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for full_recfldgrn in full_recfldgrn_list:\n",
    "    # (1) get the info_raw from batch_rfg\n",
    "    info_raw = batch_rfg[full_recfldgrn]\n",
    "    print('Input:',full_recfldgrn)\n",
    "    print(info_raw.shape)\n",
    "\n",
    "    # (2) get the holder (input_idx) and holder_wgt (for nume embedding only)\n",
    "    if '_idx' in full_recfldgrn:\n",
    "        holder_wgt = 'Empty'\n",
    "        holder = torch.LongTensor(info_raw)\n",
    "    elif '_wgt' in full_recfldgrn:\n",
    "        holder_wgt = torch.FloatTensor(info_raw)\n",
    "        # ATTENTION: here holder_wgt could contain zeros in some valid positions.\n",
    "        holder = torch.ones_like(holder_wgt).cumsum(-1).masked_fill(holder_wgt == 0, 0).long()\n",
    "    else:\n",
    "        raise ValueError(f'Invalid suffix \"{suffix}\"')\n",
    "\n",
    "    print(holder.shape, '<------ holder shape')\n",
    "    if type(holder_wgt) == str:  \n",
    "        print(holder_wgt, '<------ holder wgt information')\n",
    "    else:\n",
    "        print(holder_wgt.shape, '<------ holder wgt information')\n",
    "        \n",
    "        \n",
    "    NN = FullRFG_2_Embed[full_recfldgrn] \n",
    "    print(holder.shape, '<----- holder shape')\n",
    "    output_recfld, holder, info = NN(full_recfldgrn, holder, holder_wgt)\n",
    "    print('Output:', output_recfld)\n",
    "    print(info.shape, '<----- info shape')\n",
    "\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43de639a-2932-4ef1-8f6a-dbea429f3af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb0acc7-9ea7-421e-b620-0eb3659f0528",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
