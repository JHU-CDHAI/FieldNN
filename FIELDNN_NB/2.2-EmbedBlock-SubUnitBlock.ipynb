{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7588aa63-50a8-4f68-b40d-5e65e1783790",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/floydluo/Library/CloudStorage/OneDrive-JohnsHopkins/000Projects/0000-Infrastructure/0000-RecFld/FieldNN\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f1850-8d92-40fd-ba69-6657f63ca703",
   "metadata": {},
   "source": [
    "# Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98e6de85-919d-4ffa-b1d6-0f286e9dc6f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 <---- dataset\n",
      "1 <---- dataset\n",
      "B-P-InfoGrn_wgt torch.Size([4, 43])\n",
      "B-P-InfoGrn_tknidx torch.Size([4, 43])\n",
      "B-P-InfoGrn_fldidx torch.Size([4, 43])\n",
      "B-P-EC-PNSect-TknzGrn_wgt torch.Size([4, 23, 14, 221])\n",
      "B-P-EC-PNSect-TknzGrn_tknidx torch.Size([4, 23, 14, 221])\n",
      "B-P-EC-PNSect-TknzGrn_fldidx torch.Size([4, 23, 14, 221])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from fieldnn.dataset import RFGDataset, my_collate_fn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "Tensor_folder = 'data/ProcData/FldGrnTensor/'\n",
    "recfldgrn_list = ['P-InfoGrn',  'P-EC-PNSect-TknzGrn']\n",
    "\n",
    "# from the get_grain_fn to get the Elig_Set.\n",
    "Elig_Set = ['P4', 'P5', 'P6', 'P7']\n",
    "\n",
    "dataset = RFGDataset(Tensor_folder, recfldgrn_list, Elig_Set, RecRootID = 'PID')\n",
    "print(len(dataset), '<---- dataset')\n",
    "dataloader = DataLoader(dataset, batch_size = 4, shuffle = True, collate_fn = my_collate_fn)\n",
    "print(len(dataloader), '<---- dataset')\n",
    "\n",
    "\n",
    "for idx, batch in enumerate(dataloader):\n",
    "    # print(f'\\n------ {idx}')\n",
    "    batch_rfg, batch_y = batch\n",
    "    for k, v in batch_rfg.items(): print(k, v.shape)\n",
    "    break\n",
    "    # for k, v in batch_rfg.items(): print(k, v.shape)\n",
    "    # print(batch_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc781d1-edf2-4cd2-8c5e-6f68a4a49417",
   "metadata": {},
   "source": [
    "# get df_SubUnit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e7209fc-8b11-4168-b5f6-5fc10d39a3d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P-InfoGrn', 'B-P-EC-PNSect-TknzGrn']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_recfldgrn_list = ['B-' + i for i in recfldgrn_list]\n",
    "full_recfldgrn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2b113ed-5259-4f4e-b836-64eb2b7c4bf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to fieldnn.dataflowfn.embedflowfn.py\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def get_EmbeddingBlock_SubUnit(full_recfldgrn_list, default_E_subunit_name = 'E'):\n",
    "    SubUnit_List = []\n",
    "    for input_name in full_recfldgrn_list:\n",
    "        d = {}\n",
    "        d['SubUnitName'] = default_E_subunit_name\n",
    "        recfldgrn = '-'.join(input_name.split('-')[-2:])\n",
    "        output_layerid = len(input_name.split('-'))\n",
    "        output_name = input_name.split('Grn')[0]\n",
    "        d['input_names'] = [input_name]\n",
    "        d['output_name'] = output_name\n",
    "        d['output_layerid'] = output_layerid\n",
    "        SubUnit_List.append(d)\n",
    "        \n",
    "    df_SubUnit = pd.DataFrame(SubUnit_List)\n",
    "    \n",
    "    return df_SubUnit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa4f990a-2b17-4b0f-8c44-d2fd957ca6d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubUnitName</th>\n",
       "      <th>input_names</th>\n",
       "      <th>output_name</th>\n",
       "      <th>output_layerid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E</td>\n",
       "      <td>[B-P-InfoGrn]</td>\n",
       "      <td>B-P-Info</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E</td>\n",
       "      <td>[B-P-EC-PNSect-TknzGrn]</td>\n",
       "      <td>B-P-EC-PNSect-Tknz</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SubUnitName              input_names         output_name  output_layerid\n",
       "0           E            [B-P-InfoGrn]            B-P-Info               3\n",
       "1           E  [B-P-EC-PNSect-TknzGrn]  B-P-EC-PNSect-Tknz               5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_E_subunit_name = 'E'\n",
    "df_SubUnit = get_EmbeddingBlock_SubUnit(full_recfldgrn_list, default_E_subunit_name)\n",
    "df_SubUnit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b256f270-7138-44fc-b149-10c7f65487ab",
   "metadata": {},
   "source": [
    "# get df_SubUnit Extra Info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca54d64-d838-466c-bd20-708ffd9d3d4c",
   "metadata": {},
   "source": [
    "## Get SubUnit Name to NN List\n",
    "\n",
    "* E --> [E]\n",
    "* M --> [M]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "308036f5-cc2b-4be7-8ba7-1599992b4bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from fieldnn.dataflowfn.baseflowfn import mapping_SubUnitName_to_SubUnitNNList\n",
    "\n",
    "def mapping_SubUnitName_to_SubUnitNNList(SubUnitName, input_names, \n",
    "                                         default_BasicNNtype_To_NNName):\n",
    "    SubUnitNNList = []\n",
    "    for idx, NAME in enumerate(SubUnitName):\n",
    "        if NAME == 'E':\n",
    "            nn_type = 'expander'\n",
    "            input_name = input_names[0]\n",
    "            \n",
    "            assert 'Grn' in input_name\n",
    "            assert len(input_names) == 1\n",
    "            \n",
    "            if 'Tkn' in input_name.split('-')[-1]:\n",
    "                nn_name = 'LLMEmbed'\n",
    "            elif '_wgt' in input_name:\n",
    "                nn_name = 'NumeEmbed'\n",
    "            else:\n",
    "                nn_name = 'CateEmbed'\n",
    "            \n",
    "        elif NAME == 'R':\n",
    "            if idx == 0: assert len(input_names) == 1\n",
    "            nn_type = 'reducer'\n",
    "            nn_name = default_BasicNNtype_To_NNName[nn_type]\n",
    "            \n",
    "        elif NAME == 'M':\n",
    "            nn_type = 'merger'\n",
    "            nn_name = default_BasicNNtype_To_NNName[nn_type]\n",
    "            \n",
    "        elif NAME == 'L':\n",
    "            # print(input_names)\n",
    "            assert idx != 0\n",
    "            # assert len(input_names) == 1; not necessary, L can follow M\n",
    "            nn_type = 'learner'\n",
    "            input_name = input_names[0]\n",
    "            layers_num = len(input_name.split('-'))\n",
    "            if layers_num >= 3:\n",
    "                nn_name = 'TFM'\n",
    "            elif layers_num == 2:\n",
    "                nn_name = 'Linear'\n",
    "            else:\n",
    "                raise ValueError(f'incorrect layers_num {layers_num}')\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f'The BasicNN is not correct {NAME}')\n",
    "        \n",
    "        SubUnitNNList.append(nn_type + '-' + nn_name)\n",
    "    return SubUnitNNList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a3f2e77-67a5-41e2-b1e8-da4e306764c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############################################# Hyperparameters\n",
    "default_BasicNNtype_To_NNName = {\n",
    "    'expander': None, # will be updated according to the Grn Type\n",
    "    'reducer': 'ReduceMax',\n",
    "    'merger': 'MergeConcat',\n",
    "    'learner': None, # TODO: ignore this currently\n",
    "}\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f446db25-1fed-4722-a770-87545b0e449d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubUnitName</th>\n",
       "      <th>input_names</th>\n",
       "      <th>output_name</th>\n",
       "      <th>output_layerid</th>\n",
       "      <th>SubUnit_BasicNN_List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E</td>\n",
       "      <td>[B-P-InfoGrn]</td>\n",
       "      <td>B-P-Info</td>\n",
       "      <td>3</td>\n",
       "      <td>[expander-CateEmbed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E</td>\n",
       "      <td>[B-P-EC-PNSect-TknzGrn]</td>\n",
       "      <td>B-P-EC-PNSect-Tknz</td>\n",
       "      <td>5</td>\n",
       "      <td>[expander-LLMEmbed]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SubUnitName              input_names         output_name  output_layerid  \\\n",
       "0           E            [B-P-InfoGrn]            B-P-Info               3   \n",
       "1           E  [B-P-EC-PNSect-TknzGrn]  B-P-EC-PNSect-Tknz               5   \n",
       "\n",
       "   SubUnit_BasicNN_List  \n",
       "0  [expander-CateEmbed]  \n",
       "1   [expander-LLMEmbed]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = df_SubUnit.apply(lambda x: mapping_SubUnitName_to_SubUnitNNList(x['SubUnitName'], \n",
    "                                                                    x['input_names'],\n",
    "                                                                    default_BasicNNtype_To_NNName), \n",
    "                    axis = 1)\n",
    "\n",
    "\n",
    "df_SubUnit['SubUnit_BasicNN_List'] = s\n",
    "df_SubUnit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c110c3ba-d710-4549-ab29-3d3a4c0d3eeb",
   "metadata": {},
   "source": [
    "## Get Default BasicNN Config List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e63b099a-1657-425e-a0e1-11ac01e31297",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fieldnn.configfn.expanderfn import get_expander_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6f35d7d-4e89-4881-88cf-31edb7ed32c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to dataflowfn.embedflowfn\n",
    "def get_Default_ExpanderNNPara(full_recfldgrn, fldgrn_folder):\n",
    "    \n",
    "    # (1) get basic information\n",
    "    # recfld = [i for i in full_recfldgrn.split('-') if '@' in i][0]\n",
    "    recfld = [i for i in full_recfldgrn.split('-')][-2]\n",
    "    # rec, fld = recfld.split('@')\n",
    "    # grn_suffix = [i for i in full_recfldgrn.split('-') if 'Grn' in i][0]\n",
    "    # grn, suffix = grn_suffix.split('_')\n",
    "    # prefix_ids = [i for i in full_recfldgrn.split('-') if 'Grn' not in i and '@' not in i]\n",
    "    # recfldgrn = rec + '@' + fld + '-' + grn\n",
    "\n",
    "    # (2) get vocab information\n",
    "    # fldgrn_folder = 'data/ProcData/FldGrnInfo'\n",
    "    fullfldgrn_file = os.path.join(fldgrn_folder, full_recfldgrn[2:] + '.p')\n",
    "    Info = pd.read_pickle(fullfldgrn_file)\n",
    "\n",
    "\n",
    "    # (3) get vocab information\n",
    "    # no matter what type of grain, in the end, we will have vocab_tokenizer.\n",
    "    # if 'LLM' in full_recfldgrn:\n",
    "    #     vocab_tokenizer = df_FieldGrainInfo[df_FieldGrainInfo['recfield2grain'] == recfldgrn].iloc[0]['Vocab']['v2idx']\n",
    "    #     init = vocab_tokenizer.name_or_path\n",
    "    # else:\n",
    "    #     vocab_tokenizer = df_FieldGrainInfo[df_FieldGrainInfo['recfield2grain'] == recfldgrn].iloc[0]['Vocab']['v2idx']\n",
    "    #     init = 'random'\n",
    "\n",
    "    d = {'full_recfldgrn': full_recfldgrn, 'Info': Info}\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a6fda49-c3b3-4664-b2a6-4ce4a2d66566",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_SubUnit_Default_NNPara_List(SubUnit_BasicNN_List, SubUnit_input_names, \n",
    "                                    fldgrn_folder, learner_default_dict):\n",
    "    \n",
    "    SubUnit_DefaultBasicNN_List = []\n",
    "    for basic_nn_idx, nn_type_nn_name in enumerate(SubUnit_BasicNN_List):\n",
    "        nn_type, nn_name = nn_type_nn_name.split('-')\n",
    "        \n",
    "        if basic_nn_idx == 0:\n",
    "            # the first BasicNN in the SubUnit\n",
    "            # expander and merger will only be here.\n",
    "            # this assigments only works for the first iteration\n",
    "            # let's make a village rule: only E, R, M can be the first. \n",
    "            assert nn_type in ['expander', 'reducer', 'merger']\n",
    "        \n",
    "            if nn_type == 'expander':\n",
    "                input_names_nnlvl = SubUnit_input_names \n",
    "                assert len(input_names_nnlvl) == 1\n",
    "                full_recfldgrn = input_names_nnlvl[0]\n",
    "                default_para = get_Default_ExpanderNNPara(full_recfldgrn, fldgrn_folder)\n",
    "                \n",
    "            else:\n",
    "                default_para = {}\n",
    "            \n",
    "        else:\n",
    "            assert nn_type in ['reducer', 'learner']\n",
    "            if nn_type == 'learner':\n",
    "                default_para = learner_default_dict[nn_name] # TODO\n",
    "            else:\n",
    "                default_para = {}\n",
    "        \n",
    "        SubUnit_DefaultBasicNN_List.append(default_para)    \n",
    "        \n",
    "    return SubUnit_DefaultBasicNN_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7318b03-899a-4528-8f07-22d5555e5155",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubUnitName</th>\n",
       "      <th>input_names</th>\n",
       "      <th>output_name</th>\n",
       "      <th>output_layerid</th>\n",
       "      <th>SubUnit_BasicNN_List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E</td>\n",
       "      <td>[B-P-InfoGrn]</td>\n",
       "      <td>B-P-Info</td>\n",
       "      <td>3</td>\n",
       "      <td>[expander-CateEmbed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E</td>\n",
       "      <td>[B-P-EC-PNSect-TknzGrn]</td>\n",
       "      <td>B-P-EC-PNSect-Tknz</td>\n",
       "      <td>5</td>\n",
       "      <td>[expander-LLMEmbed]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SubUnitName              input_names         output_name  output_layerid  \\\n",
       "0           E            [B-P-InfoGrn]            B-P-Info               3   \n",
       "1           E  [B-P-EC-PNSect-TknzGrn]  B-P-EC-PNSect-Tknz               5   \n",
       "\n",
       "   SubUnit_BasicNN_List  \n",
       "0  [expander-CateEmbed]  \n",
       "1   [expander-LLMEmbed]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SubUnit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7587050-a67d-491a-ab6e-c6c0a0526dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SubUnit_info = df_SubUnit.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d356d74a-7630-47e3-acb1-08b10de14e67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SubUnit_BasicNN_List = SubUnit_info['SubUnit_BasicNN_List']\n",
    "SubUnit_input_names = SubUnit_info['input_names']\n",
    "SubUnit_output_name = SubUnit_info['output_name']\n",
    "fldgrn_folder = 'data/ProcData/FldGrnInfo'\n",
    "learner_default_dict = {} # To update it in the future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16da2c37-ac1f-43c9-a52c-3f971c41649f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['expander-CateEmbed']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SubUnit_BasicNN_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "265c1706-59f0-4e08-b3a3-d4aba4d6ddc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['full_recfldgrn', 'Info'])\n"
     ]
    }
   ],
   "source": [
    "SubUnit_DefaultBasicNN_List = get_SubUnit_Default_NNPara_List(SubUnit_BasicNN_List, SubUnit_input_names, \n",
    "                                                              fldgrn_folder, learner_default_dict)\n",
    "\n",
    "for i in SubUnit_DefaultBasicNN_List:\n",
    "    print(i.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2802852-c921-40dd-947c-15f9b64a3162",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubUnitName</th>\n",
       "      <th>input_names</th>\n",
       "      <th>output_name</th>\n",
       "      <th>output_layerid</th>\n",
       "      <th>SubUnit_BasicNN_List</th>\n",
       "      <th>SubUnit_DefaultBasicNN_List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E</td>\n",
       "      <td>[B-P-InfoGrn]</td>\n",
       "      <td>B-P-Info</td>\n",
       "      <td>3</td>\n",
       "      <td>[expander-CateEmbed]</td>\n",
       "      <td>[{'full_recfldgrn': 'B-P-InfoGrn', 'Info': ['P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E</td>\n",
       "      <td>[B-P-EC-PNSect-TknzGrn]</td>\n",
       "      <td>B-P-EC-PNSect-Tknz</td>\n",
       "      <td>5</td>\n",
       "      <td>[expander-LLMEmbed]</td>\n",
       "      <td>[{'full_recfldgrn': 'B-P-EC-PNSect-TknzGrn', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SubUnitName              input_names         output_name  output_layerid  \\\n",
       "0           E            [B-P-InfoGrn]            B-P-Info               3   \n",
       "1           E  [B-P-EC-PNSect-TknzGrn]  B-P-EC-PNSect-Tknz               5   \n",
       "\n",
       "   SubUnit_BasicNN_List                        SubUnit_DefaultBasicNN_List  \n",
       "0  [expander-CateEmbed]  [{'full_recfldgrn': 'B-P-InfoGrn', 'Info': ['P...  \n",
       "1   [expander-LLMEmbed]  [{'full_recfldgrn': 'B-P-EC-PNSect-TknzGrn', '...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fldgrn_folder = 'data/ProcData/FldGrnInfo'\n",
    "learner_default_dict = {} # To update it in the future. \n",
    "\n",
    "\n",
    "s = df_SubUnit.apply(lambda x: get_SubUnit_Default_NNPara_List(x['SubUnit_BasicNN_List'], \n",
    "                                                               x['input_names'],\n",
    "                                                               fldgrn_folder, \n",
    "                                                               learner_default_dict), axis = 1)\n",
    "\n",
    "df_SubUnit['SubUnit_DefaultBasicNN_List'] = s\n",
    "\n",
    "\n",
    "df_SubUnit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5d2183-c267-4526-a6b5-c6ac6307391e",
   "metadata": {},
   "source": [
    "## Get BasicNN Config List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f291e204-ba6a-4ac3-8afa-0c00f6aff8cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fieldnn.configfn.expanderfn import get_expander_para\n",
    "from fieldnn.configfn.mergerfn import get_merger_para   # ignore this one in this notebook\n",
    "from fieldnn.configfn.reducerfn import get_reducer_para # ignore this one in this notebook\n",
    "from fieldnn.configfn.learnerfn import get_learner_para # ignore this one in this notebook\n",
    "\n",
    "\n",
    "def generate_BasicNN_Config(nn_type_nn_name, \n",
    "                            input_names_nnlvl, \n",
    "                            default_nnpara, \n",
    "                            embed_size, \n",
    "                            process):\n",
    "    '''\n",
    "        please notince here, this function is not the final version yet.\n",
    "    '''\n",
    "    nn_type, nn_name = nn_type_nn_name.split('-')\n",
    "\n",
    "    if nn_type == 'expander':\n",
    "        \n",
    "        assert len(input_names_nnlvl) == 1\n",
    "        # fld = input_names_nnlvl[0].split('-')[-1]\n",
    "        # Get the output_name_nnlvl\n",
    "        output_name_nnlvl = input_names_nnlvl[0].split('Grn')[0]\n",
    "        \n",
    "        # Get the input_size and output_size\n",
    "        input_size = None\n",
    "        output_size = embed_size \n",
    "        \n",
    "        # Get the postprocess\n",
    "        postprocess = process\n",
    "        \n",
    "        # Derive the para\n",
    "        full_recfldgrn = default_nnpara['full_recfldgrn']\n",
    "        Info = default_nnpara['Info']\n",
    "        # para = get_expander_para(nn_name, default_nnpara, embed_size, vocab_tokenizer, init, postprocess)\n",
    "        para = get_expander_para(full_recfldgrn, Info, embed_size, postprocess)\n",
    "\n",
    "    elif nn_type == 'reducer': \n",
    "        \n",
    "        assert len(input_names_nnlvl) == 1\n",
    "        fld = input_names_nnlvl[0].split('-')[-1]\n",
    "        # Get the output_name_nnlvl\n",
    "        output_name_nnlvl = input_names_nnlvl[0].replace('-' + fld, '@' + fld)\n",
    "\n",
    "        # Get the para for the NN layer\n",
    "        nn_para = default_nnpara # this will be updated.\n",
    "\n",
    "        # Get the input_size\n",
    "        input_size = embed_size\n",
    "\n",
    "        # Get the output_size\n",
    "        output_size = embed_size \n",
    "\n",
    "        # Get the postprocess\n",
    "        postprocess = process\n",
    "\n",
    "        # Derive the para\n",
    "        para = get_reducer_para(nn_name, default_nnpara, input_size, output_size, postprocess)  \n",
    "        \n",
    "    elif nn_type == 'merger':\n",
    "        # generate the output name\n",
    "        \n",
    "        assert len(input_names_nnlvl) > 1\n",
    "        # input_names_nnlvl: ['B-P-EC-A1C@DT', 'B-P-EC-A1C@V']\n",
    "        \n",
    "        childflds = [i.split('-')[-1] for i in input_names_nnlvl]\n",
    "        # childflds: ['A1C@DT', 'A1C@V']\n",
    "        \n",
    "        fld_childflds = '&'.join([i.split('@')[-1] for i in childflds])\n",
    "        # fld_childflds: DT&V\n",
    "        \n",
    "        output_prefix = input_names_nnlvl[0].replace('@' + childflds[0].split('@')[-1], '')\n",
    "        # output_prefix: B-P-EC-A1C\n",
    "        \n",
    "        output_name_nnlvl = output_prefix + '-' + fld_childflds\n",
    "        # output_name_nnlvl: B-P-EC-A1C-DT&V\n",
    "        \n",
    "        # Prepare the para for the NN layer\n",
    "        nn_para = default_nnpara # this will be updated.\n",
    "\n",
    "        # Get the input_size\n",
    "        input_size = embed_size\n",
    "        output_size = embed_size\n",
    "\n",
    "        # Get the postprocess\n",
    "        postprocess = process\n",
    "\n",
    "        # Derive the para\n",
    "        para = get_merger_para(nn_name, default_nnpara, input_size, output_size, postprocess) \n",
    "        \n",
    "        \n",
    "    elif nn_type == 'learner':\n",
    "        # generate the output name\n",
    "        assert len(input_names_nnlvl) == 1\n",
    "        output_name_nnlvl = input_names_nnlvl[0] # just the same name as before\n",
    "        \n",
    "        # Prepare the para for the NN layer\n",
    "        nn_para = default_nnpara # this will be updated.\n",
    "\n",
    "        # Get the input_size\n",
    "        input_size = embed_size\n",
    "        output_size = embed_size\n",
    "\n",
    "        # Get the postprocess\n",
    "        postprocess = process\n",
    "\n",
    "        # Derive the para\n",
    "        para = get_learner_para(nn_name, default_nnpara, input_size, output_size, postprocess)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f'nn_type {nn_type} is not available yet')\n",
    "\n",
    "    Basic_Config = {'input_names_nnlvl': input_names_nnlvl, \n",
    "                    'output_name_nnlvl': output_name_nnlvl, \n",
    "                    f'{nn_type}_para': para}\n",
    "    \n",
    "    return Basic_Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0036919a-590b-41f4-b0cd-72a89606483d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from fieldnn.configfn.expanderfn import get_expander_para\n",
    "from fieldnn.configfn.mergerfn import get_merger_para\n",
    "from fieldnn.configfn.reducerfn import get_reducer_para\n",
    "from fieldnn.configfn.learnerfn import get_learner_para\n",
    "\n",
    "\n",
    "\n",
    "def generate_BasicNN_Config(nn_type_nn_name, \n",
    "                            input_names_nnlvl, \n",
    "                            default_nnpara, \n",
    "                            embed_size, \n",
    "                            process):\n",
    "    '''\n",
    "        please notince here, this function is not the final version yet.\n",
    "    '''\n",
    "    nn_type, nn_name = nn_type_nn_name.split('-')\n",
    "\n",
    "    if nn_type == 'expander':\n",
    "        \n",
    "        assert len(input_names_nnlvl) == 1\n",
    "        # fld = input_names_nnlvl[0].split('-')[-1]\n",
    "        # Get the output_name_nnlvl\n",
    "        output_name_nnlvl = input_names_nnlvl[0].split('Grn')[0]\n",
    "        \n",
    "        # Get the input_size and output_size\n",
    "        input_size = None\n",
    "        output_size = embed_size \n",
    "        \n",
    "        # Get the postprocess\n",
    "        postprocess = process\n",
    "        \n",
    "        # Derive the para\n",
    "        full_recfldgrn = default_nnpara['full_recfldgrn']\n",
    "        Info = default_nnpara['Info']\n",
    "        # para = get_expander_para(nn_name, default_nnpara, embed_size, vocab_tokenizer, init, postprocess)\n",
    "        para = get_expander_para(full_recfldgrn, Info, embed_size, postprocess)\n",
    "\n",
    "    elif nn_type == 'reducer': \n",
    "        \n",
    "        assert len(input_names_nnlvl) == 1\n",
    "        fld = input_names_nnlvl[0].split('-')[-1]\n",
    "        # Get the output_name_nnlvl\n",
    "        output_name_nnlvl = input_names_nnlvl[0].replace('-' + fld, '')\n",
    "\n",
    "        # Get the para for the NN layer\n",
    "        nn_para = default_nnpara # this will be updated.\n",
    "\n",
    "        # Get the input_size\n",
    "        input_size = embed_size\n",
    "        output_size = embed_size \n",
    "        \n",
    "        # Get the postprocess\n",
    "        postprocess = process\n",
    "\n",
    "        # Derive the para\n",
    "        para = get_reducer_para(nn_name, default_nnpara, input_size, output_size, postprocess)  \n",
    "        \n",
    "    elif nn_type == 'merger':\n",
    "        # generate the output name\n",
    "        \n",
    "        assert len(input_names_nnlvl) > 1\n",
    "        # input_names_nnlvl: ['B-P-EC-A1CDT', 'B-P-EC-A1CV']\n",
    "        \n",
    "        childflds = [i.split('-')[-1] for i in input_names_nnlvl]\n",
    "        # childflds: ['A1CDT', 'A1CV']\n",
    "        \n",
    "        fld_childflds = '&'.join([i for i in childflds])\n",
    "        # fld_childflds: A1CDT&A1CV\n",
    "        \n",
    "        # output_prefix = input_names_nnlvl[0].replace('@' + childflds[0].split('@')[-1], '')\n",
    "        output_prefix = '-'.join(input_names_nnlvl[0].split('-')[:-1])\n",
    "        \n",
    "        # output_prefix: B-P-EC-A1C\n",
    "        output_name_nnlvl = output_prefix + '-' + fld_childflds\n",
    "        # output_name_nnlvl: B-P-EC-A1C-DT&V\n",
    "        \n",
    "        # Prepare the para for the NN layer\n",
    "        nn_para = default_nnpara # this will be updated.\n",
    "\n",
    "        # Get the input_size\n",
    "        input_size = embed_size\n",
    "        output_size = embed_size\n",
    "\n",
    "        # Get the postprocess\n",
    "        postprocess = process\n",
    "\n",
    "        # Derive the para\n",
    "        para = get_merger_para(nn_name, default_nnpara, input_size, output_size, postprocess) \n",
    "        \n",
    "        \n",
    "    elif nn_type == 'learner':\n",
    "        # generate the output name\n",
    "        assert len(input_names_nnlvl) == 1\n",
    "        output_name_nnlvl = input_names_nnlvl[0] # just the same name as before\n",
    "        \n",
    "        # Prepare the para for the NN layer\n",
    "        nn_para = default_nnpara # this will be updated.\n",
    "\n",
    "        # Get the input_size\n",
    "        input_size = embed_size\n",
    "        output_size = embed_size\n",
    "\n",
    "        # Get the postprocess\n",
    "        postprocess = process\n",
    "\n",
    "        # Derive the para\n",
    "        para = get_learner_para(nn_name, default_nnpara, input_size, output_size, postprocess)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f'nn_type {nn_type} is not available yet')\n",
    "\n",
    "    Basic_Config = {'input_names_nnlvl': input_names_nnlvl, \n",
    "                    'output_name_nnlvl': output_name_nnlvl, \n",
    "                    f'{nn_type}_para': para}\n",
    "    \n",
    "    return Basic_Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b126004-41d6-4890-bea8-c86e37266441",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_SubUnit_BasicNN_Config_List(SubUnit_BasicNN_List, \n",
    "                                    SubUnit_DefaultBasicNN_List, \n",
    "                                    SubUnit_input_names, \n",
    "                                    SubUnit_output_name, \n",
    "                                    embed_size, \n",
    "                                    process, \n",
    "                                   ):\n",
    "    \n",
    "    \n",
    "    # TODO: also add the layer_idx in order to deal with the learn_layer_para.\n",
    "    # This function also needs to be updated. \n",
    "    \n",
    "    SubUnit_BasicNN_Config_List = []\n",
    "    \n",
    "    # print('\\n\\n************** SubUnit_BasicNN_List ****************')\n",
    "    # print(SubUnit_BasicNN_List)\n",
    "    # print(SubUnit_input_names)\n",
    "    # print(SubUnit_output_name)\n",
    "    for basic_nn_idx, nn_type_nn_name in enumerate(SubUnit_BasicNN_List):\n",
    "\n",
    "        # Get the input_names_nnlvl\n",
    "        if basic_nn_idx == 0:\n",
    "            input_names_nnlvl = SubUnit_input_names # this assigments only works for the first iteration\n",
    "        else:\n",
    "            input_names_nnlvl = [output_name_nnlvl]\n",
    "        \n",
    "        ##############\n",
    "        default_nnpara = SubUnit_DefaultBasicNN_List[basic_nn_idx] \n",
    "        ##############\n",
    "        \n",
    "        \n",
    "        Basic_Config = generate_BasicNN_Config(nn_type_nn_name, \n",
    "                                               input_names_nnlvl, \n",
    "                                               default_nnpara, \n",
    "                                               embed_size, \n",
    "                                               process)\n",
    "        output_name_nnlvl = Basic_Config['output_name_nnlvl']\n",
    "        BasicNN_Config = {'nn_type_nn_name': nn_type_nn_name, 'Basic_Config': Basic_Config}\n",
    "        SubUnit_BasicNN_Config_List.append(BasicNN_Config)\n",
    "        \n",
    "        # print('==========================')\n",
    "        # print(basic_nn_idx, nn_type_nn_name)\n",
    "        # print(input_names_nnlvl, '<-------- input_names_nnlvl')\n",
    "        # print(output_name_nnlvl, '<-------- output_name_nnlvl')\n",
    "        \n",
    "        \n",
    "        # also check the input_size of dim and output_size of dim\n",
    "\n",
    "    final_output_name_nnlvl = output_name_nnlvl\n",
    "\n",
    "    # if not SubUnit_output_name in final_output_name_nnlvl:\n",
    "    #     print('xxx errors xxx')\n",
    "    #     print(final_output_name_nnlvl, '<------- final_output_name_nnlvl')\n",
    "    #     print(SubUnit_output_name, '<------- SubUnit_output_name')\n",
    "    #     print('xxx errors xxx')\n",
    "    assert SubUnit_output_name in final_output_name_nnlvl\n",
    "    # print('\\n************** End SubUnit_BasicNN_List ****************')\n",
    "    return SubUnit_BasicNN_Config_List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "348c8c6e-96ac-4c3e-9992-34197a4154df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SubUnit_BasicNN_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3de3f837-643b-468c-ac36-f6a81d1302ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SubUnit_DefaultBasicNN_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0590a4cf-d0cb-4159-a04d-8b2d14db09ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############################\n",
    "embed_size = 128\n",
    "process = {'activator': 'gelu',\n",
    "           'dropout': {'p': 0.5, 'inplace': False},\n",
    "           'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "############################\n",
    "\n",
    "s = get_SubUnit_BasicNN_Config_List(SubUnit_BasicNN_List, \n",
    "                                    SubUnit_DefaultBasicNN_List, \n",
    "                                    SubUnit_input_names, \n",
    "                                    SubUnit_output_name, \n",
    "                                    embed_size, \n",
    "                                    process, \n",
    "                                   )\n",
    "\n",
    "SubUnit_BasicNN_Config_List = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbffb436-3428-4c4e-a669-6029624cf84b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'nn_type_nn_name': 'expander-CateEmbed',\n",
       "  'Basic_Config': {'input_names_nnlvl': ['B-P-InfoGrn'],\n",
       "   'output_name_nnlvl': 'B-P-Info',\n",
       "   'expander_para': {'input_size': None,\n",
       "    'output_size': 128,\n",
       "    'nn_type': 'expander',\n",
       "    'B-P-InfoGrn_tknidx': {'nn_name': 'CateEmbed',\n",
       "     'nn_para': {'embedding_size': 128, 'init': 'random', 'vocab_size': 55}},\n",
       "    'B-P-InfoGrn_fldidx': {'nn_name': 'CateEmbed',\n",
       "     'nn_para': {'embedding_size': 128, 'init': 'random', 'vocab_size': 5}},\n",
       "    'postprocess': {'activator': 'gelu',\n",
       "     'dropout': {'p': 0.5, 'inplace': False},\n",
       "     'layernorm': {'eps': 1e-05, 'elementwise_affine': True}},\n",
       "    'use_wgt': True}}}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SubUnit_BasicNN_Config_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a8cef11-12bc-4848-ab15-cfa7045798cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubUnitName</th>\n",
       "      <th>input_names</th>\n",
       "      <th>output_name</th>\n",
       "      <th>output_layerid</th>\n",
       "      <th>SubUnit_BasicNN_List</th>\n",
       "      <th>SubUnit_DefaultBasicNN_List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E</td>\n",
       "      <td>[B-P-InfoGrn]</td>\n",
       "      <td>B-P-Info</td>\n",
       "      <td>3</td>\n",
       "      <td>[expander-CateEmbed]</td>\n",
       "      <td>[{'full_recfldgrn': 'B-P-InfoGrn', 'Info': ['P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E</td>\n",
       "      <td>[B-P-EC-PNSect-TknzGrn]</td>\n",
       "      <td>B-P-EC-PNSect-Tknz</td>\n",
       "      <td>5</td>\n",
       "      <td>[expander-LLMEmbed]</td>\n",
       "      <td>[{'full_recfldgrn': 'B-P-EC-PNSect-TknzGrn', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SubUnitName              input_names         output_name  output_layerid  \\\n",
       "0           E            [B-P-InfoGrn]            B-P-Info               3   \n",
       "1           E  [B-P-EC-PNSect-TknzGrn]  B-P-EC-PNSect-Tknz               5   \n",
       "\n",
       "   SubUnit_BasicNN_List                        SubUnit_DefaultBasicNN_List  \n",
       "0  [expander-CateEmbed]  [{'full_recfldgrn': 'B-P-InfoGrn', 'Info': ['P...  \n",
       "1   [expander-LLMEmbed]  [{'full_recfldgrn': 'B-P-EC-PNSect-TknzGrn', '...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SubUnit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69afd91b-0a1c-49d5-a123-b431f758850c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############################\n",
    "embed_size = 128\n",
    "process = {'activator': 'gelu',\n",
    "           'dropout': {'p': 0.5, 'inplace': False},\n",
    "           'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2202db12-e84e-458e-afac-c658fdb7d8c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubUnitName</th>\n",
       "      <th>input_names</th>\n",
       "      <th>output_name</th>\n",
       "      <th>output_layerid</th>\n",
       "      <th>SubUnit_BasicNN_List</th>\n",
       "      <th>SubUnit_DefaultBasicNN_List</th>\n",
       "      <th>SubUnit_BasicNN_Config_List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E</td>\n",
       "      <td>[B-P-InfoGrn]</td>\n",
       "      <td>B-P-Info</td>\n",
       "      <td>3</td>\n",
       "      <td>[expander-CateEmbed]</td>\n",
       "      <td>[{'full_recfldgrn': 'B-P-InfoGrn', 'Info': ['P...</td>\n",
       "      <td>[{'nn_type_nn_name': 'expander-CateEmbed', 'Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E</td>\n",
       "      <td>[B-P-EC-PNSect-TknzGrn]</td>\n",
       "      <td>B-P-EC-PNSect-Tknz</td>\n",
       "      <td>5</td>\n",
       "      <td>[expander-LLMEmbed]</td>\n",
       "      <td>[{'full_recfldgrn': 'B-P-EC-PNSect-TknzGrn', '...</td>\n",
       "      <td>[{'nn_type_nn_name': 'expander-LLMEmbed', 'Bas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SubUnitName              input_names         output_name  output_layerid  \\\n",
       "0           E            [B-P-InfoGrn]            B-P-Info               3   \n",
       "1           E  [B-P-EC-PNSect-TknzGrn]  B-P-EC-PNSect-Tknz               5   \n",
       "\n",
       "   SubUnit_BasicNN_List                        SubUnit_DefaultBasicNN_List  \\\n",
       "0  [expander-CateEmbed]  [{'full_recfldgrn': 'B-P-InfoGrn', 'Info': ['P...   \n",
       "1   [expander-LLMEmbed]  [{'full_recfldgrn': 'B-P-EC-PNSect-TknzGrn', '...   \n",
       "\n",
       "                         SubUnit_BasicNN_Config_List  \n",
       "0  [{'nn_type_nn_name': 'expander-CateEmbed', 'Ba...  \n",
       "1  [{'nn_type_nn_name': 'expander-LLMEmbed', 'Bas...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = df_SubUnit.apply(lambda x: get_SubUnit_BasicNN_Config_List(x['SubUnit_BasicNN_List'], \n",
    "                                                               x['SubUnit_DefaultBasicNN_List'], \n",
    "                                                               x['input_names'], \n",
    "                                                               x['output_name'], \n",
    "                                                                embed_size, \n",
    "                                                                process, \n",
    "                                                               ), axis = 1)\n",
    "\n",
    "s\n",
    "\n",
    "df_SubUnit['SubUnit_BasicNN_Config_List'] = s\n",
    "df_SubUnit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebaa5bbe-6afa-473e-8f5b-fee5a6e61be6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'nn_type_nn_name': 'expander-CateEmbed',\n",
       "  'Basic_Config': {'input_names_nnlvl': ['B-P-InfoGrn'],\n",
       "   'output_name_nnlvl': 'B-P-Info',\n",
       "   'expander_para': {'input_size': None,\n",
       "    'output_size': 128,\n",
       "    'nn_type': 'expander',\n",
       "    'B-P-InfoGrn_tknidx': {'nn_name': 'CateEmbed',\n",
       "     'nn_para': {'embedding_size': 128, 'init': 'random', 'vocab_size': 55}},\n",
       "    'B-P-InfoGrn_fldidx': {'nn_name': 'CateEmbed',\n",
       "     'nn_para': {'embedding_size': 128, 'init': 'random', 'vocab_size': 5}},\n",
       "    'postprocess': {'activator': 'gelu',\n",
       "     'dropout': {'p': 0.5, 'inplace': False},\n",
       "     'layernorm': {'eps': 1e-05, 'elementwise_affine': True}},\n",
       "    'use_wgt': True}}}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SubUnit['SubUnit_BasicNN_Config_List'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af47c602-be03-457b-bbb9-dd215dcb7ebe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'nn_type_nn_name': 'expander-LLMEmbed',\n",
       "  'Basic_Config': {'input_names_nnlvl': ['B-P-EC-PNSect-TknzGrn'],\n",
       "   'output_name_nnlvl': 'B-P-EC-PNSect-Tknz',\n",
       "   'expander_para': {'input_size': None,\n",
       "    'output_size': 128,\n",
       "    'nn_type': 'expander',\n",
       "    'B-P-EC-PNSect-TknzGrn_tknidx': {'nn_name': 'LLMEmbed',\n",
       "     'nn_para': {'embedding_size': 128,\n",
       "      'init': 'bert-base-uncased',\n",
       "      'tokenizer': BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)}},\n",
       "    'B-P-EC-PNSect-TknzGrn_fldidx': {'nn_name': 'CateEmbed',\n",
       "     'nn_para': {'embedding_size': 128, 'init': 'random', 'vocab_size': 3}},\n",
       "    'postprocess': {'activator': 'gelu',\n",
       "     'dropout': {'p': 0.5, 'inplace': False},\n",
       "     'layernorm': {'eps': 1e-05, 'elementwise_affine': True}},\n",
       "    'use_wgt': False}}}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SubUnit['SubUnit_BasicNN_Config_List'].iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d263698-1555-413c-9730-e42ebba649c2",
   "metadata": {},
   "source": [
    "# SubUnit \n",
    "\n",
    "## Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3398cd46-f65c-4004-b3f9-ee429252807a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from fieldnn.basicnn.expander import Expander_Layer\n",
    "from fieldnn.basicnn.reducer import Reducer_Layer\n",
    "from fieldnn.basicnn.merger import Merger_Layer\n",
    "from fieldnn.basicnn.learner import Learner_Layer\n",
    "\n",
    "# from ..basicnn.expander import Expander_Layer\n",
    "# from ..basicnn.reducer import Reducer_Layer\n",
    "# from ..basicnn.merger import Merger_Layer\n",
    "# from ..basicnn.learner import Learner_Layer\n",
    "\n",
    "\n",
    "class SubUnit_Layer(torch.nn.Module):\n",
    "    '''Currently, it is not latest version'''\n",
    "    \n",
    "    def __init__(self, SubUnit_info):\n",
    "        super(SubUnit_Layer, self).__init__()\n",
    "        \n",
    "        # the input names for the SubUnit\n",
    "        self.SubUnit_input_names = SubUnit_info['input_names']\n",
    "        \n",
    "        # the output name for this SubUnit\n",
    "        self.SubUnit_output_name = SubUnit_info['output_name']\n",
    "        \n",
    "        # get the SubUnit's BasicNN Config List\n",
    "        self.SubUnit_BasicNN_Config_List = SubUnit_info['SubUnit_BasicNN_Config_List']\n",
    "        \n",
    "        \n",
    "        # construct the LayersDict to hold all BasicNN within this SubUnit.\n",
    "        self.LayersDict = torch.nn.ModuleDict()\n",
    "        \n",
    "        # initialize all the BasicNN for this SubUnit.\n",
    "        for idx, BasicNN_Config_Dict in enumerate(self.SubUnit_BasicNN_Config_List):\n",
    "            # print(BasicNN_Config_Dict)\n",
    "            # nn_type_nn_name: like reducer-Max, learner-TFM, merger-Merger, expander-llmembed.\n",
    "            nn_type_nn_name = BasicNN_Config_Dict['nn_type_nn_name']\n",
    "            \n",
    "            # Basic_Config: the Config for this NN.\n",
    "            Basic_Config = BasicNN_Config_Dict['Basic_Config']\n",
    "            \n",
    "            input_names_nnlvl = Basic_Config['input_names_nnlvl']\n",
    "            output_name_nnlvl = Basic_Config['output_name_nnlvl']\n",
    "                \n",
    "            if 'expander' in nn_type_nn_name:\n",
    "                expander_para = Basic_Config['expander_para']\n",
    "                # print('\\n')\n",
    "                # print(expander_para)\n",
    "                # print(input_names_nnlvl)\n",
    "                # print(output_name_nnlvl)\n",
    "                assert len(input_names_nnlvl) == 1\n",
    "                # full_recfldgrn = input_names_nnlvl[0]\n",
    "                # input_names_nnlvl = [i for i in expander_para if full_recfldgrn in i]\n",
    "                # input_names_nnlvl = input_names_nnlvl if expander_para['use_wgt'] == False else input_names_nnlvl + [f'{full_recfldgrn}_wgt']\n",
    "                \n",
    "                NN = Expander_Layer(input_names_nnlvl, output_name_nnlvl, expander_para)\n",
    "                self.LayersDict[f'{idx}_{nn_type_nn_name}'] = NN\n",
    "                \n",
    "            elif 'reducer' in nn_type_nn_name:\n",
    "                reducer_para = Basic_Config['reducer_para']\n",
    "                NN = Reducer_Layer(input_names_nnlvl, output_name_nnlvl, reducer_para)\n",
    "                self.LayersDict[f'{idx}_{nn_type_nn_name}'] = NN\n",
    "                \n",
    "            elif 'merger' in nn_type_nn_name:\n",
    "                merger_para = Basic_Config['merger_para']\n",
    "                NN = Merger_Layer(input_names_nnlvl, output_name_nnlvl, merger_para)\n",
    "                self.LayersDict[f'{idx}_{nn_type_nn_name}'] = NN\n",
    "                \n",
    "                \n",
    "            elif 'learner' in nn_type_nn_name:\n",
    "                learner_para = Basic_Config['learner_para']\n",
    "                NN = Learner_Layer(input_names_nnlvl, output_name_nnlvl, learner_para)\n",
    "                self.LayersDict[f'{idx}_{nn_type_nn_name}'] = NN\n",
    "                \n",
    "            else:\n",
    "                raise ValueError(f'Current BasicNN {nn_type_nn_name} is not available')\n",
    "\n",
    "\n",
    "    def forward(self, SubUnit_input_names, RECFLD_TO_TENSOR):\n",
    "\n",
    "        INPUTS_TO_INFODICT = {}\n",
    "        \n",
    "        for idx, BasicNN_Config_Dict in enumerate(self.SubUnit_BasicNN_Config_List):\n",
    "            \n",
    "            nn_type_nn_name = BasicNN_Config_Dict['nn_type_nn_name']\n",
    "            Basic_Config = BasicNN_Config_Dict['Basic_Config']\n",
    "            input_names_nnlvl = Basic_Config['input_names_nnlvl']\n",
    "            output_name_nnlvl = Basic_Config['output_name_nnlvl']\n",
    "            \n",
    "            NN = self.LayersDict[f'{idx}_{nn_type_nn_name}']\n",
    "            \n",
    "            # prepare the input.\n",
    "            if idx == 0:\n",
    "                for tensor_name in input_names_nnlvl:\n",
    "                    INPUTS_TO_INFODICT[tensor_name] = RECFLD_TO_TENSOR[tensor_name]\n",
    "            else:\n",
    "                for input_name in input_names_nnlvl:\n",
    "                    assert input_name in INPUTS_TO_INFODICT\n",
    "                \n",
    "            output_name_nnlvl, info_dict = NN(input_names_nnlvl, INPUTS_TO_INFODICT)\n",
    "            \n",
    "            # current output will be the input in the next round. \n",
    "            INPUTS_TO_INFODICT[output_name_nnlvl] = info_dict\n",
    "            \n",
    "        # pick up the SubUnit_output_name and its info_dict\n",
    "        final_output_name_nnlvl = output_name_nnlvl\n",
    "        SubUnit_output_name = self.SubUnit_output_name\n",
    "        if not SubUnit_output_name in final_output_name_nnlvl:\n",
    "            print(f'Mismatched SubUnit Output and Final NN Output: {final_output_name_nnlvl} vs {output_name_nnlvl}')\n",
    "        \n",
    "        info_dict = INPUTS_TO_INFODICT[final_output_name_nnlvl]\n",
    "        \n",
    "        return SubUnit_output_name, info_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcef192-7ebe-49aa-9b92-b0fdb517fe57",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ed1122c-f8f4-4551-8545-2bf6988c016a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubUnitName                                                                    E\n",
      "input_names                                                        [B-P-InfoGrn]\n",
      "output_name                                                             B-P-Info\n",
      "output_layerid                                                                 3\n",
      "SubUnit_BasicNN_List                                        [expander-CateEmbed]\n",
      "SubUnit_DefaultBasicNN_List    [{'full_recfldgrn': 'B-P-InfoGrn', 'Info': ['P...\n",
      "SubUnit_BasicNN_Config_List    [{'nn_type_nn_name': 'expander-CateEmbed', 'Ba...\n",
      "Name: 0, dtype: object\n",
      "SubUnitName                                                                    E\n",
      "input_names                                              [B-P-EC-PNSect-TknzGrn]\n",
      "output_name                                                   B-P-EC-PNSect-Tknz\n",
      "output_layerid                                                                 5\n",
      "SubUnit_BasicNN_List                                         [expander-LLMEmbed]\n",
      "SubUnit_DefaultBasicNN_List    [{'full_recfldgrn': 'B-P-EC-PNSect-TknzGrn', '...\n",
      "SubUnit_BasicNN_Config_List    [{'nn_type_nn_name': 'expander-LLMEmbed', 'Bas...\n",
      "Name: 1, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "OutputTensor_2_Embed = {}\n",
    "\n",
    "for idx, SubUnit_info in df_SubUnit.iterrows():\n",
    "    # print(SubUnit_info)\n",
    "    # print(SubUnit_info['SubUnit_BasicNN_Config_List'])\n",
    "    output_name = SubUnit_info['output_name']\n",
    "    \n",
    "    print(SubUnit_info)\n",
    "    \n",
    "    SubUnitLayer = SubUnit_Layer(SubUnit_info)\n",
    "    OutputTensor_2_Embed[output_name] = SubUnitLayer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48f16bab-c047-4785-b8ae-aa49b2fcc0ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P-InfoGrn_wgt',\n",
       " 'B-P-InfoGrn_tknidx',\n",
       " 'B-P-InfoGrn_fldidx',\n",
       " 'B-P-EC-PNSect-TknzGrn_wgt',\n",
       " 'B-P-EC-PNSect-TknzGrn_tknidx',\n",
       " 'B-P-EC-PNSect-TknzGrn_fldidx']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in batch_rfg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54c25a1c-7c6f-4714-a34e-1e296ea1b771",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P-InfoGrn', 'B-P-EC-PNSect-TknzGrn']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the Input\n",
    "RECFLD_TO_TENSOR = {}\n",
    "for full_recfldgrn in full_recfldgrn_list:\n",
    "    RECFLD_TO_TENSOR[full_recfldgrn] = {k: v for k, v in batch_rfg.items() if full_recfldgrn in k}\n",
    "    \n",
    "[i for i in RECFLD_TO_TENSOR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8cdca40-6df6-4496-b07b-00d91217cb97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P-Info\n",
      "torch.Size([4, 43, 128])\n",
      "B-P-EC-PNSect-Tknz\n",
      "torch.Size([4, 23, 14, 221, 128])\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_TO_TENSOR = {}\n",
    "\n",
    "for output_name, SubUnitLayer in OutputTensor_2_Embed.items():\n",
    "    input_names = SubUnitLayer.SubUnit_input_names\n",
    "    SubUnit_output_name, info_dict = SubUnitLayer(input_names, RECFLD_TO_TENSOR)\n",
    "    \n",
    "    print(SubUnit_output_name)\n",
    "    print(info_dict['info'].shape)\n",
    "    OUTPUT_TO_TENSOR[SubUnit_output_name] = info_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba52978a-475b-4294-a87e-a29e73ce60c6",
   "metadata": {},
   "source": [
    "# EmbedBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ace42fd-6140-4c93-81a5-976c75b0635a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubUnitName</th>\n",
       "      <th>input_names</th>\n",
       "      <th>output_name</th>\n",
       "      <th>output_layerid</th>\n",
       "      <th>SubUnit_BasicNN_List</th>\n",
       "      <th>SubUnit_DefaultBasicNN_List</th>\n",
       "      <th>SubUnit_BasicNN_Config_List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E</td>\n",
       "      <td>[B-P-InfoGrn]</td>\n",
       "      <td>B-P-Info</td>\n",
       "      <td>3</td>\n",
       "      <td>[expander-CateEmbed]</td>\n",
       "      <td>[{'full_recfldgrn': 'B-P-InfoGrn', 'Info': ['P...</td>\n",
       "      <td>[{'nn_type_nn_name': 'expander-CateEmbed', 'Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E</td>\n",
       "      <td>[B-P-EC-PNSect-TknzGrn]</td>\n",
       "      <td>B-P-EC-PNSect-Tknz</td>\n",
       "      <td>5</td>\n",
       "      <td>[expander-LLMEmbed]</td>\n",
       "      <td>[{'full_recfldgrn': 'B-P-EC-PNSect-TknzGrn', '...</td>\n",
       "      <td>[{'nn_type_nn_name': 'expander-LLMEmbed', 'Bas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SubUnitName              input_names         output_name  output_layerid  \\\n",
       "0           E            [B-P-InfoGrn]            B-P-Info               3   \n",
       "1           E  [B-P-EC-PNSect-TknzGrn]  B-P-EC-PNSect-Tknz               5   \n",
       "\n",
       "   SubUnit_BasicNN_List                        SubUnit_DefaultBasicNN_List  \\\n",
       "0  [expander-CateEmbed]  [{'full_recfldgrn': 'B-P-InfoGrn', 'Info': ['P...   \n",
       "1   [expander-LLMEmbed]  [{'full_recfldgrn': 'B-P-EC-PNSect-TknzGrn', '...   \n",
       "\n",
       "                         SubUnit_BasicNN_Config_List  \n",
       "0  [{'nn_type_nn_name': 'expander-CateEmbed', 'Ba...  \n",
       "1  [{'nn_type_nn_name': 'expander-LLMEmbed', 'Bas...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eventually, we get a df_SubUnit\n",
    "df_SubUnit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ac0791-6020-4cfa-b5b3-186ae2bb2bb9",
   "metadata": {},
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c085c0e-22c4-46e7-b1ea-d51b2a89eb76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# from .subunit import SubUnit_Layer\n",
    "\n",
    "\n",
    "class EmbedBlockLayer(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, df_SubUnit):\n",
    "        super(EmbedBlockLayer, self).__init__()\n",
    "        self.df_SubUnit = df_SubUnit\n",
    "        self.SubUnitDict = torch.nn.ModuleDict()\n",
    "        \n",
    "        for idx, SubUnit_info in df_SubUnit.iterrows():\n",
    "            output_name = SubUnit_info['output_name']\n",
    "            SubUnitLayer = SubUnit_Layer(SubUnit_info)\n",
    "            self.SubUnitDict[output_name] = SubUnitLayer\n",
    "\n",
    "    def forward(self, RECFLD_TO_TENSOR):\n",
    "        \n",
    "        OUTPUT_TO_TENSOR = {}\n",
    "        \n",
    "        for output_name, SubUnitLayer in self.SubUnitDict.items():\n",
    "            input_names = SubUnitLayer.SubUnit_input_names\n",
    "            SubUnit_output_name, info_dict = SubUnitLayer(input_names, RECFLD_TO_TENSOR)\n",
    "            \n",
    "            assert output_name == SubUnit_output_name\n",
    "            OUTPUT_TO_TENSOR[SubUnit_output_name] = info_dict\n",
    "        \n",
    "        return OUTPUT_TO_TENSOR\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ac9fd2-177f-4508-b706-bf2267758ba6",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5464ff4a-aa9d-432d-990a-12776c5ba84f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EmbedBlockLayer(\n",
       "  (SubUnitDict): ModuleDict(\n",
       "    (B-P-Info): SubUnit_Layer(\n",
       "      (LayersDict): ModuleDict(\n",
       "        (0_expander-CateEmbed): Expander_Layer(\n",
       "          (EmbedDict): ModuleDict(\n",
       "            (B-P-InfoGrn_tknidx): CateEmbeddingLayer(\n",
       "              (embedding): Embedding(55, 128, padding_idx=0)\n",
       "            )\n",
       "            (B-P-InfoGrn_fldidx): CateEmbeddingLayer(\n",
       "              (embedding): Embedding(5, 128, padding_idx=0)\n",
       "            )\n",
       "          )\n",
       "          (postprocess): ModuleDict(\n",
       "            (activator): GELU(approximate='none')\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "            (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (B-P-EC-PNSect-Tknz): SubUnit_Layer(\n",
       "      (LayersDict): ModuleDict(\n",
       "        (0_expander-LLMEmbed): Expander_Layer(\n",
       "          (EmbedDict): ModuleDict(\n",
       "            (B-P-EC-PNSect-TknzGrn_tknidx): LLMEmbeddingLayer(\n",
       "              (LLM): BertModel(\n",
       "                (embeddings): BertEmbeddings(\n",
       "                  (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "                  (position_embeddings): Embedding(512, 768)\n",
       "                  (token_type_embeddings): Embedding(2, 768)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (encoder): BertEncoder(\n",
       "                  (layer): ModuleList(\n",
       "                    (0-11): 12 x BertLayer(\n",
       "                      (attention): BertAttention(\n",
       "                        (self): BertSelfAttention(\n",
       "                          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (dropout): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                        (output): BertSelfOutput(\n",
       "                          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                          (dropout): Dropout(p=0.1, inplace=False)\n",
       "                        )\n",
       "                      )\n",
       "                      (intermediate): BertIntermediate(\n",
       "                        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                        (intermediate_act_fn): GELUActivation()\n",
       "                      )\n",
       "                      (output): BertOutput(\n",
       "                        (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                        (dropout): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "                (pooler): BertPooler(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (activation): Tanh()\n",
       "                )\n",
       "              )\n",
       "              (linear): Linear(in_features=768, out_features=128, bias=True)\n",
       "            )\n",
       "            (B-P-EC-PNSect-TknzGrn_fldidx): CateEmbeddingLayer(\n",
       "              (embedding): Embedding(3, 128, padding_idx=0)\n",
       "            )\n",
       "          )\n",
       "          (postprocess): ModuleDict(\n",
       "            (activator): GELU(approximate='none')\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "            (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EmbedBlock = EmbedBlockLayer(df_SubUnit)\n",
    "\n",
    "EmbedBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9432e540-2979-48fd-bce3-10ea5852f839",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P-InfoGrn', 'B-P-EC-PNSect-TknzGrn']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the Input\n",
    "RECFLD_TO_TENSOR = {}\n",
    "for full_recfldgrn in full_recfldgrn_list:\n",
    "    RECFLD_TO_TENSOR[full_recfldgrn] = {k: v for k, v in batch_rfg.items() if full_recfldgrn in k}\n",
    "    \n",
    "[i for i in RECFLD_TO_TENSOR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff6e7f1-3c84-4523-a9cb-6e1a5b050eb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OUTPUT_TO_TENSOR = EmbedBlock(RECFLD_TO_TENSOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de09c1fe-5907-4d66-b185-573f09ec770d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for k, v in OUTPUT_TO_TENSOR.items():\n",
    "    print(k, v['info'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4935d2cf-d74c-40ac-8138-88b04e905399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a791ad3a-eecd-4bae-9373-3c2f02fee955",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
