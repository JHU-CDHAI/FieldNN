{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c6d4c1-3173-4cea-a5c3-804177c1bac3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/floydluo/Library/CloudStorage/OneDrive-JohnsHopkins/000Projects/0000-Infrastructure/0000-RecFld/FieldNN\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877c26b6-8bdd-4817-867e-9325fc7cb7ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  PreCode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1354ec4a-0c7a-424b-a6dd-9102be454423",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DataLoader & Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e23b291b-be62-4950-8406-c8fc3518f85a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 <---- dataset\n",
      "1 <---- dataset\n",
      "B-P-InfoGrn_wgt torch.Size([4, 43])\n",
      "B-P-InfoGrn_tknidx torch.Size([4, 43])\n",
      "B-P-InfoGrn_fldidx torch.Size([4, 43])\n",
      "B-P-EC-PNSect-TknzGrn_wgt torch.Size([4, 23, 14, 221])\n",
      "B-P-EC-PNSect-TknzGrn_tknidx torch.Size([4, 23, 14, 221])\n",
      "B-P-EC-PNSect-TknzGrn_fldidx torch.Size([4, 23, 14, 221])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from fieldnn.dataset import RFGDataset, my_collate_fn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "Tensor_folder = 'data/ProcData/FldGrnTensor/'\n",
    "recfldgrn_list = ['P-InfoGrn',  'P-EC-PNSect-TknzGrn']\n",
    "full_recfldgrn_list = ['B-' + i for i in recfldgrn_list]\n",
    "\n",
    "# from the get_grain_fn to get the Elig_Set.\n",
    "Elig_Set = ['P4', 'P5', 'P6', 'P7']\n",
    "\n",
    "dataset = RFGDataset(Tensor_folder, recfldgrn_list, Elig_Set, RecRootID = 'PID')\n",
    "print(len(dataset), '<---- dataset')\n",
    "dataloader = DataLoader(dataset, batch_size = 4, shuffle = True, collate_fn = my_collate_fn)\n",
    "print(len(dataloader), '<---- dataset')\n",
    "\n",
    "\n",
    "for idx, batch in enumerate(dataloader):\n",
    "    # print(f'\\n------ {idx}')\n",
    "    batch_rfg, batch_y = batch\n",
    "    for k, v in batch_rfg.items(): print(k, v.shape)\n",
    "    break\n",
    "    # for k, v in batch_rfg.items(): print(k, v.shape)\n",
    "    # print(batch_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7c30bab-14cf-4d04-aa9c-d2e7ebdf5703",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P-InfoGrn', 'B-P-EC-PNSect-TknzGrn']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the Input\n",
    "RECFLD_TO_TENSOR = {}\n",
    "for full_recfldgrn in full_recfldgrn_list:\n",
    "    RECFLD_TO_TENSOR[full_recfldgrn] = {k: v for k, v in batch_rfg.items() if full_recfldgrn in k}\n",
    "    \n",
    "[i for i in RECFLD_TO_TENSOR]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca2206f-b6ab-4cd3-af09-ee8cb926d05f",
   "metadata": {},
   "source": [
    "## EmbedBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bf623db-bab4-42e5-85fa-4884cd8d3506",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fieldnn.dataflowfn.embedflowfn import get_EmbeddingBlock_SubUnit\n",
    "from fieldnn.dataflowfn.baseflowfn import mapping_SubUnitName_to_SubUnitNNList\n",
    "from fieldnn.dataflowfn.baseflowfn import get_SubUnit_Default_NNPara_List\n",
    "from fieldnn.dataflowfn.baseflowfn import get_SubUnit_BasicNN_Config_List\n",
    "\n",
    "############################################# Hyperparameters\n",
    "default_BasicNNtype_To_NNName = {\n",
    "    'expander': None, # will be updated according to the Grn Type\n",
    "    'reducer': 'ReduceMax',\n",
    "    'merger': 'MergeConcat',\n",
    "    'learner': None, # TODO: ignore this currently\n",
    "    \n",
    "}\n",
    "#############################################\n",
    "\n",
    "############################\n",
    "embed_size = 128\n",
    "process = {'activator': 'gelu',\n",
    "           'dropout': {'p': 0.5, 'inplace': False},\n",
    "           'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "############################\n",
    "\n",
    "\n",
    "###########################################################\n",
    "psn_embedprocess = {\n",
    "    # 'activator': 'gelu',\n",
    "    # 'dropout': {'p': 0.5, 'inplace': False},\n",
    "    # 'layernorm': {'eps': 1e-05, 'elementwise_affine': True}\n",
    "}\n",
    "\n",
    "learner_default_dict = {\n",
    "    'TFM': {'psn_max': 512, \n",
    "            'psn_embedprocess': psn_embedprocess},\n",
    "    'Linear': {'initrange': 0.1},   \n",
    "}\n",
    "###########################################################\n",
    "\n",
    "\n",
    "######################\n",
    "default_E_subunitName = 'EL'\n",
    "fldgrn_folder = 'data/ProcData/FldGrnInfo'\n",
    "# learner_default_dict = {} # To update it in the future. \n",
    "######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d219a350-ac51-4f96-9c27-4ed388e97ec7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P-InfoGrn', 'B-P-EC-PNSect-TknzGrn']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_recfldgrn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d7be33f-9348-434f-9bdb-23cfddcba301",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubUnitName</th>\n",
       "      <th>input_names</th>\n",
       "      <th>output_name</th>\n",
       "      <th>output_layerid</th>\n",
       "      <th>SubUnit_BasicNN_List</th>\n",
       "      <th>SubUnit_DefaultBasicNN_List</th>\n",
       "      <th>SubUnit_BasicNN_Config_List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EL</td>\n",
       "      <td>[B-P-InfoGrn]</td>\n",
       "      <td>B-P-Info</td>\n",
       "      <td>3</td>\n",
       "      <td>[expander-CateEmbed, learner-TFM]</td>\n",
       "      <td>[{'full_recfldgrn': 'B-P-InfoGrn', 'Info': ['P...</td>\n",
       "      <td>[{'nn_type_nn_name': 'expander-CateEmbed', 'Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EL</td>\n",
       "      <td>[B-P-EC-PNSect-TknzGrn]</td>\n",
       "      <td>B-P-EC-PNSect-Tknz</td>\n",
       "      <td>5</td>\n",
       "      <td>[expander-LLMEmbed, learner-TFM]</td>\n",
       "      <td>[{'full_recfldgrn': 'B-P-EC-PNSect-TknzGrn', '...</td>\n",
       "      <td>[{'nn_type_nn_name': 'expander-LLMEmbed', 'Bas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SubUnitName              input_names         output_name  output_layerid  \\\n",
       "0          EL            [B-P-InfoGrn]            B-P-Info               3   \n",
       "1          EL  [B-P-EC-PNSect-TknzGrn]  B-P-EC-PNSect-Tknz               5   \n",
       "\n",
       "                SubUnit_BasicNN_List  \\\n",
       "0  [expander-CateEmbed, learner-TFM]   \n",
       "1   [expander-LLMEmbed, learner-TFM]   \n",
       "\n",
       "                         SubUnit_DefaultBasicNN_List  \\\n",
       "0  [{'full_recfldgrn': 'B-P-InfoGrn', 'Info': ['P...   \n",
       "1  [{'full_recfldgrn': 'B-P-EC-PNSect-TknzGrn', '...   \n",
       "\n",
       "                         SubUnit_BasicNN_Config_List  \n",
       "0  [{'nn_type_nn_name': 'expander-CateEmbed', 'Ba...  \n",
       "1  [{'nn_type_nn_name': 'expander-LLMEmbed', 'Bas...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_SubUnit = get_EmbeddingBlock_SubUnit(full_recfldgrn_list, default_E_subunitName)\n",
    "df_SubUnit['SubUnit_BasicNN_List'] = df_SubUnit.apply(lambda x: mapping_SubUnitName_to_SubUnitNNList(x['SubUnitName'], \n",
    "                                                                    x['input_names'],\n",
    "                                                                    default_BasicNNtype_To_NNName),  axis = 1)\n",
    "\n",
    "df_SubUnit['SubUnit_DefaultBasicNN_List'] = df_SubUnit.apply(lambda x: get_SubUnit_Default_NNPara_List(x['SubUnit_BasicNN_List'], \n",
    "                                                               x['input_names'],\n",
    "                                                               fldgrn_folder, \n",
    "                                                               learner_default_dict), axis = 1)\n",
    "df_SubUnit['SubUnit_BasicNN_Config_List'] = df_SubUnit.apply(lambda x: get_SubUnit_BasicNN_Config_List(x['SubUnit_BasicNN_List'], \n",
    "                                                               x['SubUnit_DefaultBasicNN_List'], \n",
    "                                                               x['input_names'], \n",
    "                                                               x['output_name'], \n",
    "                                                                embed_size, \n",
    "                                                                process, ), axis = 1)\n",
    "df_Embed_SubUnit = df_SubUnit\n",
    "df_Embed_SubUnit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2cc8bb0-d75b-4e96-9df6-e98f93e6d0c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P-Info torch.Size([4, 43, 128])\n",
      "B-P-EC-PNSect-Tknz torch.Size([4, 23, 14, 221, 128])\n"
     ]
    }
   ],
   "source": [
    "from fieldnn.module.embedblock import EmbedBlockLayer\n",
    "\n",
    "EmbedBlock = EmbedBlockLayer(df_SubUnit)\n",
    "\n",
    "RECFLD_TO_EMBEDTESNOR = EmbedBlock(RECFLD_TO_TENSOR)\n",
    "\n",
    "for k, v in RECFLD_TO_EMBEDTESNOR.items():\n",
    "    print(k, v['info'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a9568d-47fd-424b-a4e0-9032a2378df6",
   "metadata": {},
   "source": [
    "## ReprBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a2b470a-7acd-40c1-aac1-bcb4fb8ab1fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fieldnn.dataflowfn.baseflowfn import mapping_SubUnitName_to_SubUnitNNList\n",
    "from fieldnn.dataflowfn.baseflowfn import generate_BasicNN_Config\n",
    "from fieldnn.dataflowfn.baseflowfn import get_SubUnit_Default_NNPara_List\n",
    "from fieldnn.dataflowfn.baseflowfn import get_SubUnit_BasicNN_Config_List\n",
    "from fieldnn.dataflowfn.reprflowfn import get_Repr_dataflow_table\n",
    "from fieldnn.dataflowfn.reprflowfn import update_df_Repr_dataflow\n",
    "from fieldnn.dataflowfn.reprflowfn import update_df_Repr_dataflow_completename\n",
    "from fieldnn.dataflowfn.reprflowfn import get_Repr_SubUnit_List\n",
    "\n",
    "#################\n",
    "default_R_subunit_name = 'RL'\n",
    "default_MR_subunit_name = 'ML'\n",
    "#################\n",
    "\n",
    "############################################# Hyperparameters\n",
    "default_BasicNNtype_To_NNName = {\n",
    "    'expander': None, # will be updated according to the Grn Type\n",
    "    'reducer': 'Max',\n",
    "    'merger': 'Merger',\n",
    "    'learner': None, # TODO: ignore this currently\n",
    "}\n",
    "#############################################\n",
    "\n",
    "#############################################\n",
    "fldgrn_folder = 'data/ProcData/FldGrnInfo'\n",
    "learner_default_dict = {} # To update it in the future. \n",
    "#############################################\n",
    "\n",
    "############################\n",
    "embed_size = 128\n",
    "process = {'activator': 'gelu',\n",
    "           'dropout': {'p': 0.5, 'inplace': False},\n",
    "           'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "############################\n",
    "\n",
    "###########################################################\n",
    "psn_embedprocess = {\n",
    "    # 'activator': 'gelu',\n",
    "    # 'dropout': {'p': 0.5, 'inplace': False},\n",
    "    # 'layernorm': {'eps': 1e-05, 'elementwise_affine': True}\n",
    "}\n",
    "\n",
    "learner_default_dict = {\n",
    "    'TFM': {'psn_max': 512, \n",
    "            'psn_embedprocess': psn_embedprocess},\n",
    "    'Linear': {'initrange': 0.1},   \n",
    "}\n",
    "###########################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe3d4fdd-6804-4986-b236-e36e62ec4e1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_recfldgrn_list_new = [i.replace('Grn', '') for i in full_recfldgrn_list]\n",
    "df_dataflow = get_Repr_dataflow_table(full_recfldgrn_list_new)\n",
    "df_dataflow_new = update_df_Repr_dataflow(df_dataflow)\n",
    "df_dataflow = df_dataflow_new.copy()\n",
    "df_SubUnit = get_Repr_SubUnit_List(df_dataflow, default_R_subunit_name, default_MR_subunit_name)\n",
    "df_SubUnit['SubUnit_BasicNN_List'] = df_SubUnit.apply(lambda x: mapping_SubUnitName_to_SubUnitNNList(x['SubUnitName'], \n",
    "                                                                    x['input_names'],\n",
    "                                                                    default_BasicNNtype_To_NNName),  axis = 1)\n",
    "df_SubUnit['SubUnit_DefaultBasicNN_List'] = df_SubUnit.apply(lambda x: get_SubUnit_Default_NNPara_List(x['SubUnit_BasicNN_List'], \n",
    "                                                               x['input_names'],\n",
    "                                                               fldgrn_folder, \n",
    "                                                               learner_default_dict), axis = 1)\n",
    "df_SubUnit['SubUnit_BasicNN_Config_List'] = df_SubUnit.apply(lambda x: get_SubUnit_BasicNN_Config_List(x['SubUnit_BasicNN_List'], \n",
    "                                                               x['SubUnit_DefaultBasicNN_List'], \n",
    "                                                               x['input_names'], \n",
    "                                                               x['output_name'], \n",
    "                                                                embed_size, \n",
    "                                                                process, \n",
    "                                                               ), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da186015-cbda-43ac-8460-393cb2c576a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "There is no layer for \"Max\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfieldnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreprblock\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReprBlockLayer\n\u001b[1;32m      3\u001b[0m df_Repr_SubUnit \u001b[38;5;241m=\u001b[39m df_SubUnit\n\u001b[0;32m----> 4\u001b[0m ReprBlock \u001b[38;5;241m=\u001b[39m \u001b[43mReprBlockLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_SubUnit\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-JohnsHopkins/000Projects/0000-Infrastructure/0000-RecFld/FieldNN/fieldnn/module/reprblock.py:14\u001b[0m, in \u001b[0;36mReprBlockLayer.__init__\u001b[0;34m(self, df_SubUnit)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, SubUnit_info \u001b[38;5;129;01min\u001b[39;00m df_SubUnit\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m     13\u001b[0m     output_name \u001b[38;5;241m=\u001b[39m SubUnit_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 14\u001b[0m     SubUnitLayer \u001b[38;5;241m=\u001b[39m \u001b[43mSubUnit_Layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSubUnit_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSubUnitDict[output_name] \u001b[38;5;241m=\u001b[39m SubUnitLayer\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-JohnsHopkins/000Projects/0000-Infrastructure/0000-RecFld/FieldNN/fieldnn/module/subunit.py:61\u001b[0m, in \u001b[0;36mSubUnit_Layer.__init__\u001b[0;34m(self, SubUnit_info)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreducer\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m nn_type_nn_name:\n\u001b[1;32m     60\u001b[0m     reducer_para \u001b[38;5;241m=\u001b[39m Basic_Config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreducer_para\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 61\u001b[0m     NN \u001b[38;5;241m=\u001b[39m \u001b[43mReducer_Layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_names_nnlvl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_name_nnlvl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreducer_para\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayersDict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnn_type_nn_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m NN\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmerger\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m nn_type_nn_name:\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-JohnsHopkins/000Projects/0000-Infrastructure/0000-RecFld/FieldNN/fieldnn/basicnn/reducer/__init__.py:45\u001b[0m, in \u001b[0;36mReducer_Layer.__init__\u001b[0;34m(self, input_names_nnlvl, output_name_nnlvl, reducer_layer_para)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_size \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThere is no layer for \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnn_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Part 2: PostProcess\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModuleDict()\n",
      "\u001b[0;31mValueError\u001b[0m: There is no layer for \"Max\""
     ]
    }
   ],
   "source": [
    "from fieldnn.module.reprblock import ReprBlockLayer\n",
    "\n",
    "df_Repr_SubUnit = df_SubUnit\n",
    "ReprBlock = ReprBlockLayer(df_SubUnit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c9915c-3e63-4fec-9d35-db2233c37445",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fld_updates_dict = {}\n",
    "# for i in RECFLD_TO_EMBEDTESNOR:\n",
    "#     layernum = len(i.split('-'))\n",
    "#     fld = i.split('-')[-1]\n",
    "#     if '@' in fld:\n",
    "#         # print(fld)\n",
    "#         neat_i = '-'.join(i.split('-')[:-1]) + '-' + fld.split('@')[0]\n",
    "#         # print(neat_i)\n",
    "#         same_neat_list = [t for t in RECFLD_TO_EMBEDTESNOR if neat_i + '@' in t]\n",
    "#         # print(same_neat_list)\n",
    "#         if len(same_neat_list) == 1: # itself\n",
    "#             # RECFLD_TO_EMBEDTESNOR[]\n",
    "#             fld_updates_dict[i] = neat_i\n",
    "            \n",
    "# for old, new in fld_updates_dict.items():\n",
    "#     RECFLD_TO_EMBEDTESNOR[new] = RECFLD_TO_EMBEDTESNOR.pop(old)\n",
    "    \n",
    "    \n",
    "[i for i in RECFLD_TO_EMBEDTESNOR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2feed97-f72e-43b0-9dfa-42174b8a5114",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OUTPUT_TO_TENSOR = ReprBlock(RECFLD_TO_EMBEDTESNOR)\n",
    "[i for i in OUTPUT_TO_TENSOR]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8aee38-cfe5-4a62-b1dc-1943fe509495",
   "metadata": {},
   "source": [
    "# RecModelPL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2f90e9-09e8-4a99-8832-103d1be086ad",
   "metadata": {},
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a056ff4a-6065-47a1-8db2-09e3d8df955f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "# from .embedblock import EmbedBlockLayer\n",
    "# from .reprblock import ReprBlockLayer\n",
    "from fieldnn.module.embedblock import EmbedBlockLayer\n",
    "from fieldnn.module.reprblock import ReprBlockLayer\n",
    "\n",
    "\n",
    "class RecModelPL(pl.LightningModule):\n",
    "    \"\"\" Naive softmax-layer \"\"\"\n",
    "    def __init__(self, df_Embed_SubUnit, df_Repr_SubUnit, \n",
    "                 actn_fn_name, loss_fn_name,\n",
    "                 output_name, embed_size, output_size):\n",
    "        \n",
    "        '''\n",
    "            df_Embed_SubUnit: df_SubUnit for the Embed Block.\n",
    "            df_Repr_SubUnit: df_Repr_SubUnit for the Repr Block.\n",
    "            actn_fn_name: like sigmoid, softmax\n",
    "            loss_fn_name: like CrossEntropy, BCELoss.\n",
    "            output_name: the featvec name.\n",
    "            embed_size: the featvec dim.\n",
    "            output_size: the output dim size. if actn_fn is softmax, then label sets. if actn_fn is sigmoid, then 1. \n",
    "            \n",
    "        '''\n",
    "        super(RecModelPL, self).__init__()\n",
    "        \n",
    "        self.output_name = output_name\n",
    "        self.EmbedBlock = EmbedBlockLayer(df_Embed_SubUnit)\n",
    "        self.ReprBlock  = ReprBlockLayer(df_Repr_SubUnit)\n",
    "        self.OutputBlock = torch.nn.Linear(embed_size, output_size)\n",
    "        \n",
    "        self.actn_fn_name = actn_fn_name\n",
    "        if self.actn_fn_name == 'Sigmoid':\n",
    "            self.actn_method = torch.nn.Sigmoid()\n",
    "            self.actn_fn = lambda outputvecs: self.actn_method(outputvecs) # will return probs \n",
    "        elif self.actn_fn_name == 'Softmax':\n",
    "            self.actn_method = torch.nn.Softmax()\n",
    "            self.actn_fn = lambda outputvecs: self.actn_method(outputvecs, dim = 1) # will return probs \n",
    "        else:\n",
    "            raise ValueError(f'Activation Function Name {actn_fn_name} is not available yet')\n",
    "        \n",
    "        self.loss_fn_name = loss_fn_name\n",
    "        if self.loss_fn_name == 'BCELoss':\n",
    "            assert self.actn_fn_name == 'Sigmoid'\n",
    "            self.loss_method = torch.nn.BCELoss()\n",
    "            self.loss_fn = lambda probs, targets: self.loss_method(probs, targets) # will return loss\n",
    "        \n",
    "        elif self.loss_fn_name == 'CrossEntropyLoss':\n",
    "            assert self.actn_fn_name == 'Softmax'\n",
    "            self.loss_method = torch.nn.CrossEntropyLoss()\n",
    "            self.loss_fn = lambda probs, targets: self.loss_method(probs, targets) # will return loss\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f'Loss Function Name {loss_fn_name} is not available yet')\n",
    "        \n",
    "\n",
    "    def get_REPR_TENSOR(self, batch_rfg):\n",
    "        # (1) Embed Part\n",
    "        # get the full_recfldgrn_list\n",
    "        full_recfldgrn_list = list(set([i.split('_')[0] for i in batch_rfg]))\n",
    "\n",
    "        # prepare RECFLD_TO_TENSOR\n",
    "        RECFLD_TO_TENSOR = {}\n",
    "        for full_recfldgrn in full_recfldgrn_list:\n",
    "            RECFLD_TO_TENSOR[full_recfldgrn] = {k: v for k, v in batch_rfg.items() if full_recfldgrn in k}\n",
    "    \n",
    "        # get RECLD_TO_EMBEDTENSOR from RECFLD_TO_TENSOR and EmbedBlock\n",
    "        RECFLD_TO_EMBEDTESNOR = self.EmbedBlock(RECFLD_TO_TENSOR)\n",
    "        \n",
    "        # (2) Update RECFLD_TO_EMBEDTESNOR.\n",
    "        # update the names of full_recfldgrn_list\n",
    "            \n",
    "        # (3) REPR Part\n",
    "        # get the OUTPUT_TO_TENSOR data holder\n",
    "        REPR_TENSOR = self.ReprBlock(RECFLD_TO_EMBEDTESNOR)\n",
    "        return REPR_TENSOR\n",
    "\n",
    "    def loss_funciton(self, batch_rfg, batch_targets):\n",
    "        # batch -> Embed -> Repr -> repr_tensor\n",
    "        REPR_TENSOR = self.get_REPR_TENSOR(batch_rfg)\n",
    "        info_dict = REPR_TENSOR[self.output_name]\n",
    "        featvecs = info_dict['info']\n",
    "        outputvecs = self.OutputBlock(featvecs)\n",
    "        probs = self.actn_fn(outputvecs) \n",
    "        batch_targets = batch_targets.float()\n",
    "        l = self.loss_fn(probs, batch_targets)\n",
    "        return l\n",
    "        \n",
    "    def forward(self, batch_rfg):\n",
    "        # forward is the method for the inference.\n",
    "        # batch -> Embed -> Repr -> repr tensor\n",
    "        REPR_TENSOR = self.get_REPR_TENSOR(batch_rfg)\n",
    "        info_dict = REPR_TENSOR[self.output_name]\n",
    "        featvecs = info_dict['info']\n",
    "        outputvecs = self.OutputBlock(featvecs)\n",
    "        probs = self.actn_fn(outputvecs) \n",
    "        return probs\n",
    "    \n",
    "    ############# pl part.\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        batch_rfg, batch_targets = batch\n",
    "        loss = self.loss_funciton(batch_rfg, batch_targets)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self._shared_eval(batch, batch_idx, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self._shared_eval(batch, batch_idx, \"test\")\n",
    "\n",
    "    def _shared_eval(self, batch, batch_idx, prefix):\n",
    "        batch_rfg, batch_targets = batch\n",
    "        loss = self.loss_funciton(batch_rfg, batch_targets)\n",
    "        self.log(f\"{prefix}_loss\", loss)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cf1737-546d-41c8-bc3c-52a1186d6e1c",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7b57f2-4c35-409f-bd22-6fdd2379eff4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fieldnn.dataflowfn.embedflowfn import get_EmbeddingBlock_SubUnit\n",
    "from fieldnn.dataflowfn.baseflowfn import mapping_SubUnitName_to_SubUnitNNList\n",
    "from fieldnn.dataflowfn.baseflowfn import get_SubUnit_Default_NNPara_List\n",
    "from fieldnn.dataflowfn.baseflowfn import get_SubUnit_BasicNN_Config_List\n",
    "from fieldnn.dataflowfn.reprflowfn import get_Repr_dataflow_table\n",
    "from fieldnn.dataflowfn.reprflowfn import update_df_Repr_dataflow\n",
    "from fieldnn.dataflowfn.reprflowfn import update_df_Repr_dataflow_completename\n",
    "from fieldnn.dataflowfn.reprflowfn import get_Repr_SubUnit_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f687d4c-7d52-4a27-9936-00a01353a60a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############\n",
    "recfldgrn_list = ['P@PatEcInfo-InfoGrn',  'P-EC-PNSect@AllText-TknzGrn']\n",
    "############\n",
    "\n",
    "############################################# Hyperparameters\n",
    "default_BasicNNtype_To_NNName = {\n",
    "    'expander': None, # will be updated according to the Grn Type\n",
    "    'reducer': 'ReMax',\n",
    "    'merger': 'Merger',\n",
    "    'learner': None, # TODO: ignore this currently\n",
    "}\n",
    "#############################################\n",
    "\n",
    "############################\n",
    "embed_size = 128\n",
    "process = {'activator': 'gelu',\n",
    "           'dropout': {'p': 0.5, 'inplace': False},\n",
    "           'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "############################\n",
    "\n",
    "\n",
    "###########################################################\n",
    "psn_embedprocess = {\n",
    "    # 'activator': 'gelu',\n",
    "    # 'dropout': {'p': 0.5, 'inplace': False},\n",
    "    # 'layernorm': {'eps': 1e-05, 'elementwise_affine': True}\n",
    "}\n",
    "\n",
    "learner_default_dict = {\n",
    "    'TFM': {'psn_max': 512, \n",
    "            'psn_embedprocess': psn_embedprocess},\n",
    "    'Linear': {'initrange': 0.1},   \n",
    "}\n",
    "###########################################################\n",
    "\n",
    "\n",
    "############################\n",
    "default_E_subunitName = 'EL'\n",
    "default_R_subunit_name = 'RL'\n",
    "default_MR_subunit_name = 'ML'\n",
    "fldgrn_folder = 'data/ProcData/FldGrnInfo'\n",
    "learner_default_dict = {} # To update it in the future. \n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ecbedd-f70e-4c87-b29b-6e822d1e1b80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "full_recfldgrn_list = ['B-' + i for i in recfldgrn_list]\n",
    "df_SubUnit = get_EmbeddingBlock_SubUnit(full_recfldgrn_list, default_E_subunitName)\n",
    "df_SubUnit['SubUnit_BasicNN_List'] = df_SubUnit.apply(lambda x: mapping_SubUnitName_to_SubUnitNNList(x['SubUnitName'], \n",
    "                                                                    x['input_names'],\n",
    "                                                                    default_BasicNNtype_To_NNName), axis = 1)\n",
    "df_SubUnit['SubUnit_DefaultBasicNN_List'] = df_SubUnit.apply(lambda x: get_SubUnit_Default_NNPara_List(x['SubUnit_BasicNN_List'], \n",
    "                                                               x['input_names'],\n",
    "                                                               fldgrn_folder, \n",
    "                                                               learner_default_dict), axis = 1)\n",
    "df_SubUnit['SubUnit_BasicNN_Config_List'] = df_SubUnit.apply(lambda x: get_SubUnit_BasicNN_Config_List(x['SubUnit_BasicNN_List'], \n",
    "                                                               x['SubUnit_DefaultBasicNN_List'], \n",
    "                                                               x['input_names'], \n",
    "                                                               x['output_name'], \n",
    "                                                                embed_size, \n",
    "                                                                process, ), axis = 1)\n",
    "df_Embed_SubUnit = df_SubUnit\n",
    "df_Embed_SubUnit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b325846-5024-4c68-bed8-abcb8ebb7cb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_recfldgrn_list_new = [i.replace('Grn', '') for i in full_recfldgrn_list]\n",
    "df_dataflow = get_Repr_dataflow_table(full_recfldgrn_list_new)\n",
    "df_dataflow_new = update_df_Repr_dataflow(df_dataflow, style = 'Reducer&Merger')\n",
    "df_dataflow = df_dataflow_new.copy()\n",
    "df_SubUnit = get_Repr_SubUnit_List(df_dataflow, default_R_subunit_name, default_MR_subunit_name)\n",
    "df_SubUnit['SubUnit_BasicNN_List'] = df_SubUnit.apply(lambda x: mapping_SubUnitName_to_SubUnitNNList(x['SubUnitName'], \n",
    "                                                                    x['input_names'],\n",
    "                                                                    default_BasicNNtype_To_NNName),  axis = 1)\n",
    "df_SubUnit['SubUnit_DefaultBasicNN_List'] = df_SubUnit.apply(lambda x: get_SubUnit_Default_NNPara_List(x['SubUnit_BasicNN_List'], \n",
    "                                                               x['input_names'],\n",
    "                                                               fldgrn_folder, \n",
    "                                                               learner_default_dict), axis = 1)\n",
    "df_SubUnit['SubUnit_BasicNN_Config_List'] = df_SubUnit.apply(lambda x: get_SubUnit_BasicNN_Config_List(x['SubUnit_BasicNN_List'], \n",
    "                                                               x['SubUnit_DefaultBasicNN_List'], \n",
    "                                                               x['input_names'], \n",
    "                                                               x['output_name'], \n",
    "                                                                embed_size, \n",
    "                                                                process, \n",
    "                                                               ), axis = 1)\n",
    "df_SubUnit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fcb056-cc87-41f2-85fe-cbf4fe18554d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_Embed_SubUnit = df_Embed_SubUnit\n",
    "df_Repr_SubUnit = df_Repr_SubUnit\n",
    "output_name = 'B-P'\n",
    "embed_size = embed_size\n",
    "output_size = 1\n",
    "actn_fn_name = 'Sigmoid' # torch.nn.Sigmoid()\n",
    "loss_fn_name = 'BCELoss' # torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d978ab-96b9-4914-878c-70d3af8fce0a",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcbf2fb-0068-4bc4-90fa-5cc28200d146",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Model = RecModelPL(df_Embed_SubUnit, df_Repr_SubUnit,  actn_fn_name, \n",
    "                   loss_fn_name, output_name, embed_size, output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f50518f-a36b-4f2d-b542-105d7a8eefed",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8e1027-e123-4c37-a46e-ac4176bce480",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from fieldnn.dataset import RFGDataset, my_collate_fn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(Tensor_folder)\n",
    "print(recfldgrn_list)\n",
    "print(full_recfldgrn_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd99597-08db-425f-955b-f3f902faf4c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from the get_grain_fn to get the Elig_Set.\n",
    "Elig_Set = ['P4', 'P5', 'P6', 'P7']\n",
    "\n",
    "dataset = RFGDataset(Tensor_folder, recfldgrn_list, Elig_Set, RecRootID = 'PID')\n",
    "print(len(dataset), '<---- dataset')\n",
    "dataloader = DataLoader(dataset, batch_size = 2, shuffle = True, collate_fn = my_collate_fn)\n",
    "print(len(dataloader), '<---- dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4d586e-1463-45b1-b970-a941d29c08ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx, batch in enumerate(dataloader):\n",
    "    # print(f'\\n------ {idx}')\n",
    "    batch_rfg, batch_y = batch\n",
    "    for k, v in batch_rfg.items(): print(k, v.shape)\n",
    "    break\n",
    "    # for k, v in batch_rfg.items(): print(k, v.shape)\n",
    "    # print(batch_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763351e0-8551-44ad-a1b0-53823add104e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# input\n",
    "[i for i in batch_rfg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d22d15-7e61-45b3-a0ee-53b24be0a4d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # REPR output\n",
    "\n",
    "# REPR_TENSOR = Model.get_REPR_TENSOR(batch_rfg)\n",
    "\n",
    "# [i for i in REPR_TENSOR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77ada9a-5da4-4f01-9353-000cfbe5d4e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model.output_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a46a4f4-8fb3-4fba-8e9d-a3f8b1d4dc41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [i for i in batch_rfg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c221fdc3-6666-4421-8298-39e009cc0839",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# probs = Model(batch_rfg)\n",
    "# probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1ca2297e-1485-4c92-b98e-8a2ee1607b10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befaafd0-da8c-47db-a403-c1a7acdce051",
   "metadata": {},
   "source": [
    "# Test PyTorch-Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8f1ae2b8-9142-4486-b040-8bbbdbe82f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "num_gpus = 0\n",
    "checkpoint_path = 'checkpoint/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a2bf92e-9186-48e6-a2f5-6832900d9a95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "16b03fba-dd66-4c95-bed2-308f83d01160",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_rfg, batch_y = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "616f8678-b7f3-4082-a8a1-13ab8f6b666f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "36d4adb5-b117-419a-8471-f69efccc2250",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/floydluo/opt/miniconda3/envs/boost/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:72: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name        | Type            | Params\n",
      "------------------------------------------------\n",
      "0 | EmbedBlock  | EmbedBlockLayer | 109 M \n",
      "1 | ReprBlock   | ReprBlockLayer  | 1.5 K \n",
      "2 | OutputBlock | Linear          | 129   \n",
      "3 | actn_method | Sigmoid         | 0     \n",
      "4 | loss_method | BCELoss         | 0     \n",
      "------------------------------------------------\n",
      "109 M     Trainable params\n",
      "0         Non-trainable params\n",
      "109 M     Total params\n",
      "438.364   Total estimated model params size (MB)\n",
      "/Users/floydluo/opt/miniconda3/envs/boost/lib/python3.8/site-packages/lightning_fabric/loggers/csv_logs.py:188: UserWarning: Experiment logs directory checkpoint/lightning_logs/version_0 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "  rank_zero_warn(\n",
      "/Users/floydluo/opt/miniconda3/envs/boost/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/floydluo/opt/miniconda3/envs/boost/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "143ad41df03c43938c1bb43380be761c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs = num_epochs, default_root_dir = checkpoint_path)\n",
    "trainer.fit(model = Model, train_dataloaders = dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8e2bb2d2-04ec-43b0-9e5a-41a428e799dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/floydluo/opt/miniconda3/envs/boost/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:478: PossibleUserWarning: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "  rank_zero_warn(\n",
      "/Users/floydluo/opt/miniconda3/envs/boost/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c2f0ebe59e461c9aa6be4c760b4b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8326095342636108\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.8326095342636108}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the model\n",
    "# trainer.test(model, dataloaders=DataLoader(test_set))\n",
    "\n",
    "trainer.test(model = Model, dataloaders = dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f08df76-a776-4315-9d63-55318730e4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
