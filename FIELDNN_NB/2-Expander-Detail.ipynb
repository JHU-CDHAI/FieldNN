{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7588aa63-50a8-4f68-b40d-5e65e1783790",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/floydluo/Library/CloudStorage/GoogleDrive-jjluo@terpmail.umd.edu/.shortcut-targets-by-id/1qNzMmGHCg5Xa63Vw3aKbZdMXvkfT2CgC/MedStar/MS_CODE/FieldNN\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47a2660-824c-41fd-81e5-58a2207cbc74",
   "metadata": {},
   "source": [
    "# Simulate Data\n",
    "\n",
    "\n",
    "Given a field name, and first 2 dimensional numbes, simulate tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c7d713-7310-40cb-86f3-358ecf3274bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from fieldnn.utils.simulate import get_next_info, get_simulated_tensor_from_fldname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd5bf74-00e1-41c6-ab91-f25613356b2d",
   "metadata": {},
   "source": [
    "# Holder\n",
    "\n",
    "1. Current Layer:\n",
    "```python\n",
    "leng_mask = info_idx == 0 # or info_idx != 0\n",
    "leng = leng_mask.sum(-1)\n",
    "```\n",
    "\n",
    "2. Transfer\n",
    "\n",
    "```python\n",
    "old_leng = leng\n",
    "```\n",
    "\n",
    "\n",
    "3. Next Layer\n",
    "```python\n",
    "leng_mask = old_leng != 0\n",
    "leng = (leng_mask == 0).sum(-1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84cbfc6e-dd63-459a-ad83-4c5d940788f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# leng_mask = info_idx == 0\n",
    "\n",
    "import torch\n",
    "\n",
    "def get_Layer2Holder(fullname, holder, Ignore_PSN_Layers = ['B', 'P']):\n",
    "    # holder = holder\n",
    "    d = {}\n",
    "    for layername in list(reversed(fullname.split('-'))):\n",
    "        if layername in Ignore_PSN_Layers: continue\n",
    "        leng_mask = holder == 0\n",
    "        leng = (leng_mask == 0).sum(-1)\n",
    "        psn_idx = (leng_mask == False).cumsum(-1).masked_fill(leng_mask, 0)\n",
    "        d[layername] = {'holder': holder, \n",
    "                        'leng_mask': leng_mask, \n",
    "                        'leng': leng, \n",
    "                        'psn_idx': psn_idx}\n",
    "        # d[layername] = holder, psn_idx\n",
    "        holder = leng\n",
    "    Layer2Hoder = d\n",
    "    return Layer2Hoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee61bb27-4e3f-4dc8-8ba2-d7a4772acf8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def align_psn_idx(source_layer, current_layer, Layer2Idx, Layer2Holder):\n",
    "    if source_layer == current_layer:\n",
    "        psn_idx = Layer2Holder[current_layer]['psn_idx']\n",
    "        return psn_idx\n",
    "    else:\n",
    "        source_psn_idx = Layer2Holder[source_layer]['psn_idx']\n",
    "        current_leng_mask = Layer2Holder[current_layer]['leng_mask']\n",
    "        gaps = Layer2Idx[current_layer] - Layer2Idx[source_layer]\n",
    "        # print(gaps)\n",
    "        # print(layername)\n",
    "        # print(prev_info.shape)\n",
    "        # print(leng_mask.shape)\n",
    "        # print(leng.shape)\n",
    "        # print(psn_idx.shape)\n",
    "        shape0 = list(source_psn_idx.shape) + [1] * gaps\n",
    "        shape1 = current_leng_mask.shape\n",
    "        psn_idx = source_psn_idx.view(*shape0).expand(shape1).masked_fill(current_leng_mask, 0)\n",
    "        # print(cpsn_idx.shape)\n",
    "        return psn_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b8e219-ce20-4012-8e0c-3cfd74ac673d",
   "metadata": {},
   "source": [
    "# Simulate Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cb41993-c83b-4019-b270-63a024e32188",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# # ======= within forward\n",
    "\n",
    "# ###############\n",
    "# B_lenP = 3\n",
    "# B2P_lnEC = [6, 5, 2] # \n",
    "# prefix_layers_num = 2\n",
    "# vocab_size = 5001\n",
    "# Ignore_PSN_Layers = ['B', 'P']\n",
    "# ###############\n",
    "\n",
    "\n",
    "# full_recfldgrn = 'B-P-EC-Diag:Value-DiagVdftGrn' # full_recflgrn.\n",
    "\n",
    "# info_idx = get_simulated_tensor_from_fldname(full_recfldgrn, \n",
    "#                                              B_lenP, B2P_lnEC, \n",
    "#                                              prefix_layers_num, vocab_size)\n",
    "# print(info_idx.shape)\n",
    "# holder = torch.LongTensor(info_idx)\n",
    "\n",
    "\n",
    "# ############### gsn_embeddings\n",
    "# Layer2Idx = {v:idx for idx, v in enumerate(full_recfldgrn.split('-'))}\n",
    "# name = full_recfldgrn.split('-')[-1]\n",
    "# Layer2Holder = get_Layer2Holder(full_recfldgrn, holder, Ignore_PSN_Layers)\n",
    "# psn_layers = list(reversed([i for i in Layer2Idx if i not in Ignore_PSN_Layers]))\n",
    "\n",
    "\n",
    "# print(Layer2Idx)\n",
    "# print(name)\n",
    "# print([i for i in Layer2Holder], '<---- Layer2Holder')\n",
    "# print(psn_layers, '<---- psn_layers')\n",
    "\n",
    "# for source_layer in psn_layers:\n",
    "#     cpsn_idx = align_psn_idx(source_layer, name, Layer2Idx, Layer2Holder)\n",
    "#     print(source_layer, cpsn_idx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f1850-8d92-40fd-ba69-6657f63ca703",
   "metadata": {},
   "source": [
    "# Real Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98e6de85-919d-4ffa-b1d6-0f286e9dc6f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/ProcData/TensorFolder/Task2YearXXX\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['A1C@DT-DTDftGrn',\n",
       " 'A1C@V-A1CNumeDftGrn',\n",
       " 'Diag@DT-DTDftGrn',\n",
       " 'Diag@Value-DiagDftGrn',\n",
       " 'EC@BasicInfo-BasicDftGrn',\n",
       " 'EC@DT_min-DTDftGrn',\n",
       " 'P@age-AgeNumeDftGrn',\n",
       " 'P@basicInfo-basicInfoDftGrn',\n",
       " 'PN@DT-DTDftGrn',\n",
       " 'PNSect@SectName-PNSctNmDftGrn',\n",
       " 'PNSectSent@Sentence-Tk@TknzLLMGrn',\n",
       " 'Smoking@DT-DTDftGrn',\n",
       " 'Smoking@V-SmokingDftGrn']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from recfldgrn.datapoint import load_df_data_from_folder\n",
    "from fieldnn.utils.layerfn import traverse, convert_relational_list_to_numpy\n",
    "\n",
    "\n",
    "###################### take this as given\n",
    "batch_PID_order = ['P1', 'P4', 'P5', 'P6']\n",
    "######################\n",
    "\n",
    "TaskTensor_folder = 'data/ProcData/TensorFolder/Task2YearXXX'\n",
    "print(TaskTensor_folder)\n",
    "\n",
    "l = sorted([i for i in os.listdir(TaskTensor_folder) if 'Grn' in i])\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "148b0bee-5e48-47e4-abb7-eef0f9638c26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recfldgrn_list = [\n",
    "                  'A1C@V-A1CNumeDftGrn',\n",
    "                  'Diag@DT-DTDftGrn',\n",
    "                  'Diag@Value-DiagDftGrn',\n",
    "                  'PNSectSent@Sentence-Tk@TknzLLMGrn'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f98dd28e-0fb5-43b2-ae78-5b07f07b814a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P-EC-A1C@V-A1CNumeDftGrn_wgt (4, 25, 1, 37)\n",
      "B-P-EC-Diag@DT-DTDftGrn_idx (4, 25, 22, 7)\n",
      "B-P-EC-Diag@Value-DiagDftGrn_idx (4, 25, 22, 3)\n",
      "B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx (4, 25, 1, 14, 121, 11)\n"
     ]
    }
   ],
   "source": [
    "batch_rfg = {}\n",
    "\n",
    "for recfldgrn in recfldgrn_list:\n",
    "    \n",
    "    # (1) get tensor_folder\n",
    "    tensor_folder = os.path.join(TaskTensor_folder, recfldgrn)\n",
    "\n",
    "    # (2) get df_Pat and full_recfldgrn\n",
    "    df_Pat = load_df_data_from_folder(tensor_folder).set_index('PID')\n",
    "    full_recfldgrn = df_Pat.columns[0]\n",
    "    suffix = full_recfldgrn.split('_')[-1]\n",
    "    assert recfldgrn in full_recfldgrn\n",
    "\n",
    "    # (3) load batch: TODO: convert this to DataSet and DataLoader\n",
    "    df_batch = df_Pat.loc[batch_PID_order]\n",
    "\n",
    "    # (4) tensor batch as tensor_idx\n",
    "    new_full_recfldgrn = 'B-' + full_recfldgrn\n",
    "    values_list = df_batch[full_recfldgrn].to_list()\n",
    "    suffix = full_recfldgrn.split('_')[-1]\n",
    "    # print(suffix)\n",
    "    # print(new_full_recfldgrn)\n",
    "    D = convert_relational_list_to_numpy(values_list, new_full_recfldgrn, suffix)\n",
    "    tensor_idx = D[new_full_recfldgrn]\n",
    "    \n",
    "    batch_rfg[new_full_recfldgrn] = tensor_idx\n",
    "    \n",
    "for k, v in batch_rfg.items(): print(k, v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecda0376-dbf4-4701-88e4-f372159d4a8e",
   "metadata": {},
   "source": [
    "## Analyze One RecFldGrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63e47c3d-c151-43be-a641-ac417599fcdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 25, 22, 3)\n"
     ]
    }
   ],
   "source": [
    "full_recfldgrn = 'B-P-EC-Diag@Value-DiagDftGrn_idx'\n",
    "info_idx = batch_rfg[full_recfldgrn]\n",
    "print(info_idx.shape)\n",
    "holder = torch.LongTensor(info_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d08ac0d5-7d8b-4160-9cb3-c1ccb252aba0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'P', 'EC']\n",
      "Diag\n",
      "Value\n",
      "DiagDftGrn\n",
      "idx\n",
      "Diag@Value-DiagDftGrn\n"
     ]
    }
   ],
   "source": [
    "# full_recfldgrn\n",
    "\n",
    "def parse_full_recfldgrn(full_recfldgrn):\n",
    "    # suffix = full_recfldgrn.split('_')[-1]\n",
    "    recfld = [i for i in full_recfldgrn.split('-') if '@' in i][0]\n",
    "    rec, fld = recfld.split('@')\n",
    "    grn_suffix = [i for i in full_recfldgrn.split('-') if 'Grn' in i][0]\n",
    "    grn, suffix = grn_suffix.split('_')\n",
    "    prefix_ids = [i for i in full_recfldgrn.split('-') if 'Grn' not in i and '@' not in i]\n",
    "    return prefix_ids, rec, fld, grn, suffix\n",
    "\n",
    "\n",
    "prefix_ids, rec, fld, grn, suffix = parse_full_recfldgrn(full_recfldgrn)\n",
    "recfldgrn = rec + '@' + fld + '-' + grn\n",
    "print(prefix_ids)\n",
    "print(rec)\n",
    "print(fld)\n",
    "print(grn)\n",
    "print(suffix)\n",
    "print(recfldgrn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8746e2-b284-4678-8296-af91de24c40e",
   "metadata": {},
   "source": [
    "# Expander Core\n",
    "\n",
    "Expander try to convert GRN_idx (or GRN_wgt) to embedding vectors.\n",
    "\n",
    "It is from idx to vector.\n",
    "\n",
    "It is a type of order-increase. \n",
    "\n",
    "\n",
    "Here the core include: CateEmbedding, NumeEmbedding, and LLMEmbed. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c46d1e8-572e-4144-9cea-07f7ffa37024",
   "metadata": {},
   "source": [
    "## CateEmbedding (Expander)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efbdd72-00cf-4032-a9fe-f03dbe0d21a4",
   "metadata": {},
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "734f6b6b-7a1e-443e-b5fb-5aa3cab8a7de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fieldlm.nn.embedding\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class CatEmbeddingLayer(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 vocab_size, \n",
    "                 embedding_size, \n",
    "                 init = 'random', \n",
    "                 freeze = False):\n",
    "        \n",
    "        super(CatEmbeddingLayer, self).__init__()\n",
    "        \n",
    "        # create embedding\n",
    "        if init == 'random':\n",
    "            # c. initial from random initialization\n",
    "            self.embedding = torch.nn.Embedding(vocab_size, embedding_size, padding_idx = 0)\n",
    "        \n",
    "        elif type(init) == np.ndarray:\n",
    "            # a. load from pretrained array. Here init is an array.\n",
    "            weight = torch.FloatTensor(init)\n",
    "            assert weight.shape == (vocab_size, embedding_size)\n",
    "            self.embedding = torch.nn.Embedding.from_pretrained(weight, freeze = freeze)\n",
    "            \n",
    "        elif os.path.isfile(init):\n",
    "            # b. load from the pretrained array file.\n",
    "            weight = torch.FloatTensor(np.load(init))\n",
    "            assert tuple(weight.shape) == (vocab_size, embedding_size)\n",
    "            self.embedding = torch.nn.Embedding.from_pretrained(weight, freeze = freeze)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f'In correct init method \"{init}\"')\n",
    "        \n",
    "    def forward(self, holder):\n",
    "        # info is the grain\n",
    "        info = self.embedding(holder)\n",
    "        return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c037187-afc8-488f-a05b-ea6e63f0bc2c",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f025b352-c680-4634-a62d-8a86fb6bbbf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Main Config\n",
    "### others will change with each recfldgrn\n",
    "\n",
    "#######################\n",
    "embed_size = 512\n",
    "init = 'random'\n",
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95dbdf0c-dca2-42b9-846c-c0b8952c1fec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_recfldgrn_embedding(full_recfldgrn, embed_size, vocab_size, init = 'random'):\n",
    "    embed_para =  {'embedding_size': embed_size,\n",
    "                   'init': init, \n",
    "                   'vocab_size': vocab_size}\n",
    "    return embed_para\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e9c31a-8e65-41a1-ba35-9db4d56cf9d4",
   "metadata": {},
   "source": [
    "### Usage "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be93e9b-9f71-47eb-9dc8-5d82be10c86c",
   "metadata": {},
   "source": [
    "#### recfldgrn information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "253476f7-4414-4131-b7bc-113fe054d5fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# (1) full recfldgrn information\n",
    "full_recfldgrn = 'B-P-EC-Diag@Value-DiagDftGrn_idx'\n",
    "\n",
    "prefix_ids, rec, fld, grn, suffix = parse_full_recfldgrn(full_recfldgrn)\n",
    "recfldgrn = rec + '@' + fld + '-' + grn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e78ecc94-1413-4faf-9aea-3f26df9f2647",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801\n"
     ]
    }
   ],
   "source": [
    "# (2) get vocab information\n",
    "fldgrn_folder = 'data/ProcData/FldGrnInfo'\n",
    "fullfldgrn_file = os.path.join(fldgrn_folder, rec + '.p')\n",
    "df_FieldGrainInfo = pd.read_pickle(fullfldgrn_file)\n",
    "v2idx = df_FieldGrainInfo[df_FieldGrainInfo['recfield2grain'] == recfldgrn].iloc[0]['Vocab']['v2idx']\n",
    "# TODO: also adding padding to v2idx\n",
    "vocab_size = len(v2idx)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7a655e-c2b7-4c7f-818c-d3aa41dfe598",
   "metadata": {},
   "source": [
    "#### get configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6d5135c-6426-4a69-94ec-00d8e7c15f6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_size': 512, 'init': 'random', 'vocab_size': 801}\n"
     ]
    }
   ],
   "source": [
    "embed_para = get_recfldgrn_embedding(recfldgrn, embed_size, vocab_size, init)\n",
    "print(embed_para)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c442a153-d28e-456a-9967-0e77219248b2",
   "metadata": {},
   "source": [
    "#### init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5de858f5-2214-4274-858f-a9bd2668ea12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatEmbeddingLayer(\n",
      "  (embedding): Embedding(801, 512, padding_idx=0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if suffix == 'idx':\n",
    "    NN = CatEmbeddingLayer(**embed_para)\n",
    "    print(NN)\n",
    "else:\n",
    "    raise ValueError(f'suffix is not correct \"{suffix}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709fea05-7bce-4dcf-9211-8ff9a29af647",
   "metadata": {},
   "source": [
    "#### prepare input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95855eec-9dc9-4a91-b852-1b686221c026",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 25, 22, 3)\n",
      "torch.Size([4, 25, 22, 3]) <------ holder shape\n",
      "Empty <------ holder wgt information\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# (1) get the info_raw from batch_rfg\n",
    "info_raw = batch_rfg[full_recfldgrn]\n",
    "print(info_raw.shape)\n",
    "\n",
    "# (2) get the holder (input_idx) and holder_wgt (for nume embedding only)\n",
    "if suffix == 'idx':\n",
    "    holder_wgt = 'Empty'\n",
    "    holder = torch.LongTensor(info_raw)\n",
    "elif suffix == 'wgt':\n",
    "    holder_wgt = torch.FloatTensor(info_raw)\n",
    "    # ATTENTION: here holder_wgt could contain zeros in some valid positions.\n",
    "    holder = torch.ones_like(holder_wgt).cumsum(-1).masked_fill(holder_wgt == 0, 0).long()\n",
    "else:\n",
    "    raise ValueError(f'Invalid suffix \"{suffix}\"')\n",
    "    \n",
    "print(holder.shape, '<------ holder shape')\n",
    "if type(holder_wgt) == str: \n",
    "    print(holder_wgt, '<------ holder wgt information')\n",
    "else:\n",
    "    print(holder_wgt.shape, '<------ holder wgt information')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef61e65-601b-4054-a73a-3768a97c7645",
   "metadata": {},
   "source": [
    "#### I-NN-O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62bd8ff2-e0ce-479a-ba21-9f8d61346315",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 25, 22, 3]) <----- holder shape\n",
      "torch.Size([4, 25, 22, 3, 512]) <----- info shape\n"
     ]
    }
   ],
   "source": [
    "print(holder.shape, '<----- holder shape')\n",
    "info = NN(holder)\n",
    "print(info.shape, '<----- info shape')\n",
    "\n",
    "if type(holder_wgt) != str:\n",
    "    info = info * holder_wgt.unsqueeze(-1)\n",
    "    print(info.shape, '<----- updated by holder_wgt')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c17849d-c27e-4727-9ad7-404799e4e3c0",
   "metadata": {},
   "source": [
    "## NumeEmbedding (Expander)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4a4aad-7350-4c0d-a4f8-5dac8d501834",
   "metadata": {},
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffe4d991-5fba-4bbe-bfd2-98d7ae5f8196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# just the same as the CateEmbeddingLayer\n",
    "\n",
    "class NumEmbeddingLayer(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 vocab_size, \n",
    "                 embedding_size, \n",
    "                 init = 'random', \n",
    "                 freeze = False):\n",
    "        \n",
    "        super(NumEmbeddingLayer, self).__init__()\n",
    "        \n",
    "        # create embedding\n",
    "        if init == 'random':\n",
    "            # c. initial from random initialization\n",
    "            self.embedding = torch.nn.Embedding(vocab_size, embedding_size, padding_idx = 0)\n",
    "        \n",
    "        elif type(init) == np.ndarray:\n",
    "            # a. load from pretrained array. Here init is an array.\n",
    "            weight = torch.FloatTensor(init)\n",
    "            assert weight.shape == (vocab_size, embedding_size)\n",
    "            self.embedding = torch.nn.Embedding.from_pretrained(weight, freeze = freeze)\n",
    "            \n",
    "        elif os.path.isfile(init):\n",
    "            # b. load from the pretrained array file.\n",
    "            weight = torch.FloatTensor(np.load(init))\n",
    "            assert tuple(weight.shape) == (vocab_size, embedding_size)\n",
    "            self.embedding = torch.nn.Embedding.from_pretrained(weight, freeze = freeze)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f'In correct init method \"{init}\"')\n",
    "        \n",
    "    def forward(self, holder):\n",
    "        # info is the grain\n",
    "        info = self.embedding(holder)\n",
    "        return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fcb5d2-ca55-45e5-bc22-3e14d25de19c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b5c5fc3-3c57-4fba-9e73-573aadfb3ef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# same as CateEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b38e5aa-ffeb-4c8b-84e3-e3f5eb02ef27",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deeaa95-e4de-42f7-bb8a-b73cae8b5e68",
   "metadata": {},
   "source": [
    "#### recfldgrn information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15498ebf-7d38-4899-badb-89c6e54c9a29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "# (1) full recfldgrn information\n",
    "full_recfldgrn = 'B-P-EC-A1C@V-A1CNumeDftGrn_wgt'\n",
    "prefix_ids, rec, fld, grn, suffix = parse_full_recfldgrn(full_recfldgrn)\n",
    "recfldgrn = rec + '@' + fld + '-' + grn\n",
    "\n",
    "\n",
    "# (2) get vocab information\n",
    "fldgrn_folder = 'data/ProcData/FldGrnInfo'\n",
    "fullfldgrn_file = os.path.join(fldgrn_folder, rec + '.p')\n",
    "df_FieldGrainInfo = pd.read_pickle(fullfldgrn_file)\n",
    "v2idx = df_FieldGrainInfo[df_FieldGrainInfo['recfield2grain'] == recfldgrn].iloc[0]['Vocab']['v2idx']\n",
    "# TODO: also adding padding to v2idx\n",
    "vocab_size = len(v2idx)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c6ce27-e1cf-4fcb-9f32-a753bec2c51a",
   "metadata": {},
   "source": [
    "#### get configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da9e4d1f-fdfa-4ffb-88c4-7b1ecde4bbd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_size': 512, 'init': 'random', 'vocab_size': 37}\n"
     ]
    }
   ],
   "source": [
    "embed_para = get_recfldgrn_embedding(recfldgrn, embed_size, vocab_size, init)\n",
    "print(embed_para)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b146f8-2f1d-4d6a-b5fb-1cc0e1d73aa7",
   "metadata": {},
   "source": [
    "#### init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db19885a-45d8-4ef1-8b4c-24cc9e176ddc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumEmbeddingLayer(\n",
      "  (embedding): Embedding(37, 512, padding_idx=0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if suffix == 'idx':\n",
    "    NN = CatEmbeddingLayer(**embed_para)\n",
    "    print(NN)\n",
    "elif suffix == 'wgt':\n",
    "    NN = NumEmbeddingLayer(**embed_para)\n",
    "    print(NN)\n",
    "else:\n",
    "    raise ValueError(f'suffix is not correct \"{suffix}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa183c8-1bfc-481c-9e23-6af06107f898",
   "metadata": {},
   "source": [
    "#### prepare input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a96719a-f784-413b-bcc6-d72ac0d83f1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 25, 1, 37)\n",
      "torch.Size([4, 25, 1, 37]) <------ holder shape\n",
      "torch.Size([4, 25, 1, 37]) <------ holder wgt information\n"
     ]
    }
   ],
   "source": [
    "# (1) get the info_raw from batch_rfg\n",
    "info_raw = batch_rfg[full_recfldgrn]\n",
    "print(info_raw.shape)\n",
    "\n",
    "# (2) get the holder (input_idx) and holder_wgt (for nume embedding only)\n",
    "if suffix == 'idx':\n",
    "    holder_wgt = 'Empty'\n",
    "    holder = torch.LongTensor(info_raw)\n",
    "elif suffix == 'wgt':\n",
    "    holder_wgt = torch.FloatTensor(info_raw)\n",
    "    # ATTENTION: here holder_wgt could contain zeros in some valid positions.\n",
    "    holder = torch.ones_like(holder_wgt).cumsum(-1).masked_fill(holder_wgt == 0, 0).long()\n",
    "else:\n",
    "    raise ValueError(f'Invalid suffix \"{suffix}\"')\n",
    "    \n",
    "print(holder.shape, '<------ holder shape')\n",
    "if type(holder_wgt) == str: \n",
    "    print(holder_wgt, '<------ holder wgt information')\n",
    "else:\n",
    "    print(holder_wgt.shape, '<------ holder wgt information')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "114bb9a5-8124-4760-bff8-71181aefb12b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  0,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
       "         0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holder[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27aa91a5-d9aa-4288-978a-f74380f3ab20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  0.,  0.,  0., 11.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " holder_wgt[0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a793d750-59c6-4f97-9889-1b957cf54ac1",
   "metadata": {},
   "source": [
    "#### I-NN-O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62a10901-4694-4215-b0de-1fd6ca880c42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 25, 1, 37]) <----- holder shape\n",
      "torch.Size([4, 25, 1, 37, 512]) <----- info shape\n",
      "torch.Size([4, 25, 1, 37, 512]) <----- updated by holder_wgt\n"
     ]
    }
   ],
   "source": [
    "print(holder.shape, '<----- holder shape')\n",
    "info = NN(holder)\n",
    "print(info.shape, '<----- info shape')\n",
    "\n",
    "if type(holder_wgt) != str:\n",
    "    info_wgt = info * holder_wgt.unsqueeze(-1)\n",
    "    print(info_wgt.shape, '<----- updated by holder_wgt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef324f6c-9125-420e-841d-73cb0e1bb149",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  0,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
       "         0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holder[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "389a1db2-aafe-4c12-a402-c91dacca18e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  0.,  0.,  0., 11.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holder_wgt[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1155811-5822-49f5-bb29-3c08066d500c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.8789,  0.2751,  0.1745, -1.1499,\n",
       "         0.7458, -0.1231,  1.2537, -0.6791, -1.9465, -0.7298,  0.6623,  1.0437,\n",
       "        -0.1583, -0.7005,  0.1771,  0.3816,  0.8535,  1.0558,  1.3356, -0.5503,\n",
       "        -0.5504, -0.4645, -1.2046,  1.3446, -1.3729,  1.0688,  1.5735,  1.2675,\n",
       "        -1.7918,  0.2977,  0.7187, -0.7210,  0.0000],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info[0, 0, 0][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "378f4c23-9b02-403d-ac97-c68619274366",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  9.6680,  0.2751,  0.1745, -1.1499,\n",
       "         0.7458, -0.1231,  1.2537, -0.6791, -1.9465, -0.7298,  0.6623,  1.0437,\n",
       "        -0.1583, -0.7005,  0.1771,  0.3816,  0.8535,  1.0558,  1.3356, -0.5503,\n",
       "        -0.5504, -0.4645, -1.2046,  1.3446, -1.3729,  1.0688,  1.5735,  1.2675,\n",
       "        -1.7918,  0.2977,  0.7187, -0.7210,  0.0000],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_wgt[0, 0, 0][:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3b98f4-6655-4341-994f-e2b565a96d5c",
   "metadata": {},
   "source": [
    "## LLMEmbedding (Expander)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37b782b-9367-41cd-b83c-3e51a08aa4b7",
   "metadata": {},
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "647216ab-990c-46bd-8cf8-2b8f9c423438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "# from ...utils.layerfn import orderSeq, restoreSeq\n",
    "from fieldnn.utils.layerfn import orderSeq, restoreSeq\n",
    "from transformers import AutoModel\n",
    "\n",
    "\n",
    "class LLMEmbeddingLayer(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 tokenizer, \n",
    "                 embedding_size, \n",
    "                 init, \n",
    "                 freeze = False):\n",
    "        \n",
    "        super(LLMEmbeddingLayer, self).__init__()\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        assert init == tokenizer.name_or_path \n",
    "        \n",
    "        self.LLM = AutoModel.from_pretrained(init)\n",
    "        self.hidden_size = self.LLM.config.hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        self.linear  = torch.nn.Linear(self.hidden_size, self.embedding_size)\n",
    "        self.init_linear_weights()\n",
    "            \n",
    "    def init_linear_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.linear.bias.data.zero_()\n",
    "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "        \n",
    "    def forward(self, holder):\n",
    "        # 1. get leng_mask\n",
    "        leng_mask = holder == 0\n",
    "        \n",
    "        # 2. get ordered holder\n",
    "        ord_holder, ord_leng_mask, r_idx = self.reshape(holder, leng_mask)\n",
    "        \n",
    "        # 3. embedding ordered holder by LLM\n",
    "        # expanding by the HuggingFace Language Model\n",
    "        \n",
    "        # 3.1 we might want to freeze LLM here\n",
    "        output = self.LLM(ord_holder)\n",
    "        # 3.2 adjust the hidden dimension\n",
    "        ord_info_output = output['last_hidden_state']\n",
    "        ord_info_output = self.linear(ord_info_output) # bias might not be zeros.\n",
    "        ord_info_output = ord_info_output.masked_fill(ord_leng_mask.unsqueeze(-1), 0)\n",
    "    \n",
    "        # 4. restore orderded output to original shape\n",
    "        info = self.restore(ord_info_output, leng_mask, r_idx)\n",
    "        \n",
    "        return info\n",
    "    \n",
    "    \n",
    "    def reshape(self, holder, leng_mask):\n",
    "        nbs = np.array(holder.shape[:-1]).prod()\n",
    "        ngrn = holder.shape[-1]\n",
    "        # print(nbs, ngrn, dim)\n",
    "        \n",
    "        tmp_holder = holder.contiguous().view(nbs, ngrn)\n",
    "        # print(tmp_info.shape)\n",
    "\n",
    "        tmp_leng_mask = leng_mask.contiguous().view(nbs, ngrn)\n",
    "        # print(tmp_leng_mask.shape)\n",
    "\n",
    "        tmp_leng = (tmp_leng_mask == 0).sum(-1)\n",
    "        # print(tmp_leng.shape)\n",
    "        \n",
    "        ord_holder,    ord_leng, r_idx = orderSeq(tmp_holder, tmp_leng)\n",
    "        ord_leng_mask, ord_leng, r_idx = orderSeq(tmp_leng_mask, tmp_leng)\n",
    "        return ord_holder, ord_leng_mask, r_idx\n",
    "    \n",
    "    \n",
    "    \n",
    "    def restore(self, ord_info_output, leng_mask, r_idx):\n",
    "        info_new = restoreSeq(ord_info_output, r_idx)\n",
    "        output_size = info_new.shape[-1]\n",
    "        info_output = info_new.view(*list(leng_mask.shape) + [output_size])\n",
    "        return info_output\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4137e457-a469-4434-a5dd-130e1a4e8f0c",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62d17f8e-4bd8-4868-9d44-53a6fa19326c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_recfldgrn_llmembedding(full_recfldgrn, embed_size, tokenizer, init):\n",
    "    embed_para =  {'embedding_size': embed_size,\n",
    "                   'init': init, \n",
    "                   'tokenizer': tokenizer}\n",
    "    return embed_para\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a225d743-5e17-4f68-94ea-cf718fb8b352",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcc0ecc-2683-4fda-8984-cf39fcdf2c69",
   "metadata": {},
   "source": [
    "#### recfldgrn information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c73c30b5-43bc-436c-b9ca-ccae4b20d630",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P-EC-A1C@V-A1CNumeDftGrn_wgt',\n",
       " 'B-P-EC-Diag@DT-DTDftGrn_idx',\n",
       " 'B-P-EC-Diag@Value-DiagDftGrn_idx',\n",
       " 'B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in batch_rfg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c1793cd-979d-4d4e-8288-b5a07e6f0994",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30522\n"
     ]
    }
   ],
   "source": [
    "# (1) full recfldgrn information\n",
    "full_recfldgrn = 'B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx'\n",
    "prefix_ids, rec, fld, grn, suffix = parse_full_recfldgrn(full_recfldgrn)\n",
    "recfldgrn = rec + '@' + fld + '-' + grn\n",
    "\n",
    "\n",
    "# (2) get vocab information\n",
    "fldgrn_folder = 'data/ProcData/FldGrnInfo'\n",
    "fullfldgrn_file = os.path.join(fldgrn_folder, rec + '.p')\n",
    "df_FieldGrainInfo = pd.read_pickle(fullfldgrn_file)\n",
    "\n",
    "if 'LLM' in full_recfldgrn:\n",
    "    tokenizer = df_FieldGrainInfo[df_FieldGrainInfo['recfield2grain'] == recfldgrn].iloc[0]['Vocab']['v2idx']\n",
    "    # TODO: also adding padding to v2idx\n",
    "    vocab_size = len(tokenizer)\n",
    "    print(vocab_size)\n",
    "else:\n",
    "    v2idx = df_FieldGrainInfo[df_FieldGrainInfo['recfield2grain'] == recfldgrn].iloc[0]['Vocab']['v2idx']\n",
    "    # TODO: also adding padding to v2idx\n",
    "    vocab_size = len(v2idx)\n",
    "    print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592e72d8-ace7-4fb4-af49-bcdfb7485db7",
   "metadata": {},
   "source": [
    "#### get configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6b257ae-84cc-4a87-af1f-c932f299ff98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding_size': 512,\n",
       " 'init': 'bert-base-uncased',\n",
       " 'tokenizer': BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = tokenizer.name_or_path\n",
    "embed_para = get_recfldgrn_llmembedding(recfldgrn, embed_size, tokenizer, init)\n",
    "embed_para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78333f24-d16b-4c24-8597-e4860f5f9160",
   "metadata": {},
   "source": [
    "#### init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6fc910ac-d6b7-4908-9ecf-6b7df6b8e9ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "if suffix == 'idx' and 'LLM' not in recfldgrn:\n",
    "    NN = CatEmbeddingLayer(**embed_para)\n",
    "    print(NN)\n",
    "    \n",
    "elif suffix == 'idx' and 'LLM' in recfldgrn:\n",
    "    NN = LLMEmbeddingLayer(**embed_para)\n",
    "    \n",
    "elif suffix == 'wgt':\n",
    "    NN = NumEmbeddingLayer(**embed_para)\n",
    "    print(NN)\n",
    "else:\n",
    "    raise ValueError(f'suffix is not correct \"{suffix}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688c514a-b73f-4fb2-8539-b91689195d3b",
   "metadata": {},
   "source": [
    "#### prepare input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f7d728e8-5c8d-4c01-9b34-e80cc56774a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 25, 1, 14, 121, 11)\n",
      "torch.Size([4, 25, 1, 14, 121, 11]) <------ holder shape\n",
      "Empty <------ holder wgt information\n"
     ]
    }
   ],
   "source": [
    "# (1) get the info_raw from batch_rfg\n",
    "info_raw = batch_rfg[full_recfldgrn]\n",
    "print(info_raw.shape)\n",
    "\n",
    "# (2) get the holder (input_idx) and holder_wgt (for nume embedding only)\n",
    "if suffix == 'idx':\n",
    "    holder_wgt = 'Empty'\n",
    "    holder = torch.LongTensor(info_raw)\n",
    "elif suffix == 'wgt':\n",
    "    holder_wgt = torch.FloatTensor(info_raw)\n",
    "    # ATTENTION: here holder_wgt could contain zeros in some valid positions.\n",
    "    holder = torch.ones_like(holder_wgt).cumsum(-1).masked_fill(holder_wgt == 0, 0).long()\n",
    "else:\n",
    "    raise ValueError(f'Invalid suffix \"{suffix}\"')\n",
    "    \n",
    "print(holder.shape, '<------ holder shape')\n",
    "if type(holder_wgt) == str: \n",
    "    print(holder_wgt, '<------ holder wgt information')\n",
    "else:\n",
    "    print(holder_wgt.shape, '<------ holder wgt information')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08a5262-e7e3-4c54-8acb-856324f34666",
   "metadata": {},
   "source": [
    "#### I-NN-O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a456aed7-f7ea-4158-a38f-397938388b1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 25, 1, 14, 121, 11]) <----- holder shape\n",
      "torch.Size([4, 25, 1, 14, 121, 11, 512]) <----- info shape\n"
     ]
    }
   ],
   "source": [
    "print(holder.shape, '<----- holder shape')\n",
    "info = NN(holder)\n",
    "print(info.shape, '<----- info shape')\n",
    "\n",
    "if type(holder_wgt) != str:\n",
    "    info_wgt = info * holder_wgt.unsqueeze(-1)\n",
    "    print(info_wgt.shape, '<----- updated by holder_wgt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "10bae60d-2d96-4f71-a326-8ae637d3a805",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 25, 1, 14, 121, 11])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leng_mask = holder == 0\n",
    "leng_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "74edaea3-4a46-40c0-995b-9f1a7a0f0fbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 25, 1, 14, 121, 11, 512])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "074a63ac-d75e-491d-8364-421d87396fbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: do the tensor validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40584876-b4a9-4a9d-b019-c708af7ef283",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Expander"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e24762-5519-45f2-a109-7cc23f4f5402",
   "metadata": {},
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0867d2ee-0680-4862-8fc4-64066212f1dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from fieldnn.nn.embedding.catembedding import CatEmbeddingLayer\n",
    "from fieldnn.nn.embedding.numembedding import NumEmbeddingLayer \n",
    "from fieldnn.nn.embedding.llmembedding import LLMEmbeddingLayer\n",
    "\n",
    "# from ..nn.embedding.catembedding import CatEmbeddingLayer\n",
    "# from ..nn.embedding.numembedding import NumEmbeddingLayer \n",
    "# from ..nn.embedding.llmembedding import LLMEmbeddingLayer\n",
    "\n",
    "\n",
    "class Expander_Layer(torch.nn.Module):\n",
    "    \n",
    "    '''Only for Increasing Input_idx's Order'''\n",
    "    def __init__(self, full_recfldgrn, output_recfld, expander_para):\n",
    "        super(Expander_Layer, self).__init__()\n",
    "        \n",
    "        self.input_size = expander_para['input_size']\n",
    "        self.output_size = expander_para['output_size']\n",
    "        \n",
    "        # Part 1: embedding\n",
    "        self.input_fullname = full_recfldgrn\n",
    "        self.output_fullname = output_recfld\n",
    "        \n",
    "        assert 'Grn' in full_recfldgrn\n",
    "        assert full_recfldgrn.split('Grn')[0] == output_recfld\n",
    "        \n",
    "        nn_name, embed_para = expander_para[self.input_fullname]\n",
    "        \n",
    "        if nn_name.lower() == 'catembeddinglayer':\n",
    "            assert 'idx' in full_recfldgrn and 'LLM' not in full_recfldgrn\n",
    "            self.Embed = CatEmbeddingLayer(**embed_para)\n",
    "        elif nn_name.lower() == 'llmembeddinglayer':\n",
    "            assert 'idx' in full_recfldgrn and 'LLM' in full_recfldgrn\n",
    "            self.Embed = LLMEmbeddingLayer(**embed_para)\n",
    "        elif nn_name.lower() == 'numembeddinglayer':\n",
    "            assert 'wgt' in full_recfldgrn\n",
    "            self.Embed = NumEmbeddingLayer(**embed_para)\n",
    "        else:\n",
    "            raise ValueError(f'suffix is not correct \"{full_recfldgrn}\"')\n",
    "\n",
    "        self.embed_size = self.output_size\n",
    "        \n",
    "        # Part 2: PostProcess\n",
    "        self.postprocess = torch.nn.ModuleDict()\n",
    "        for method, config in expander_para['postprocess'].items():\n",
    "            if method == 'dropout':\n",
    "                self.postprocess[method] = torch.nn.Dropout(**config)\n",
    "            elif method == 'activator':\n",
    "                activator = config\n",
    "                if activator.lower() == 'relu': \n",
    "                    self.postprocess[method] = torch.nn.ReLU()\n",
    "                elif activator.lower() == 'tanh': \n",
    "                    self.postprocess[method] = torch.nn.Tanh()\n",
    "                elif activator.lower() == 'gelu':\n",
    "                    self.postprocess[method] = torch.nn.GELU()\n",
    "            elif method == 'layernorm':\n",
    "                self.postprocess[method] = torch.nn.LayerNorm(self.embed_size, **config)\n",
    "\n",
    "    def forward(self, fullname, holder, holder_wgt = 'Empty'):\n",
    "        '''\n",
    "            fullname: full name of field, GRN is here\n",
    "            holder: info_idx\n",
    "            info: info_wgt\n",
    "        '''\n",
    "        assert self.input_fullname == fullname\n",
    "        leng_mask = holder == 0\n",
    "        embed = self.Embed(holder)\n",
    "        \n",
    "        if type(holder_wgt) != str:\n",
    "            embed = embed * holder_wgt.unsqueeze(-1)\n",
    "        \n",
    "        for nn, layer in self.postprocess.items():\n",
    "            embed = layer(embed)\n",
    "        \n",
    "        return self.output_fullname, holder, embed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b742218-976a-41d2-ae12-5f28851629bd",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d19fb289-7483-4f98-b489-c7ee947d943d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_recfldgrn_embedding(full_recfldgrn, embed_size, vocab_size, init = 'random'):\n",
    "#     embed_para =  {'embedding_size': embed_size,\n",
    "#                    'init': init, \n",
    "#                    'vocab_size': vocab_size}\n",
    "#     return embed_para\n",
    "\n",
    "# def get_recfldgrn_llmembedding(full_recfldgrn, embed_size, tokenizer, init):\n",
    "#     embed_para =  {'embedding_size': embed_size,\n",
    "#                    'init': init, \n",
    "#                    'tokenizer': tokenizer}\n",
    "#     return embed_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b1c10efe-46e7-43cd-a5fa-1ac6d15427bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_expander_para(full_recfldgrn, \n",
    "                      nn_name,\n",
    "                      embed_size, vocabsize_tokenizer, init, \n",
    "                      postprocess):\n",
    "    \n",
    "    expander_para = {}\n",
    "    #(0) Input size, output size\n",
    "    expander_para['input_size'] = None\n",
    "    expander_para['output_size'] = embed_size\n",
    "    expander_para['nn_name'] = nn_name\n",
    "\n",
    "    #(1) Main NN\n",
    "    # print(nn_name)\n",
    "    if nn_name.lower() == 'catembeddinglayer':\n",
    "        para = get_recfldgrn_embedding(full_recfldgrn, embed_size, vocabsize_tokenizer, init)\n",
    "    elif nn_name.lower() == 'numembeddinglayer':\n",
    "        para = get_recfldgrn_embedding(full_recfldgrn, embed_size, vocabsize_tokenizer, init)\n",
    "    elif nn_name.lower() == 'llmembeddinglayer':\n",
    "        para = get_recfldgrn_llmembedding(full_recfldgrn, embed_size,  vocabsize_tokenizer, init)\n",
    "    else:\n",
    "        raise ValueError(f'The NN \"{nn_name}\" is not available yet')\n",
    "    \n",
    "    # print(para, '<--------- inside get_expander_para')\n",
    "    expander_para[full_recfldgrn] = nn_name, para\n",
    "\n",
    "    # (2) Post Process\n",
    "    expander_para['postprocess'] = postprocess\n",
    "    \n",
    "    return expander_para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba90527f-bf4d-4dcd-8fdd-fbd8b153c941",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc781d1-edf2-4cd2-8c5e-6f68a4a49417",
   "metadata": {},
   "source": [
    "### recfldgrn information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3e7209fc-8b11-4168-b5f6-5fc10d39a3d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-P-EC-A1C@V-A1CNumeDftGrn_wgt',\n",
       " 'B-P-EC-Diag@Value-DiagDftGrn_idx',\n",
       " 'B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_recfldgrn_list = ['B-P-EC-A1C@V-A1CNumeDftGrn_wgt',\n",
    "                       'B-P-EC-Diag@Value-DiagDftGrn_idx',\n",
    "                       'B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx']\n",
    "\n",
    "full_recfldgrn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "38ab0267-fc18-4cba-abd0-d6d997604dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "03ac61bb-81c0-4e7c-b0e8-504ed8a2c911",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-P-EC-A1C@V-A1CNumeDftGrn_wgt': {'vocabsize_tokenizer': 37,\n",
       "  'init': 'random'},\n",
       " 'B-P-EC-Diag@Value-DiagDftGrn_idx': {'vocabsize_tokenizer': 801,\n",
       "  'init': 'random'},\n",
       " 'B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx': {'vocabsize_tokenizer': BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}),\n",
       "  'init': 'bert-base-uncased'}}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_rfg_to_basicInfo = {}\n",
    "\n",
    "for full_recfldgrn in full_recfldgrn_list:\n",
    "    # (1) full recfldgrn information\n",
    "    prefix_ids, rec, fld, grn, suffix = parse_full_recfldgrn(full_recfldgrn)\n",
    "    recfldgrn = rec + '@' + fld + '-' + grn\n",
    "\n",
    "\n",
    "    # (2) get vocab information\n",
    "    fldgrn_folder = 'data/ProcData/FldGrnInfo'\n",
    "    fullfldgrn_file = os.path.join(fldgrn_folder, rec + '.p')\n",
    "    df_FieldGrainInfo = pd.read_pickle(fullfldgrn_file)\n",
    "\n",
    "    if 'LLM' in full_recfldgrn:\n",
    "        tokenizer = df_FieldGrainInfo[df_FieldGrainInfo['recfield2grain'] == recfldgrn].iloc[0]['Vocab']['v2idx']\n",
    "        # TODO: also adding padding to v2idx\n",
    "        # vocab_size = len(tokenizer)\n",
    "        # print(vocab_size)\n",
    "        vocab_tokenizer = tokenizer\n",
    "        init = tokenizer.name_or_path\n",
    "    else:\n",
    "        v2idx = df_FieldGrainInfo[df_FieldGrainInfo['recfield2grain'] == recfldgrn].iloc[0]['Vocab']['v2idx']\n",
    "        # TODO: also adding padding to v2idx\n",
    "        vocab_size = len(v2idx)\n",
    "        # print(vocab_size)\n",
    "        vocab_tokenizer = vocab_size\n",
    "        init = 'random'\n",
    "    \n",
    "    d = {'vocabsize_tokenizer': vocab_tokenizer, 'init': init}\n",
    "    full_rfg_to_basicInfo[full_recfldgrn] = d\n",
    "    \n",
    "    \n",
    "full_rfg_to_basicInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5301c3cc-6857-4455-866f-8595fe5943b9",
   "metadata": {},
   "source": [
    "### get configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8bb1325b-3292-4426-900f-b4a48b90d600",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############################\n",
    "embed_size = 128\n",
    "process = {'activator': 'gelu',\n",
    "           'dropout': {'p': 0.5, 'inplace': False},\n",
    "           'layernorm': {'eps': 1e-05, 'elementwise_affine': True}}\n",
    "############################\n",
    "\n",
    "\n",
    "full_rfg_to_ExpanderConfig = {}\n",
    "\n",
    "for full_recfldgrn in full_recfldgrn_list:\n",
    "    \n",
    "    # determine the nn_name\n",
    "    if '_idx' in full_recfldgrn and 'LLM' not in full_recfldgrn:\n",
    "        nn_name = 'CatEmbeddingLayer'\n",
    "\n",
    "    elif '_idx' in full_recfldgrn and 'LLM' in full_recfldgrn:\n",
    "        nn_name = 'LLMEmbeddingLayer'\n",
    "\n",
    "    elif '_wgt' in full_recfldgrn:\n",
    "        nn_name = 'NumEmbeddingLayer'\n",
    "    else:\n",
    "        raise ValueError(f'full_recfldgrn is not correct \"{full_recfldgrn}\"')\n",
    "    \n",
    "    d = full_rfg_to_basicInfo[full_recfldgrn]\n",
    "    \n",
    "    # print('\\n----')\n",
    "    # print(full_recfldgrn)\n",
    "    # print(d)\n",
    "    # print(nn_name)\n",
    "    expander_para = get_expander_para(full_recfldgrn, \n",
    "                                       nn_name,\n",
    "                                       embed_size, d['vocabsize_tokenizer'], d['init'], \n",
    "                                       process)\n",
    "    # print(expander_para)\n",
    "    output_recfld = full_recfldgrn.split('Grn')[0]\n",
    "    \n",
    "    full_rfg_to_ExpanderConfig[full_recfldgrn] = {\n",
    "        'full_recfldgrn': full_recfldgrn,\n",
    "        'output_recfld': output_recfld,\n",
    "        'expander_para': expander_para,\n",
    "    }\n",
    "    \n",
    "    \n",
    "# full_rfg_to_ExpanderConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "174af83a-c3a7-4a8a-96f4-3364c667faf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# full_rfg_to_ExpanderConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b702251-c619-4201-8ba6-62db69650d40",
   "metadata": {},
   "source": [
    "### init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "36f4afd9-5ee5-4353-8ebc-afee95667596",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P-EC-A1C@V-A1CNumeDftGrn_wgt\n",
      "Expander_Layer(\n",
      "  (Embed): NumEmbeddingLayer(\n",
      "    (embedding): Embedding(37, 128, padding_idx=0)\n",
      "  )\n",
      "  (postprocess): ModuleDict(\n",
      "    (activator): GELU(approximate='none')\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "B-P-EC-Diag@Value-DiagDftGrn_idx\n",
      "Expander_Layer(\n",
      "  (Embed): CatEmbeddingLayer(\n",
      "    (embedding): Embedding(801, 128, padding_idx=0)\n",
      "  )\n",
      "  (postprocess): ModuleDict(\n",
      "    (activator): GELU(approximate='none')\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx\n",
      "Expander_Layer(\n",
      "  (Embed): LLMEmbeddingLayer(\n",
      "    (LLM): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-11): 12 x BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (linear): Linear(in_features=768, out_features=128, bias=True)\n",
      "  )\n",
      "  (postprocess): ModuleDict(\n",
      "    (activator): GELU(approximate='none')\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "FullRFG_2_Embed = {}\n",
    "\n",
    "for full_recfldgrn, ExpanderConfig in full_rfg_to_ExpanderConfig.items():\n",
    "    \n",
    "    FullRFG_2_Embed[full_recfldgrn] = Expander_Layer(**ExpanderConfig)\n",
    "    print(full_recfldgrn)\n",
    "    print(FullRFG_2_Embed[full_recfldgrn])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162d3e1c-4932-4a13-9c90-170d4968191c",
   "metadata": {},
   "source": [
    "### prepare input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d248c563-25ca-4585-b4c8-f002cd384901",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P-EC-A1C@V-A1CNumeDftGrn_wgt\n",
      "(4, 25, 1, 37)\n",
      "torch.Size([4, 25, 1, 37]) <------ holder shape\n",
      "torch.Size([4, 25, 1, 37]) <------ holder wgt information\n",
      "\n",
      "\n",
      "B-P-EC-Diag@Value-DiagDftGrn_idx\n",
      "(4, 25, 22, 3)\n",
      "torch.Size([4, 25, 22, 3]) <------ holder shape\n",
      "Empty <------ holder wgt information\n",
      "\n",
      "\n",
      "B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx\n",
      "(4, 25, 1, 14, 121, 11)\n",
      "torch.Size([4, 25, 1, 14, 121, 11]) <------ holder shape\n",
      "Empty <------ holder wgt information\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for full_recfldgrn in full_recfldgrn_list:\n",
    "    # (1) get the info_raw from batch_rfg\n",
    "    info_raw = batch_rfg[full_recfldgrn]\n",
    "    print(full_recfldgrn)\n",
    "    print(info_raw.shape)\n",
    "\n",
    "    # (2) get the holder (input_idx) and holder_wgt (for nume embedding only)\n",
    "    if '_idx' in full_recfldgrn:\n",
    "        holder_wgt = 'Empty'\n",
    "        holder = torch.LongTensor(info_raw)\n",
    "    elif '_wgt' in full_recfldgrn:\n",
    "        holder_wgt = torch.FloatTensor(info_raw)\n",
    "        # ATTENTION: here holder_wgt could contain zeros in some valid positions.\n",
    "        holder = torch.ones_like(holder_wgt).cumsum(-1).masked_fill(holder_wgt == 0, 0).long()\n",
    "    else:\n",
    "        raise ValueError(f'Invalid suffix \"{suffix}\"')\n",
    "\n",
    "    print(holder.shape, '<------ holder shape')\n",
    "    if type(holder_wgt) == str: \n",
    "        print(holder_wgt, '<------ holder wgt information')\n",
    "    else:\n",
    "        print(holder_wgt.shape, '<------ holder wgt information')\n",
    "\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522e9dfa-cbf1-4e25-9ddc-61b612daa1f0",
   "metadata": {},
   "source": [
    "### I-NN-O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a588c5a0-a497-481b-a03f-035dd170df72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: B-P-EC-A1C@V-A1CNumeDftGrn_wgt\n",
      "(4, 25, 1, 37)\n",
      "torch.Size([4, 25, 1, 37]) <------ holder shape\n",
      "torch.Size([4, 25, 1, 37]) <------ holder wgt information\n",
      "torch.Size([4, 25, 1, 37]) <----- holder shape\n",
      "Output: B-P-EC-A1C@V-A1CNumeDft\n",
      "torch.Size([4, 25, 1, 37, 128]) <----- info shape\n",
      "\n",
      "\n",
      "Input: B-P-EC-Diag@Value-DiagDftGrn_idx\n",
      "(4, 25, 22, 3)\n",
      "torch.Size([4, 25, 22, 3]) <------ holder shape\n",
      "Empty <------ holder wgt information\n",
      "torch.Size([4, 25, 22, 3]) <----- holder shape\n",
      "Output: B-P-EC-Diag@Value-DiagDft\n",
      "torch.Size([4, 25, 22, 3, 128]) <----- info shape\n",
      "\n",
      "\n",
      "Input: B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx\n",
      "(4, 25, 1, 14, 121, 11)\n",
      "torch.Size([4, 25, 1, 14, 121, 11]) <------ holder shape\n",
      "Empty <------ holder wgt information\n",
      "torch.Size([4, 25, 1, 14, 121, 11]) <----- holder shape\n",
      "Output: B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLM\n",
      "torch.Size([4, 25, 1, 14, 121, 11, 128]) <----- info shape\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for full_recfldgrn in full_recfldgrn_list:\n",
    "    # (1) get the info_raw from batch_rfg\n",
    "    info_raw = batch_rfg[full_recfldgrn]\n",
    "    print('Input:',full_recfldgrn)\n",
    "    print(info_raw.shape)\n",
    "\n",
    "    # (2) get the holder (input_idx) and holder_wgt (for nume embedding only)\n",
    "    if '_idx' in full_recfldgrn:\n",
    "        holder_wgt = 'Empty'\n",
    "        holder = torch.LongTensor(info_raw)\n",
    "    elif '_wgt' in full_recfldgrn:\n",
    "        holder_wgt = torch.FloatTensor(info_raw)\n",
    "        # ATTENTION: here holder_wgt could contain zeros in some valid positions.\n",
    "        holder = torch.ones_like(holder_wgt).cumsum(-1).masked_fill(holder_wgt == 0, 0).long()\n",
    "    else:\n",
    "        raise ValueError(f'Invalid suffix \"{suffix}\"')\n",
    "\n",
    "    print(holder.shape, '<------ holder shape')\n",
    "    if type(holder_wgt) == str:  \n",
    "        print(holder_wgt, '<------ holder wgt information')\n",
    "    else:\n",
    "        print(holder_wgt.shape, '<------ holder wgt information')\n",
    "        \n",
    "        \n",
    "    NN = FullRFG_2_Embed[full_recfldgrn] \n",
    "    print(holder.shape, '<----- holder shape')\n",
    "    output_recfld, holder, info = NN(full_recfldgrn, holder, holder_wgt)\n",
    "    print('Output:', output_recfld)\n",
    "    print(info.shape, '<----- info shape')\n",
    "\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd22e154-cf0a-4acf-9d9a-a60d7bead2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
