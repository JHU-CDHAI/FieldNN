{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7588aa63-50a8-4f68-b40d-5e65e1783790",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/floydluo/Library/CloudStorage/GoogleDrive-jjluo@terpmail.umd.edu/.shortcut-targets-by-id/1qNzMmGHCg5Xa63Vw3aKbZdMXvkfT2CgC/MedStar/MS_CODE/FieldNN\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47a2660-824c-41fd-81e5-58a2207cbc74",
   "metadata": {},
   "source": [
    "# Simulate Data\n",
    "\n",
    "\n",
    "Given a field name, and first 2 dimensional numbes, simulate tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c7d713-7310-40cb-86f3-358ecf3274bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fieldnn.utils.layerfn import traverse\n",
    "from fieldnn.utils.simulate import get_next_info, get_simulated_tensor_from_fldname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd5bf74-00e1-41c6-ab91-f25613356b2d",
   "metadata": {},
   "source": [
    "# Holder\n",
    "\n",
    "1. Current Layer:\n",
    "```python\n",
    "leng_mask = info_idx == 0 # or info_idx != 0\n",
    "leng = leng_mask.sum(-1)\n",
    "```\n",
    "\n",
    "2. Transfer\n",
    "\n",
    "```python\n",
    "old_leng = leng\n",
    "```\n",
    "\n",
    "\n",
    "3. Next Layer\n",
    "```python\n",
    "leng_mask = old_leng != 0\n",
    "leng = (leng_mask == 0).sum(-1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84cbfc6e-dd63-459a-ad83-4c5d940788f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# leng_mask = info_idx == 0\n",
    "\n",
    "import torch\n",
    "\n",
    "def get_Layer2Holder(fullname, holder, Ignore_PSN_Layers = ['B', 'P']):\n",
    "    # holder = holder\n",
    "    d = {}\n",
    "    for layername in list(reversed(fullname.split('-'))):\n",
    "        if layername in Ignore_PSN_Layers: continue\n",
    "        leng_mask = holder == 0\n",
    "        leng = (leng_mask == 0).sum(-1)\n",
    "        psn_idx = (leng_mask == False).cumsum(-1).masked_fill(leng_mask, 0)\n",
    "        d[layername] = {'holder': holder, \n",
    "                        'leng_mask': leng_mask, \n",
    "                        'leng': leng, \n",
    "                        'psn_idx': psn_idx}\n",
    "        # d[layername] = holder, psn_idx\n",
    "        holder = leng\n",
    "    Layer2Hoder = d\n",
    "    return Layer2Hoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee61bb27-4e3f-4dc8-8ba2-d7a4772acf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def align_psn_idx(source_layer, current_layer, Layer2Idx, Layer2Holder):\n",
    "    if source_layer == current_layer:\n",
    "        psn_idx = Layer2Holder[current_layer]['psn_idx']\n",
    "        return psn_idx\n",
    "    else:\n",
    "        source_psn_idx = Layer2Holder[source_layer]['psn_idx']\n",
    "        current_leng_mask = Layer2Holder[current_layer]['leng_mask']\n",
    "        gaps = Layer2Idx[current_layer] - Layer2Idx[source_layer]\n",
    "        # print(gaps)\n",
    "        # print(layername)\n",
    "        # print(prev_info.shape)\n",
    "        # print(leng_mask.shape)\n",
    "        # print(leng.shape)\n",
    "        # print(psn_idx.shape)\n",
    "        shape0 = list(source_psn_idx.shape) + [1] * gaps\n",
    "        shape1 = current_leng_mask.shape\n",
    "        psn_idx = source_psn_idx.view(*shape0).expand(shape1).masked_fill(current_leng_mask, 0)\n",
    "        # print(cpsn_idx.shape)\n",
    "        return psn_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b8e219-ce20-4012-8e0c-3cfd74ac673d",
   "metadata": {},
   "source": [
    "# Simulate Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cb41993-c83b-4019-b270-63a024e32188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# # ======= within forward\n",
    "\n",
    "# ###############\n",
    "# B_lenP = 3\n",
    "# B2P_lnEC = [6, 5, 2] # \n",
    "# prefix_layers_num = 2\n",
    "# vocab_size = 5001\n",
    "# Ignore_PSN_Layers = ['B', 'P']\n",
    "# ###############\n",
    "\n",
    "\n",
    "# full_recfldgrn = 'B-P-EC-Diag:Value-DiagVdftGrn' # full_recflgrn.\n",
    "\n",
    "# info_idx = get_simulated_tensor_from_fldname(full_recfldgrn, \n",
    "#                                              B_lenP, B2P_lnEC, \n",
    "#                                              prefix_layers_num, vocab_size)\n",
    "# print(info_idx.shape)\n",
    "# holder = torch.LongTensor(info_idx)\n",
    "\n",
    "\n",
    "# ############### gsn_embeddings\n",
    "# Layer2Idx = {v:idx for idx, v in enumerate(full_recfldgrn.split('-'))}\n",
    "# name = full_recfldgrn.split('-')[-1]\n",
    "# Layer2Holder = get_Layer2Holder(full_recfldgrn, holder, Ignore_PSN_Layers)\n",
    "# psn_layers = list(reversed([i for i in Layer2Idx if i not in Ignore_PSN_Layers]))\n",
    "\n",
    "\n",
    "# print(Layer2Idx)\n",
    "# print(name)\n",
    "# print([i for i in Layer2Holder], '<---- Layer2Holder')\n",
    "# print(psn_layers, '<---- psn_layers')\n",
    "\n",
    "# for source_layer in psn_layers:\n",
    "#     cpsn_idx = align_psn_idx(source_layer, name, Layer2Idx, Layer2Holder)\n",
    "#     print(source_layer, cpsn_idx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f1850-8d92-40fd-ba69-6657f63ca703",
   "metadata": {},
   "source": [
    "# Real Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98e6de85-919d-4ffa-b1d6-0f286e9dc6f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/ProcData/TensorFolder/Task2YearXXX\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['A1C@DT-DTDftGrn',\n",
       " 'A1C@V-A1CNumeDftGrn',\n",
       " 'Diag@DT-DTDftGrn',\n",
       " 'Diag@Value-DiagDftGrn',\n",
       " 'EC@BasicInfo-BasicDftGrn',\n",
       " 'EC@DT_min-DTDftGrn',\n",
       " 'P@age-AgeNumeDftGrn',\n",
       " 'P@basicInfo-basicInfoDftGrn',\n",
       " 'PNSectSent@Sentence-Tk@TknzLLMGrn']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from recfldgrn.datapoint import load_df_data_from_folder\n",
    "from recfldgrn.utils import convert_relational_list_to_numpy\n",
    "\n",
    "###################### take this as given\n",
    "batch_PID_order = ['P0', 'P2', 'P1', 'P3', 'P4', 'P5', 'P6', 'P7']\n",
    "######################\n",
    "\n",
    "TaskTensor_folder = 'data/ProcData/TensorFolder/Task2YearXXX'\n",
    "print(TaskTensor_folder)\n",
    "\n",
    "l = sorted([i for i in os.listdir(TaskTensor_folder) if 'Grn' in i])\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "148b0bee-5e48-47e4-abb7-eef0f9638c26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recfldgrn_list = [\n",
    "                  'A1C@V-A1CNumeDftGrn',\n",
    "                  'Diag@DT-DTDftGrn',\n",
    "                  'Diag@Value-DiagDftGrn',\n",
    "                  'PNSectSent@Sentence-Tk@TknzLLMGrn'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f98dd28e-0fb5-43b2-ae78-5b07f07b814a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P-EC-A1C@V-A1CNumeDftGrn_wgt (8, 87, 1, 37)\n",
      "B-P-EC-Diag@DT-DTDftGrn_idx (8, 87, 22, 7)\n",
      "B-P-EC-Diag@Value-DiagDftGrn_idx (8, 87, 22, 3)\n",
      "B-P-EC-PN-PNSect-PNSectSent@Sentence-Tk@TknzLLMGrn_idx (8, 87, 1, 15, 121, 11)\n"
     ]
    }
   ],
   "source": [
    "batch_rfg = {}\n",
    "\n",
    "for recfldgrn in recfldgrn_list:\n",
    "    \n",
    "    # (1) get tensor_folder\n",
    "    tensor_folder = os.path.join(TaskTensor_folder, recfldgrn)\n",
    "\n",
    "    # (2) get df_Pat and full_recfldgrn\n",
    "    df_Pat = load_df_data_from_folder(tensor_folder).set_index('PID')\n",
    "    full_recfldgrn = df_Pat.columns[0]\n",
    "    suffix = full_recfldgrn.split('_')[-1]\n",
    "    assert recfldgrn in full_recfldgrn\n",
    "\n",
    "    # (3) load batch: TODO: convert this to DataSet and DataLoader\n",
    "    df_batch = df_Pat.loc[batch_PID_order]\n",
    "\n",
    "    # (4) tensor batch as tensor_idx\n",
    "    new_full_recfldgrn = 'B-' + full_recfldgrn\n",
    "    values_list = df_batch[full_recfldgrn].to_list()\n",
    "    suffix = full_recfldgrn.split('_')[-1]\n",
    "    # print(suffix)\n",
    "    # print(new_full_recfldgrn)\n",
    "    D = convert_relational_list_to_numpy(values_list, new_full_recfldgrn, suffix)\n",
    "    tensor_idx = D[new_full_recfldgrn]\n",
    "    \n",
    "    batch_rfg[new_full_recfldgrn] = tensor_idx\n",
    "    \n",
    "for k, v in batch_rfg.items(): print(k, v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecda0376-dbf4-4701-88e4-f372159d4a8e",
   "metadata": {},
   "source": [
    "## Analyze One RecFldGrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63e47c3d-c151-43be-a641-ac417599fcdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 87, 22, 3)\n"
     ]
    }
   ],
   "source": [
    "full_recfldgrn = 'B-P-EC-Diag@Value-DiagDftGrn_idx'\n",
    "info_idx = batch_rfg[full_recfldgrn]\n",
    "print(info_idx.shape)\n",
    "holder = torch.LongTensor(info_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d08ac0d5-7d8b-4160-9cb3-c1ccb252aba0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'P', 'EC']\n",
      "Diag\n",
      "Value\n",
      "DiagDftGrn\n",
      "idx\n",
      "Diag@Value-DiagDftGrn\n"
     ]
    }
   ],
   "source": [
    "# full_recfldgrn\n",
    "\n",
    "def parse_full_recfldgrn(full_recfldgrn):\n",
    "    # suffix = full_recfldgrn.split('_')[-1]\n",
    "    recfld = [i for i in full_recfldgrn.split('-') if '@' in i][0]\n",
    "    rec, fld = recfld.split('@')\n",
    "    grn_suffix = [i for i in full_recfldgrn.split('-') if 'Grn' in i][0]\n",
    "    grn, suffix = grn_suffix.split('_')\n",
    "    prefix_ids = [i for i in full_recfldgrn.split('-') if 'Grn' not in i and '@' not in i]\n",
    "    return prefix_ids, rec, fld, grn, suffix\n",
    "\n",
    "\n",
    "prefix_ids, rec, fld, grn, suffix = parse_full_recfldgrn(full_recfldgrn)\n",
    "recfldgrn = rec + '@' + fld + '-' + grn\n",
    "print(prefix_ids)\n",
    "print(rec)\n",
    "print(fld)\n",
    "print(grn)\n",
    "print(suffix)\n",
    "print(recfldgrn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8746e2-b284-4678-8296-af91de24c40e",
   "metadata": {},
   "source": [
    "# Expander Core\n",
    "\n",
    "Expander try to convert GRN_idx (or GRN_wgt) to embedding vectors.\n",
    "\n",
    "It is from idx to vector.\n",
    "\n",
    "It is a type of order-increase. \n",
    "\n",
    "\n",
    "Here the core include: CateEmbedding, NumeEmbedding, and LLMEmbed. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "551b602b-6f49-44a1-a1ff-1a532afe99e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 87, 22, 3)\n"
     ]
    }
   ],
   "source": [
    "full_recfldgrn = 'B-P-EC-Diag@Value-DiagDftGrn_idx'\n",
    "info_idx = batch_rfg[full_recfldgrn]\n",
    "print(info_idx.shape)\n",
    "holder = torch.LongTensor(info_idx)\n",
    "prefix_ids, rec, fld, grn, suffix = parse_full_recfldgrn(full_recfldgrn)\n",
    "recfldgrn = rec + '@' + fld + '-' + grn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a9f1a9e-b94b-4ad7-ac79-57687fb890a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "fldgrn_folder = 'data/ProcData/FldGrnInfo'\n",
    "fullfldgrn_file = os.path.join(fldgrn_folder, rec + '.p')\n",
    "df_FieldGrainInfo = pd.read_pickle(fullfldgrn_file)\n",
    "v2idx = df_FieldGrainInfo[df_FieldGrainInfo['recfield2grain'] == recfldgrn].iloc[0]['Vocab']['v2idx']\n",
    "# TODO: also adding padding to v2idx\n",
    "print(len(v2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c971003-741f-4e0c-bf96-fee2c353c9f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# v2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8b2bd29-75fc-4712-a583-2380a01332e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B': 0, 'P': 1, 'EC': 2, 'Diag@Value': 3, 'DiagDftGrn_idx': 4}\n",
      "DiagDftGrn_idx\n",
      "['DiagDftGrn_idx', 'Diag@Value', 'EC'] <---- Layer2Holder\n",
      "['DiagDftGrn_idx', 'Diag@Value', 'EC'] <---- psn_layers\n",
      "DiagDftGrn_idx torch.Size([8, 87, 22, 3])\n",
      "Diag@Value torch.Size([8, 87, 22, 3])\n",
      "EC torch.Size([8, 87, 22, 3])\n"
     ]
    }
   ],
   "source": [
    "############### gsn_embeddings\n",
    "Ignore_PSN_Layers = ['B', 'P']\n",
    "prefix_layers_num = len(Ignore_PSN_Layers)\n",
    "##################\n",
    "\n",
    "Layer2Idx = {v:idx for idx, v in enumerate(full_recfldgrn.split('-'))}\n",
    "name = full_recfldgrn.split('-')[-1]\n",
    "Layer2Holder = get_Layer2Holder(full_recfldgrn, holder, Ignore_PSN_Layers)\n",
    "psn_layers = list(reversed([i for i in Layer2Idx if i not in Ignore_PSN_Layers]))\n",
    "\n",
    "print(Layer2Idx)\n",
    "print(name)\n",
    "print([i for i in Layer2Holder], '<---- Layer2Holder')\n",
    "print(psn_layers, '<---- psn_layers')\n",
    "\n",
    "for source_layer in psn_layers:\n",
    "    cpsn_idx = align_psn_idx(source_layer, name, Layer2Idx, Layer2Holder)\n",
    "    print(source_layer, cpsn_idx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c46d1e8-572e-4144-9cea-07f7ffa37024",
   "metadata": {},
   "source": [
    "## CateEmbedding (Expander)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efbdd72-00cf-4032-a9fe-f03dbe0d21a4",
   "metadata": {},
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "734f6b6b-7a1e-443e-b5fb-5aa3cab8a7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fieldlm.nn.embedding\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class CateEmbeddingLayer(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 input_size, \n",
    "                 embedding_size, \n",
    "                 init = 'random', \n",
    "                 freeze = False):\n",
    "        \n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        \n",
    "        # create embedding\n",
    "        if init == 'random':\n",
    "            # c. initial from random initialization\n",
    "            self.embedding = torch.nn.Embedding(input_size, embedding_size, padding_idx = 0)\n",
    "        \n",
    "        elif type(init) == np.ndarray:\n",
    "            # a. load from pretrained array. Here init is an array.\n",
    "            weight = torch.FloatTensor(init)\n",
    "            assert weight.shape == (input_size, embedding_size)\n",
    "            self.embedding = torch.nn.Embedding.from_pretrained(weight, freeze = freeze)\n",
    "            \n",
    "        elif os.path.isfile(init):\n",
    "            # b. load from the pretrained array file.\n",
    "            weight = torch.FloatTensor(np.load(init))\n",
    "            assert tuple(weight.shape) == (input_size, embedding_size)\n",
    "            self.embedding = torch.nn.Embedding.from_pretrained(weight, freeze = freeze)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f'In correct init method \"{init}\"')\n",
    "        \n",
    "    def forward(self, info):\n",
    "        # info is the grain\n",
    "        info = self.embedding(info)\n",
    "        return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c037187-afc8-488f-a05b-ea6e63f0bc2c",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f025b352-c680-4634-a62d-8a86fb6bbbf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embed_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ba78e46-aed6-47a9-aad5-1388e3324630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [i for i in Layer2Holder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bfd2eb4-a95d-4188-96ae-ff8ded732878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer2Holder['EC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dbeeb54-4aa5-4947-8d72-6ba9567b3cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding_size': 512, 'init': 'random', 'input_size': 5001}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vocab_size = 5000 # Need to be updated.\n",
    "\n",
    "embed_para =  {'embedding_size': embed_size,\n",
    "               'init': 'random', \n",
    "               'input_size': vocab_size + 1 } # 1:the size of special tokens\n",
    "embed_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f877e4d8-fcd2-41fe-a59d-71afa84765c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_psn_embed_para(layername, embed_size):\n",
    "    \n",
    "    if 'Grn' not in layername: \n",
    "        vocab_size = 100\n",
    "    else:\n",
    "        vocab_size = 512\n",
    "        \n",
    "    embed_para = {'embedding_size': embed_size,\n",
    "                  'init': 'random', \n",
    "                  'input_size': vocab_size + 1 }\n",
    "    return embed_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba04c59f-9794-4410-a8c7-86016b00d3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-PatRec:EC-ECRec:Diag-DiagRec:DiagV-DiagVdftGrn': {'embedding_size': 512,\n",
       "  'init': 'random',\n",
       "  'input_size': 5001},\n",
       " 'DiagVdftGrn_psn': {'embedding_size': 512,\n",
       "  'init': 'random',\n",
       "  'input_size': 513},\n",
       " 'DiagRec:DiagV_psn': {'embedding_size': 512,\n",
       "  'init': 'random',\n",
       "  'input_size': 101},\n",
       " 'ECRec:Diag_psn': {'embedding_size': 512,\n",
       "  'init': 'random',\n",
       "  'input_size': 101},\n",
       " 'PatRec:EC_psn': {'embedding_size': 512, 'init': 'random', 'input_size': 101}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {}\n",
    "d[fullname] = embed_para\n",
    "\n",
    "\n",
    "\n",
    "psn_layers = [i for i in Layer2Holder]\n",
    "\n",
    "for layername in psn_layers:\n",
    "    if layername == 'P': break\n",
    "    embed_para = generate_psn_embed_para(layername, embed_size)\n",
    "    d[f'{layername}_psn'] = generate_psn_embed_para(layername, embed_size)\n",
    "    \n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "048332fb-6c14-401a-8886-49e1400b28f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-PatRec:EC-ECRec:Diag-DiagRec:DiagV-DiagVdftGrn\n",
      "{'embedding_size': 512, 'init': 'random', 'input_size': 5001}\n",
      "DiagVdftGrn_psn\n",
      "{'embedding_size': 512, 'init': 'random', 'input_size': 513}\n",
      "DiagRec:DiagV_psn\n",
      "{'embedding_size': 512, 'init': 'random', 'input_size': 101}\n",
      "ECRec:Diag_psn\n",
      "{'embedding_size': 512, 'init': 'random', 'input_size': 101}\n",
      "PatRec:EC_psn\n",
      "{'embedding_size': 512, 'init': 'random', 'input_size': 101}\n"
     ]
    }
   ],
   "source": [
    "for nn_name, layer_para in d.items():\n",
    "    print(nn_name)\n",
    "    print(layer_para)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e9c31a-8e65-41a1-ba35-9db4d56cf9d4",
   "metadata": {},
   "source": [
    "### Usage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d27962a-d6d3-4d44-80f5-09bf341447fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-PatRec:EC-ECRec:Diag-DiagRec:DiagV-DiagVdftGrn': EmbeddingLayer(\n",
       "   (embedding): Embedding(5001, 512, padding_idx=0)\n",
       " ),\n",
       " 'DiagVdftGrn_psn': EmbeddingLayer(\n",
       "   (embedding): Embedding(513, 512, padding_idx=0)\n",
       " ),\n",
       " 'DiagRec:DiagV_psn': EmbeddingLayer(\n",
       "   (embedding): Embedding(101, 512, padding_idx=0)\n",
       " ),\n",
       " 'ECRec:Diag_psn': EmbeddingLayer(\n",
       "   (embedding): Embedding(101, 512, padding_idx=0)\n",
       " ),\n",
       " 'PatRec:EC_psn': EmbeddingLayer(\n",
       "   (embedding): Embedding(101, 512, padding_idx=0)\n",
       " )}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_Dict = {}\n",
    "\n",
    "for nn_name, layer_para in d.items():\n",
    "    layer = EmbeddingLayer(**layer_para)\n",
    "    NN_Dict[nn_name] = layer\n",
    "    \n",
    "NN_Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0616728-fd99-4536-81f4-bc21a9820636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 6)\n",
      "3\n",
      "3 --> (3, 6, 6)\n",
      "4 --> (3, 6, 6, 8)\n",
      "(3, 6, 6, 8)\n",
      "torch.Size([3, 6, 6, 8])\n",
      "DiagVdftGrn\n",
      "DiagRec:DiagV\n",
      "ECRec:Diag\n",
      "PatRec:EC\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "########################\n",
    "B_lenP = 3\n",
    "B2P_lnEC = [6, 4, 3] # \n",
    "prefix_layers_num = 2\n",
    "vocab_size = 100\n",
    "########################\n",
    "\n",
    "fullname = 'B-PatRec:EC-ECRec:Diag-DiagRec:DiagV-DiagVdftGrn'\n",
    "layer2layeridx = {v:idx for idx, v in enumerate(fullname.split('2'))}\n",
    "name = fullname.split('-')[-1]\n",
    "\n",
    "data = get_simulated_tensor_from_fldname(fullname, B_lenP, B2P_lnEC, prefix_layers_num, vocab_size)\n",
    "print(data.shape)\n",
    "# fld_tensor_idx\n",
    "\n",
    "\n",
    "info_idx = torch.LongTensor(data)\n",
    "print(info_idx.shape)\n",
    "holder = info_idx\n",
    "# grn_leng_mask = info_idx == 0\n",
    "# print(grn_leng_mask.shape)\n",
    "\n",
    "Layer2Holder = get_Layer2Holder(fullname, holder)\n",
    "for i in Layer2Holder: print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b12ed771-69e2-447f-b899-8c205a4ac9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingLayer(\n",
       "  (embedding): Embedding(5001, 512, padding_idx=0)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embed\n",
    "Embed = NN_Dict[fullname]\n",
    "Embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e87e0bf7-be84-4a02-9d00-b1e30fd55ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 6, 6, 8, 512])\n"
     ]
    }
   ],
   "source": [
    "info = Embed(info_idx)\n",
    "# tensor_name = tensor_name.replace('_idx', '2Feat_flt')\n",
    "print(info.shape)\n",
    "# print(tensor_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d5310dd-6982-4346-9e80-69a61e22ef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor_name.replace('_idx', '2Feat_flt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c17849d-c27e-4727-9ad7-404799e4e3c0",
   "metadata": {},
   "source": [
    "## NumeEmbedding (Expander)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3b98f4-6655-4341-994f-e2b565a96d5c",
   "metadata": {},
   "source": [
    "## LLMEmbedding (Expander)\n",
    "\n",
    "TODO: adding huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09dd3ed-708f-41b2-bfe8-c16947bcb63a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9e5809-efdc-41f4-ba55-facb6366c44f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40584876-b4a9-4a9d-b019-c708af7ef283",
   "metadata": {},
   "source": [
    "# Expander"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac66a58e-1b0b-4f78-a392-79294f8318bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# from fieldnn.nn.embedding import EmbeddingLayer\n",
    "# from fieldnn.nn.lmembed import LMEmbedLayer\n",
    "# from fieldnn.utils.layer import get_Layer2Holder, align_psn_idx\n",
    "\n",
    "# from ..nn.embedding import EmbeddingLayer\n",
    "# from ..nn.lmembed import LMEmbedLayer\n",
    "# from ..utils.layerfn import get_Layer2Holder, align_psn_idx\n",
    "\n",
    "\n",
    "class Expander_Layer(torch.nn.Module):\n",
    "    \n",
    "    '''Only for Increasing Embedding Dimensions'''\n",
    "    def __init__(self, input_fullname, output_fullname, expander_layer_para):\n",
    "        super(Expander_Layer, self).__init__()\n",
    "        \n",
    "        # tensor.shape[-1]\n",
    "        self.input_size = expander_layer_para['input_size']\n",
    "        self.output_size = expander_layer_para['output_size']\n",
    "        self.Ignore_PSN_Layers = expander_layer_para['Ignore_PSN_Layers']\n",
    "        \n",
    "        # Part 1: embedding\n",
    "        self.input_fullname = input_fullname\n",
    "        self.output_fullname = output_fullname\n",
    "        \n",
    "        assert 'Grn' == input_fullname[-3:]\n",
    "        assert input_fullname.replace('Grn', '') == output_fullname\n",
    "        \n",
    "        nn_name, para = expander_layer_para[input_fullname]\n",
    "        \n",
    "        if nn_name.lower() == 'embedding':\n",
    "            self.Embed = EmbeddingLayer(**para)\n",
    "            self.embed_size = para['embedding_size']\n",
    "        elif nn_name.lower() == 'lmembed':\n",
    "            # TODO\n",
    "            self.Embed = LMEmbedLayer(**para)\n",
    "            self.embed_size = para['embedding_size']\n",
    "        else:\n",
    "            raise ValueError(f'NN \"{nn_name}\" is not available')\n",
    "            \n",
    "        assert self.embed_size == self.output_size\n",
    "        \n",
    "        # Part 2: PSN embedding\n",
    "        # psn_layers = expander_layer_para['psn_layers']\n",
    "        # self.PSN_Embed_Dict = torch.nn.ModuleDict()\n",
    "        # for layername in psn_layers:\n",
    "        #     para = generate_psn_embed_para(layername, self.embed_size)\n",
    "        #     self.PSN_Embed_Dict[layername] = EmbeddingLayer(**para)\n",
    "        \n",
    "        # Part 3: PostProcess\n",
    "        self.postprocess = torch.nn.ModuleDict()\n",
    "        for method, config in expander_layer_para['postprocess'].items():\n",
    "            if method == 'dropout':\n",
    "                self.postprocess[method] = torch.nn.Dropout(**config)\n",
    "            elif method == 'activator':\n",
    "                activator = config\n",
    "                if activator.lower() == 'relu': \n",
    "                    self.postprocess[method] = torch.nn.ReLU()\n",
    "                elif activator.lower() == 'tanh': \n",
    "                    self.postprocess[method] = torch.nn.Tanh()\n",
    "                elif activator.lower() == 'gelu':\n",
    "                    self.postprocess[method] = torch.nn.GELU()\n",
    "            elif method == 'layernorm':\n",
    "                self.postprocess[method] = torch.nn.LayerNorm(self.embed_size, **config)\n",
    "                \n",
    "    # def get_psn_embed(self, fullname, holder):\n",
    "    #     name = fullname.split('-')[-1]\n",
    "    #     Layer2Idx = {v:idx for idx, v in enumerate(fullname.split('-'))}\n",
    "    #     Layer2Holder = get_Layer2Holder(fullname, holder, self.Ignore_PSN_Layers)\n",
    "        \n",
    "    #     psn_embed = 0\n",
    "    #     for source_layer, Embed in self.PSN_Embed_Dict.items():\n",
    "    #         cpsn_idx = align_psn_idx(source_layer, name, Layer2Idx, Layer2Holder)\n",
    "    #         psn_embed = psn_embed + Embed(cpsn_idx)\n",
    "        \n",
    "    #     return psn_embed\n",
    "\n",
    "    def forward(self, fullname, holder, info = 'Empty'):\n",
    "        '''\n",
    "            fullname: full name of field, GRN is here\n",
    "            holder: info_idx\n",
    "            info: info_wgt\n",
    "        '''\n",
    "        assert self.input_fullname == fullname\n",
    "        leng_mask = holder == 0\n",
    "        embed = self.Embed(holder)\n",
    "        \n",
    "        if type(info) != str:\n",
    "            embed = embed * info.unsqueeze(-1)\n",
    "        \n",
    "        # Comments: move these to Learner.\n",
    "        # if len(self.PSN_Embed_Dict):\n",
    "        #     psn_embed = self.get_psn_embed(fullname, holder)\n",
    "        #     embed = embed + psn_embed\n",
    "        \n",
    "        for nn, layer in self.postprocess.items():\n",
    "            embed = layer(embed)\n",
    "        \n",
    "        return self.output_fullname, holder, embed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e2efc1-c2d7-4add-a485-cb7f64e94f9e",
   "metadata": {},
   "source": [
    "# Transformer (Learner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e179734-2f05-4220-b842-e7331d946abe",
   "metadata": {},
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4502f140-697c-412e-9709-17f5bc719339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class TFMLayer(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_size = 512, \n",
    "                 output_size = 512, # d_model\n",
    "                 nhead = 8,\n",
    "                 num_encoder_layers = 6, # only have encoder part\n",
    "                 num_decoder_layers = 0, # in default, we don't need decoder part. \n",
    "                 dim_feedforward = 2048, \n",
    "                 tfm_dropout = 0.1,\n",
    "                 tfm_activation = 'relu'):\n",
    "        \n",
    "        '''https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/transformer.py'''\n",
    "\n",
    "        super(TFMLayer,self).__init__()\n",
    "        self.num_encoder_layers = num_encoder_layers\n",
    "        self.num_decoder_layers = num_decoder_layers\n",
    "        self.input_size = input_size\n",
    "        self.tfm_input_size = input_size\n",
    "        self.n_directions = 1\n",
    "        self.output_size = output_size\n",
    "        assert output_size % self.n_directions == 0 \n",
    "        self.hidden_size = int(output_size / self.n_directions)\n",
    "        assert self.hidden_size == self.tfm_input_size\n",
    "            \n",
    "        self.transformer  = torch.nn.Transformer(d_model = self.hidden_size, \n",
    "                                                 nhead = nhead,\n",
    "                                                 num_encoder_layers = self.num_encoder_layers,\n",
    "                                                 num_decoder_layers = self.num_decoder_layers,\n",
    "                                                 dim_feedforward = dim_feedforward, \n",
    "                                                 dropout = tfm_dropout,\n",
    "                                                 activation = tfm_activation,\n",
    "                                                 batch_first = True,\n",
    "                                                 # src_mask_flag = False, # see all tokens in a sentence \n",
    "                                                 # # This IS THE NEW PART. NOT PyTorch.nn.\n",
    "                                                 ) \n",
    "\n",
    "\n",
    "    def forward(self, info, leng_mask):\n",
    "        info = self.transformer(info, info, src_key_padding_mask = leng_mask,  tgt_key_padding_mask  = leng_mask)\n",
    "        # for layer in self.postprocess:\n",
    "        #     info = layer(info)\n",
    "        return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a0a55c-ce55-411d-ab7d-058e2f5d3dbd",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df7319aa-ed3f-4d76-8dd6-ca0db4c14fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_size': 512,\n",
       " 'output_size': 512,\n",
       " 'nhead': 8,\n",
       " 'num_encoder_layers': 6,\n",
       " 'num_decoder_layers': 0,\n",
       " 'dim_feedforward': 2048,\n",
       " 'tfm_dropout': 0.1,\n",
       " 'tfm_activation': 'relu'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_para =  {'input_size': 512,\n",
    "             'output_size': 512,\n",
    "             'nhead': 8,\n",
    "             'num_encoder_layers': 6,\n",
    "             'num_decoder_layers': 0,\n",
    "             'dim_feedforward': 2048,\n",
    "             'tfm_dropout': 0.1,\n",
    "             'tfm_activation': 'relu'}\n",
    "tfm_para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ee79c2-a9c3-4282-93d8-8ad6737485a1",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "803f5e37-6389-4280-933c-89bf734b48ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFMLayer(\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList()\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_layer = TFMLayer(**tfm_para)\n",
    "tfm_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8c6aaaf-ffdd-48a6-b708-19b66d5d9dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-PatRec:EC-ECRec:Diag-DiagRec:DiagV-DiagVdftGrn\n",
      "torch.Size([3, 6, 6, 8])\n",
      "torch.Size([3, 6, 6, 8, 512])\n"
     ]
    }
   ],
   "source": [
    "print(fullname)\n",
    "print(info_idx.shape)\n",
    "info = Embed(info_idx)\n",
    "print(info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d94b742-2dd4-4c8e-b267-15049186be5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 6, 6, 8])\n",
      "torch.Size([3, 6, 6, 8, 512])\n",
      "torch.Size([3, 6, 6, 8])\n"
     ]
    }
   ],
   "source": [
    "print(info_idx.shape)\n",
    "leng_mask = info_idx == 0\n",
    "print(info.shape)\n",
    "print(leng_mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95c64af-93c2-4847-9524-d22dfd7ff2b6",
   "metadata": {},
   "source": [
    "### Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a3f7dce-eebe-43f9-87eb-912a47441589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3*6*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09298b82-285d-4a21-ad72-cc2fbd8c87f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 8 512\n",
      "torch.Size([108, 8, 512])\n",
      "torch.Size([108, 8])\n",
      "torch.Size([108])\n"
     ]
    }
   ],
   "source": [
    "nbs = np.array(info.shape[:-2]).prod()\n",
    "ngrn, dim = info.shape[-2:]\n",
    "print(nbs, ngrn, dim)\n",
    "\n",
    "\n",
    "tmp_info = info.contiguous().view(nbs, ngrn, dim)\n",
    "print(tmp_info.shape)\n",
    "\n",
    "tmp_leng_mask = leng_mask.contiguous().view(nbs, ngrn)\n",
    "print(tmp_leng_mask.shape)\n",
    "\n",
    "tmp_leng = (tmp_leng_mask == 0).sum(-1)\n",
    "print(tmp_leng.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48947be8-20b4-460c-b140-31af3af45cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# order sequences and restore sequences according to their lenghts\n",
    "# TODO: test the speed of orderSeq and restoreSeq\n",
    "\n",
    "def orderSeq(seq_unordered, leng_unordered):\n",
    "    # leng_unordered is a tensor\n",
    "    # seq_unordered is a numpy\n",
    "    leng_ordered, seq_index = leng_unordered.sort(descending=True) \n",
    "    _, reverse_index = seq_index.sort()\n",
    "    leng_ordered = leng_ordered[leng_ordered>0]\n",
    "    seq_index    = seq_index[:len(leng_ordered)]\n",
    "    seq_ordered  = seq_unordered[seq_index.cpu()]\n",
    "    return seq_ordered, leng_ordered, reverse_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c29c883-44dd-49d6-bf11-dc60e2f8c3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([108, 8, 512])\n",
      "torch.Size([48, 8, 512])\n",
      "torch.Size([48])\n",
      "torch.Size([108])\n",
      "tensor([8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 7, 7, 6, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "tmp_info = info.contiguous().view(nbs, ngrn, dim)\n",
    "print(tmp_info.shape)\n",
    "\n",
    "ord_info,      ord_leng, r_idx = orderSeq(tmp_info, tmp_leng)\n",
    "ord_leng_mask, ord_leng, r_idx = orderSeq(tmp_leng_mask, tmp_leng)\n",
    "print(ord_info.shape)\n",
    "print(ord_leng.shape)\n",
    "print(r_idx.shape)\n",
    "print(ord_leng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b485ae3-5540-42e9-a4c3-e05ee4ac3d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [image1,    image2,    image3]\n",
    "# [outcome1, outcome2, outcome3]\n",
    "# 48, 8, 512\n",
    "# 20, 15, 13\n",
    "# [s1, s2.....]\n",
    "# [r1, r2,....]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f04a0a8-4e3f-4fdc-9ca6-9e2fe8773df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([108, 8])\n",
      "torch.Size([48, 8])\n",
      "torch.Size([48])\n",
      "torch.Size([108])\n",
      "tensor([8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 7, 7, 6, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(tmp_leng_mask.shape)\n",
    "ord_leng_mask, ord_leng, r_idx = orderSeq(tmp_leng_mask, tmp_leng)\n",
    "print(ord_leng_mask.shape)\n",
    "print(ord_leng.shape)\n",
    "print(r_idx.shape)\n",
    "print(ord_leng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce6d15a-edbc-408c-be52-92d08eaf6069",
   "metadata": {},
   "source": [
    "### Calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "180ec929-b20b-4b8d-8aed-2d5d39975bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48, 8, 512])\n"
     ]
    }
   ],
   "source": [
    "ord_info_output = tfm_layer(ord_info, ord_leng_mask)\n",
    "print(ord_info_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce140a9-1cd8-4c58-a05a-7e62b0fe1407",
   "metadata": {},
   "source": [
    "### Restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "685e4ec6-d06f-4ae8-a0ec-796732b1a4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restoreSeq(seq_ordered, reverse_index):\n",
    "    # shape = list(seq_ordered.shape)\n",
    "    data_type = seq_ordered.type()\n",
    "    shape = list(seq_ordered.shape)\n",
    "    shape[0] = len(reverse_index) - shape[0]\n",
    "    t = torch.cat([seq_ordered, torch.zeros(shape).type(data_type)])\n",
    "    seq_restored = t[reverse_index]\n",
    "    return seq_restored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6c3be77-0194-4a9d-8052-9d312405daed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([108, 8, 512])\n"
     ]
    }
   ],
   "source": [
    "info_new = restoreSeq(ord_info_output, r_idx)\n",
    "print(info_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90c17ba4-03cd-4ff0-83a7-876f899a9e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 6, 6, 8, 512])\n"
     ]
    }
   ],
   "source": [
    "output_size = dim\n",
    "info_output = info_new.view(*list(leng_mask.shape) + [output_size])\n",
    "print(info_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3bf4fad8-a610-47a6-815d-bfd82c2e40bf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.2140,  0.2946,  0.8117,  0.8469,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [-0.5250,  0.8469,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.1241, -1.9581,  0.7282, -1.8982,  1.9860, -1.9581,  1.6688,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000]],\n",
       "\n",
       "         [[ 0.6670,  1.9860,  0.0610,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 1.2140,  0.2701,  1.2046,  0.0610, -0.9479, -0.4609,  0.7881,\n",
       "            1.0486],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000]],\n",
       "\n",
       "         [[ 0.1632,  0.3346, -1.8982,  1.9860,  0.0610, -0.0164, -0.3702,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000]],\n",
       "\n",
       "         [[-0.4077, -0.8134, -0.9163, -0.7658,  1.1806, -2.4329,  2.5638,\n",
       "            0.0000],\n",
       "          [ 0.2095,  0.4794, -0.2375,  0.6555,  0.3052,  0.5356,  0.1152,\n",
       "            0.0000],\n",
       "          [ 1.0747, -0.1809,  0.0196, -0.7138,  1.0486, -0.4760, -0.9157,\n",
       "            0.0000],\n",
       "          [ 1.6688,  0.2946, -0.9479, -0.7658, -1.2023,  1.5160,  0.3346,\n",
       "           -0.1951],\n",
       "          [-1.8982, -0.5250,  0.5356, -0.9958,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000]],\n",
       "\n",
       "         [[ 0.5356,  0.2095,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.8117,  1.0433, -0.6869, -0.6869,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [-0.1088, -0.6676,  0.2940,  0.0921, -0.1765,  0.1852, -1.8982,\n",
       "            1.0436],\n",
       "          [-2.4329, -0.7658, -0.0999,  0.1241, -2.8440, -0.5250, -0.1088,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000]],\n",
       "\n",
       "         [[ 0.5946,  1.9860,  0.6753,  0.5356,  0.2701,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.8682,  0.6753,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [-0.6869, -0.7721,  0.1152, -0.4077, -0.0999,  1.6688,  1.9860,\n",
       "           -0.2375],\n",
       "          [ 0.2095, -0.7138,  0.8469,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.4076, -0.0164,  0.2095,  0.0196,  0.7282,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 1.9860, -0.0217,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 1.6688,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.3346,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [-0.4760,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [-1.6243,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 1.6688,  0.7357,  0.0610,  2.5638,  0.2095,  0.0000,  0.0000,\n",
       "            0.0000]],\n",
       "\n",
       "         [[ 0.8682, -0.9163, -0.8134,  0.1632,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [-0.1951, -0.9163, -0.0164,  0.7282, -0.2122,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.1609, -0.4609,  1.5160,  1.6275,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 1.6688,  0.7881,  0.7282,  0.0196, -0.3012,  1.0433,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.6555, -0.9931,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000]],\n",
       "\n",
       "         [[ 1.6688,  1.2140,  1.5160,  0.7881, -0.0768,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [-1.0980,  1.6688, -0.5488,  0.8248,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.7357,  0.0610, -0.5488,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000]],\n",
       "\n",
       "         [[-0.6869, -0.8134,  0.3499, -1.8982,  0.0921, -0.1951,  0.4794,\n",
       "            0.0000],\n",
       "          [-0.9931, -1.8982,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [-1.2023, -0.2922,  0.4794,  0.0196,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.9157,  0.2946,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.6670, -1.2023,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.8248,  1.6615, -0.3702,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000]],\n",
       "\n",
       "         [[-1.2997,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [-2.4329,  1.6275, -1.6243,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [-0.4797, -1.2997, -0.0999, -0.6676,  0.8248, -0.9157, -0.4760,\n",
       "            0.0000],\n",
       "          [-0.7589,  0.0196, -0.2122,  1.1806, -1.6367,  1.6688,  0.5946,\n",
       "           -0.3012],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000]],\n",
       "\n",
       "         [[ 0.1852,  0.7357, -1.5501,  0.2701,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [-0.2375,  1.5160, -0.9479, -0.2922,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.1632, -0.2922,  0.7357,  1.9738,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [-1.6367,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000]]]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_output[:,:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17c872ad-09f1-4b92-af98-1bb8749e5e3e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[False, False, False, False,  True,  True,  True,  True],\n",
       "          [False, False,  True,  True,  True,  True,  True,  True],\n",
       "          [False, False, False, False, False, False, False,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[False, False, False,  True,  True,  True,  True,  True],\n",
       "          [False, False, False, False, False, False, False, False],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[False, False, False, False, False, False, False,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[False, False, False, False, False, False, False,  True],\n",
       "          [False, False, False, False, False, False, False,  True],\n",
       "          [False, False, False, False, False, False, False,  True],\n",
       "          [False, False, False, False, False, False, False, False],\n",
       "          [False, False, False, False,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[False, False,  True,  True,  True,  True,  True,  True],\n",
       "          [False, False, False, False,  True,  True,  True,  True],\n",
       "          [False, False, False, False, False, False, False, False],\n",
       "          [False, False, False, False, False, False, False,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[False, False, False, False, False,  True,  True,  True],\n",
       "          [False, False,  True,  True,  True,  True,  True,  True],\n",
       "          [False, False, False, False, False, False, False, False],\n",
       "          [False, False, False,  True,  True,  True,  True,  True],\n",
       "          [False, False, False, False, False,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True]]],\n",
       "\n",
       "\n",
       "        [[[False, False,  True,  True,  True,  True,  True,  True],\n",
       "          [False,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [False,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [False,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [False,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [False, False, False, False, False,  True,  True,  True]],\n",
       "\n",
       "         [[False, False, False, False,  True,  True,  True,  True],\n",
       "          [False, False, False, False, False,  True,  True,  True],\n",
       "          [False, False, False, False,  True,  True,  True,  True],\n",
       "          [False, False, False, False, False, False,  True,  True],\n",
       "          [False, False,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[False, False, False, False, False,  True,  True,  True],\n",
       "          [False, False, False, False,  True,  True,  True,  True],\n",
       "          [False, False, False,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[False, False, False, False, False, False, False,  True],\n",
       "          [False, False,  True,  True,  True,  True,  True,  True],\n",
       "          [False, False, False, False,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True]]],\n",
       "\n",
       "\n",
       "        [[[False, False,  True,  True,  True,  True,  True,  True],\n",
       "          [False, False,  True,  True,  True,  True,  True,  True],\n",
       "          [False, False, False,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[False,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [False, False, False,  True,  True,  True,  True,  True],\n",
       "          [False, False, False, False, False, False, False,  True],\n",
       "          [False, False, False, False, False, False, False, False],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[False, False, False, False,  True,  True,  True,  True],\n",
       "          [False, False, False, False,  True,  True,  True,  True],\n",
       "          [False, False, False, False,  True,  True,  True,  True],\n",
       "          [False,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True,  True,  True]]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leng_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bbb706-d953-4244-ad79-a5a5670ab8e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771a158a-1c01-47f9-9a58-77092d451c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
