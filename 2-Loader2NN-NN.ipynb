{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a47a2660-824c-41fd-81e5-58a2207cbc74",
   "metadata": {},
   "source": [
    "# Simulate Data\n",
    "\n",
    "\n",
    "Given a field name, and first 2 dimensional numbes, simulate tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "922efef5-587d-4d27-8882-74ef116dcde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.alias import Instance\n",
    "import numpy as np\n",
    "\n",
    "def traverse(o, tree_types=(list, tuple, np.ndarray), index = None, nest_layer = 100):\n",
    "    if isinstance(o, tree_types) and nest_layer > 0:\n",
    "        for idx, value in enumerate(o):\n",
    "            new_index = index + [idx] if type(index) == list else [idx]\n",
    "            for subvalue in traverse(value, tree_types, new_index, nest_layer - 1):\n",
    "                yield subvalue\n",
    "    else:\n",
    "        if not isinstance(o, tree_types): \n",
    "            length = None\n",
    "        else:\n",
    "            length = len(o)\n",
    "        yield index, length, o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "757b98d5-c154-4658-88f0-a900335842f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[3, 6, 8, 4, 100]\n"
     ]
    }
   ],
   "source": [
    "# TODO: based on fld_name, get input_tensor\n",
    "import numpy as np\n",
    "B_lenP = 3\n",
    "B2P_lnEC = [6, 5, 2] # \n",
    "prefix_layers_num = 2\n",
    "vocab_size = 100\n",
    "\n",
    "###############\n",
    "# 'B-P-EC:Diag-Rec:V-VdftGrn'\n",
    "# B: batch\n",
    "# P: patient\n",
    "# EC:Diag: Encounter's DiagInfo\n",
    "# Rec:V: a Rec's Value: E11\n",
    "# VdftGrn: Value to a list of Grn. ICD-10 [E, 1, 1]\n",
    "fld_name = 'B-P-EC:Diag-Rec:V-VdftGrn'\n",
    "###############\n",
    "\n",
    "\n",
    "# fld_name = 'B2St2TkGrn'\n",
    "layers_num = len(fld_name.split('-'))\n",
    "print(layers_num)\n",
    "\n",
    "# max_list = df['max'].astype(int).to_list()\n",
    "prefix = [np.array(B_lenP).max(), max(B2P_lnEC)] \n",
    "max_list = [np.array(B_lenP).max(), max(B2P_lnEC)] + list(np.random.randint(1, 10, layers_num - len(prefix) - 1)) + [vocab_size]\n",
    "print(max_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c30464f1-dbb4-4d40-b8be-382912a56173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_info(layer, current_info, max_list):\n",
    "    current_max = max_list[layer]\n",
    "    next_max = max_list[layer + 1]\n",
    "    # to do: get next_info\n",
    "    next_info = np.zeros(list(np.array(current_info).shape) + [current_max]).astype(int)\n",
    "    # print(next_info.shape)\n",
    "    for element in list(traverse(current_info, nest_layer = layer)):\n",
    "        idx, leng, value = element\n",
    "        # print(next_info[tuple(idx)])\n",
    "        next_info[tuple(idx)][:value] = np.random.randint(1, next_max + 1, value)\n",
    "\n",
    "    # print(next_info)\n",
    "    return next_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89fca9a3-6f78-4a6c-ae25-4c130fb6d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simulated_tensor_from_fldname(fld_name, B_lenP, B2P_lnEC, prefix_layers_num, vocab_size):\n",
    "    layers_num = len(fld_name.split('-'))\n",
    "    # print(layers_num)\n",
    "\n",
    "    # max_list = df['max'].astype(int).to_list()\n",
    "    prefix = [np.array(B_lenP).max(), max(B2P_lnEC)] \n",
    "    max_list = [np.array(B_lenP).max(), max(B2P_lnEC)] + list(np.random.randint(1, 10, layers_num - len(prefix) - 1)) + [vocab_size]\n",
    "    # print(max_list)\n",
    "\n",
    "    init_info = np.array(B2P_lnEC)\n",
    "    \n",
    "    for layer_idx in range(prefix_layers_num - 1, layers_num - 1):\n",
    "        print(layer_idx)\n",
    "        current_info = init_info\n",
    "        next_info = get_next_info(layer_idx, current_info, max_list)\n",
    "        # print(next_info)\n",
    "        init_info = next_info\n",
    "\n",
    "        print(layer_idx, '-->', current_info.shape)\n",
    "        print(layer_idx + 1, '-->', next_info.shape)\n",
    "\n",
    "\n",
    "    fld_tensor_idx = next_info\n",
    "    # print(fld_tensor.shape)\n",
    "    return fld_tensor_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1af33ffb-1dae-425a-bddb-d83de1da20a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 4)\n",
      "3\n",
      "3 --> (3, 6, 4)\n",
      "4 --> (3, 6, 4, 3)\n",
      "(3, 6, 4, 3)\n"
     ]
    }
   ],
   "source": [
    "B_lenP = 3\n",
    "B2P_lnEC = [6, 5, 2] # \n",
    "prefix_layers_num = 2\n",
    "vocab_size = 100\n",
    "\n",
    "\n",
    "fld_name = 'B-P-EC:Diag-DiagRec:V-VdftGrn'\n",
    "fld_tensor_idx = get_simulated_tensor_from_fldname(fld_name, B_lenP, B2P_lnEC, prefix_layers_num, vocab_size)\n",
    "print(fld_tensor_idx.shape)\n",
    "# fld_tensor_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c5af8f1-6e5f-41a3-986d-4f0a5f990991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 6, 4, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fld_tensor_idx.shape\n",
    "\n",
    "# ( 3,6,      4,    3)\n",
    "# 'B-P-EC:Diag-DiagRec:V-VdftGrn' [E, 1, 1]\n",
    "# fld_tensor_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e4149a-a345-4cc3-93eb-1208d6f5a5ae",
   "metadata": {},
   "source": [
    "# info_idx, info, leng_mask, leng\n",
    "\n",
    "1. Current Layer:\n",
    "```python\n",
    "leng_mask = info_idx == 0 # or info_idx != 0\n",
    "leng = leng_mask.sum(-1)\n",
    "```\n",
    "\n",
    "2. Transfer\n",
    "\n",
    "```python\n",
    "old_leng = leng\n",
    "```\n",
    "\n",
    "\n",
    "3. Next Layer\n",
    "```python\n",
    "leng_mask = old_leng != 0\n",
    "leng = (leng_mask == 0).sum(-1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "826150be-1413-4b3e-b619-51de65e9c119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 7)\n",
      "3\n",
      "3 --> (3, 6, 7)\n",
      "4 --> (3, 6, 7, 6)\n",
      "(3, 6, 7, 6)\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "B_lenP = 3\n",
    "B2P_lnEC = [6, 4, 3] # \n",
    "prefix_layers_num = 2\n",
    "vocab_size = 100\n",
    "########################\n",
    "\n",
    "fullname = 'B-P-EC:Diag-DiagRec:V-VdftGrn'\n",
    "# fld_name = 'B2St2TkGrn'\n",
    "data = get_simulated_tensor_from_fldname(fullname, B_lenP, B2P_lnEC, prefix_layers_num, vocab_size)\n",
    "print(data.shape)\n",
    "# fld_tensor_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4d9dff-c6d8-4981-9506-f21817d89e5b",
   "metadata": {},
   "source": [
    "## 'B-P-EC:Diag-DiagRec:V-VdftGrn' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cd26b641-697a-466d-a8e9-d9a3498dd4d7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 50,  23,  55,   0,   0,   0],\n",
       "         [ 60,  76,  45,  54,   0,   0],\n",
       "         [ 84,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0]],\n",
       "\n",
       "        [[ 17,   7,  69,  97,  92,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0]],\n",
       "\n",
       "        [[ 25,  71,  38,   0,   0,   0],\n",
       "         [ 12,  99,  82,  72,   0,   0],\n",
       "         [ 87,  36,  98,   0,   0,   0],\n",
       "         [ 17,  81,  33,   0,   0,   0],\n",
       "         [ 34,  44,   0,   0,   0,   0],\n",
       "         [ 16,  81,  17,  85,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0]],\n",
       "\n",
       "        [[ 25,  71,  13,  84,  56,  15],\n",
       "         [ 13,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0]],\n",
       "\n",
       "        [[ 19,  59,   0,   0,   0,   0],\n",
       "         [ 60,   5,   0,   0,   0,   0],\n",
       "         [ 90,  31,  98,  83,  32,  34],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0]],\n",
       "\n",
       "        [[ 16,  35,   7,  42,   0,   0],\n",
       "         [ 60,  59,  54,  93,  37,  61],\n",
       "         [ 28,   0,   0,   0,   0,   0],\n",
       "         [ 92,   1,  18,  45,   0,   0],\n",
       "         [ 52,  49,   0,   0,   0,   0],\n",
       "         [ 94,  17,  62,  53,  59,  31],\n",
       "         [  0,   0,   0,   0,   0,   0]]],\n",
       "\n",
       "\n",
       "       [[[ 46,  12,  49,  45,   9,   0],\n",
       "         [ 90,  78,  93,   0,   0,   0],\n",
       "         [ 19,  29,   0,   0,   0,   0],\n",
       "         [ 43,  16,  52,  75,  90,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0]],\n",
       "\n",
       "        [[  8,   0,   0,   0,   0,   0],\n",
       "         [ 78,  74,  58,  19,   0,   0],\n",
       "         [ 53,  74,   3,   0,   0,   0],\n",
       "         [ 66,  35,  18,  91,   0,   0],\n",
       "         [ 72,  95,  65,  96,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0]],\n",
       "\n",
       "        [[ 52,  39,   4,  63,  15,  31],\n",
       "         [ 50,  93,  24,  53,  93,  10],\n",
       "         [100,  37,  50,  44,  45,   0],\n",
       "         [  1,  64,  92,   0,   0,   0],\n",
       "         [ 98,   4,  70,  67,   0,   0],\n",
       "         [ 52,  24,  50,  49,  53,  57],\n",
       "         [  0,   0,   0,   0,   0,   0]],\n",
       "\n",
       "        [[ 40,  77,  14,  78,  99,   0],\n",
       "         [ 41,   0,   0,   0,   0,   0],\n",
       "         [ 65,  17,  74,  54,   0,   0],\n",
       "         [ 69,  73, 100,  65,  43,   0],\n",
       "         [ 53,  79,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0]],\n",
       "\n",
       "        [[  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0]],\n",
       "\n",
       "        [[  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0]]],\n",
       "\n",
       "\n",
       "       [[[ 37,  45,   0,   0,   0,   0],\n",
       "         [ 77,  45,  15,  40,   5,   0],\n",
       "         [ 75,  80,   0,   0,   0,   0],\n",
       "         [  2,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0]],\n",
       "\n",
       "        [[ 34,  24,   0,   0,   0,   0],\n",
       "         [ 32,  45,  95,  86,  45,   0],\n",
       "         [ 78,  39,  26,  82,  61,   0],\n",
       "         [ 32,   1,   9,  63,  59,  18],\n",
       "         [ 48,  94,  53,  69,   0,   0],\n",
       "         [ 64,  38,   9,  28,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0]],\n",
       "\n",
       "        [[ 47,  35,  58,  43, 100,   0],\n",
       "         [  2,  63,   0,   0,   0,   0],\n",
       "         [  8,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0]],\n",
       "\n",
       "        [[  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0]],\n",
       "\n",
       "        [[  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0]],\n",
       "\n",
       "        [[  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0]]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "431ab9f1-8984-4e77-8be6-2ffd869733d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 6, 7, 6])\n",
      "torch.Size([3, 6, 7, 6])\n",
      "torch.Size([3, 6, 7, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[False, False, False,  True,  True,  True],\n",
       "          [False, False, False, False,  True,  True],\n",
       "          [False,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[False, False, False, False, False,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[False, False, False,  True,  True,  True],\n",
       "          [False, False, False, False,  True,  True],\n",
       "          [False, False, False,  True,  True,  True],\n",
       "          [False, False, False,  True,  True,  True],\n",
       "          [False, False,  True,  True,  True,  True],\n",
       "          [False, False, False, False,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[False, False, False, False, False, False],\n",
       "          [False,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[False, False,  True,  True,  True,  True],\n",
       "          [False, False,  True,  True,  True,  True],\n",
       "          [False, False, False, False, False, False],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[False, False, False, False,  True,  True],\n",
       "          [False, False, False, False, False, False],\n",
       "          [False,  True,  True,  True,  True,  True],\n",
       "          [False, False, False, False,  True,  True],\n",
       "          [False, False,  True,  True,  True,  True],\n",
       "          [False, False, False, False, False, False],\n",
       "          [ True,  True,  True,  True,  True,  True]]],\n",
       "\n",
       "\n",
       "        [[[False, False, False, False, False,  True],\n",
       "          [False, False, False,  True,  True,  True],\n",
       "          [False, False,  True,  True,  True,  True],\n",
       "          [False, False, False, False, False,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[False,  True,  True,  True,  True,  True],\n",
       "          [False, False, False, False,  True,  True],\n",
       "          [False, False, False,  True,  True,  True],\n",
       "          [False, False, False, False,  True,  True],\n",
       "          [False, False, False, False,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[False, False, False, False, False, False],\n",
       "          [False, False, False, False, False, False],\n",
       "          [False, False, False, False, False,  True],\n",
       "          [False, False, False,  True,  True,  True],\n",
       "          [False, False, False, False,  True,  True],\n",
       "          [False, False, False, False, False, False],\n",
       "          [ True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[False, False, False, False, False,  True],\n",
       "          [False,  True,  True,  True,  True,  True],\n",
       "          [False, False, False, False,  True,  True],\n",
       "          [False, False, False, False, False,  True],\n",
       "          [False, False,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True]]],\n",
       "\n",
       "\n",
       "        [[[False, False,  True,  True,  True,  True],\n",
       "          [False, False, False, False, False,  True],\n",
       "          [False, False,  True,  True,  True,  True],\n",
       "          [False,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[False, False,  True,  True,  True,  True],\n",
       "          [False, False, False, False, False,  True],\n",
       "          [False, False, False, False, False,  True],\n",
       "          [False, False, False, False, False, False],\n",
       "          [False, False, False, False,  True,  True],\n",
       "          [False, False, False, False,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[False, False, False, False, False,  True],\n",
       "          [False, False,  True,  True,  True,  True],\n",
       "          [False,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True,  True]]]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "info_idx = torch.LongTensor(data)\n",
    "print(info_idx.shape)\n",
    "\n",
    "holder = info_idx\n",
    "\n",
    "leng_mask = holder == 0\n",
    "print(leng_mask.shape)\n",
    "leng = (leng_mask == 0).sum(-1)\n",
    "pos_idx = (leng_mask == False).cumsum(-1).masked_fill(leng_mask, 0)\n",
    "print(pos_idx.shape)\n",
    "\n",
    "leng_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df7f593-5c14-417b-bc33-4db64ea1c0f1",
   "metadata": {},
   "source": [
    "## 'B-P-EC:Diag-DiagRec:V' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "745fb975-1bba-458a-bab6-8a01068a46dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 6, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[False, False, False,  True,  True,  True,  True],\n",
       "         [False,  True,  True,  True,  True,  True,  True],\n",
       "         [False, False, False, False, False, False,  True],\n",
       "         [False, False,  True,  True,  True,  True,  True],\n",
       "         [False, False, False,  True,  True,  True,  True],\n",
       "         [False, False, False, False, False, False,  True]],\n",
       "\n",
       "        [[False, False, False, False,  True,  True,  True],\n",
       "         [False, False, False, False, False,  True,  True],\n",
       "         [False, False, False, False, False, False,  True],\n",
       "         [False, False, False, False, False,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "        [[False, False, False, False,  True,  True,  True],\n",
       "         [False, False, False, False, False, False,  True],\n",
       "         [False, False, False,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True,  True,  True,  True]]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next layer\n",
    "holder = leng\n",
    "\n",
    "leng_mask = holder == 0\n",
    "print(leng_mask.shape)\n",
    "leng = (leng_mask == 0).sum(-1)\n",
    "\n",
    "leng_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd8c74d-2123-40db-a881-b59a1bd9732b",
   "metadata": {},
   "source": [
    "## 'B-P-EC:Diag' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "32c21d20-9421-4e79-870e-15882af2732a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False],\n",
       "        [False, False, False, False,  True,  True],\n",
       "        [False, False, False,  True,  True,  True]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holder = leng\n",
    "leng_mask = holder == 0\n",
    "print(leng_mask.shape)\n",
    "leng = (leng_mask == 0).sum(-1)\n",
    "\n",
    "leng_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6397f0e-3ceb-4b54-bb12-f66bbda8300b",
   "metadata": {},
   "source": [
    "## 'B-P' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "61d80a49-c423-4e39-8941-865f1ba32381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holder = leng\n",
    "leng_mask = holder == 0\n",
    "\n",
    "print(leng_mask.shape)\n",
    "leng_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b169014d-8da5-4e58-af5e-26753e06f5af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leng = (leng_mask == 0).sum(-1)\n",
    "leng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ec0eee05-a6c9-49bb-8ef4-53121020aa8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 4, 3]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B2P_lnEC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd5bf74-00e1-41c6-ab91-f25613356b2d",
   "metadata": {},
   "source": [
    "# Holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "375664a8-183d-4733-8608-a9972f0c4da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 5)\n",
      "3\n",
      "3 --> (3, 6, 5)\n",
      "4 --> (3, 6, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "B_lenP = 3\n",
    "B2P_lnEC = [6, 4, 3] # \n",
    "prefix_layers_num = 2\n",
    "vocab_size = 100\n",
    "########################\n",
    "\n",
    "fullname = 'B-P-EC:Diag-DiagRec:DiagV-DiagVdftGrn'\n",
    "Ignore_PSN_Layers = ['B', 'P']\n",
    "# fullname = 'B2St2TkGrn'\n",
    "info_idx = get_simulated_tensor_from_fldname(fld_name, B_lenP, B2P_lnEC, prefix_layers_num, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c8c86c77-c820-4012-9542-40478881bbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B': 0, 'P': 1, 'EC:Diag': 2, 'DiagRec:DiagV': 3, 'DiagVdftGrn': 4}\n",
      "DiagVdftGrn\n"
     ]
    }
   ],
   "source": [
    "Layer2Idx = {v:idx for idx, v in enumerate(fullname.split('-'))}\n",
    "name = fullname.split('-')[-1]\n",
    "print(Layer2Idx)\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4b8e3c5e-baf7-40e3-acf9-489e7662436f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P-EC:Diag-DiagRec:DiagV-DiagVdftGrn\n",
      "DiagVdftGrn\n",
      "torch.Size([3, 6, 5, 5]) <-- holder\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "holder = info_idx\n",
    "holder = torch.LongTensor(holder)\n",
    "\n",
    "info = None\n",
    "print(fullname)\n",
    "print(name)\n",
    "print(holder.shape, '<-- holder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "84cbfc6e-dd63-459a-ad83-4c5d940788f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 6, 5, 5])\n",
      "B-P-EC:Diag-DiagRec:DiagV-DiagVdftGrn\n",
      "DiagVdftGrn\n",
      "DiagRec:DiagV\n",
      "EC:Diag\n"
     ]
    }
   ],
   "source": [
    "# leng_mask = info_idx == 0\n",
    "\n",
    "def get_Layer2Holder(fullname, holder, Ignore_PSN_Layers = ['B', 'P']):\n",
    "    # holder = holder\n",
    "    d = {}\n",
    "    for layername in list(reversed(fullname.split('-'))):\n",
    "        if layername in Ignore_PSN_Layers: continue\n",
    "        leng_mask = holder == 0\n",
    "        leng = (leng_mask == 0).sum(-1)\n",
    "        psn_idx = (leng_mask == False).cumsum(-1).masked_fill(leng_mask, 0)\n",
    "        d[layername] = {'holder': holder, \n",
    "                        'leng_mask': leng_mask, \n",
    "                        'leng': leng, \n",
    "                        'psn_idx': psn_idx}\n",
    "        # d[layername] = holder, psn_idx\n",
    "        holder = leng\n",
    "    Layer2Hoder = d\n",
    "    return Layer2Hoder\n",
    "\n",
    "print(holder.shape)\n",
    "print(fullname)\n",
    "Layer2Holder = get_Layer2Holder(fullname, holder)\n",
    "for i in Layer2Holder: print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ee61bb27-4e3f-4dc8-8ba2-d7a4772acf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def align_psn_idx(source_layer, current_layer, Layer2Idx, Layer2Holder):\n",
    "    if source_layer == current_layer:\n",
    "        psn_idx = Layer2Holder[current_layer]['psn_idx']\n",
    "        return psn_idx\n",
    "    else:\n",
    "        source_psn_idx = Layer2Holder[source_layer]['psn_idx']\n",
    "        current_leng_mask = Layer2Holder[current_layer]['leng_mask']\n",
    "        gaps = Layer2Idx[current_layer] - Layer2Idx[source_layer]\n",
    "        # print(gaps)\n",
    "        # print(layername)\n",
    "        # print(prev_info.shape)\n",
    "        # print(leng_mask.shape)\n",
    "        # print(leng.shape)\n",
    "        # print(psn_idx.shape)\n",
    "        shape0 = list(source_psn_idx.shape) + [1] * gaps\n",
    "        shape1 = current_leng_mask.shape\n",
    "        psn_idx = source_psn_idx.view(*shape0).expand(shape1).masked_fill(current_leng_mask, 0)\n",
    "        # print(cpsn_idx.shape)\n",
    "        return psn_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6aad5076-19a5-4615-972d-929bb321035c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DiagVdftGrn', 'DiagRec:DiagV', 'EC:Diag']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in Layer2Holder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "afcb8504-d0df-49b2-8deb-bc966cfc1f58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiagVdftGrn\n",
      "torch.Size([3, 6, 5, 5]) DiagVdftGrn\n",
      "torch.Size([3, 6, 5, 5]) DiagRec:DiagV\n",
      "torch.Size([3, 6, 5, 5]) EC:Diag\n"
     ]
    }
   ],
   "source": [
    "psn_layers = [i for i in Layer2Holder]\n",
    "\n",
    "print(name) # 'DiagVdftGrn'\n",
    "for source_layer in psn_layers:\n",
    "    cpsn_idx = align_psn_idx(source_layer, name, Layer2Idx, Layer2Holder)\n",
    "    print(cpsn_idx.shape, source_layer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9f4e0759-832a-459c-8bb2-547eb4b78c28",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Layer2Holder\n",
    "\n",
    "name = 'DiagVdftGrn'\n",
    "source_layer = 'DiagRec:DiagV'\n",
    "psn_idx = Layer2Holder[source_layer]['psn_idx']\n",
    "cpsn_idx = align_psn_idx(source_layer, name, Layer2Idx, Layer2Holder)\n",
    "# cpsn_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c46d1e8-572e-4144-9cea-07f7ffa37024",
   "metadata": {},
   "source": [
    "# Embedding (Expander)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efbdd72-00cf-4032-a9fe-f03dbe0d21a4",
   "metadata": {},
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "734f6b6b-7a1e-443e-b5fb-5aa3cab8a7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fieldlm.nn.embedding\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class EmbeddingLayer(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 input_size, \n",
    "                 embedding_size, \n",
    "                 init = 'init', \n",
    "                 freeze = False):\n",
    "        \n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        \n",
    "        # (+) self.embedding\n",
    "        if type(init) == np.ndarray:\n",
    "            # 1. from given array\n",
    "            weight = torch.FloatTensor(init)\n",
    "            assert weight.shape == (input_size, embedding_size)\n",
    "            self.embedding = torch.nn.Embedding.from_pretrained(weight, freeze = freeze)\n",
    "            \n",
    "        elif os.path.isfile(init):\n",
    "            weight = torch.FloatTensor(np.load(init))\n",
    "            assert tuple(weight.shape) == (input_size, embedding_size)\n",
    "            \n",
    "            self.embedding = torch.nn.Embedding.from_pretrained(weight, freeze = freeze)\n",
    "            \n",
    "        else:\n",
    "            # from random initialization\n",
    "            self.embedding = torch.nn.Embedding(input_size, embedding_size, padding_idx = 0)\n",
    "        \n",
    "    def forward(self, info):\n",
    "        # tensor0 to tensor1\n",
    "        info = self.embedding(info)\n",
    "        return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c037187-afc8-488f-a05b-ea6e63f0bc2c",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6ba78e46-aed6-47a9-aad5-1388e3324630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DiagVdftGrn', 'DiagRec:DiagV', 'EC:Diag']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in Layer2Holder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1bfd2eb4-a95d-4188-96ae-ff8ded732878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'holder': tensor([[2, 2, 1, 5, 3, 2],\n",
       "         [1, 4, 1, 3, 0, 0],\n",
       "         [2, 1, 3, 0, 0, 0]]),\n",
       " 'leng_mask': tensor([[False, False, False, False, False, False],\n",
       "         [False, False, False, False,  True,  True],\n",
       "         [False, False, False,  True,  True,  True]]),\n",
       " 'leng': tensor([6, 4, 3]),\n",
       " 'psn_idx': tensor([[1, 2, 3, 4, 5, 6],\n",
       "         [1, 2, 3, 4, 0, 0],\n",
       "         [1, 2, 3, 0, 0, 0]])}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Layer2Holder['EC:Diag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8dbeeb54-4aa5-4947-8d72-6ba9567b3cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding_size': 512, 'init': 'random', 'input_size': 5001}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_size = 512\n",
    "vocab_size = 5000\n",
    "\n",
    "embed_para =  {'embedding_size': embed_size,\n",
    "               'init': 'random', \n",
    "               'input_size': vocab_size + 1 } # 1:the size of special tokens\n",
    "embed_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f877e4d8-fcd2-41fe-a59d-71afa84765c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_psn_embed_para(layername, embed_size):\n",
    "    \n",
    "    if 'Grn' not in layername: \n",
    "        vocab_size = 100\n",
    "    else:\n",
    "        vocab_size = 512\n",
    "        \n",
    "    embed_para = {'embedding_size': embed_size,\n",
    "                  'init': 'random', \n",
    "                  'input_size': vocab_size + 1 }\n",
    "    return embed_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ba04c59f-9794-4410-a8c7-86016b00d3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-P-EC:Diag-DiagRec:DiagV-DiagVdftGrn': {'embedding_size': 512,\n",
       "  'init': 'random',\n",
       "  'input_size': 5001},\n",
       " 'DiagVdftGrn_psn': {'embedding_size': 512,\n",
       "  'init': 'random',\n",
       "  'input_size': 513},\n",
       " 'DiagRec:DiagV_psn': {'embedding_size': 512,\n",
       "  'init': 'random',\n",
       "  'input_size': 101},\n",
       " 'EC:Diag_psn': {'embedding_size': 512, 'init': 'random', 'input_size': 101}}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {}\n",
    "d[fullname] = embed_para\n",
    "\n",
    "\n",
    "\n",
    "psn_layers = [i for i in Layer2Holder]\n",
    "\n",
    "for layername in psn_layers:\n",
    "    if layername == 'P': break\n",
    "    embed_para = generate_psn_embed_para(layername, embed_size)\n",
    "    d[f'{layername}_psn'] = generate_psn_embed_para(layername, embed_size)\n",
    "    \n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "048332fb-6c14-401a-8886-49e1400b28f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P-EC:Diag-DiagRec:DiagV-DiagVdftGrn\n",
      "{'embedding_size': 512, 'init': 'random', 'input_size': 5001}\n",
      "DiagVdftGrn_psn\n",
      "{'embedding_size': 512, 'init': 'random', 'input_size': 513}\n",
      "DiagRec:DiagV_psn\n",
      "{'embedding_size': 512, 'init': 'random', 'input_size': 101}\n",
      "EC:Diag_psn\n",
      "{'embedding_size': 512, 'init': 'random', 'input_size': 101}\n"
     ]
    }
   ],
   "source": [
    "for nn_name, layer_para in d.items():\n",
    "    print(nn_name)\n",
    "    print(layer_para)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e9c31a-8e65-41a1-ba35-9db4d56cf9d4",
   "metadata": {},
   "source": [
    "## Usage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1d27962a-d6d3-4d44-80f5-09bf341447fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-P-EC:Diag-DiagRec:DiagV-DiagVdftGrn': EmbeddingLayer(\n",
       "   (embedding): Embedding(5001, 512, padding_idx=0)\n",
       " ),\n",
       " 'DiagVdftGrn_psn': EmbeddingLayer(\n",
       "   (embedding): Embedding(513, 512, padding_idx=0)\n",
       " ),\n",
       " 'DiagRec:DiagV_psn': EmbeddingLayer(\n",
       "   (embedding): Embedding(101, 512, padding_idx=0)\n",
       " ),\n",
       " 'EC:Diag_psn': EmbeddingLayer(\n",
       "   (embedding): Embedding(101, 512, padding_idx=0)\n",
       " )}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_Dict = {}\n",
    "\n",
    "for nn_name, layer_para in d.items():\n",
    "    layer = EmbeddingLayer(**layer_para)\n",
    "    NN_Dict[nn_name] = layer\n",
    "    \n",
    "NN_Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e0616728-fd99-4536-81f4-bc21a9820636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1 --> (3,)\n",
      "2 --> (3, 6)\n",
      "2\n",
      "2 --> (3, 6)\n",
      "3 --> (3, 6, 1)\n",
      "3\n",
      "3 --> (3, 6, 1)\n",
      "4 --> (3, 6, 1, 6)\n",
      "(3, 6, 1, 6)\n",
      "torch.Size([3, 6, 1, 6])\n",
      "DiagVdftGrn\n",
      "DiagRec:DiagV\n",
      "EC:Diag\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "########################\n",
    "B_lenP = 3\n",
    "B2P_lnEC = [6, 4, 3] # \n",
    "prefix_layers_num = 2\n",
    "vocab_size = 100\n",
    "########################\n",
    "\n",
    "fullname = 'B-P-EC:Diag-DiagRec:DiagV-DiagVdftGrn'\n",
    "# fullname = 'B2St2TkSlfGrn'\n",
    "layer2layeridx = {v:idx for idx, v in enumerate(fullname.split('2'))}\n",
    "name = fullname.split('-')[-1]\n",
    "\n",
    "data = get_simulated_tensor_from_fldname(fullname, B_lenP, B2P_lnEC, prefix_layers_num, vocab_size)\n",
    "print(data.shape)\n",
    "# fld_tensor_idx\n",
    "\n",
    "\n",
    "info_idx = torch.LongTensor(data)\n",
    "print(info_idx.shape)\n",
    "holder = info_idx\n",
    "# grn_leng_mask = info_idx == 0\n",
    "# print(grn_leng_mask.shape)\n",
    "\n",
    "Layer2Holder = get_Layer2Holder(fullname, holder)\n",
    "for i in Layer2Holder: print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b12ed771-69e2-447f-b899-8c205a4ac9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingLayer(\n",
       "  (embedding): Embedding(5001, 512, padding_idx=0)\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embed\n",
    "Embed = NN_Dict[fullname]\n",
    "Embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e87e0bf7-be84-4a02-9d00-b1e30fd55ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 6, 1, 6, 512])\n"
     ]
    }
   ],
   "source": [
    "info = Embed(info_idx)\n",
    "# tensor_name = tensor_name.replace('_idx', '2Feat_flt')\n",
    "print(info.shape)\n",
    "# print(tensor_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3d5310dd-6982-4346-9e80-69a61e22ef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor_name.replace('_idx', '2Feat_flt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e2efc1-c2d7-4add-a485-cb7f64e94f9e",
   "metadata": {},
   "source": [
    "# Transformer (Learner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e179734-2f05-4220-b842-e7331d946abe",
   "metadata": {},
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4502f140-697c-412e-9709-17f5bc719339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TFMLayer(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_size = 512, \n",
    "                 output_size = 512, # d_model\n",
    "                 nhead = 8,\n",
    "                 num_encoder_layers = 6, # only have encoder part\n",
    "                 num_decoder_layers = 0, # in default, we don't need decoder part. \n",
    "                 dim_feedforward = 2048, \n",
    "                 tfm_dropout = 0.1,\n",
    "                 tfm_activation = 'relu'):\n",
    "        \n",
    "        '''https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/transformer.py'''\n",
    "\n",
    "        super(TFMLayer,self).__init__()\n",
    "        self.num_encoder_layers = num_encoder_layers\n",
    "        self.num_decoder_layers = num_decoder_layers\n",
    "        self.input_size = input_size\n",
    "        self.tfm_input_size = input_size\n",
    "        self.n_directions = 1\n",
    "        self.output_size = output_size\n",
    "        assert output_size % self.n_directions == 0 \n",
    "        self.hidden_size = int(output_size / self.n_directions)\n",
    "        assert self.hidden_size == self.tfm_input_size\n",
    "            \n",
    "        self.transformer  = torch.nn.Transformer(d_model = self.hidden_size, \n",
    "                                                 nhead = nhead,\n",
    "                                                 num_encoder_layers = self.num_encoder_layers,\n",
    "                                                 num_decoder_layers = self.num_decoder_layers,\n",
    "                                                 dim_feedforward = dim_feedforward, \n",
    "                                                 dropout = tfm_dropout,\n",
    "                                                 activation = tfm_activation,\n",
    "                                                 batch_first = True,\n",
    "                                                 # src_mask_flag = False, # see all tokens in a sentence \n",
    "                                                 # # This IS THE NEW PART. NOT PyTorch.nn.\n",
    "                                                 ) \n",
    "        # self.postprocess = []\n",
    "        # for method, use_config in postprecess.items():\n",
    "        #     use, config = use_config\n",
    "        #     if use == False: continue\n",
    "        #     if method == 'activator':\n",
    "        #         activator = config\n",
    "        #         if activator.lower() == 'relu': \n",
    "        #             self.activator = F.relu\n",
    "        #         elif activator.lower() == 'tanh': \n",
    "        #             self.activator = F.tanh\n",
    "        #         elif activator.lower() == 'gelu':\n",
    "        #             self.activator = F.gelu\n",
    "        #         else:\n",
    "        #             self.activator = lambda x: x\n",
    "        #         self.postprocess.append(self.activator)\n",
    "            \n",
    "        #     if method == 'dropout':\n",
    "        #         self.drop = torch.nn.Dropout(**config)\n",
    "        #         self.postprocess.append(self.drop)\n",
    "                \n",
    "        #     elif method == 'layernorm':\n",
    "        #         self.layernorm = torch.nn.LayerNorm(self.output_size, **config)\n",
    "        #         self.postprocess.append(self.layernorm)\n",
    "\n",
    "\n",
    "    def forward(self, info, leng_mask):\n",
    "        info = self.transformer(info, info, src_key_padding_mask = leng_mask,  tgt_key_padding_mask  = leng_mask)\n",
    "        # for layer in self.postprocess:\n",
    "        #     info = layer(info)\n",
    "        return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a0a55c-ce55-411d-ab7d-058e2f5d3dbd",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "df7319aa-ed3f-4d76-8dd6-ca0db4c14fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_size': 512,\n",
       " 'output_size': 512,\n",
       " 'nhead': 8,\n",
       " 'num_encoder_layers': 6,\n",
       " 'num_decoder_layers': 0,\n",
       " 'dim_feedforward': 2048,\n",
       " 'tfm_dropout': 0.1,\n",
       " 'tfm_activation': 'relu'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_para =  {'input_size': 512,\n",
    "             'output_size': 512,\n",
    "             'nhead': 8,\n",
    "             'num_encoder_layers': 6,\n",
    "             'num_decoder_layers': 0,\n",
    "             'dim_feedforward': 2048,\n",
    "             'tfm_dropout': 0.1,\n",
    "             'tfm_activation': 'relu'}\n",
    "tfm_para"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ee79c2-a9c3-4282-93d8-8ad6737485a1",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "803f5e37-6389-4280-933c-89bf734b48ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFMLayer(\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList()\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_layer = TFMLayer(**tfm_para)\n",
    "tfm_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c8c6aaaf-ffdd-48a6-b708-19b66d5d9dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-P-EC:Diag-DiagRec:V-VdftGrn\n",
      "B-P-EC:Diag-DiagRec:V-VdftGrn_idx\n",
      "torch.Size([3, 6, 1, 6])\n",
      "torch.Size([3, 6, 1, 6, 512])\n",
      "B-P-EC:Diag-DiagRec:V-VdftGrn2Feat_flt\n"
     ]
    }
   ],
   "source": [
    "print(fld_name)\n",
    "tensor_name = fld_name + '_idx'\n",
    "print(tensor_name)\n",
    "print(info_idx.shape)\n",
    "info = Embed(info_idx)\n",
    "tensor_name = tensor_name.replace('_idx', '2Feat_flt')\n",
    "print(info.shape)\n",
    "print(tensor_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9d94b742-2dd4-4c8e-b267-15049186be5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 6, 1, 6])\n",
      "torch.Size([3, 6, 1, 6, 512])\n",
      "torch.Size([3, 6, 1, 6])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(info_idx.shape)\n",
    "leng_mask = info_idx == 0\n",
    "print(info.shape)\n",
    "print(leng_mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95c64af-93c2-4847-9524-d22dfd7ff2b6",
   "metadata": {},
   "source": [
    "### Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "09298b82-285d-4a21-ad72-cc2fbd8c87f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 6 512\n",
      "torch.Size([18, 6, 512])\n",
      "torch.Size([18, 6])\n",
      "torch.Size([18])\n"
     ]
    }
   ],
   "source": [
    "nbs = np.array(info.shape[:-2]).prod()\n",
    "ngrn, dim = info.shape[-2:]\n",
    "print(nbs, ngrn, dim)\n",
    "\n",
    "\n",
    "tmp_info = info.contiguous().view(nbs, ngrn, dim)\n",
    "print(tmp_info.shape)\n",
    "\n",
    "tmp_leng_mask = leng_mask.contiguous().view(nbs, ngrn)\n",
    "print(tmp_leng_mask.shape)\n",
    "\n",
    "tmp_leng = (tmp_leng_mask == 0).sum(-1)\n",
    "print(tmp_leng.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "48947be8-20b4-460c-b140-31af3af45cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# order sequences and restore sequences according to their lenghts\n",
    "# TODO: test the speed of orderSeq and restoreSeq\n",
    "\n",
    "def orderSeq(seq_unordered, leng_unordered):\n",
    "    # leng_unordered is a tensor\n",
    "    # seq_unordered is a numpy\n",
    "    leng_ordered, seq_index = leng_unordered.sort(descending=True) \n",
    "    _, reverse_index = seq_index.sort()\n",
    "    leng_ordered = leng_ordered[leng_ordered>0]\n",
    "    seq_index    = seq_index[:len(leng_ordered)]\n",
    "    seq_ordered  = seq_unordered[seq_index.cpu()]\n",
    "    return seq_ordered, leng_ordered, reverse_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6c29c883-44dd-49d6-bf11-dc60e2f8c3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 6, 512])\n",
      "torch.Size([13, 6, 512])\n",
      "torch.Size([13])\n",
      "torch.Size([18])\n",
      "tensor([6, 6, 6, 5, 4, 4, 3, 3, 3, 3, 2, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "tmp_info = info.contiguous().view(nbs, ngrn, dim)\n",
    "print(tmp_info.shape)\n",
    "\n",
    "ord_info,      ord_leng, r_idx = orderSeq(tmp_info, tmp_leng)\n",
    "ord_leng_mask, ord_leng, r_idx = orderSeq(tmp_leng_mask, tmp_leng)\n",
    "print(ord_info.shape)\n",
    "print(ord_leng.shape)\n",
    "print(r_idx.shape)\n",
    "print(ord_leng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6f04a0a8-4e3f-4fdc-9ca6-9e2fe8773df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 6])\n",
      "torch.Size([13, 6])\n",
      "torch.Size([13])\n",
      "torch.Size([18])\n",
      "tensor([6, 6, 6, 5, 4, 4, 3, 3, 3, 3, 2, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "print(tmp_leng_mask.shape)\n",
    "ord_leng_mask, ord_leng, r_idx = orderSeq(tmp_leng_mask, tmp_leng)\n",
    "print(ord_leng_mask.shape)\n",
    "print(ord_leng.shape)\n",
    "print(r_idx.shape)\n",
    "print(ord_leng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce6d15a-edbc-408c-be52-92d08eaf6069",
   "metadata": {},
   "source": [
    "### Calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "180ec929-b20b-4b8d-8aed-2d5d39975bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 6, 512])\n"
     ]
    }
   ],
   "source": [
    "ord_info_output = tfm_layer(ord_info, ord_leng_mask)\n",
    "print(ord_info_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce140a9-1cd8-4c58-a05a-7e62b0fe1407",
   "metadata": {},
   "source": [
    "### Restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "685e4ec6-d06f-4ae8-a0ec-796732b1a4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restoreSeq(seq_ordered, reverse_index):\n",
    "    # shape = list(seq_ordered.shape)\n",
    "    data_type = seq_ordered.type()\n",
    "    shape = list(seq_ordered.shape)\n",
    "    shape[0] = len(reverse_index) - shape[0]\n",
    "    t = torch.cat([seq_ordered, torch.zeros(shape).type(data_type)])\n",
    "    seq_restored = t[reverse_index]\n",
    "    return seq_restored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a6c3be77-0194-4a9d-8052-9d312405daed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 6, 512])\n"
     ]
    }
   ],
   "source": [
    "info_new = restoreSeq(ord_info_output, r_idx)\n",
    "print(info_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "90c17ba4-03cd-4ff0-83a7-876f899a9e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 6, 1, 6, 512])\n"
     ]
    }
   ],
   "source": [
    "output_size = dim\n",
    "info_output = info_new.view(*list(leng_mask.shape) + [output_size])\n",
    "print(info_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3bf4fad8-a610-47a6-815d-bfd82c2e40bf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.4219, -0.1160, -0.5974,  0.4538, -0.4686,  1.8094]],\n",
       "\n",
       "         [[ 0.9934,  0.3924,  0.2562,  1.4032,  0.3456,  1.4251]],\n",
       "\n",
       "         [[ 0.3973,  0.2109, -0.8690,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.3130, -0.0413, -0.7882,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[-1.4392,  0.3513,  0.7602,  0.0945, -0.2210,  0.0000]],\n",
       "\n",
       "         [[ 2.4675,  1.4251, -0.6225, -0.0158,  1.5988,  0.5250]]],\n",
       "\n",
       "\n",
       "        [[[ 0.8921, -0.7882,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.3973, -0.0158, -0.8690,  0.1951,  0.0000,  0.0000]],\n",
       "\n",
       "         [[-0.6225,  0.4470,  0.3456,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[-0.3868,  0.1158,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 1.5988, -0.0158,  0.4735, -0.7329,  0.0000,  0.0000]],\n",
       "\n",
       "         [[-0.6603, -0.0467, -0.7141,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 1.4032,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_output[:,:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "17c872ad-09f1-4b92-af98-1bb8749e5e3e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[False, False, False, False, False, False]],\n",
       "\n",
       "         [[False, False, False, False, False, False]],\n",
       "\n",
       "         [[False, False, False,  True,  True,  True]],\n",
       "\n",
       "         [[False, False, False,  True,  True,  True]],\n",
       "\n",
       "         [[False, False, False, False, False,  True]],\n",
       "\n",
       "         [[False, False, False, False, False, False]]],\n",
       "\n",
       "\n",
       "        [[[False, False,  True,  True,  True,  True]],\n",
       "\n",
       "         [[False, False, False, False,  True,  True]],\n",
       "\n",
       "         [[False, False, False,  True,  True,  True]],\n",
       "\n",
       "         [[False, False,  True,  True,  True,  True]],\n",
       "\n",
       "         [[ True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[ True,  True,  True,  True,  True,  True]]],\n",
       "\n",
       "\n",
       "        [[[False, False, False, False,  True,  True]],\n",
       "\n",
       "         [[False, False, False,  True,  True,  True]],\n",
       "\n",
       "         [[False,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[ True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[ True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "         [[ True,  True,  True,  True,  True,  True]]]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leng_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bbb706-d953-4244-ad79-a5a5670ab8e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771a158a-1c01-47f9-9a58-77092d451c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
